{"searchDocs":[{"title":"Version 1.0.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-0-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.0.0","url":"/preview-docs/changelog/v1-0-0#new-features","content":" Volume Configuration: You can now configure volumes in project environments directly from the form.Nightly Shutdown with Timezone: Added support for selecting time zones in the nightly shutdown.Manual Cluster Startup: New button to manually start clusters.CloudFront Integration: Support for using CloudFront to improve content delivery.Automatic Backups: You can configure automatic backups for dependencies.Graviton Instances: Support for using Graviton instances on nodes.Encryption: Implemented encryption in StackSettings for added security.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.0.0","url":"/preview-docs/changelog/v1-0-0#bug-fixes","content":" Resolved an issue in the billing API and cost estimation.Fixed errors when deleting Providers and VPNs.You can now delete ACM certificates used by a Load Balancer without problems. ","version":null,"tagName":"h2"},{"title":"Test2","type":0,"sectionRef":"#","url":"/preview-docs/changelog/Testset-dasd-sad-","content":"SADdasd","keywords":"","version":null},{"title":"Test","type":0,"sectionRef":"#","url":"/preview-docs/changelog/testset-test","content":"Test","keywords":"","version":null},{"title":"Version 1.0.1","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-0-1","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.0.1","url":"/preview-docs/changelog/v1-0-1#new-features","content":" Subscription Management: Login and token updates are controlled based on the subscription status. Additionally, a new API was implemented to register users and companies, validating pending subscriptions, with a new model to better manage subscriptions, integrating AwsClient.Marketplace Onboarding: Simplified process for creating users who come from a marketplace. ","version":null,"tagName":"h2"},{"title":"Version 1.0.2","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-0-2","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.0.2","url":"/preview-docs/changelog/v1-0-2#new-features","content":" Deployment Optimization: Simplified the deployment process and project environment (ProjectEnv) editing, facilitating configuration and deployment.Resource and Configuration Adjustments: You can now create custom aliases for buckets.Health Check Improvements: The readiness probe for services in the development account is now optional.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.0.2","url":"/preview-docs/changelog/v1-0-2#bug-fixes","content":" Solved issues related to VPN and security parameter configuration. ","version":null,"tagName":"h2"},{"title":"Version 1.0.3","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-0-3","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.0.3","url":"/preview-docs/changelog/v1-0-3#new-features","content":" Management Buttons and Form Improvements: Added buttons for resource management and improved variable mapping forms.Cronjobs and Domain Regeneration: You can now stop or activate cronjobs and regenerate domains.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.0.3","url":"/preview-docs/changelog/v1-0-3#bug-fixes","content":" Solved the issue of obtaining the VPN URI in Pritunl.Fixed the account selection issue for viewer users.Improved the handling of health check information sent to the backend. ","version":null,"tagName":"h2"},{"title":"Version 1.0.4","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-0-4","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.0.4","url":"/preview-docs/changelog/v1-0-4#new-features","content":" Refactoring and Improvements: Refactored the dashboard and improved log visualization and the management of entity deletion.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.0.4","url":"/preview-docs/changelog/v1-0-4#bug-fixes","content":" Fixed user editing issues.Corrected cluster state management.Solved problems with environment domains.Fixed error handling in S3 responses with CloudFront. ","version":null,"tagName":"h2"},{"title":"Version 1.1.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-1-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.1.0","url":"/preview-docs/changelog/v1-1-0#new-features","content":" Vargroups Management: Added the option to show vargroups in the forms for services, workers, hooks, and cronjobs.Kubecost: Integrated Kubecost with Prometheus-stack.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.1.0","url":"/preview-docs/changelog/v1-1-0#bug-fixes","content":" Solved the issue with Karpenter on spot instances.Fixed user roles and user editing.Corrected problems when deleting an environment and the incorrect deletion of domains.Fixed the error when trying to manually start the cluster.Resolved an error in generating hooks. ","version":null,"tagName":"h2"},{"title":"Version 1.0.5","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-0-5","content":"","keywords":"","version":null},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.0.5","url":"/preview-docs/changelog/v1-0-5#bug-fixes","content":" Solved deployment issues and fixed Karpenter with spot instances.Fixed issues in deleting entities and validating service URLs. ","version":null,"tagName":"h2"},{"title":"Version 1.1.1","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-1-1","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.1.1","url":"/preview-docs/changelog/v1-1-1#new-features","content":" Log Viewer in Jobs: Added a log viewer in the job list, similar to what already exists for deployments.Dashboard v2: Improvements in the second version of the Dashboard, with more options and better organization of information.Cluster Certificates: Cluster certificates are now automatically deleted and updated to prevent expiration issues. ","version":null,"tagName":"h2"},{"title":"Version 1.2.1","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-2-1","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.2.1","url":"/preview-docs/changelog/v1-2-1#new-features","content":" Vargroup Form Optimization: Usability improvements have been made to the Vargroup forms.Provider and User Account Deletion: Deleting a provider now also deletes associated user accounts.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.2.1","url":"/preview-docs/changelog/v1-2-1#bug-fixes","content":" A bug in ACM certificate regeneration has been fixed.A provider deletion issue has been corrected. ","version":null,"tagName":"h2"},{"title":"Version 1.2.2","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-2-2","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.2.2","url":"/preview-docs/changelog/v1-2-2#new-features","content":" Domain Validation Button: A &quot;check validation&quot; button has been added to the domain drawer for easier domain management.Activity Log Table: An activity log table has been created.Access Key Encryption: Access keys for code version providers (GIT) are now encrypted.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.2.2","url":"/preview-docs/changelog/v1-2-2#bug-fixes","content":" An issue where the API didn't correctly recreate the ACM module during regeneration has been fixed. ","version":null,"tagName":"h2"},{"title":"Version 1.2.3","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-2-3","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.2.3","url":"/preview-docs/changelog/v1-2-3#new-features","content":" Alias Decoupling in Web Services: The creation of aliases is now separated from the web services form.IAM Password Reset: It is now possible to reset the IAM password for a user.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.2.3","url":"/preview-docs/changelog/v1-2-3#bug-fixes","content":" A minor issue with release tasks has been corrected. ","version":null,"tagName":"h2"},{"title":"Version 1.2.4","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-2-4","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.2.4","url":"/preview-docs/changelog/v1-2-4#new-features","content":" Cluster Switcher Optimization: Cluster selector behavior has been optimized.Login in AWS Subscription Flow: The AWS subscription flow now includes the ability to log in directly.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.2.4","url":"/preview-docs/changelog/v1-2-4#bug-fixes","content":" Callback issues for Git integrations and Docker file path for GitLab have been resolved.Minor billing screen-related bugs have been fixed. ","version":null,"tagName":"h2"},{"title":"Version 1.2.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-2-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.2.0","url":"/preview-docs/changelog/v1-2-0#new-features","content":" Logs in Grafana: A data source has been configured in Grafana to display logs from S3.Cluster Update Button: A button has been added to allow cluster updates from the interface.User Activity Log: An activity log for user actions has been created.Domain Validation Deploy: You can now create a deploy that runs once domains are validated.Two-Factor Authentication: Two-factor authentication (2FA) has been added to the login for enhanced security.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.2.0","url":"/preview-docs/changelog/v1-2-0#bug-fixes","content":" An issue with builds using the same branch as the default has been fixed.Log reading has been improved for faster processing.Various frontend optimizations, including styles, search, and pending resource visibility, have been made. ","version":null,"tagName":"h2"},{"title":"Version 1.4.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-4-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.4.0","url":"/preview-docs/changelog/v1-4-0#new-features","content":" Grafana Configuration: The database for the Grafana addon was configured, along with DataSources and Dashboards.Prometheus Metrics Persistence with Thanos: Added support for persisting Prometheus metrics using Thanos.New Volume API: Implemented support for the new volume API, displaying statuses and applying configuration for deployments.The update option in addons has been disabled.Now, when a dependency is deleted, a deploy with &quot;pending-approval&quot; will be created instead of an automatic one.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.4.0","url":"/preview-docs/changelog/v1-4-0#bug-fixes","content":" Fixed an issue where pre-hooks and new volumes were added during deploys, preventing them from being generated.Subdomains are now correctly marked as delegated if the parent domains are already delegated. ","version":null,"tagName":"h2"},{"title":"Version 1.3.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-3-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.3.0","url":"/preview-docs/changelog/v1-3-0#new-features","content":" Project Details View: A detailed project view is now available in the new interface.RDS Metrics API: A new API for displaying RDS metrics has been added, improving resource visibility.Improved LogViewer: LogViewer loading is now faster and more efficient.Enhanced Onboarding: A new onboarding process has been implemented for easier setup.Redis Monitoring: Redis monitoring has been added, improving infrastructure supervision.RDS Replica Configuration: The option to configure replicas in the RDS Dependency has been added for more flexibility.Domain Deletion Status: Domain deletion now creates a deploy with pending-approval status, rather than an automatic deploy.Job Workload Improvements: Job workload has been improved, allowing automatic retries in case of an initial failure.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.3.0","url":"/preview-docs/changelog/v1-3-0#bug-fixes","content":" Bitbucket integration issues have been resolved.Undefined value issues in Vargroups have been fixed. ","version":null,"tagName":"h2"},{"title":"Version 1.4.1","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-4-1","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.4.1","url":"/preview-docs/changelog/v1-4-1#new-features","content":" Dependency and OpenSearch Monitoring: A new monitoring page was created for dependencies, facilitating the tracking of their status. OpenSearch was included.ECR Lifecycle Policy: A lifecycle policy was configured for ECR, improving image management.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.4.1","url":"/preview-docs/changelog/v1-4-1#bug-fixes","content":" Fixed the issue of duplicate names between cluster and node in Redis.Resolved various frontend errors that affected the user experience.Fixed the problem where an error was displayed when attempting to publish a vargroup without an associated service.Issues with performing multiple deployments and releases in a row were fixed. ","version":null,"tagName":"h2"},{"title":"Version 1.5.1","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-5-1","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.5.1","url":"/preview-docs/changelog/v1-5-1#new-features","content":" Advanced Resource Configuration: Advanced options for resource configuration in project environments have been implemented.Optimization of Data Collection Scripts: Improved the efficiency of data collection scripts for faster workload.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.5.1","url":"/preview-docs/changelog/v1-5-1#bug-fixes","content":" Several interface errors affecting system usability have been resolved. ","version":null,"tagName":"h2"},{"title":"Version 1.4.2","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-4-2","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.4.2","url":"/preview-docs/changelog/v1-4-2#new-features","content":" New Metrics: Added new metrics for S3 buckets and RabbitMQ, improving service monitoring. An OpenSearch metrics monitoring system was also implemented.Monitoring Schema Reorganization: Monitoring schema structures were reorganized for better management and visualization. The Dependencies monitoring screen now supports different resource types, providing a more detailed view.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.4.2","url":"/preview-docs/changelog/v1-4-2#bug-fixes","content":" A critical issue with vargroups was resolved, ensuring their proper functioning. ","version":null,"tagName":"h2"},{"title":"Version 1.4.3","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-4-3","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.4.3","url":"/preview-docs/changelog/v1-4-3#new-features","content":" Dashboard Management Improvements: Dashboard loading was improved, allowing it to be viewed even if no account is selected.Billing and Project Screen Improvements: Improvements to the billing screen were made, including a new &quot;others&quot; section to account for previously unconsidered costs. The project environment screen was also improved.Policy Updates: CloudFormation policy has been updated to enhance management and security.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.4.3","url":"/preview-docs/changelog/v1-4-3#bug-fixes","content":" Fixed a critical error that prevented the creation of providers.Reviewed and resolved an issue related to NewRelic integration.Fixed a problem with the refresh token when requesting the VPN URI.ACM Validation Screen and Build Logs Errors: Corrections made to the ACM validation table and logs display for builds in creation state. ","version":null,"tagName":"h2"},{"title":"Version 1.5.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-5-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.5.0","url":"/preview-docs/changelog/v1-5-0#new-features","content":" Multiple Project Environments Creation: You can now create multiple project environments using the same repository and branch.Domain Validation for Aliases: Improved domain creation validation for aliases by using an existing usable ACM for ingress.Resource Configuration in Project Env: Added the ability to configure build and deploy resources per project environment.Deploy and Build Request Configuration: Added the option to configure deploy and build requests in a ProjectEnv.Grafana Dashboard: A Grafana dashboard was incorporated to visualize consumption by namespace.Loki Configuration: Logs can now be searched by namespace with the new Loki configuration.Data Collection: Improved the billing collection script to be idempotent and executable for specific dates.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.5.0","url":"/preview-docs/changelog/v1-5-0#bug-fixes","content":" Fixed an error when creating S3 dependencies and solved a critical problem with vargroups during cluster shutdown updates.Fixed a critical error when inviting collaborators. ","version":null,"tagName":"h2"},{"title":"Version 1.6.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-6-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.6.0","url":"/preview-docs/changelog/v1-6-0#new-features","content":" Support for ARM Instances and Additional RDS Versions: Added ARM instances and extra versions in RDS.EKS Updated to Version 1.29: EKS has been updated to version 1.29. Changelogs for EKS updates are now displayed.Improvements in Provider Creation and Editing: Screens and fields for provider forms were updated, including changes in states and visual display.Improved Repository Search: Added support for asynchronous search in the repository selector and enhanced the search function for GitHub, GitLab, and Bitbucket.Healthcheck Parameterization: Healthcheck properties can now be parameterized with JSONSchema.New Dashboard: A new dashboard has been added to view consumption by namespace.Fixed an error when regenerating certificates, as well as issues with builds not running properly.Frontend errors related to listing and API problems that caused filtering errors have been corrected.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.6.0","url":"/preview-docs/changelog/v1-6-0#bug-fixes","content":" Fixed an error when regenerating certificates, as well as issues with builds not running properly.Frontend errors related to listing and API problems that caused filtering errors have been corrected. ","version":null,"tagName":"h2"},{"title":"Version 1.6.2","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-6-2","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.6.2","url":"/preview-docs/changelog/v1-6-2#new-features","content":" Upgrades: Updated Prometheus, Loki, and EBS CSI Driver to the latest versions as of August 2024.EBS CSI Driver Migration: SleakOps now uses the AWS-managed EKS Addon for the EBS CSI Driver, replacing the self-managed version.Prometheus and Loki with EBS: Prometheus now utilizes EBS volumes for data persistence, preventing data loss even if the pods crash.Loki with SimpleScalable: It adopts a SimpleScalable structure with TSDB storage for logs, enhancing performance.SQS Dead-letter Queues: Now supports the creation of SQS queues with associated dead-letter queues for improved error handling.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.6.2","url":"/preview-docs/changelog/v1-6-2#bug-fixes","content":" Various minor bug fixes and improvements to the platform's workload flows. ","version":null,"tagName":"h2"},{"title":"Version 1.6.1","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-6-1","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.6.1","url":"/preview-docs/changelog/v1-6-1#new-features","content":" Dependency Version Updates: Updated versions of MQ, Elasticsearch, Memcache, and Redis dependencies.Authentication Improvements: Added support for storing authentication tokens via cookies instead of local storage.Added ACM validation record printing on the ACM detail screen, and ACM status is now included in the system.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.6.1","url":"/preview-docs/changelog/v1-6-1#bug-fixes","content":" Issues with the provider flow have been resolved. ","version":null,"tagName":"h2"},{"title":"Version 1.6.3","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-6-3","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.6.3","url":"/preview-docs/changelog/v1-6-3#new-features","content":" Registration: Implemented a new registration flow.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.6.3","url":"/preview-docs/changelog/v1-6-3#bug-fixes","content":" Various minor bug fixes and improvements. ","version":null,"tagName":"h2"},{"title":"Version 1.7.1","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-1","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.1","url":"/preview-docs/changelog/v1-7-1#new-features","content":" Environment and Domain Creation: Improved the process for creating environments and domains. You can now use a different domain than the one configured globally without any limitations.Notifications: Added a notification system to inform users about pending manual actions and scheduled infrastructure updates.Documentation: Updated documentation on managing domains, projects, dependencies, and environment variables.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.1","url":"/preview-docs/changelog/v1-7-1#bug-fixes","content":" Various minor bug fixes. ","version":null,"tagName":"h2"},{"title":"Version 1.7.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.0","url":"/preview-docs/changelog/v1-7-0#new-features","content":" Advanced Node Management: Introduced node pool management to provide greater control over the types of nodes where workloads are executed.Cluster Module Migration: All modules created with the cluster now run on Graviton instances, enhancing performance and reducing costs.Cluster Add-ons: All add-ons now run on Graviton instances, further improving performance and lowering costs.Isolated Build Nodes: Builds are now executed on dedicated nodes separate from the application nodes, improving the stability of the nodes running applications.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.0","url":"/preview-docs/changelog/v1-7-0#bug-fixes","content":" Various minor bug fixes. ","version":null,"tagName":"h2"},{"title":"Version 1.7.10","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-10","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.10","url":"/preview-docs/changelog/v1-7-10#new-features","content":" Enhanced Permission Control: Projects can now have additional associated permissions, whether they are AWS IAM Policies or custom permissions.Dependency Details: The configuration details of each dependency are now displayed within its detail view.Cluster Update Screen Improvements: EKS Insights analysis is now included directly in SleakOps to streamline cluster updates.Build &amp; Project Enhancements: Additional information during builds and improved project validation workflows.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.10","url":"/preview-docs/changelog/v1-7-10#bug-fixes","content":" Improved Text Input: Resolved issues affecting text inputs in forms.Cluster Access Data: Fixed a bug when retrieving cluster connection data under a different selected account.Domain List Filters: Added filters by account to the domain listing.Nodepool List Improvements: Refined visuals for the nodepool list view.Add-on Installation Updates: The list of add-ons now refreshes properly after installation.Variable Group Editing: Fixed an issue with editing variable groups.Subscription Attachment: Addressed a bug that prevented new subscriptions from attaching correctly.Cost Forecast: Fixed forecasting issues for better cost estimations. ","version":null,"tagName":"h2"},{"title":"Version 1.7.11","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-11","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.11","url":"/preview-docs/changelog/v1-7-11#new-features","content":" Kubernetes 1.31 &amp; Karpenter 1.3: SleakOps now provisions clusters on EKS 1.31 and upgrades the autoscaler to Karpenter 1.3.Stronger Secret Management : All secrets are now also stored encrypted in AWS Systems Manager Parameter Store, adding an extra layer of durability beyond the in-cluster copy.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.11","url":"/preview-docs/changelog/v1-7-11#bug-fixes","content":" Dev-Cluster Workers: Removed the PodDisruptionBudge improving worker reliability in development clusters when the cluster had the scheduler shutdown enabled.Builds: Builds are no longer triggered for every minor project edit.Deployments: Switched deployments jobs away from Fargate; build logs are now persisted for easier troubleshooting.Web Service Details: Refined the service detail page for clearer visibility of endpoints, status, and metrics.Kubecost Add-on: Stability improvements ","version":null,"tagName":"h2"},{"title":"Version 1.7.12","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-12","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.12","url":"/preview-docs/changelog/v1-7-12#new-features","content":" New Support Flow: Introduced a support chatbot and ticketing system to provide better traceability and faster response times.Subscription &amp; Plan Management: Enhanced tools for managing subscriptions and service plans.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.12","url":"/preview-docs/changelog/v1-7-12#bug-fixes","content":" Form Improvements: General enhancements to form usability and validation.Project Console: UI/UX improvements in the project console screen. ","version":null,"tagName":"h2"},{"title":"Version 1.7.13","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-13","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.13","url":"/preview-docs/changelog/v1-7-13#new-features","content":" Dependency Monitoring: Improved visualization and tracking of dependencies.Service Control: New toggle to turn webservices and workers on or off.Builds with or without cache: Option to run builds using cache or from scratch.S3 Bucket Import with Versioning: Added support for importing S3 Buckets with active versioning.Variable Groups: Enhanced interface for managing variable groups.Dockerfile Validation: New validations to ensure reliability of Dockerfiles.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.13","url":"/preview-docs/changelog/v1-7-13#bug-fixes","content":" Job Logs: Fixed broken log links for Jobs.Branch Names: Added support for branches with / in their names.GitLab Pipelines: Fixed issues affecting pipeline execution. ","version":null,"tagName":"h2"},{"title":"Version 1.7.14","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-14","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.14","url":"/preview-docs/changelog/v1-7-14#new-features","content":" State Transition Improvements: Smoother state changes for cluster addons and forms.Support with Images: Users can now upload images in the support chat.Jobs from Cronjobs or Existing Jobs: Ability to launch a Job from an existing cronjob or Job.Infrastructure Errors: Improved parsing and display of infrastructure errors for easier troubleshooting.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.14","url":"/preview-docs/changelog/v1-7-14#bug-fixes","content":" Duplicate Volumes: Fixed issue when creating volumes with the same name.Duplicate Users: Prevented creation of users with the same email.Duplicate Dependencies: Blocked creation of dependencies with duplicate names.Dependency Monitoring: Fixed date range issues on the dependency monitoring screen. ","version":null,"tagName":"h2"},{"title":"Version 1.7.15","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-15","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.15","url":"/preview-docs/changelog/v1-7-15#new-features","content":" Nodegroup Spot Resilience: Spot nodegroups now prevent failures when no Spot instances are available.File-based VariableGroups: Added support for creating variablegroups of type file.Agent Bot (beta): Experimental agent bot released in beta.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.15","url":"/preview-docs/changelog/v1-7-15#bug-fixes","content":" Dependent domain configuration: Generate DNS records when parent domain already created.Cluster status with nightly shutdown: Fixed incorrect status display for clusters with nightly shutdown enabled.VariableGroups filters: Fiter by projects on variablegroups listDelete cluster: Fixed deletion cluster flow.Support ticket status: Fixed close support ticket status. ","version":null,"tagName":"h2"},{"title":"Version 1.7.16","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-16","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.16","url":"/preview-docs/changelog/v1-7-16#new-features","content":" Projects with Public Repositories: You can now create and manage projects linked to public repositories.Exclude Builds from Metrics: Builds can be excluded from the Grafana metrics dashboard for more accurate reporting.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.16","url":"/preview-docs/changelog/v1-7-16#bug-fixes","content":" New Project Deployments: Fixed issues preventing successful deployment of newly created projects. ","version":null,"tagName":"h2"},{"title":"Version 1.7.2","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-2","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.2","url":"/preview-docs/changelog/v1-7-2#new-features","content":" S3 Bucket Deletion: Introduced the ability to delete S3 buckets containing a large number of files.VPN: Updated the Pritunl module to the latest version for enhanced security and performance.Subscription Management Improvements: Enhanced the management of subscriptions for a better user experience.User Registration: Enabled the registration of new users to the platform.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.2","url":"/preview-docs/changelog/v1-7-2#bug-fixes","content":" Various minor bug fixes. ","version":null,"tagName":"h2"},{"title":"Version 1.7.4","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-4","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.4","url":"/preview-docs/changelog/v1-7-4#new-features","content":" Add-on Accessibility: Added links in SleakOps for easy access to view logs, APM, or metrics for specific resources.OpenTelemetry (Beta): Introduced an add-on to enhance observability in applications deployed with SleakOps. With OpenTelemetry, you can have your own APM to monitor metrics like request rate, latency, and error rate of your application.Add-on Availability Configurations: Added various availability settings for each add-on.Documentation: Updated the add-on documentation and made it available in Spanish.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.4","url":"/preview-docs/changelog/v1-7-4#bug-fixes","content":" Kubecost Integration Review: Reviewed the Prometheus-Kubecost integration. Kubecost now correctly maps the names of deployed resources to their costs, greatly improving the accuracy of its estimates. It's now possible to enable approximate network traffic cost analysis within the cluster in Kubecost (Beta). ","version":null,"tagName":"h2"},{"title":"Version 1.7.3","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-3","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.3","url":"/preview-docs/changelog/v1-7-3#new-features","content":" Oracle RDS Support (Beta): You can now manage Oracle RDS instances as dependencies within SleakOps.Aurora PostgreSQL Serverless Support (Beta): Added the ability to create and manage Aurora PostgreSQL Serverless databases.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.3","url":"/preview-docs/changelog/v1-7-3#bug-fixes","content":" Various minor bug fixes. ","version":null,"tagName":"h2"},{"title":"Version 1.7.6","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-6","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.6","url":"/preview-docs/changelog/v1-7-6#new-features","content":" New Nodepool Configurations: You can now set additional parameters, such as minimum instance sizes and more.Job with Specific Images: When creating a job, you can specify the exact image and tag you want to run (e.g., postgres:16.4).(BETA) Chart Extension by Project: SleakOps can now extend the charts used to deploy project workloads, allowing you to add dependencies. For more information, see the Helm documentation.CI/CD Improvements: The file for configuring CI/CD has been simplified and optimized.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.6","url":"/preview-docs/changelog/v1-7-6#bug-fixes","content":" Internal Web Service URL: Fixed an issue that caused incorrect URLs for “internal” type web services.Volume Deletion: Resolved problems related to volume deletion under various retention policies.UX/UI Enhancements: Improvements in the interface for Projects, Volumes, and Variable Groups. ","version":null,"tagName":"h2"},{"title":"Version 1.7.5","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-5","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.5","url":"/preview-docs/changelog/v1-7-5#new-features","content":" AWS Integration Error Handling:: Implemented a mechanism to handle delays in AWS account activations created by SleakOps.Add-on Links in Builds: Added links for easily viewing logs and metrics during the build process. ","version":null,"tagName":"h2"},{"title":"Version 1.7.7","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-7","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.7","url":"/preview-docs/changelog/v1-7-7#new-features","content":" Import from External Buckets: Quickly copy files from an external S3 Bucket into SleakOps via the new Import Bucket feature.Project View Overhaul: See logs and key info in a single screen for better visibility.Executions Renamed to Workloads: Updated terminology to align with internal cluster notation.Cluster Deletion Optimization: Added extra validation for a more secure and stable deletion process.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.7","url":"/preview-docs/changelog/v1-7-7#bug-fixes","content":" Project Permissions for Jobs: Fixed an issue where Jobs used cluster node permissions instead of Project permissions.Docker Args Modification: Builds now correctly apply any Docker Args changed just before they run.VPN Profile Generation: Resolved an issue preventing third-party user profiles from being generated successfully. ","version":null,"tagName":"h2"},{"title":"Version 1.7.8","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-8","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.8","url":"/preview-docs/changelog/v1-7-8#new-features","content":" Kubernetes 1.30: Updated EKS support to version 1.30.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.8","url":"/preview-docs/changelog/v1-7-8#bug-fixes","content":" Minor UI Enhancements: Improved the visual design for project and workload screens. ","version":null,"tagName":"h2"},{"title":"Version 1.7.9","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v1-7-9","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 1.7.9","url":"/preview-docs/changelog/v1-7-9#new-features","content":" Cronjob Enhancements: Configure cronjob policies and easily filter between active and inactive cronjobs.Support Emails on Notifications: When SleakOps generates a notification, users now receive it via email.EKS Insights: During cluster upgrades, SleakOps checks EKS Insights to ensure everything is running smoothly.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 1.7.9","url":"/preview-docs/changelog/v1-7-9#bug-fixes","content":" Project Flow Improvements: Enhanced various settings, forms, and other elements for smoother project management.AWS Account Creation Flow: Now supports inactive AWS accounts, providing clear guidance on how to manually activate them before resuming the process in SleakOps. ","version":null,"tagName":"h2"},{"title":"Version 2.0.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v2-0-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 2.0.0","url":"/preview-docs/changelog/v2-0-0#new-features","content":" Full Console Redesign: Modernized UI for a cleaner, more intuitive experience.Light Theme Support: Complete support for light mode.Support Bot: Automated responses for common support questions.Comprehensive Documentation: Expanded guides covering all features.Update lambdas: Update python versions for lambdas.Project Chart: Promoted to stable.Project Access: Promoted to stable.Dependency Aurora MySQL: Promoted to stable.Dependency Oracle: Promoted to stable.Dependency MariaDB: Promoted to stable.Dependency Aurora PostgreSQL: Promoted to stable.Dependency Editing: Ability to edit existing dependencies.Dockertron (beta): AI-powered automatic dockerization.Builds cancel: Could cancel pending builds.New MSK Dependency: Support for Kafka via AWS MSK.Enhanced Webservices: Configure custom ingress annotations and optional healthchecks.Advanced Nodepools: New fallback strategies and instance mix (reserved, spot, on-demand) for better cost and performance control.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 2.0.0","url":"/preview-docs/changelog/v2-0-0#bug-fixes","content":" GitLab self-hosted: Fixed URL validation.Cluster deletion: Improved cascading deletion handling. ","version":null,"tagName":"h2"},{"title":"Version 2.0.1","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v2-0-1","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 2.0.1","url":"/preview-docs/changelog/v2-0-1#new-features","content":" Builds and Deploys Table: Improvements to the data shown in the builds and deploys table.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 2.0.1","url":"/preview-docs/changelog/v2-0-1#bug-fixes","content":" Nightly Shutdown Cron: Fixed visualization of the nightly shutdown cron.Cluster Status: Fixed Cluster status update while updating.Long Notifications: Fixed visualization of long notifications.Third-Party VPN: Fixed VPN access for third parties.Deploy Cancellation: Fixed deploy cancellation flow.Provider Creation: Fixed text hierarchies in the Provider creation flow.Missing Information: Fixed redirection in the missing information flow for Project.Viewer User: Fixed navigation for viewer users.Light Mode Toggles: Improved toggle visibility in light mode.Dependency MQ Password: Fixed password auto-generation for Dependency MQ.Icon Loading: Improvements in icon loading.Transition Screens: Fixed transition screens during data loading.Project Console Tables: Improved table visualization on the &quot;Project Console&quot; screen.Infrastructure Errors: Fixed error messages when infrastructure module execution fails.Mobile Account Selector: Support for account selector on mobile devices. ","version":null,"tagName":"h2"},{"title":"Version 2.1.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v2-1-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 2.1.0","url":"/preview-docs/changelog/v2-1-0#new-features","content":" Cluster Update: Support for Cluster update from 1.31 to 1.32.Dependency Tour: New guided tour for the Dependency screen.Workload Tour: New guided tour for the Workload screen.Variable Group Tour: New guided tour for the Variable Group screen.Cluster Tour: New guided tour for the Cluster screen.Project Tour: New guided tour for the Project screen.Cluster Update Optimization: Optimization of Cluster update tasks.Screen Loading: Improvements in loading drawers and secondary screens.Schedule Update: New flow to schedule Cluster updates.Onboarding: New onboarding flow for new users.Nodepool Configuration: Support for more Nodepool configuration parameters (instance types, fallbacks, etc.).Upgrade Monitoring: New service monitoring flow during Cluster upgrade with error reporting.Build Logs: Improvements in build logs with more context.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 2.1.0","url":"/preview-docs/changelog/v2-1-0#bug-fixes","content":" SSL Certificate for S3: Fixed SSL certificate errors for S3 with CloudFront.Activity Logs: Fixed names in some Activity Logs.User Creation: Fixed errors in the user creation flow.Support Tickets: Fixed support ticket status.Build with CLI: Fixed parameters when building using the CLI.Nightly Shutdown: Fixed Cluster status with nightly shutdown enabled.Screen Resolutions: Adjustments for some resolutions on the main console screen.Delete Web Services: Fixed errors when deleting a Web Service from the table. ","version":null,"tagName":"h2"},{"title":"Version 2.2.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v2-2-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 2.2.0","url":"/preview-docs/changelog/v2-2-0#new-features","content":" Code Viewer: New component for viewing code within the console.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 2.2.0","url":"/preview-docs/changelog/v2-2-0#bug-fixes","content":" Deleted Users: Fixed errors with deleted users.Update Branches: Fixed the flow for updating branches in Project.Incomplete Information: Fixed the flow when Project information is incomplete.Extra Policies: Fixed the flow for configuring extra policies in Project. ","version":null,"tagName":"h2"},{"title":"Version 2.3.0","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v2-3-0","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 2.3.0","url":"/preview-docs/changelog/v2-3-0#new-features","content":" Environment Cloning: New function to clone Environments.Project Cloning: New function to clone Projects.Dependency Cloning: New function to clone Dependencies.Workload Cloning: New function to clone Workloads.Variable Group Cloning: New function to clone Variable Groups.Cluster Monitoring Filters: Added filters for navigating Cluster events in Cluster Monitoring.Variable Group Search: Ability to search Variable Groups by internal key names from the general search.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 2.3.0","url":"/preview-docs/changelog/v2-3-0#bug-fixes","content":" Selected Account: The selected account now persists when switching users.Web Services Shutdown: Improved Web Services shutdown. ","version":null,"tagName":"h2"},{"title":"Version 2.3.1","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v2-3-1","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 2.3.1","url":"/preview-docs/changelog/v2-3-1#new-features","content":" Image Analysis in Support: Support for image analysis in the support bot.Documentation: New documentation for Dockertron and chart management.Custom Values in Addons: Ability to use custom values when installing an addon.Nodegroup Change: Ability to change the nodegroup of non-production clusters.Support Flow: Conversation flow for support between bot and human.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes​","type":1,"pageTitle":"Version 2.3.1","url":"/preview-docs/changelog/v2-3-1#bug-fixes","content":" Confirmation Modals: Fixed position of deletion confirmation modals.Builds Table: Fixed data and column errors in the builds table.Dashboard Notifications: Fixed notification messages in the dashboard.Workload Names: Adjusted name sizes for Workloads.Chart Dependency: Fixed chart dependency flow.Console Alerts: Fixed notification alerts in the console. ","version":null,"tagName":"h2"},{"title":"Version 2.3.2","type":0,"sectionRef":"#","url":"/preview-docs/changelog/v2-3-2","content":"","keywords":"","version":null},{"title":"New Features​","type":1,"pageTitle":"Version 2.3.2","url":"/preview-docs/changelog/v2-3-2#new-features","content":" SleakOps CLI: Improvements and new features, including the ability to open a Workload shell locally.S3 with CloudFront: Improvements in S3 integration with CloudFront.Python in Lambdas: Updated Python versions for Lambdas.Charts in Projects: Improvements to the chart configuration screen in Projects.Subnet Tags: Improvements in subnet tag handling for autodiscovery.DB Restoration: Improvements in the database restoration flow from a snapshot.Ingress in Web Services: Support for configuring URL and ingress annotations in Web Services.API Performance: Optimization of API performance.Domain Errors: Improvements in domain error handling.Addon Buttons: Visual improvements to addon buttons.Notifications: Visual improvements when displaying notifications.Button Options: Visual improvements to button options (settings, copy, etc.).RDS Versions: Updated available RDS versions.Infrastructure Modules: Optimization of execution times for infrastructure modules.  ","version":null,"tagName":"h2"},{"title":"Bug Fixes:​","type":1,"pageTitle":"Version 2.3.2","url":"/preview-docs/changelog/v2-3-2#bug-fixes","content":" Role Deletion: Handling of role deletion when deleting a Project.Multi-Provider Billing: Fixed billing screen with multiple providers.Registration and Login: Handling of registration and login flow with different subscription states.Nodepool Form: Error handling in the Nodepool form.Account Switching: Error handling when switching between accounts.Variable Characters: Handling of invalid characters in variable names in Variable Groups.Cluster Access: Handling of Cluster access for different user types.VPN Access: Error handling when obtaining VPN access for different user types.Listing Texts: Fixed texts in listings and forms.AWS Connection: Fixed texts in the step-by-step guide for connecting with AWS.Pending Deployments: Alert indicator for deployments pending approval.Postgres Upgrade: Error handling in PostgreSQL upgrade from 14 to 17.RDS Security Group: Fixed security group for public and private RDS replicas.Support Chat: Fixed delegation in support chat. ","version":null,"tagName":"h2"},{"title":"Basic Concepts","type":0,"sectionRef":"#","url":"/preview-docs/docs/basicconcepts","content":"","keywords":"","version":"Next"},{"title":"Provider​","type":1,"pageTitle":"Basic Concepts","url":"/preview-docs/docs/basicconcepts#provider","content":" As the first step to start an infrastructure is to decide which cloud provider to use (AWS, Azure or GCP, etc.), in SleakOps a Provider represents the selection of one of this cloud providers, the credentials granted to SleakOps to it and the set of accounts created in order to properly manage the infrastructure. It is composed by an Organizative Unit on AWS and its accounts.  ","version":"Next","tagName":"h3"},{"title":"Cluster​","type":1,"pageTitle":"Basic Concepts","url":"/preview-docs/docs/basicconcepts#cluster","content":" A Kubernetes cluster is a distributed system for managing containerized applications. It consists of nodes (physical or virtual machines) running pods (groups of one or more containers). A central control plane, composed of various software components, coordinates the activity of the nodes and manages the lifecycle of the pods.  ","version":"Next","tagName":"h3"},{"title":"Environment​","type":1,"pageTitle":"Basic Concepts","url":"/preview-docs/docs/basicconcepts#environment","content":" In computing, an environment or namespace typically refers to an isolated area where specific resources, applications, or Workloads operate independently. This isolation enhances organization, security, and resource management within larger systems or platforms.  ","version":"Next","tagName":"h3"},{"title":"Project​","type":1,"pageTitle":"Basic Concepts","url":"/preview-docs/docs/basicconcepts#project","content":" A project is a collection of files and code managed using Git, representing a codebase within a git repository.  ","version":"Next","tagName":"h3"},{"title":"Workload​","type":1,"pageTitle":"Basic Concepts","url":"/preview-docs/docs/basicconcepts#workload","content":" A workload is a fundamental unit of functionality that can be independently deployed and managed within an environment. Workloads perform specific tasks or processes, interacting with other services via defined interfaces. They are scalable and modular, forming the building blocks of architectures like microservices and service-oriented architectures (SOA), allowing for flexible and efficient system development.  ","version":"Next","tagName":"h3"},{"title":"Dependency​","type":1,"pageTitle":"Basic Concepts","url":"/preview-docs/docs/basicconcepts#dependency","content":" A dependency is an external resource or service that an application requires to function properly in a cloud environment. These dependencies include various infrastructure components such as relational databases, storage services, and caches. Each dependency is associated with provider-specific services, ensuring seamless integration and operation within the cloud platform.  ","version":"Next","tagName":"h3"},{"title":"Var Group​","type":1,"pageTitle":"Basic Concepts","url":"/preview-docs/docs/basicconcepts#var-group","content":" In Sleakops, a variable group (or var group) is a set of key-value pairs, similar to a dictionary, that provides configuration settings for workloads within a specific project and environment.  ","version":"Next","tagName":"h3"},{"title":"Build​","type":1,"pageTitle":"Basic Concepts","url":"/preview-docs/docs/basicconcepts#build","content":" A build is the process of creating a new version of your application's code as a container image from a Dockerfile, incorporating the compiled code and necessary dependencies.  ","version":"Next","tagName":"h3"},{"title":"Deploy​","type":1,"pageTitle":"Basic Concepts","url":"/preview-docs/docs/basicconcepts#deploy","content":" In technology, to deploy means to release a software application, service, or update to a production environment, making it available for use by end-users. ","version":"Next","tagName":"h3"},{"title":"Welcome to SleakOps!","type":0,"sectionRef":"#","url":"/preview-docs/docs","content":"","keywords":"","version":"Next"},{"title":"Guiding principles​","type":1,"pageTitle":"Welcome to SleakOps!","url":"/preview-docs/docs#guiding-principles","content":" Respect the AWS well architected bases.Keeping always an eye on costs.You have full control, it’s your repo and your cloud.  ","version":"Next","tagName":"h2"},{"title":"Main Features​","type":1,"pageTitle":"Welcome to SleakOps!","url":"/preview-docs/docs#main-features","content":" GitHub, Bitbucket and Gitlab integrationBased on your repo and DockerfilesManage multiple environments using our proposed structure (dev, staging and production) or customize your own.Configure your CI/CD pipeline.Complete Observability stack for logging, monitoring and tracing.Secrets and env vars managment.Secure connections by TLS.Automated configuration for your services behind a load balancer and secure ingress.Easy add AddOns to your cluster.Lot of dependencies ready to go (RDS, S3, Redis, SQL, rRabbit, etc.).Users access to services management.Automated VPNs.  Providers A cloud provider account. Getting Started Clusters A set of worker machines, called nodes, that run containerized applications. Getting Started Environments Abstraction that let us isolate the different resources. Getting Started Projects Represents a codebase and it is managed by a git repository. Getting Started Dependencies Pieces of underlying infrastructure your apps need to run in the cloud, such as relational databases, storage services or caches. Getting Started Workloads An abstract way to expose an application running on a set of Pods as a network service. Getting Started Deployments ... Getting Started Build Represents a deployable state of all the services. Getting Started Var Group Dictionary that provides configuration for services. Getting Started ","version":"Next","tagName":"h2"},{"title":"Access your Cluster","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/access-cluster","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Access your Cluster","url":"/preview-docs/docs/cluster/access-cluster#faqs","content":" What is Kubeconfig?​ Kubeconfig is a configuration file used by the Kubernetes command-line tool kubectl to interact with Kubernetes clusters. It contains information about the clusters, users, contexts, and namespaces that kubectl uses to communicate with one or more Kubernetes clusters.  What is an IDE?​ An IDE for Kubernetes is a software environment that provides tools and features specifically designed to help developers create, manage, and deploy applications on Kubernetes clusters, integrating Kubernetes commands, resource management, and YAML/Helm chart editing within the development workflow. Lens is an open-source IDE for Kubernetes, providing a user-friendly GUI to manage, monitor, and troubleshoot multiple clusters in real-time.  ","version":"Next","tagName":"h2"},{"title":"How to access your cluster?​","type":1,"pageTitle":"Access your Cluster","url":"/preview-docs/docs/cluster/access-cluster#how-to-access-your-cluster","content":" ","version":"Next","tagName":"h2"},{"title":"1. Go to the Access Cluster setting​","type":1,"pageTitle":"Access your Cluster","url":"/preview-docs/docs/cluster/access-cluster#1-go-to-the-access-cluster-setting","content":" Click on Clusters, select one and access its settings.  Go to the Access Cluster option.    ","version":"Next","tagName":"h3"},{"title":"2. Install the following Dependencies​","type":1,"pageTitle":"Access your Cluster","url":"/preview-docs/docs/cluster/access-cluster#2-install-the-following-dependencies","content":" AWS Cli: AWS DocsKubeCtl: Kubernetes DocsLens: K8SLens DocsPritunl VPN Client: Pritunl Page  ","version":"Next","tagName":"h3"},{"title":"3. Set up a VPN​","type":1,"pageTitle":"Access your Cluster","url":"/preview-docs/docs/cluster/access-cluster#3-set-up-a-vpn","content":" Open the Pritunl VPN ClientGenerate a VPN URi, copy it and set it up on the client.    ","version":"Next","tagName":"h3"},{"title":"4. Generate your AWS Keys and generate the kubeconfig file​","type":1,"pageTitle":"Access your Cluster","url":"/preview-docs/docs/cluster/access-cluster#4-generate-your-aws-keys-and-generate-the-kubeconfig-file","content":" Login into AWS with your username.Then, go to AWS Access Key Wizard to generate the keys on AWS.Paste the keys in the form and generate the kubeconfig file.Copy the output.    ","version":"Next","tagName":"h3"},{"title":"5. Add it to Lens​","type":1,"pageTitle":"Access your Cluster","url":"/preview-docs/docs/cluster/access-cluster#5-add-it-to-lens","content":" Open Lens, locate the 'Import Kubeconfig' option, and import the YAML file obtained from the Access Cluster section.   ","version":"Next","tagName":"h3"},{"title":"CLI","type":0,"sectionRef":"#","url":"/preview-docs/docs/cli","content":"","keywords":"","version":"Next"},{"title":"Streamline CI/CD with SleakOps CLI​","type":1,"pageTitle":"CLI","url":"/preview-docs/docs/cli#streamline-cicd-with-sleakops-cli","content":" SleakOps CLI is a Python package designed to simplify your CI/CD workflows. With just two straightforward subcommands, you can effortlessly create builds and deploy your applications, ensuring a smooth and efficient development process. To get started, simply install SleakOps using pip:  pip install sleakops   ","version":"Next","tagName":"h2"},{"title":"1. Authentication​","type":1,"pageTitle":"CLI","url":"/preview-docs/docs/cli#1-authentication","content":" To authenticate with the SleakOps CLI, you need an API_KEY. You can obtain this key from the console by clicking on Generate API-Key. Each company is allowed to have only one active API_KEY at a time. If you request a new API_KEY, the old one will be automatically revoked. The page shows the company keys and who generated them.  Once you have your API_KEY, you can use it as an argument when running SleakOps commands or set it as an environment variable named SLEAKOPS_KEY.  Setting up SLEAKOPS_KEY in CI/CD Pipelines For CI/CD pipelines, it's recommended to set SLEAKOPS_KEY as a secret environment variable in your Git provider: GitHub: Add it as a repository secret in Settings → Secrets and variables → ActionsGitLab: Add it as a CI/CD variable in Settings → CI/CD → VariablesBitbucket: Add it as a repository variable in Repository settings → Pipelines → Repository variables This ensures secure access to SleakOps services without exposing your API key in your pipeline configuration files.  ","version":"Next","tagName":"h3"},{"title":"2. Create a Build​","type":1,"pageTitle":"CLI","url":"/preview-docs/docs/cli#2-create-a-build","content":" To create a build for your application, use the following command:  sleakops build [options]   This command initiates the build process, and SleakOps takes care of compiling your code, running tests, and packaging the application for deployment. You can specify additional options to tailor the build process to your specific needs.  There are two required arguments project and branch, which are used to know what to build. Besides, you might add a commit to build a previous commit, a tag for the image, and the provider if you need to specify it.  As previously mentioned the key might be an input here or a environment variable.  Also, you might mark if you want the process to wait the build to be finished or not.  ","version":"Next","tagName":"h3"},{"title":"3. Make a Deploy​","type":1,"pageTitle":"CLI","url":"/preview-docs/docs/cli#3-make-a-deploy","content":" Once your build is ready, you can effortlessly deploy your application using the following command:  sleakops deploy [options]   SleakOps seamlessly handles the deployment process, ensuring that your application is up and running in no time. You can specify deployment options to fine-tune the process according to your requirements.  Here project and environment are the required arguments. User might add a build or tag image to specify an image. Here the wait and key options are present to, the usage is the same as in the build command.  ","version":"Next","tagName":"h3"},{"title":"CI/CD Examples​","type":1,"pageTitle":"CLI","url":"/preview-docs/docs/cli#cicd-examples","content":" With SleakOps CLI, you can integrate your CI/CD pipelines, automate the build and deployment process, and focus on delivering exceptional applications without the hassle of manual intervention. Enjoy a seamless development experience with SleakOps, and make your custom CI/CD workflows.  GitHubGitLabBitBucket name: Deploy on: push: branches: - main jobs: build: runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 - name: Install SleakOps CLI run: pip install sleakops - name: Run SleakOps build env: SLEAKOPS_KEY: ${{ secrets.SLEAKOPS_KEY }} run: sleakops build -p core -b main -w deploy: needs: [build] runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 - name: Install SleakOps CLI run: pip install sleakops - name: Run SleakOps deploy env: SLEAKOPS_KEY: ${{ secrets.SLEAKOPS_KEY }} run: sleakops deploy -p core -e main -w  ","version":"Next","tagName":"h2"},{"title":"Cluster","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Cluster","url":"/preview-docs/docs/cluster#faqs","content":" What are the benefits of having a cluster?​ Clusters allow you to deploy multiple instances of the same application effortlessly, ensuring that if one instance fails, others can instantly take over. Additionally, clusters offer auto-scaling capabilities, automatically adjusting the number of worker nodes as traffic fluctuates, which ensures high availability and optimal performance. They also provide an excellent way to isolate your production environment from your staging environment.  How SleakOps manage clusters?​ SleakOps offers you the flexibility and control needed to create an EKS cluster that aligns precisely with your requirements. To define how to create your infra, you can see: Designing your Infra: Single Schema Vs. Multi Schema   What happens when a Cluster is created on SleakOps?​ SleakOps creates a group of Node Pools that will allow you to run your applications using Kubernetes orchestration based on your needs. See Node Pools.  What is Karpenter?​ In the process of creating your EKS cluster, node provisioning is seamlessly managed by advanced Karpenter technology. Karpenter automatically provisions nodes with just the required resources and scales the cluster based on application demands, removing concerns about deprovisioning. As your workload changes, Karpenter adjusts nodes and resources dynamically, optimizing performance and cost. See Karpenter Web  How do I choose the right instance types for my cluster?​ Choosing the right instance types depends on your application requirements, cost optimization goals, and availability needs. SleakOps provides different node pools (Spot, On-Demand, Reserved) to help you optimize costs while maintaining performance. For detailed guidance on instance types and cluster sizing, see Instance Types and Node Management.  How does SleakOps handle cluster updates and upgrades?​ We notify users about new version coming in approximatively 1 month in advance.Upgrade clusters for a group of selected customers.Upgrade all non-production flagged clusters.Upgrade all clusters.  How do I control cluster's expenses?​ SleakOps allows you to see all your clusters expenses in one place, classified by account, resources, dates. Access Clusters, select one and click the button: $  How do I monitor my cluster?​ You can monitor your cluster's activity by accessing Clusters, and clicking into the button:  ","version":"Next","tagName":"h2"},{"title":"Lets create your first Cluster on SleakOps​","type":1,"pageTitle":"Cluster","url":"/preview-docs/docs/cluster#lets-create-your-first-cluster-on-sleakops","content":" warning Creating a cluster incurs costs on your AWS account, as the EKS service includes a fixed fee plus variable costs based on resource consumption.  ","version":"Next","tagName":"h2"},{"title":"1. Select the account under the cluster’ll be created.​","type":1,"pageTitle":"Cluster","url":"/preview-docs/docs/cluster#1-select-the-account-under-the-clusterll-be-created","content":" For more information regarding accounts, see Accounts.  On the left pane, you will see a selector with the account names, select the one you'll use based on how you decide to manage your clusters and environments. We suggest to move forward with a Multiple Schema configuration, that aligns with the best practices. To follow this schema select the development account to create the cluster for your staging environments, and the production account for the production cluster. Check Designing your Infra: Single Schema Vs. Multi Schema for more information.  ","version":"Next","tagName":"h3"},{"title":"2. Navigate to create Cluster section​","type":1,"pageTitle":"Cluster","url":"/preview-docs/docs/cluster#2-navigate-to-create-cluster-section","content":" Into the Left Pane, access Clusters option and then, at the top right corner, click on the Create button.    ","version":"Next","tagName":"h3"},{"title":"3. Set up your Cluster​","type":1,"pageTitle":"Cluster","url":"/preview-docs/docs/cluster#3-set-up-your-cluster","content":" With your Account selected, you will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Setting\tDescriptionName\tIdentify your cluster Description\tOptional space to describe what is included into this cluster. Architecture Type\tSelect the architecture type to be used during the creation for your instances: (64-Bit) ARM or (64-Bit) X86, based on your performance and compatibility needs. Then you'll be able of creating new instances using a different architecture. Production\tHigh-Availability (HA) Configuration: When enabled, this setting transforms your cluster into a production-ready environment by distributing the EKS cluster across multiple Availability Zones (AZs). This provides redundancy and fault tolerance, ensuring uninterrupted operations even if one AZ experiences issues. Production clusters also benefit from enhanced monitoring, automated backups, and optimized resource allocation for critical workloads.  Once you've completed the form, click on Submit in order to trigger the cluster creation into the selected account on AWS.  This process will create a Cluster with five node pools by default. See Node Pools. ","version":"Next","tagName":"h3"},{"title":"EBS (Elastic Block Store)","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/addons/ebs","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"EBS (Elastic Block Store)","url":"/preview-docs/docs/cluster/addons/ebs#faqs","content":" What is AWS EBS?​ AWS EBS is a block storage service from AWS designed to provide persistent storage for EC2 instances. EBS volumes are automatically replicated within their Availability Zone, offering high availability and durability, and protecting against hardware failures.  How is EBS used in SleakOps?​ In SleakOps, EBS is used to deliver persistent storage for applications running on EC2 instances. Each EBS volume can be attached to a single EC2 instance at a time, although multiple volumes can be attached to one instance. Within Kubernetes, EBS is used for persistent volumes, ensuring data consistency across pod restarts and rescheduling. SleakOps manages and configures EBS automatically to suit your application needs.  What are the benefits of using EBS?​ EBS provides several key benefits for high-performance applications: High performance: EBS offers consistent and low-latency performance, ideal for applications requiring quick data access.Durability: EBS volumes are replicated within their Availability Zone to ensure high durability.Scalability: Volumes can be easily resized to accommodate growing application demands.  How do I configure volumes with EBS in SleakOps?​ To set up and manage volumes using EBS within SleakOps, please refer to the Volumes documentation. This guide provides instructions on creating and managing EBS volumes to support your application’s storage requirements.  How do I use ebs volumes on my own charts?​ To use EBS Volumes you must pass to the chart values the 'StorageClass' name 'default-sc'. You can check your current StorageClasses kubectl get storageclass --all-namespaces   When do I use EBS?​ You should use EBS when I need a volume that will be mounted to only one pod, for example a database running in the Cluster without replicas. ","version":"Next","tagName":"h2"},{"title":"Addons","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/addons","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Addons","url":"/preview-docs/docs/cluster/addons#faqs","content":" Which are the essential add-ons?​ By default SleakOps includes in your infra: Metric Server: SleakOps installs the Metric Server to collect cluster and node-level metrics, enabling performance monitoring and informed scaling decisions.External-DNS: SleakOps deploys External-DNS for automatic DNS record management, ensuring seamless connectivity with user-friendly domain names.Automatic Load Balancer: SleakOps provisions load balancers automatically, efficiently distributing traffic and maintaining high availability.Karpenter Deployment: SleakOps deploys Karpenter for intelligent node provisioning, scaling your cluster based on actual resource needs to optimize performance.  Which optional Add-ons are available?​ Grafana: Visualize and analyze data with Grafana's dashboards, making it easier to monitor system performance and troubleshoot issues. Perfect for tracking application memory and CPU usage.LOKI: Use Loki for cost-effective log aggregation. It simplifies log management by labeling log streams without indexing content, making it ideal for browsing and monitoring application logs.Kubecost: Gain real-time insights into Kubernetes cloud costs with Kubecost. This add-on helps you monitor and reduce expenses across projects in your cluster.Prometheus: SleakOps deploys Prometheus for monitoring and alerting, providing detailed insights into cluster performance and resource utilization.OTEL: Use OpenTelemetry to collect and analyze distributed traces, enabling you to monitor and optimize application performance across your cluster.EFS Controller: The EFS Controller allows you to manage EFS volumes within your EKS cluster, providing scalable and shared storage for your applications. For more details, refer to the EFS documentation.EBS Controller: The EBS Controller allows you to manage EBS volumes within your EKS cluster, providing persistent block storage for your applications. For more details, refer to the EBS documentation.  How do I set up an Add-on?​ To set up an add-on, follow these steps: Navigate to the Add-ons section in the Cluster sectionSelect the desired add-on from the list of available options.Configure the add-on settings as needed.Click &quot;Deploy&quot; to install the add-on in your EKS cluster. For more detailed instructions, refer to the Add-ons setup guide. ","version":"Next","tagName":"h2"},{"title":"Changelog","type":0,"sectionRef":"#","url":"/preview-docs/docs/changelog","content":"","keywords":"","version":"Next"},{"title":"Version 2.4.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-240","content":" 🗓️ 01/08/2026  🚀 New Features:  Workload Auto-Diagnostics: With the help of AI, you can now quickly and easily discover what's happening with your Workloads. With just one click from the console, you'll get a complete diagnosis.Grace Period for Workloads: Support for configuring grace period in Workloads.Cost Tags Notifications: Added notifications for configuring cost tags.Cascade Deletion: Improvements in cascade deletion flow with active Dependencies.File-based Variable Groups: Improvements in the Variable Groups form for file types.Project Selector: Improvements in forms with Project selector.Activity Logs Navigation: Added links to navigate between Activity Logs and resources.Sidebar: Visual improvements to the sidebar.Billing Screen: Improvements to the billing screen.Domain Editing: Ability to modify domains in existing Environments.Variable Names: Handling of variable name length in Variable Groups.Environment Names: Adjustments to default Environment names.Dependency Monitoring: Improvements in Dependency monitoring.Small Resolutions: UI improvements for low resolutions or small screens.Modified Variables: Improvements in the Variable Groups form to mark which variables were modified.Target Port in Web Services: Support for configuring targetPort for services in Web Services.  🐞 Bug Fixes:  Environment Names: Handling of Environment name length.Persistent Filters: Project and Environment filters now persist between screens.Project Icons: Improved icons for Projects.Addons with Custom Attributes: Fixed editing of addons with custom attributes.RDS Replicas: Validation of RDS replica length.Web Services URL: Fixed URL auto-generation when editing a Web Service.Project Selector: Fixed visibility of the Project selector.Nodepool Forms: Fixed errors in Nodepool editing and creation forms.State Transition: Fixed transition from pending to completed state.SSL Certificate: Fixed alerts for SSL certificate validation.Cloning with Versions: Fixed cloning with Dependency versions.Notification Emails: Fixed visual errors in notification emails.Cloning URL: Fixed Web Services URL in cloning flow.Delete Project with RDS: Fixed deletion of a Project with an RDS that has deletion protection enabled.  ","version":"Next","tagName":"h2"},{"title":"Version 2.3.2​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-232","content":" 🗓️ 12/19/2025  🚀 New Features:  SleakOps CLI: Improvements and new features, including the ability to open a Workload shell locally.S3 with CloudFront: Improvements in S3 integration with CloudFront.Python in Lambdas: Updated Python versions for Lambdas.Charts in Projects: Improvements to the chart configuration screen in Projects.Subnet Tags: Improvements in subnet tag handling for autodiscovery.DB Restoration: Improvements in the database restoration flow from a snapshot.Ingress in Web Services: Support for configuring URL and ingress annotations in Web Services.API Performance: Optimization of API performance.Domain Errors: Improvements in domain error handling.Addon Buttons: Visual improvements to addon buttons.Notifications: Visual improvements when displaying notifications.Button Options: Visual improvements to button options (settings, copy, etc.).RDS Versions: Updated available RDS versions.Infrastructure Modules: Optimization of execution times for infrastructure modules.  🐞 Bug Fixes:  Role Deletion: Handling of role deletion when deleting a Project.Multi-Provider Billing: Fixed billing screen with multiple providers.Registration and Login: Handling of registration and login flow with different subscription states.Nodepool Form: Error handling in the Nodepool form.Account Switching: Error handling when switching between accounts.Variable Characters: Handling of invalid characters in variable names in Variable Groups.Cluster Access: Handling of Cluster access for different user types.VPN Access: Error handling when obtaining VPN access for different user types.Listing Texts: Fixed texts in listings and forms.AWS Connection: Fixed texts in the step-by-step guide for connecting with AWS.Pending Deployments: Alert indicator for deployments pending approval.Postgres Upgrade: Error handling in PostgreSQL upgrade from 14 to 17.RDS Security Group: Fixed security group for public and private RDS replicas.Support Chat: Fixed delegation in support chat.  ","version":"Next","tagName":"h2"},{"title":"Version 2.3.1​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-231","content":" 🗓️ 12/01/2025  🚀 New Features:  Image Analysis in Support: Support for image analysis in the support bot.Documentation: New documentation for Dockertron and chart management.Custom Values in Addons: Ability to use custom values when installing an addon.Nodegroup Change: Ability to change the nodegroup of non-production clusters.Support Flow: Conversation flow for support between bot and human.  🐞 Bug Fixes:  Confirmation Modals: Fixed position of deletion confirmation modals.Builds Table: Fixed data and column errors in the builds table.Dashboard Notifications: Fixed notification messages in the dashboard.Workload Names: Adjusted name sizes for Workloads.Chart Dependency: Fixed chart dependency flow.Console Alerts: Fixed notification alerts in the console.  ","version":"Next","tagName":"h2"},{"title":"Version 2.3.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-230","content":" 🗓️ 11/18/2025  🚀 New Features:  Environment Cloning: New function to clone Environments.Project Cloning: New function to clone Projects.Dependency Cloning: New function to clone Dependencies.Workload Cloning: New function to clone Workloads.Variable Group Cloning: New function to clone Variable Groups.Cluster Monitoring Filters: Added filters for navigating Cluster events in Cluster Monitoring.Variable Group Search: Ability to search Variable Groups by internal key names from the general search.  🐞 Bug Fixes:  Selected Account: The selected account now persists when switching users.Web Services Shutdown: Improved Web Services shutdown.  ","version":"Next","tagName":"h2"},{"title":"Version 2.2.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-220","content":" 🗓️ 11/13/2025  🚀 New Features:  Code Viewer: New component for viewing code within the console.  🐞 Bug Fixes:  Deleted Users: Fixed errors with deleted users.Update Branches: Fixed the flow for updating branches in Project.Incomplete Information: Fixed the flow when Project information is incomplete.Extra Policies: Fixed the flow for configuring extra policies in Project.  ","version":"Next","tagName":"h2"},{"title":"Version 2.1.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-210","content":" 🗓️ 11/10/2025  🚀 New Features:  Cluster Update: Support for Cluster update from 1.31 to 1.32.Dependency Tour: New guided tour for the Dependency screen.Workload Tour: New guided tour for the Workload screen.Variable Group Tour: New guided tour for the Variable Group screen.Cluster Tour: New guided tour for the Cluster screen.Project Tour: New guided tour for the Project screen.Cluster Update Optimization: Optimization of Cluster update tasks.Screen Loading: Improvements in loading drawers and secondary screens.Schedule Update: New flow to schedule Cluster updates.Onboarding: New onboarding flow for new users.Nodepool Configuration: Support for more Nodepool configuration parameters (instance types, fallbacks, etc.).Upgrade Monitoring: New service monitoring flow during Cluster upgrade with error reporting.Build Logs: Improvements in build logs with more context.  🐞 Bug Fixes:  SSL Certificate for S3: Fixed SSL certificate errors for S3 with CloudFront.Activity Logs: Fixed names in some Activity Logs.User Creation: Fixed errors in the user creation flow.Support Tickets: Fixed support ticket status.Build with CLI: Fixed parameters when building using the CLI.Nightly Shutdown: Fixed Cluster status with nightly shutdown enabled.Screen Resolutions: Adjustments for some resolutions on the main console screen.Delete Web Services: Fixed errors when deleting a Web Service from the table.  ","version":"Next","tagName":"h2"},{"title":"Version 2.0.1​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-201","content":" 🗓️ 10/15/2025  🚀 New Features:  Builds and Deploys Table: Improvements to the data shown in the builds and deploys table.  🐞 Bug Fixes:  Nightly Shutdown Cron: Fixed visualization of the nightly shutdown cron.Cluster Status: Fixed Cluster status update while updating.Long Notifications: Fixed visualization of long notifications.Third-Party VPN: Fixed VPN access for third parties.Deploy Cancellation: Fixed deploy cancellation flow.Provider Creation: Fixed text hierarchies in the Provider creation flow.Missing Information: Fixed redirection in the missing information flow for Project.Viewer User: Fixed navigation for viewer users.Light Mode Toggles: Improved toggle visibility in light mode.Dependency MQ Password: Fixed password auto-generation for Dependency MQ.Icon Loading: Improvements in icon loading.Transition Screens: Fixed transition screens during data loading.Project Console Tables: Improved table visualization on the &quot;Project Console&quot; screen.Infrastructure Errors: Fixed error messages when infrastructure module execution fails.Mobile Account Selector: Support for account selector on mobile devices.  ","version":"Next","tagName":"h2"},{"title":"Version 2.0.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-200","content":" 🗓️ 01/10/2025  🚀 New Features:  Full Console Redesign: Modernized UI for a cleaner, more intuitive experience.Light Theme Support: Complete support for light mode.Support Bot: Automated responses for common support questions.Comprehensive Documentation: Expanded guides covering all features.Update lambdas: Update python versions for lambdas.Project Chart: Promoted to stable.Project Access: Promoted to stable.Dependency Aurora MySQL: Promoted to stable.Dependency Oracle: Promoted to stable.Dependency MariaDB: Promoted to stable.Dependency Aurora PostgreSQL: Promoted to stable.Dependency Editing: Ability to edit existing dependencies.Dockertron (beta): AI-powered automatic dockerization.Builds cancel: Could cancel pending builds.New MSK Dependency: Support for Kafka via AWS MSK.Enhanced Webservices: Configure custom ingress annotations and optional healthchecks.Advanced Nodepools: New fallback strategies and instance mix (reserved, spot, on-demand) for better cost and performance control.  🐞 Bug Fixes:  GitLab self-hosted: Fixed URL validation.Cluster deletion: Improved cascading deletion handling.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.16​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-1716","content":" 🗓️ 21/07/2025  🚀 New Features:  Projects with Public Repositories: You can now create and manage projects linked to public repositories.Exclude Builds from Metrics: Builds can be excluded from the Grafana metrics dashboard for more accurate reporting.  🐞 Bug Fixes:  New Project Deployments: Fixed issues preventing successful deployment of newly created projects.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.15​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-1715","content":" 🗓️ 07/07/2025  🚀 New Features:  Nodegroup Spot Resilience: Spot nodegroups now prevent failures when no Spot instances are available.File-based VariableGroups: Added support for creating variablegroups of type file.Agent Bot (beta): Experimental agent bot released in beta.  🐞 Bug Fixes:  Dependent domain configuration: Generate DNS records when parent domain already created.Cluster status with nightly shutdown: Fixed incorrect status display for clusters with nightly shutdown enabled.VariableGroups filters: Fiter by projects on variablegroups listDelete cluster: Fixed deletion cluster flow.Support ticket status: Fixed close support ticket status.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.14​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-1714","content":" 🗓️ 26/06/2025  🚀 New Features:  State Transition Improvements: Smoother state changes for cluster addons and forms.Support with Images: Users can now upload images in the support chat.Jobs from Cronjobs or Existing Jobs: Ability to launch a Job from an existing cronjob or Job.Infrastructure Errors: Improved parsing and display of infrastructure errors for easier troubleshooting.  🐞 Bug Fixes:  Duplicate Volumes: Fixed issue when creating volumes with the same name.Duplicate Users: Prevented creation of users with the same email.Duplicate Dependencies: Blocked creation of dependencies with duplicate names.Dependency Monitoring: Fixed date range issues on the dependency monitoring screen.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.13​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-1713","content":" 🗓️ 02/06/2025  🚀 New Features:  Dependency Monitoring: Improved visualization and tracking of dependencies.Service Control: New toggle to turn webservices and workers on or off.Builds with or without cache: Option to run builds using cache or from scratch.S3 Bucket Import with Versioning: Added support for importing S3 Buckets with active versioning.Variable Groups: Enhanced interface for managing variable groups.Dockerfile Validation: New validations to ensure reliability of Dockerfiles.  🐞 Bug Fixes:  Job Logs: Fixed broken log links for Jobs.Branch Names: Added support for branches with / in their names.GitLab Pipelines: Fixed issues affecting pipeline execution.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.12​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-1712","content":" 🗓️ 14/05/2025  🚀 New Features:  New Support Flow: Introduced a support chatbot and ticketing system to provide better traceability and faster response times.Subscription &amp; Plan Management: Enhanced tools for managing subscriptions and service plans.  🐞 Bug Fixes:  Form Improvements: General enhancements to form usability and validation.Project Console: UI/UX improvements in the project console screen.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.11​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-1711","content":" 🗓️ 24/04/2025  🚀 New Features:  Kubernetes 1.31 &amp; Karpenter 1.3: SleakOps now provisions clusters on EKS 1.31 and upgrades the autoscaler to Karpenter 1.3.Stronger Secret Management : All secrets are now also stored encrypted in AWS Systems Manager Parameter Store, adding an extra layer of durability beyond the in-cluster copy.  🐞 Bug Fixes:  Dev-Cluster Workers: Removed the PodDisruptionBudge improving worker reliability in development clusters when the cluster had the scheduler shutdown enabled.Builds: Builds are no longer triggered for every minor project edit.Deployments: Switched deployments jobs away from Fargate; build logs are now persisted for easier troubleshooting.Web Service Details: Refined the service detail page for clearer visibility of endpoints, status, and metrics.Kubecost Add-on: Stability improvements  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.10​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-1710","content":" 🗓️ 01/04/2025  🚀 New Features:  Enhanced Permission Control: Projects can now have additional associated permissions, whether they are AWS IAM Policies or custom permissions.Dependency Details: The configuration details of each dependency are now displayed within its detail view.Cluster Update Screen Improvements: EKS Insights analysis is now included directly in SleakOps to streamline cluster updates.Build &amp; Project Enhancements: Additional information during builds and improved project validation workflows.  🐞 Bug Fixes:  Improved Text Input: Resolved issues affecting text inputs in forms.Cluster Access Data: Fixed a bug when retrieving cluster connection data under a different selected account.Domain List Filters: Added filters by account to the domain listing.Nodepool List Improvements: Refined visuals for the nodepool list view.Add-on Installation Updates: The list of add-ons now refreshes properly after installation.Variable Group Editing: Fixed an issue with editing variable groups.Subscription Attachment: Addressed a bug that prevented new subscriptions from attaching correctly.Cost Forecast: Fixed forecasting issues for better cost estimations.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.9​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-179","content":" 🗓️ 17/02/2025  🚀 New Features:  Cronjob Enhancements: Configure cronjob policies and easily filter between active and inactive cronjobs.Support Emails on Notifications: When SleakOps generates a notification, users now receive it via email.EKS Insights: During cluster upgrades, SleakOps checks EKS Insights to ensure everything is running smoothly.  🐞 Bug Fixes:  Project Flow Improvements: Enhanced various settings, forms, and other elements for smoother project management.AWS Account Creation Flow: Now supports inactive AWS accounts, providing clear guidance on how to manually activate them before resuming the process in SleakOps.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.8​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-178","content":" 🗓️ 10/02/2025  🚀 New Features:  Kubernetes 1.30: Updated EKS support to version 1.30.  🐞 Bug Fixes:  Minor UI Enhancements: Improved the visual design for project and workload screens.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.7​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-177","content":" 🗓️ 05/02/2025  🚀 New Features:  Import from External Buckets: Quickly copy files from an external S3 Bucket into SleakOps via the new Import Bucket feature.Project View Overhaul: See logs and key info in a single screen for better visibility.Executions Renamed to Workloads: Updated terminology to align with internal cluster notation.Cluster Deletion Optimization: Added extra validation for a more secure and stable deletion process.  🐞 Bug Fixes:  Project Permissions for Jobs: Fixed an issue where Jobs used cluster node permissions instead of Project permissions.Docker Args Modification: Builds now correctly apply any Docker Args changed just before they run.VPN Profile Generation: Resolved an issue preventing third-party user profiles from being generated successfully.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.6​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-176","content":" 🗓️ 06/01/2025  🚀 New Features:  New Nodepool Configurations: You can now set additional parameters, such as minimum instance sizes and more.Job with Specific Images: When creating a job, you can specify the exact image and tag you want to run (e.g., postgres:16.4).(BETA) Chart Extension by Project: SleakOps can now extend the charts used to deploy project workloads, allowing you to add dependencies. For more information, see the Helm documentation.CI/CD Improvements: The file for configuring CI/CD has been simplified and optimized.  🐞 Bug Fixes:  Internal Web Service URL: Fixed an issue that caused incorrect URLs for “internal” type web services.Volume Deletion: Resolved problems related to volume deletion under various retention policies.UX/UI Enhancements: Improvements in the interface for Projects, Volumes, and Variable Groups.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.5​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-175","content":" 🗓️ 09/12/2024  🚀 New Features:  AWS Integration Error Handling:: Implemented a mechanism to handle delays in AWS account activations created by SleakOps.Add-on Links in Builds: Added links for easily viewing logs and metrics during the build process.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.4​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-174","content":" 🗓️ 05/12/2024  🚀 New Features:  Add-on Accessibility: Added links in SleakOps for easy access to view logs, APM, or metrics for specific resources.OpenTelemetry (Beta): Introduced an add-on to enhance observability in applications deployed with SleakOps. With OpenTelemetry, you can have your own APM to monitor metrics like request rate, latency, and error rate of your application.Add-on Availability Configurations: Added various availability settings for each add-on.Documentation: Updated the add-on documentation and made it available in Spanish.  🐞 Bug Fixes:  Kubecost Integration Review: Reviewed the Prometheus-Kubecost integration. Kubecost now correctly maps the names of deployed resources to their costs, greatly improving the accuracy of its estimates. It's now possible to enable approximate network traffic cost analysis within the cluster in Kubecost (Beta).  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.3​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-173","content":" 🗓️ 14/11/2024  🚀 New Features:  Oracle RDS Support (Beta): You can now manage Oracle RDS instances as dependencies within SleakOps.Aurora PostgreSQL Serverless Support (Beta): Added the ability to create and manage Aurora PostgreSQL Serverless databases.  🐞 Bug Fixes:  Various minor bug fixes.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.2​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-172","content":" 🗓️ 05/11/2024  🚀 New Features:  S3 Bucket Deletion: Introduced the ability to delete S3 buckets containing a large number of files.VPN: Updated the Pritunl module to the latest version for enhanced security and performance.Subscription Management Improvements: Enhanced the management of subscriptions for a better user experience.User Registration: Enabled the registration of new users to the platform.  🐞 Fixes:  Various minor bug fixes.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.1​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-171","content":" 🗓️ 30/10/2024  🚀 New Features:  Environment and Domain Creation: Improved the process for creating environments and domains. You can now use a different domain than the one configured globally without any limitations.Notifications: Added a notification system to inform users about pending manual actions and scheduled infrastructure updates.Documentation: Updated documentation on managing domains, projects, dependencies, and environment variables.  🐞 Fixes:  Various minor bug fixes.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-170","content":" 🗓️ 14/10/2024  🚀 New Features:  Advanced Node Management: Introduced node pool management to provide greater control over the types of nodes where workloads are executed.Cluster Module Migration: All modules created with the cluster now run on Graviton instances, enhancing performance and reducing costs.Cluster Add-ons: All add-ons now run on Graviton instances, further improving performance and lowering costs.Isolated Build Nodes: Builds are now executed on dedicated nodes separate from the application nodes, improving the stability of the nodes running applications.  🐞 Fixes:  Various minor bug fixes.  ","version":"Next","tagName":"h2"},{"title":"Version 1.6.3​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-163","content":" 🗓️ 27/09/2024  🚀 New Features:  Registration: Implemented a new registration flow.  🐞 Fixes:  Various minor bug fixes and improvements.  ","version":"Next","tagName":"h2"},{"title":"Version 1.6.2​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-162","content":" 🗓️ 09/19/2024  🚀 New Features:  Upgrades: Updated Prometheus, Loki, and EBS CSI Driver to the latest versions as of August 2024.EBS CSI Driver Migration: SleakOps now uses the AWS-managed EKS Addon for the EBS CSI Driver, replacing the self-managed version.Prometheus and Loki with EBS: Prometheus now utilizes EBS volumes for data persistence, preventing data loss even if the pods crash.Loki with SimpleScalable: It adopts a SimpleScalable structure with TSDB storage for logs, enhancing performance.SQS Dead-letter Queues: Now supports the creation of SQS queues with associated dead-letter queues for improved error handling.  🐞 Fixes:  Various minor bug fixes and improvements to the platform's workload flows.  ","version":"Next","tagName":"h2"},{"title":"Version 1.6.1​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-161","content":" 🗓️ 08/22/2024  🚀 New Features:  Dependency Version Updates: Updated versions of MQ, Elasticsearch, Memcache, and Redis dependencies.Authentication Improvements: Added support for storing authentication tokens via cookies instead of local storage.Added ACM validation record printing on the ACM detail screen, and ACM status is now included in the system.  🐞 Fixes:  Issues with the provider flow have been resolved.  ","version":"Next","tagName":"h2"},{"title":"Version 1.6.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-160","content":" 🗓️ 08/12/2024  🚀 New Features:  Support for ARM Instances and Additional RDS Versions: Added ARM instances and extra versions in RDS.EKS Updated to Version 1.29: EKS has been updated to version 1.29. Changelogs for EKS updates are now displayed.Improvements in Provider Creation and Editing: Screens and fields for provider forms were updated, including changes in states and visual display.Improved Repository Search: Added support for asynchronous search in the repository selector and enhanced the search function for GitHub, GitLab, and Bitbucket.Healthcheck Parameterization: Healthcheck properties can now be parameterized with JSONSchema.New Dashboard: A new dashboard has been added to view consumption by namespace.  Fixes:  Fixed an error when regenerating certificates, as well as issues with builds not running properly.Frontend errors related to listing and API problems that caused filtering errors have been corrected.  ","version":"Next","tagName":"h2"},{"title":"Version 1.5.1​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-151","content":" 🗓️ 06/24/2024  🚀 New Features:  Advanced Resource Configuration: Advanced options for resource configuration in project environments have been implemented.Optimization of Data Collection Scripts: Improved the efficiency of data collection scripts for faster workload.  🐞 Fixes:  Several interface errors affecting system usability have been resolved.  ","version":"Next","tagName":"h2"},{"title":"Version 1.5.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-150","content":" 🗓️ 05/23/2024  🚀 New Features:  Multiple Project Environments Creation: You can now create multiple project environments using the same repository and branch.Domain Validation for Aliases: Improved domain creation validation for aliases by using an existing usable ACM for ingress.Resource Configuration in Project Env: Added the ability to configure build and deploy resources per project environment.Deploy and Build Request Configuration: Added the option to configure deploy and build requests in a ProjectEnv.Grafana Dashboard: A Grafana dashboard was incorporated to visualize consumption by namespace.Loki Configuration: Logs can now be searched by namespace with the new Loki configuration.Data Collection: Improved the billing collection script to be idempotent and executable for specific dates.  🐞 Fixes:  Fixed an error when creating S3 dependencies and solved a critical problem with vargroups during cluster shutdown updates.Fixed a critical error when inviting collaborators.  ","version":"Next","tagName":"h2"},{"title":"Version 1.4.3​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-143","content":" 🗓️ 05/13/2024  🚀 New Features:  Dashboard Management Improvements: Dashboard loading was improved, allowing it to be viewed even if no account is selected.Billing and Project Screen Improvements: Improvements to the billing screen were made, including a new &quot;others&quot; section to account for previously unconsidered costs. The project environment screen was also improved.Policy Updates: CloudFormation policy has been updated to enhance management and security.  🐞 Fixes:  Fixed a critical error that prevented the creation of providers.Reviewed and resolved an issue related to NewRelic integration.Fixed a problem with the refresh token when requesting the VPN URI.ACM Validation Screen and Build Logs Errors: Corrections made to the ACM validation table and logs display for builds in creation state.  ","version":"Next","tagName":"h2"},{"title":"Version 1.4.2​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-142","content":" 🗓️ 04/25/2024  🚀 New Features:  New Metrics: Added new metrics for S3 buckets and RabbitMQ, improving service monitoring. An OpenSearch metrics monitoring system was also implemented.Monitoring Schema Reorganization: Monitoring schema structures were reorganized for better management and visualization. The Dependencies monitoring screen now supports different resource types, providing a more detailed view.  🐞 Fixes:  A critical issue with vargroups was resolved, ensuring their proper functioning.  ","version":"Next","tagName":"h2"},{"title":"Version 1.4.1​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-141","content":" 🗓️ 04/11/2024  🚀 New Features:  Dependency and OpenSearch Monitoring: A new monitoring page was created for dependencies, facilitating the tracking of their status. OpenSearch was included.ECR Lifecycle Policy: A lifecycle policy was configured for ECR, improving image management.  🐞 Fixes:  Fixed the issue of duplicate names between cluster and node in Redis.Resolved various frontend errors that affected the user experience.Fixed the problem where an error was displayed when attempting to publish a vargroup without an associated service.Issues with performing multiple deployments and releases in a row were fixed.  ","version":"Next","tagName":"h2"},{"title":"Version 1.4.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-140","content":" 🗓️ 03/06/2024  🚀 New Features:  Grafana Configuration: The database for the Grafana addon was configured, along with DataSources and Dashboards.Prometheus Metrics Persistence with Thanos: Added support for persisting Prometheus metrics using Thanos.New Volume API: Implemented support for the new volume API, displaying statuses and applying configuration for deployments.The update option in addons has been disabled.Now, when a dependency is deleted, a deploy with &quot;pending-approval&quot; will be created instead of an automatic one.  🐞 Fixes:  Fixed an issue where pre-hooks and new volumes were added during deploys, preventing them from being generated.Subdomains are now correctly marked as delegated if the parent domains are already delegated.  ","version":"Next","tagName":"h2"},{"title":"Version 1.3.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-130","content":" 🗓️ 01/03/2024  🚀 New Features:  Project Details View: A detailed project view is now available in the new interface.RDS Metrics API: A new API for displaying RDS metrics has been added, improving resource visibility.Improved LogViewer: LogViewer loading is now faster and more efficient.Enhanced Onboarding: A new onboarding process has been implemented for easier setup.Redis Monitoring: Redis monitoring has been added, improving infrastructure supervision.RDS Replica Configuration: The option to configure replicas in the RDS Dependency has been added for more flexibility.Domain Deletion Status: Domain deletion now creates a deploy with pending-approval status, rather than an automatic deploy.Job Workload Improvements: Job workload has been improved, allowing automatic retries in case of an initial failure.  🐞 Fixes:  Bitbucket integration issues have been resolved.Undefined value issues in Vargroups have been fixed.  ","version":"Next","tagName":"h2"},{"title":"Version 1.2.4​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-124","content":" 🗓️ 15/02/2024  🚀 New Features:  Cluster Switcher Optimization: Cluster selector behavior has been optimized.Login in AWS Subscription Flow: The AWS subscription flow now includes the ability to log in directly.  🐞 Fixes:  Callback issues for Git integrations and Docker file path for GitLab have been resolved.Minor billing screen-related bugs have been fixed.  ","version":"Next","tagName":"h2"},{"title":"Version 1.2.3​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-123","content":" 🗓️ 05/02/2024  🚀 New Features:  Alias Decoupling in Web Services: The creation of aliases is now separated from the web services form.IAM Password Reset: It is now possible to reset the IAM password for a user.  🐞 Fixes:  A minor issue with release tasks has been corrected.  ","version":"Next","tagName":"h2"},{"title":"Version 1.2.2​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-122","content":" 🗓️ 25/01/2024  🚀 New Features:  Domain Validation Button: A &quot;check validation&quot; button has been added to the domain drawer for easier domain management.Activity Log Table: An activity log table has been created.Access Key Encryption: Access keys for code version providers (GIT) are now encrypted.  🐞 Fixes:  An issue where the API didn't correctly recreate the ACM module during regeneration has been fixed.  ","version":"Next","tagName":"h2"},{"title":"Version 1.2.1​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-121","content":" 🗓️ 12/01/2024  🚀 New Features:  Vargroup Form Optimization: Usability improvements have been made to the Vargroup forms.Provider and User Account Deletion: Deleting a provider now also deletes associated user accounts.  🐞 Fixes:  A bug in ACM certificate regeneration has been fixed.A provider deletion issue has been corrected.  ","version":"Next","tagName":"h2"},{"title":"Version 1.2.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-120","content":" 🗓️ 05/01/2024  🚀 New Features:  Logs in Grafana: A data source has been configured in Grafana to display logs from S3.Cluster Update Button: A button has been added to allow cluster updates from the interface.User Activity Log: An activity log for user actions has been created.Domain Validation Deploy: You can now create a deploy that runs once domains are validated.Two-Factor Authentication: Two-factor authentication (2FA) has been added to the login for enhanced security.  🐞 Fixes:  An issue with builds using the same branch as the default has been fixed.Log reading has been improved for faster processing.Various frontend optimizations, including styles, search, and pending resource visibility, have been made.  ","version":"Next","tagName":"h2"},{"title":"Version 1.1.1​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-111","content":" 🗓️ 05/12/2023  🚀 New Features:  Log Viewer in Jobs: Added a log viewer in the job list, similar to what already exists for deployments.Dashboard v2: Improvements in the second version of the Dashboard, with more options and better organization of information.Cluster Certificates: Cluster certificates are now automatically deleted and updated to prevent expiration issues.  ","version":"Next","tagName":"h2"},{"title":"Version 1.1.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-110","content":" 🗓️ 06/11/2023  🚀 New Features:  Vargroups Management: Added the option to show vargroups in the forms for services, workers, hooks, and cronjobs.Kubecost: Integrated Kubecost with Prometheus-stack.  🐞 Fixes:  Solved the issue with Karpenter on spot instances.Fixed user roles and user editing.Corrected problems when deleting an environment and the incorrect deletion of domains.Fixed the error when trying to manually start the cluster.Resolved an error in generating hooks.  ","version":"Next","tagName":"h2"},{"title":"Version 1.0.5​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-105","content":" 🗓️ 27/10/2023  🐞 Fixes:  Solved deployment issues and fixed Karpenter with spot instances.Fixed issues in deleting entities and validating service URLs.  ","version":"Next","tagName":"h2"},{"title":"Version 1.0.4​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-104","content":" 🗓️ 11/10/2023  🚀 New Features:  Refactoring and Improvements: Refactored the dashboard and improved log visualization and the management of entity deletion.  🐞 Fixes:  Fixed user editing issues.Corrected cluster state management.Solved problems with environment domains.Fixed error handling in S3 responses with CloudFront.  ","version":"Next","tagName":"h2"},{"title":"Version 1.0.3​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-103","content":" 🗓️ 25/09/2023  🚀 New Features:  Management Buttons and Form Improvements: Added buttons for resource management and improved variable mapping forms.Cronjobs and Domain Regeneration: You can now stop or activate cronjobs and regenerate domains.  🐞 Fixes:  Solved the issue of obtaining the VPN URI in Pritunl.Fixed the account selection issue for viewer users.Improved the handling of health check information sent to the backend.  ","version":"Next","tagName":"h2"},{"title":"Version 1.0.2​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-102","content":" 🗓️ 04/09/2023  🚀 New Features:  Deployment Optimization: Simplified the deployment process and project environment (ProjectEnv) editing, facilitating configuration and deployment.Resource and Configuration Adjustments: You can now create custom aliases for buckets.Health Check Improvements: The readiness probe for services in the development account is now optional.  🐞 Fixes:  Solved issues related to VPN and security parameter configuration.  ","version":"Next","tagName":"h2"},{"title":"Version 1.0.1​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-101","content":" 🗓️ 29/08/2023  🚀 New Features:  Subscription Management: Login and token updates are controlled based on the subscription status. Additionally, a new API was implemented to register users and companies, validating pending subscriptions, with a new model to better manage subscriptions, integrating AwsClient.Marketplace Onboarding: Simplified process for creating users who come from a marketplace.  ","version":"Next","tagName":"h2"},{"title":"Version 1.0.0​","type":1,"pageTitle":"Changelog","url":"/preview-docs/docs/changelog#version-100","content":" 🗓️ 23/08/2023  🚀 New Features:  Volume Configuration: You can now configure volumes in project environments directly from the form.Nightly Shutdown with Timezone: Added support for selecting time zones in the nightly shutdown.Manual Cluster Startup: New button to manually start clusters.CloudFront Integration: Support for using CloudFront to improve content delivery.Automatic Backups: You can configure automatic backups for dependencies.Graviton Instances: Support for using Graviton instances on nodes.Encryption: Implemented encryption in StackSettings for added security.  🐞 Fixes:  Resolved an issue in the billing API and cost estimation.Fixed errors when deleting Providers and VPNs.You can now delete ACM certificates used by a Load Balancer without problems. ","version":"Next","tagName":"h2"},{"title":"EFS (Elastic File System)","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/addons/efs","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"EFS (Elastic File System)","url":"/preview-docs/docs/cluster/addons/efs#faqs","content":" What is AWS EFS?​ AWS EFS is a cloud file storage service from AWS that provides shared and scalable storage for applications and services. It is ideal for workloads that require concurrent access to a common file system across different services.  How is EFS used in SleakOps?​ In SleakOps, EFS is utilized for Project volumes. Each Project can have one or more volumes, which are implemented as EFS file systems within the EKS cluster, providing shared storage that can be accessed by different services and pods.  What are the benefits of using EFS?​ EFS offers several advantages, making it a powerful option for shared storage in distributed applications: Scalability: Automatically scales as files are added or removed.High availability: Designed to be highly available and durable, with data replicated across multiple availability zones.Concurrent access: Multiple EC2 instances can mount the same EFS file system simultaneously, supporting workloads requiring concurrent access.  What is the EFS Retain Policy in SleakOps?​ SleakOps enforces a retain policy for EFS volumes, which prevents the deletion of an EFS volume in AWS when a volume is removed from SleakOps. This ensures data persistence even if the volume is detached from the cluster.  How do I configure volumes with EFS in SleakOps?​ To set up and manage volumes using EFS within SleakOps, follow the instructions in the Volumes documentation. This guide covers creating and managing volumes for your Projects and configuring EFS settings within your cluster.  How do I use EFS volumes on my own charts?​ To use EFS Volumes you must pass to the chart values the 'StorageClass' name 'efs-sc-delete' or 'efs-sc-retain' depending of which retain policy is needed. You can check your current StorageClasses kubectl get storageclass --all-namespaces   When do I use EFS?​ You should use EFS when you need a volume that will be mounted to more than one pod, for example an application running in the Cluster with two replicas or more. ","version":"Next","tagName":"h2"},{"title":"Grafana","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/addons/grafana","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Grafana","url":"/preview-docs/docs/cluster/addons/grafana#faqs","content":" Accessing Grafana​ To access Grafana, first you need to be connected to the VPN, then just click the Grafana button on the Sleakops console. tip When creating the grafana addon, Sleakops gives you the user and credential needed. You will be redirected to the Grafana login page. Once logged in, the Grafana interface will present a dashboard like this:  How it works​ Grafana as a monitoring tool, let's you directly connect to datasources within your cluster without extensive configuration. When installing Grafana, Sleakops configures Prometheus datasource, providing quick access to essential metrics through a centralized interface. When installing Loki or Otel, those datasources are also connected.  Provisioned Dashboards​ Grafana on Sleakops comes with a series of practical dashboards. They cover general system metrics, offering organized views to monitor various aspects of application performance and resource usage. These dashboards can be used out-of-the-box, offering consistent data visualizations that simplify ongoing system monitoring and management. Sleakops ships with these dashboards, to monitor Resource allocations: Kubernetes / Compute Resources / ClusterKubernetes / Compute Resources / Namespaces (Pods)Kubernetes / Compute Resources / Namespaces (Workloads)Kubernetes / Compute Resources / Nodes (Pods) These ones for networking: Kubernetes / Networking / ClusterKubernetes / Networking / Namespaces (Pods)Kubernetes / Networking / Namespaces (Workloads) And some others like CoreDNS which monitors this internal dns and service discovery system. All of them are useful to monitor the health of your cluster and the applications running on it. Specially to resize workloads, investigate if more replicas are needed or if the resources are well allocated. Dashboards are customizable, allowing you to adjust the layout and data displayed to suit your specific monitoring needs. Also you can create your own dashboards.  Viewing Deployment Resources​ To observe the resources used by a deployment, navigate to the resource monitoring dashboard in Grafana. Once logged in, go to: Home -&gt; Dashboards -&gt; Kubernetes / Compute Resources / Namespace (Pods) This dashboard is set up to display real-time data on CPU, memory, and disk usage, allowing you to track and manage the resources allocated to each deployment within your cluster. ","version":"Next","tagName":"h2"},{"title":"Kubecost: Cluster Cost Monitoring","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/addons/kubecost","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Kubecost: Cluster Cost Monitoring","url":"/preview-docs/docs/cluster/addons/kubecost#faqs","content":" What does the idle metric means?​ The 'idle' shown in all Kubecost metrics is a value that shows how much of the capacity of all your filtered options is not being used. Be careful, this value should be prudently analyzed as many of this &quot;idle&quot; capacity will be part of a Node that is not yet fully allocated or should be available for your workloads.  Should I be worried if my idle value is too high?​ No, you could optimize this value by reducing the CPU and Memory requests of the workloads deployed in your Project, but bear in mind that many of this capacity is allocated as a maximum limit for your resource utilization even if it is not being used, this gives space for the internal scaling of each workload in case it needs it. By the other side, many of these workloads are cluster-critical so they will have an &quot;idle&quot; capacity to let them scale freely.  Could I review a Namespace more deeply?​ Kubecost has a good granularity of how much specific you could be when analyzing costs, for example, besides Namespace costs you can start digging and by clicking the Namespace you can analyze the costs of the pods, deployments and others it has allocated on it.  Can I analyze something else beside namespaces?​ Yes, from the main dashboard you can analyze more specifically the costs of a specific Node as an entity. It also allows you to review the Storage costs that is being used. For example, for a specific node you could see this:  Does Kubecost has any feature to analyze Networking costs?​ At this moment SleakOps is making available the capacity to allow 'NetworkCosts' which is a feature of Kubecost that estimates the cost of the network traffic that each workload has. This feature is a really good choice if you want to analyze cluster network traffic more deeply. It can be allowed in the Kubecost form: ","version":"Next","tagName":"h2"},{"title":"Loki","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/addons/loki","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Loki","url":"/preview-docs/docs/cluster/addons/loki#faqs","content":" Which dashboards allow me to read logs?​ At this moment, Sleakops provide two dashboard to consult the logs that were recollected by Loki. Log Explorer: It's a simple dashboard that allows you to filter by Namespace, Pod, Container and Stream where you can choose between 'stdout' and 'stderr'. It also allows you to search expressions through the 'Search Query' field above.Container Log Dashboard: Similar to the previous but is more close to a Logs Dashboard that lets you analyze more complex cases that you might need. It's slower as it required more processing and for general querying it will not be needed.  Which is the best way to use Loki?​ Minimizing the time-range that is being queried is the best way for fast and error-free logs revision as this parameter is the one with the most influence in the weight of the response. We recommend to first check for a big picture of when the problem occured and then check in Loki for logs in a more specific time-range as, generally, logs quantities could be really high. Bear in mind that Loki contains small processing units for reading, writing and as a controller (backend) so big queries might be slow if not having enough read replicas or processing capacity on them. This is modifiable through Sleakops but will also increase costs.  How can I modify the processing capacity of Loki?​ SleakOps allows you to modify the processing capacity of the deployed Loki through the configuration of the Addon. One way of increasing its capacity is by modifying the quantity of replicas deployed.  How does Loki capture and store logs?​ Loki collects logs from each Node of the cluster and therefore, from every container that it's running on it. In order to achieve this, SleakOps uses Promtail that is the default log Collector for Loki, for that reason, every Node of the cluster will have a Promtail instance deployed on it that is in charge of scrapping and pushing them to the Loki write instance that after a certain period of time pushes it to the S3 for long-term storage.  How is the log collection process?​ The log collector, Promtail, collects and streams to Loki all the logs output through 'stdout' or 'stderr' from each running container in the cluster ","version":"Next","tagName":"h2"},{"title":"Creating a Node Pool","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/nodepools/creating-nodepool","content":"","keywords":"","version":"Next"},{"title":"1. Access your cluster's settings to access the Node Pools section​","type":1,"pageTitle":"Creating a Node Pool","url":"/preview-docs/docs/cluster/nodepools/creating-nodepool#1-access-your-clusters-settings-to-access-the-node-pools-section","content":" From the Cluster Listing, select one and access the Setting option. Then, click on the Node Pools box.    ","version":"Next","tagName":"h3"},{"title":"2. Click on Create​","type":1,"pageTitle":"Creating a Node Pool","url":"/preview-docs/docs/cluster/nodepools/creating-nodepool#2-click-on-create","content":" Into the Node Pool section, if you have permission, you'll find the Create option at the top right corner. Click on it.  Notice, that the quantity of Node Pools per Cluster might be limited by your plan.    ","version":"Next","tagName":"h3"},{"title":"3. Set up you node pool​","type":1,"pageTitle":"Creating a Node Pool","url":"/preview-docs/docs/cluster/nodepools/creating-nodepool#3-set-up-you-node-pool","content":" In the create Node Pool modal enter:  Setting\tDescriptionName\tEnter the name of your choice for your node pool. It cannot be repeated within a cluster. Instance Type\tSelect one or more instance types (e.g. t3.medium, m5.large, c5.xlarge) based on your compute requirements. You can choose multiple instance types to provide flexibility for the autoscaler to provision the most cost-effective available instance. Node Type\tSelect one or more billing models for your instances. You can choose multiple options, and the system will prioritize them in the following order: Reserved (best price with commitment) → Spot (best price without commitment) → On Demand (highest price but most flexible). See What are the different kind of node pools? Architecture Type\tSelect the architecture type to be used during the creation for your instances: (64-Bit) ARM or (64-Bit) X86, based on your performance and compatibility needs. Then you'll be able of creating new instances using a different architecture. Memory Limit\tThis sets the maximum memory the cluster can use as services scale. The autoscaler provisions instances based on demand, but this doesn't mean the cluster always uses the maximum memory; it just defines the upper limit for the autoscaler. CPU Limit\tThis sets the maximum CPU the cluster can use as services scale. The autoscaler provisions instances based on demand, but this doesn't mean the cluster always uses the maximum CPU; it just defines the upper limit for the autoscaler. Storage\tSet by default in 20GB, you can modify it based on your need. (Per Node) Minimum Memory\tDefines the minimum amount of memory that must be available on each node before the autoscaler considers the node as &quot;utilized&quot;. This setting helps prevent over-provisioning by ensuring nodes maintain a minimum memory buffer for system processes and unexpected workload spikes. (Per Node) Minimum CPU\tDefines the minimum amount of CPU that must be available on each node before the autoscaler considers the node as &quot;utilized&quot;. This setting helps prevent over-provisioning by ensuring nodes maintain a minimum CPU buffer for system processes and unexpected workload spikes.  Once you've completed the form, click on Create in order to trigger the node pool creation into the selected cluster. ","version":"Next","tagName":"h3"},{"title":"Prometheus: Monitoring System","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/addons/prometheus","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Prometheus: Monitoring System","url":"/preview-docs/docs/cluster/addons/prometheus#faqs","content":" Does Prometheus store metrics?​ Prometheus is not directly in charge of pushing metrics to S3, this is done by a related entity called Thanos.  How does SleakOps store Prometheus metrics?​ Prometheus has two related storage units: It depends on the EBS CSI Driver Addon for short-term storage.Uses S3 for long-term storage, this S3 is created in your Account in parallel with Prometheus.  Can I use Prometheus alone?​ It's main purpose is to collect metrics but it also includes a frontend that can be consumed portforwarding its Pod to make some specific queries to its data or to watch some metrics, but it is far easier and comfortable to watch them with Grafana. ","version":"Next","tagName":"h2"},{"title":"Open Telemetry","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/addons/otel","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Open Telemetry","url":"/preview-docs/docs/cluster/addons/otel#faqs","content":" How it works​ In order to use OpenTelemetry, you need to have a project instrumented with OpenTelemetry. Sleakops will deploy the necessary resources to collect and store the data. Instrumentation is the process of adding code to your application to collect telemetry data. OpenTelemetry provides libraries to instrument your application in a variety of languages. Also Sleakops offers Autoinstrumentation for some languages, learn more about it in the section Autoinstrumentation.  Traces and Metrics​ Telemetry data consist of three main components: traces, metrics and logs. For logs Sleakops offers Loki. Traces are the path of a request through the system, while metrics are the values of the system at a given time. The OpenTelemetry addon collects traces from the pods running your project and sends them to the OpenTelemetry collector. The collector stores the traces throw Tempo . Traces could be visualized in Grafana. Also the collector generates metrics via the SpanMetrics Connector and stores them in Prometheus. A dashboard is available in Grafana for every project that gets instrumented.  Using the Addon​ Let's dive in with a view of the OpenTelemetry dashboard. First three metrics are Request rates, Error rates and Durations, or RED metrics. These metrics are the most important to monitor the health of your application. Then we see a table that list Top operations (endpoints) and their error rate as well. Tipically the dashboard gives a quick look to problematic endpoints, application performance bottlenecks, as well as the overall health of the application.  Autoinstrumentation​ Sleakops offers autoinstrumentation for some languages. This means that Sleakops will automatically instrument your project with OpenTelemetry. This is done by deploying an init container alongside your project. The sidecar container will collect the telemetry data and send it to the OpenTelemetry collector.  Manual instrumentation​ Manual instrumentation resolves the implementation through code of OpenTelemetry in your project. This is done by adding the OpenTelemetry libraries to your project and adding the necessary code to collect the telemetry data. Sleakops presents the endpoint where the telemetry data should be sent.  What does Sleakops install when installing OpenTelemetry​ The stack deployed when the addon is installed is the following: OpenTelemetry Operator OpenTelemetry Collector Custom resource (CRD)OpenTelemetry Instrumentation Custom resource (CRD) for every autoinstrumentated projectTempo with a frontend, and caching enabledS3 Bucket as Tempo Backend  ","version":"Next","tagName":"h2"},{"title":"Start using OpenTelemetry​","type":1,"pageTitle":"Open Telemetry","url":"/preview-docs/docs/cluster/addons/otel#start-using-opentelemetry","content":" To start using OpenTelemetry, you need to install the addon. Then go to the Project list page, activate the project Instrumentation using the small white icon at the left of the name of the project.    These are the options you can choose from:  Option\tDescriptionEnabled\tEnable or disable instrumentation on this proyect. Autoinstrumentation\tOpt for autoinstrumentation. Read more on Autoinstrumentation and Manual Instrumentation Language\tIf autoinstrumentation is enabled, this option marks the language of the project. Currently GO, Java, NodeJS, Python and DotNet are available. Sample Rate\tIf autoinstrumentation is enabled, this option marks the sampling rate, where 0 is none and 1 is all the traces.  Projects that are instrumented are visible in the Project list page. Marked with a green icon, as in the image:   ","version":"Next","tagName":"h2"},{"title":"Node Pools","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/nodepools","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Node Pools","url":"/preview-docs/docs/cluster/nodepools#faqs","content":" What are the different kind of node pools?​ Reserved: are instances that you commit to using for a specific term (1 or 3 years) in exchange for significant cost savings (up to 75% less than On-Demand pricing). They provide the best price with commitment and are ideal for: Predictable Workloads: Applications with steady, predictable usage patterns that can benefit from long-term commitment.Production Environments: Critical applications that require guaranteed capacity and cost optimization.Cost Optimization: Workloads where you can commit to usage for extended periods to maximize savings. Spot: are instances that take advantage of spare capacity in a cloud provider's data center, offering up to 90% cost savings compared to On-Demand instances. While they can be terminated if the provider needs capacity back, this is not a limitation but an opportunity for well-architected applications. Ideal for: Cloud-Native Applications: Applications designed with stateless architecture that can handle pod interruptions and restart quickly.Cost-Optimized Workloads: Perfect for applications where significant cost savings (up to 90%) outweigh the need for guaranteed capacity.Resilient Systems: Applications with proper health checks, graceful shutdowns, and automatic restart capabilities. On-Demand: are instances in a Kubernetes cluster that run with a fixed pricing model, providing reliable access to compute resources without the risk of interruption. Can be used: Critical Workloads: Applications that require consistent uptime, such as databases, financial systems, or other critical services.Long-Running Tasks: Tasks that cannot be interrupted without significant consequence. Priority Order: When you select multiple node types, the system will automatically prioritize them in the following order to optimize costs: Reserved (best price with commitment) → Spot (best price without commitment) → On-Demand (highest price but most flexible). For detailed guidance on choosing the right instance types and evaluating application compatibility, see Instance Types and Node Management.  How many Node Pools can I have?​ SleakOps base plan, allows you to have three extra node pool besides the build ones. If you need more, contact us.  Can I convert a spot node pool into an on demand and viceversa?​ You can't directly convert a Spot node pool into an On-Demand node pool or vice versa, but you can achieve the desired outcome through a series of steps in SleakOps. Here’s how you can transition between node pools types: Create a Node Pool of the new desired type.Updade your workloads and projects to run into the new Node Pool.Delete the old node pool if it is not longer needed.  Can I convert a ARM node pool into an X86 and viceversa?​ You can't change the architect type of a node pool, but you can achieve the desired outcome through a series of steps in SleakOps. Here’s how you can transition between node pools architectures: Create a Node Pool of the new desired architecture.Update your workloads and projects to run into the new Node Pool.Delete the old node pool if it is not longer needed.  How do I create a Node Pool?​ Follow Creating a Node Pool  How do I manage my a Node Pool?​ Follow Managing a Node Pool ","version":"Next","tagName":"h2"},{"title":"Instance Types and Node Management","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/nodepools/instance-types","content":"","keywords":"","version":"Next"},{"title":"Available Instance Types​","type":1,"pageTitle":"Instance Types and Node Management","url":"/preview-docs/docs/cluster/nodepools/instance-types#available-instance-types","content":" ","version":"Next","tagName":"h2"},{"title":"1. Spot Instances​","type":1,"pageTitle":"Instance Types and Node Management","url":"/preview-docs/docs/cluster/nodepools/instance-types#1-spot-instances","content":" Spot instances take advantage of unused capacity in AWS data centers, offering significant discounts (up to 90% less than On-Demand) but with the risk of interruption.  Characteristics:  Cost: Up to 90% discount vs On-DemandAvailability: Variable, can be interrupted with 2 minutes noticeIdeal use: Fault-tolerant applications, batch processing, development environments  ","version":"Next","tagName":"h3"},{"title":"2. On-Demand Instances​","type":1,"pageTitle":"Instance Types and Node Management","url":"/preview-docs/docs/cluster/nodepools/instance-types#2-on-demand-instances","content":" On-Demand instances provide immediate and reliable access to compute resources with fixed pricing per hour or second.  Characteristics:  Cost: Fixed price, higher than SpotAvailability: Guaranteed, no interruption riskIdeal use: Critical applications, databases, production services  ","version":"Next","tagName":"h3"},{"title":"3. Reserved Instances​","type":1,"pageTitle":"Instance Types and Node Management","url":"/preview-docs/docs/cluster/nodepools/instance-types#3-reserved-instances","content":" Reserved instances offer significant discounts (up to 75%) in exchange for a usage commitment of 1 or 3 years.  Characteristics:  Cost: Up to 75% discount with commitmentAvailability: Guaranteed for the committed periodIdeal use: Predictable workloads, stable production environments  ","version":"Next","tagName":"h3"},{"title":"FAQs​","type":1,"pageTitle":"Instance Types and Node Management","url":"/preview-docs/docs/cluster/nodepools/instance-types#faqs","content":" How to evaluate if my application works with Spot instances?​ To determine if your application is compatible with Spot instances, evaluate the following aspects: ✅ IDEAL applications for Spot: Stateless: Don't maintain critical local stateFault-tolerant: Can recover from interruptionsBatch processing: Tasks that can be restartedDevelopment/Testing: Non-critical environmentsMicroservices: With circuit breakers and retry logicTested with FIS: Applications validated with AWS Fault Injection Simulator to test node interruptions ❌ Applications NOT recommended for Spot: Real-time applications: That require constant latencyLong-running processes: That cannot be easily restartedPayment systems: That require high availability  When should I use On-Demand instances?​ Use On-Demand instances in the following scenarios: Critical Applications: Payment and financial transaction systemsHigh-availability APIs (99.9%+ SLA)Authentication and authorization services Specific Workloads: Processes that cannot be interruptedApplications with strict latency requirementsLegacy systems that are not fault-tolerantProduction environments without redundancy Cost Considerations: When downtime cost exceeds Spot savingsFor workloads with unpredictable usage patternsIn cases where guaranteed capacity is critical ","version":"Next","tagName":"h2"},{"title":"Shutdown Cluster","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/shutdown-cluster","content":"","keywords":"","version":"Next"},{"title":"How can I activate this feature?​","type":1,"pageTitle":"Shutdown Cluster","url":"/preview-docs/docs/cluster/shutdown-cluster#how-can-i-activate-this-feature","content":" Cluster Shutdown should be manually activated in Cluster Settings through the &quot;Scheduled Shutdown&quot; card.      When you set the Cluster Shutdown, you're creating two cronjobs: one for turning ON the cluster at the scheduled time and another for turning it OFF. The configuration fields are the following:  Attribute\tDescriptionDays\tThe days that the Shutdown crons will run. Auto Downtime (Local Time)\tThe hour at which the OFF action runs. It is shown in your local time. Auto Uptime (Local Time)\tThe hour at which the ON action runs. It is shown in your local time.  Below you will see a box that shows 'Generated Cron Expressions (UTC)', which displays the OFF and ON cron expressions for these two actions in UTC time.  ","version":"Next","tagName":"h3"},{"title":"How can I shutdown my cluster at any time?​","type":1,"pageTitle":"Shutdown Cluster","url":"/preview-docs/docs/cluster/shutdown-cluster#how-can-i-shutdown-my-cluster-at-any-time","content":" In order to shutdown a cluster, just click on the Stop button and confirm the action.  This action can be performed just in Active clusters.  warning Shutdown requires that no dependencies are being updated, and no build or workload processes are active.    ","version":"Next","tagName":"h2"},{"title":"Turning On cluster​","type":1,"pageTitle":"Shutdown Cluster","url":"/preview-docs/docs/cluster/shutdown-cluster#turning-on-cluster","content":" To turn on a cluster, click on the Play button and confirm the action.  This action is available for clusters in Scheduled Shutdown and Off status    info The cron actions that turn the cluster ON or OFF based on the scheduled time will still run even if you have manually turned it ON or OFF. ","version":"Next","tagName":"h3"},{"title":"Managing a Node Pool","type":0,"sectionRef":"#","url":"/preview-docs/docs/cluster/nodepools/managing-nodepool","content":"","keywords":"","version":"Next"},{"title":"1. Access your cluster’s settings to access the Node Pools section​","type":1,"pageTitle":"Managing a Node Pool","url":"/preview-docs/docs/cluster/nodepools/managing-nodepool#1-access-your-clusters-settings-to-access-the-node-pools-section","content":" From the Cluster Listing, select a node pool and access the Setting option. Then, click on the Node Pools box.  ","version":"Next","tagName":"h3"},{"title":"2. Select the Node Pool​","type":1,"pageTitle":"Managing a Node Pool","url":"/preview-docs/docs/cluster/nodepools/managing-nodepool#2-select-the-node-pool","content":" Once you have selected your node pool, you’ll find the access to update and delete them. Each node pool is displayed with CPU and Memory bars that show you how much capacity is left. The full bar represents the total capacity of the node pool, while the colored portion indicates the combined capacity used by all associated projects/workloads.  ","version":"Next","tagName":"h3"},{"title":"Changing node pool setting​","type":1,"pageTitle":"Managing a Node Pool","url":"/preview-docs/docs/cluster/nodepools/managing-nodepool#changing-node-pool-setting","content":" ","version":"Next","tagName":"h2"},{"title":"1. Click the setting button at the top right of the node pool card​","type":1,"pageTitle":"Managing a Node Pool","url":"/preview-docs/docs/cluster/nodepools/managing-nodepool#1-click-the-setting-button-at-the-top-right-of-the-node-pool-card","content":" Update the parameters into the modal and click on Save.    ","version":"Next","tagName":"h3"},{"title":"Deleting a node pool​","type":1,"pageTitle":"Managing a Node Pool","url":"/preview-docs/docs/cluster/nodepools/managing-nodepool#deleting-a-node-pool","content":" ","version":"Next","tagName":"h2"},{"title":"1. Click the bin button at the top right of the node pool card​","type":1,"pageTitle":"Managing a Node Pool","url":"/preview-docs/docs/cluster/nodepools/managing-nodepool#1-click-the-bin-button-at-the-top-right-of-the-node-pool-card","content":" Click on Delete to confirm and trigger the action on SleakOps. ","version":"Next","tagName":"h3"},{"title":"Connect your Git Account","type":0,"sectionRef":"#","url":"/preview-docs/docs/connect_to_git","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Connect your Git Account","url":"/preview-docs/docs/connect_to_git#faqs","content":" Can I connect more than one Git Account?​ Not allowed yet.  How do I Connect my account?​ Access the Setting &gt;&gt; Autorizations section in SleakOps. Select your provider and grant access to SleakOps. See steps below.  Can I change my Git Account?​ Yes, you can do it by deleting de existing one and connecting the new one. Be sure the new account has access to the projects using in SleakOps.  How do I disconnect an account?​ By clicking in the X button next to the git provider. Consider that current projects will continue to function but won't be able to receive updates once this integration is removed. If you're using GitHub, you will also need to remove the Sleakops app from your GitHub account to complete the deletion process.  ","version":"Next","tagName":"h2"},{"title":"Set up your git Account​","type":1,"pageTitle":"Connect your Git Account","url":"/preview-docs/docs/connect_to_git#set-up-your-git-account","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navigate to the git authorization section​","type":1,"pageTitle":"Connect your Git Account","url":"/preview-docs/docs/connect_to_git#1-navigate-to-the-git-authorization-section","content":" Into the Left Pane, access the Settings option and then, click on Authorizations.    ","version":"Next","tagName":"h3"},{"title":"2. Select your Git provider and grant access to SleakOps​","type":1,"pageTitle":"Connect your Git Account","url":"/preview-docs/docs/connect_to_git#2-select-your-git-provider-and-grant-access-to-sleakops","content":" Click on your provider an follow the required steps for each one in order to grant access.    ","version":"Next","tagName":"h3"},{"title":"Integrations​","type":1,"pageTitle":"Connect your Git Account","url":"/preview-docs/docs/connect_to_git#integrations","content":" Github​  Gitlab​  Bitbucket​  Self-Hosted GitLab​ Connecting a self-hosted GitLab instance requires creating an OAuth application in your GitLab installation, as each self-hosted instance has a unique URL and authentication system. Prerequisites​ Administrator access to your self-hosted GitLab instanceYour GitLab instance must be accessible from the internet (SleakOps needs to communicate with it)HTTPS is strongly recommended for security Step 1: Create an OAuth Application in Your GitLab Instance​ Access the Applications page Navigate to your GitLab instance: https://yourgitlab.com/-/profile/applicationsOr go to: User Settings → Applications Create a new application Click &quot;Add new application&quot; or &quot;New application&quot;Fill in the following information: Field\tValueName\tSleakOps (or any descriptive name) Redirect URI\thttps://api.sleakops.com/api/integrations/self-gitlab/callback/ Scopes\tSelect api and offline_access (required for persistent access and automatic token renewal) warning The Redirect URI must be exactly as shown below (including the trailing slash): https://api.sleakops.com/api/integrations/self-gitlab/callback/ Do not modify this URL. Save the application Click &quot;Save application&quot; or &quot;Submit&quot;You will be shown two important values: Application ID (Client ID)Secret (Client Secret) caution Copy both the Application ID and Secret immediately. The Secret will only be shown once and cannot be retrieved later. tip Store these credentials securely. If you lose the Secret, you'll need to regenerate the OAuth application. Step 2: Connect Your Self-Hosted GitLab to SleakOps​ Navigate to SleakOps Authorizations Log in to your SleakOps accountGo to Settings → Authorizations Select Self-Hosted GitLab Click on &quot;Self-Hosted GitLab&quot; integration option Enter your OAuth application details GitLab Instance URL: Enter your GitLab instance URL (e.g., https://gitlab.yourcompany.com) Do not include a trailing slashMust start with http:// or https:// Application ID: Paste the Application ID from Step 1Application Secret: Paste the Secret from Step 1 Authorize SleakOps Click &quot;Connect&quot; or &quot;Authorize&quot;You will be redirected to your GitLab instanceReview the permissions and click &quot;Authorize&quot;You will be redirected back to SleakOps Verify the connection Once redirected, you should see your self-hosted GitLab account listed as connectedYou can now select repositories from your self-hosted GitLab instance when creating projects What permissions does SleakOps need?​ SleakOps requires two scopes: api scope grants the following permissions: Read repository information and file contentsCreate and manage branchesCreate and update files (for automated deployments)Create merge requestsAccess commit information offline_access scope allows SleakOps to: Obtain a refresh token for long-term accessAutomatically renew expired access tokensMaintain persistent connection without requiring re-authorization warning Without offline_access, the access token will expire after ~2 hours and the integration will break until manually re-authorized. These permissions are required for SleakOps to clone your repositories, build container images, deploy applications, and manage infrastructure-as-code. Troubleshooting​ Connection fails with &quot;Invalid URL&quot; error​ Ensure your GitLab instance URL does not end with a trailing slashVerify the URL starts with http:// or https://Example: ✅ https://gitlab.company.com ❌ https://gitlab.company.com/ Authorization redirects but connection fails​ Verify the Redirect URI in your GitLab OAuth application matches exactly: https://api.sleakops.com/api/integrations/self-gitlab/callback/Check that the Application ID and Secret are correctEnsure both api and offline_access scopes were selected when creating the OAuth application Network/Firewall issues​ Ensure your self-hosted GitLab instance is accessible from SleakOps serversIf your GitLab is behind a firewall, you may need to whitelist SleakOps IP addressesContact SleakOps support for IP whitelist information SSL/Certificate errors​ Self-signed certificates may cause connection issuesUse a valid SSL certificate from a trusted certificate authorityEnsure your GitLab instance has proper HTTPS configuration ","version":"Next","tagName":"h2"},{"title":"Domain Levels & Strategies","type":0,"sectionRef":"#","url":"/preview-docs/docs/domain","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#overview","content":"     ","version":"Next","tagName":"h2"},{"title":"1. Provider Domain (Root Level)​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#1-provider-domain-root-level","content":" What it is: Your organization's root domain.  Example: sleakops.com  What Sleakops creates:  ✅ AWS Hosted Zone✅ SSL Certificate  Use case:Establishes your main domain infrastructure. All environments and services will be organized under this domain.  When to use:  Setting up Sleakops for the first timeManaging your organization's primary domain    ","version":"Next","tagName":"h2"},{"title":"2. Environment Domain (Subdomain Level)​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#2-environment-domain-subdomain-level","content":" What it is: Subdomains representing different environments.  Examples:  qa.sleakops.comstaging.sleakops.comprod.sleakops.com  What Sleakops creates:  ✅ AWS Hosted Zone✅ SSL Certificate  Use case:Isolate and organize your deployment environments. Each environment gets its own subdomain with independent DNS management.  When to use:  Creating separate environments (development, staging, production)Isolating teams or projectsManaging multiple deployment stages    ","version":"Next","tagName":"h2"},{"title":"3. Webservice Domain (Auto-generated)​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#3-webservice-domain-auto-generated","content":" What it is: Automatic domain assignment for each webservice.  Pattern: [webservice-name].[environment-domain]  Example:  Webservice name: apiEnvironment: qa.sleakops.comResult: api.qa.sleakops.com  What Sleakops creates:  ✅ CNAME record (automatically added to the environment's hosted zone)✅ Points to Application Load Balancer (ALB)  Use case:Zero-configuration domain setup. Each service automatically gets a predictable, hierarchical domain.  When to use:  Default scenario for all webservicesWhen you want consistent, predictable URLsQuick deployments without custom domain configuration    ","version":"Next","tagName":"h2"},{"title":"4. Alias Domains (Custom Level)​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#4-alias-domains-custom-level","content":" What it is: Custom domains outside your standard hierarchy.  Examples:  api.external-domain.comwww.mycompany.ioanything.com  What Sleakops does:  ","version":"Next","tagName":"h2"},{"title":"Scenario A: Domain matches an existing hosted zone​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#scenario-a-domain-matches-an-existing-hosted-zone","content":" If external-domain.com is already a Provider or Environment in Sleakops:  ✅ Provides DNS records for SSL certificate validation✅ Provides ALB name for DNS configuration⚠️ You configure the DNS records yourself  ","version":"Next","tagName":"h3"},{"title":"Scenario B: Domain doesn't match any hosted zone​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#scenario-b-domain-doesnt-match-any-hosted-zone","content":" If anything.com is completely external:  ✅ Creates SSL certificate✅ Provides validation records for certificate✅ Provides ALB name for DNS configuration⚠️ You manage DNS at your domain provider  Use case:  Custom branded domainsExternal domains pointed to your servicesMarketing or vanity URLsMulti-domain services  When to use:  The default webservice domain doesn't fit your needsYou need multiple domains for the same serviceConnecting external domains to your Sleakops services    ","version":"Next","tagName":"h3"},{"title":"Delegation Strategies​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#delegation-strategies","content":" Sleakops offers three delegation approaches, giving you flexibility based on your infrastructure needs and organizational policies.  ","version":"Next","tagName":"h2"},{"title":"Strategy A: Full Delegation (Recommended)​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#strategy-a-full-delegation-recommended","content":" Delegate the Provider (root domain) and let Sleakops manage everything    What you delegate:​  Provider domain nameservers to AWS Route 53  What Sleakops manages automatically:  ✅ All environment domains (hosted zones + SSL certificates)✅ All webservice domains (CNAME records + routing)✅ DNS propagation and validation✅ Complete SSL certificate lifecycle  Benefits:  🚀 Zero DNS configuration after initial delegation🔒 Automated SSL certificate management🎯 Fully managed infrastructure⚡ Fastest deployment experience  Best for:  New projects starting freshTeams wanting minimal DNS overheadOrganizations embracing fully-managed solutionsStartups and fast-moving teams  Setup:  Delegate your root domain (e.g., sleakops.com) to Sleakops Everything else is automatic    ","version":"Next","tagName":"h3"},{"title":"Strategy B: Per-Environment Delegation​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#strategy-b-per-environment-delegation","content":" Delegate individual environment domains while keeping root domain control    What you delegate:​  Individual environment domain nameservers (e.g., qa.sleakops.com, prod.sleakops.com)  What Sleakops manages automatically:  ✅ All webservice domains within delegated environments✅ SSL certificates for delegated environments✅ DNS records within delegated zones  What you manage:  ⚙️ Root domain DNS⚙️ NS records pointing to each environment  Benefits:  🎛️ Control root domain for other purposes (email, marketing sites, etc.)🔒 Isolated environment management✅ Automatic webservice DNS within each environment🏢 Compliance with organizational DNS policies  Best for:  Organizations with existing root domain infrastructureTeams needing root domain for non-Sleakops servicesGradual migration to SleakopsMulti-team organizations with environment-level isolation  Setup:  Keep your root domain (e.g., sleakops.com) managed externally Delegate each environment (e.g., qa.sleakops.com) to Sleakops Add NS records in your root domain DNS for each environment    ","version":"Next","tagName":"h3"},{"title":"Strategy C: Full Control (Manual Management)​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#strategy-c-full-control-manual-management","content":" Retain complete DNS control and manually configure all records    What you delegate:​  Nothing - you manage all DNS  What Sleakops provides:  📋 DNS records for SSL certificate validation📋 ALB endpoints for traffic routing  What you manage:  ⚙️ All DNS zones and records⚙️ Certificate validation records⚙️ CNAME records pointing to ALB⚙️ All DNS updates and changes  Benefits:  🎛️ Complete DNS infrastructure control🔐 Keep DNS within existing security boundaries📊 Integration with existing DNS monitoring🏢 Meet strict compliance requirements  Best for:  Organizations with strict DNS governanceExisting complex DNS infrastructureSecurity policies requiring DNS isolationEnterprises with dedicated DNS teams  Setup:  Create domains in Sleakops (no delegation) Sleakops provides validation records and ALB endpoints Manually add all required DNS records in your DNS provider    ","version":"Next","tagName":"h3"},{"title":"Delegation Strategy Comparison​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#delegation-strategy-comparison","content":" Aspect\tFull Delegation\tPer-Environment\tFull ControlSetup Complexity\t⭐ Easiest\t⭐⭐ Moderate\t⭐⭐⭐ Complex Ongoing Maintenance\t⭐ None\t⭐⭐ Minimal\t⭐⭐⭐ High Flexibility\t⭐⭐ Limited\t⭐⭐⭐ Balanced\t⭐⭐⭐⭐ Maximum Time to Deploy\t⚡ Instant\t⚡⚡ Minutes\t⚡⚡⚡ Manual DNS Control\tSleakops\tShared\tYou Best for Teams\tSmall-Medium\tMedium-Large\tEnterprise    ","version":"Next","tagName":"h3"},{"title":"Domain Organization Patterns​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#domain-organization-patterns","content":" ","version":"Next","tagName":"h2"},{"title":"Pattern 1: Standard Hierarchy (Works with any delegation strategy)​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#pattern-1-standard-hierarchy-works-with-any-delegation-strategy","content":"   Benefits:  Clear environment separationEasy to understand and manageAutomatic SSL and DNS    ","version":"Next","tagName":"h3"},{"title":"Pattern 2: Mixed Hierarchy with Custom Domains​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#pattern-2-mixed-hierarchy-with-custom-domains","content":"   Benefits:  Professional customer-facing domainsMaintains internal structureFlexibility for white-labelingRequires manual DNS for aliases (all strategies)    ","version":"Next","tagName":"h3"},{"title":"Pattern 3: Environment per Team/Project​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#pattern-3-environment-per-teamproject","content":"   Benefits:  Clear team ownershipIndependent DNS management per teamScalable for large organizations    ","version":"Next","tagName":"h3"},{"title":"Quick Decision Guide​","type":1,"pageTitle":"Domain Levels & Strategies","url":"/preview-docs/docs/domain#quick-decision-guide","content":" Need\tRecommended StrategyFastest setup\tFull Delegation Keep root for email/other services\tPer-Environment Delegation Maximum DNS control\tFull Control Gradual migration\tPer-Environment Delegation Strict compliance\tFull Control New project\tFull Delegation Enterprise with DNS team\tFull Control or Per-Environment  Task\tToolFirst time setup\tProvider Domain Create new environment\tEnvironment Domain Deploy a service\tWebservice (automatic) Custom branded URL\tAlias Domain External domain integration\tAlias Domain White-label solution\tAlias Domain ","version":"Next","tagName":"h2"},{"title":"Overview","type":0,"sectionRef":"#","url":"/preview-docs/docs/domain/setup","content":"","keywords":"","version":"Next"},{"title":"Set up your domains​","type":1,"pageTitle":"Overview","url":"/preview-docs/docs/domain/setup#set-up-your-domains","content":" ","version":"Next","tagName":"h2"},{"title":"1. Access to the domain or subdomain information​","type":1,"pageTitle":"Overview","url":"/preview-docs/docs/domain/setup#1-access-to-the-domain-or-subdomain-information","content":" SleakOps provides a detailed information regarding domains, subdomains and alias. That looks like:    To access it, there are are different ways, based on what you need to do:  If you want to delegate your main domain​  a. Access the Dashboard and look for the domain widget. b. Click on the desired domain to display the detail.    To delegate an environment’s subdomain​  a. Access the Environment’s list and select an Environment. b. Click on the Cloud icon to display the domain detail.  Create an Alias for a web service workload and delegate it​  a. Access the Workload’s list and then, the Web services section. b. Select and Workload and click on the Three Dots button. c. Choose the Detail option d. Create the Alias if it doesn’t exist by clicking the Associate new Domain and completing the form. e. Click on the Alias domain to display the detail.      ","version":"Next","tagName":"h3"},{"title":"2. Update Name Servers with Domain Registrar​","type":1,"pageTitle":"Overview","url":"/preview-docs/docs/domain/setup#2-update-name-servers-with-domain-registrar","content":" Log in to the account where your domain is registered (e.g., GoDaddy, Namecheap, etc.).Locate the DNS settings for your domain.Replace the existing records with the ones provided.  ","version":"Next","tagName":"h3"},{"title":"3. Update Name Servers with Domain Registrar​","type":1,"pageTitle":"Overview","url":"/preview-docs/docs/domain/setup#3-update-name-servers-with-domain-registrar","content":" It may take some time for the DNS changes to propagate globally (usually within a few hours).SleakOps periodically checks it but, if you want to manually verify it, you can click the yellow button Check Delegation to trigger the process.   ","version":"Next","tagName":"h3"},{"title":"Environment","type":0,"sectionRef":"#","url":"/preview-docs/docs/environment","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Environment","url":"/preview-docs/docs/environment#faqs","content":" How can I design my environments?​ Environments can be tailored based on an application's lifecycle or the needs of different teams. For example, creating environments for development (dev), quality assurance (QA), staging (stg), and production (prod) allows each to have custom settings suitable for their specific roles. Before creating an environment, read Designing your Infra: Single Schema Vs. Multi Schema   Can I edit an environment?​ No. You must delete it and create a new one.  How do I delete an environment?​ Access the Environment List, on the Action column, click on the bin icon. Then confirm the action.  How can I delegate a domain?​ Follow: Delegate Domains  warning Your DNS service must be delegated to the Primary Route53 of SleakOps manually. Follow the steps described on this link .  ","version":"Next","tagName":"h2"},{"title":"Set up your Environment​","type":1,"pageTitle":"Environment","url":"/preview-docs/docs/environment#set-up-your-environment","content":" 1. Navigate to the Environment section​  Into the Left Pane, access the Environments option and then, at the top right corner, click on the Create button.    2. Configure your Environment​  With your Account selected, you will access the following form:    Setting\tDescriptionName\tDefine a name for your environment using down case letters and middle dashes. Cluster\tSelect one of the available clusters to host the new environment. Domain\tSpecify the domain for your environment.  Once you’ve completed the form, click on Create in order to trigger the environment creation into the selected cluster. ","version":"Next","tagName":"h2"},{"title":"Getting Started","type":0,"sectionRef":"#","url":"/preview-docs/docs/gettingstarted","content":"","keywords":"","version":"Next"},{"title":"Sign in with your email​","type":1,"pageTitle":"Getting Started","url":"/preview-docs/docs/gettingstarted#sign-in-with-your-email","content":" Sign in to our web app.    info In case you do not have an account with us, you need to subscribe using AWS. Follow How to subscribe to SleakOps using AWS.  ","version":"Next","tagName":"h2"},{"title":"Requirements to Join​","type":1,"pageTitle":"Getting Started","url":"/preview-docs/docs/gettingstarted#requirements-to-join","content":" You need to have a root user on AWS. It is the initial account created with full permissions to manage all resources and services, serving as the primary account for AWS Organizations. Go to AWS Organizations.You need access to your code repositories (GitLab, Bitbucket or GitHub).You need your services in Docker files.You need to be able to manage your domains. ","version":"Next","tagName":"h3"},{"title":"Network Resources","type":0,"sectionRef":"#","url":"/preview-docs/docs/network","content":"","keywords":"","version":"Next"},{"title":"1. Overview of the Architecture​","type":1,"pageTitle":"Network Resources","url":"/preview-docs/docs/network#1-overview-of-the-architecture","content":" The SleakOps network infrastructure is based on the following key components:  VPC (Virtual Private Cloud): Segregates networks by environment (Management, Production, Development).Subnets: Public: exposed to the Internet.Private: restricted access, Internet access via NAT Gateway.Persistence: for databases and storage. Internet Gateway: Enables communication between the VPC and the Internet.Route Tables: Define routing paths between subnets and to/from the Internet.Security Groups: Virtual firewalls that control inbound and outbound traffic for resources.Internal DNS: Allows internal resources to communicate using hostnames instead of IP addresses.External-DNS: Runs inside each Kubernetes (EKS) cluster and automatically manages public DNS records in Route53 for exposed services.  ","version":"Next","tagName":"h2"},{"title":"2. Typical Communication Flow​","type":1,"pageTitle":"Network Resources","url":"/preview-docs/docs/network#2-typical-communication-flow","content":" The following illustrates a typical flow of network traffic in SleakOps:  Access from the Internet: A user accesses a publicly exposed service (e.g., an API). Traffic reaches the Internet Gateway and is routed to the public subnet. Access Control: The Security Group associated with the resource evaluates whether the connection is allowed. Internal Communication: Internal services (in private or persistence subnets) communicate using internal DNS, under Security Group rules. Service Exposure: If a service within a Kubernetes cluster needs to be publicly accessible (e.g., an API), it is exposed via an Application Load Balancer, and External-DNS registers the public domain automatically in Route53.  This segmentation and control ensure that only necessary services are exposed while keeping sensitive data protected.    ","version":"Next","tagName":"h2"},{"title":"3. External-DNS and Route53​","type":1,"pageTitle":"Network Resources","url":"/preview-docs/docs/network#3-external-dns-and-route53","content":" An automated solution is used to manage public DNS records for deployed services, integrating the infrastructure with external DNS providers like Route53.  External-DNS does not expose services directly. It automates DNS record management for resources that are already exposed (e.g., via an Application Load Balancer).This allows services to be securely and easily accessible from the Internet.  ","version":"Next","tagName":"h2"},{"title":"4. Cross-Environment Connectivity via VPC Peering​","type":1,"pageTitle":"Network Resources","url":"/preview-docs/docs/network#4-cross-environment-connectivity-via-vpc-peering","content":" To enable controlled communication between environments (e.g., between Management and Production), SleakOps sets up VPC Peering connections between the different VPCs.  VPC Peering enables two VPCs to exchange internal traffic as if they were part of the same network.It does not require Internet, NAT Gateway, or VPN traffic routing.It is a direct connection between two networks.  💡 Besides Internet Gateway access, SleakOps also supports other connectivity options such as Pritunl VPN, NAT Gateway, and Transit Gateway, depending on use case and required isolation level. ","version":"Next","tagName":"h2"},{"title":"Domain Delegation Guide","type":0,"sectionRef":"#","url":"/preview-docs/docs/domain/delegation","content":"","keywords":"","version":"Next"},{"title":"Overview​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#overview","content":" When Sleakops creates a hosted zone, you need to delegate the domain by updating DNS records at your domain provider (registrar). This guide explains the process for each domain level.    ","version":"Next","tagName":"h2"},{"title":"Provider Domain Delegation​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#provider-domain-delegation","content":" ","version":"Next","tagName":"h2"},{"title":"What you're delegating​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#what-youre-delegating","content":" Your root domain (e.g., sleakops.com) to AWS Route 53 via Sleakops.    ","version":"Next","tagName":"h3"},{"title":"Steps​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#steps","content":" Create the Provider domain in Sleakops Sleakops creates a hosted zone in AWS Route 53You'll see a table with 4 nameserver (NS) records Locate the nameservers  ns-123.awsdns-12.com ns-456.awsdns-45.net ns-789.awsdns-78.org ns-012.awsdns-01.co.uk   Update your domain registrar Log into your domain registrar (GoDaddy, Namecheap, Google Domains, etc.)Find the DNS or Nameserver settingsReplace existing nameservers with the 4 AWS nameservers from SleakopsSave changes Verify delegation Click &quot;Check Delegate&quot; button in SleakopsWait for DNS propagation (can take up to 48 hours, usually faster)Green checkmark indicates successful delegation  ","version":"Next","tagName":"h3"},{"title":"Common Registrars​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#common-registrars","content":" GoDaddy Go to Domain ManagerClick on your domainScroll to &quot;Nameservers&quot; → Click &quot;Change&quot;Select &quot;Enter my own nameservers (advanced)&quot;Add all 4 AWS nameserversSave  Namecheap Go to Domain ListClick &quot;Manage&quot; next to your domainSelect &quot;Custom DNS&quot; under NameserversAdd all 4 AWS nameserversClick the green checkmark  Cloudflare Note: If using Cloudflare, you must disable Cloudflare proxy for proper delegation. Remove the domain from Cloudflare, ORUpdate nameservers to AWS (removes Cloudflare DNS management)    ","version":"Next","tagName":"h3"},{"title":"Environment Domain Delegation​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#environment-domain-delegation","content":" ","version":"Next","tagName":"h2"},{"title":"What you're delegating​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#what-youre-delegating-1","content":" A subdomain (e.g., qa.sleakops.com) to its own hosted zone.    ","version":"Next","tagName":"h3"},{"title":"Two Scenarios​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#two-scenarios","content":" Scenario A: Parent domain IS managed by Sleakops​    Good news! Sleakops automatically creates the NS records in the parent hosted zone.  ✅ No action needed - delegation is automatic    Scenario B: Parent domain is NOT managed by sleakops​    If sleakops.com is managed outside Sleakops, but you want qa.sleakops.com in Sleakops:  Create the Environment domain in Sleakops Sleakops creates a hosted zoneYou'll see 4 nameserver records Add NS records to parent domain Go to wherever sleakops.com DNS is managed (registrar, Cloudflare, etc.)Create 4 NS records for the subdomain:  Record Type: NS Name: qa Value: ns-123.awsdns-12.com Record Type: NS Name: qa Value: ns-456.awsdns-45.net (repeat for all 4 nameservers)   Verify delegation Click &quot;Check Delegate&quot; in SleakopsWait for DNS propagation (usually 5-30 minutes)    ","version":"Next","tagName":"h3"},{"title":"Webservice Domain Configuration​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#webservice-domain-configuration","content":" ","version":"Next","tagName":"h2"},{"title":"What happens​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#what-happens","content":" Webservice domains (e.g., api.qa.sleakops.com) are automatically configured.    ✅ No delegation needed - Sleakops automatically:  Creates CNAME record in the environment's hosted zonePoints to the Application Load Balancer (ALB)Configures SSL certificate  You don't need to do anything!    ","version":"Next","tagName":"h3"},{"title":"Alias Domain Configuration​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#alias-domain-configuration","content":" Alias domains require manual DNS configuration at your domain provider.  ","version":"Next","tagName":"h2"},{"title":"Scenario A: Alias matches existing hosted zone​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#scenario-a-alias-matches-existing-hosted-zone","content":" Example: Your alias is api.external.com and you already have external.com as a Provider or Environment in Sleakops.    For SSL Certificate Validation​  Sleakops provides validation records You'll see CNAME records for certificate validationExample:  _acme-challenge.api.external.com → _validation123.acme.aws.com   Add validation records to your DNS Go to the hosted zone for external.com (in Sleakops or wherever it's managed)Add the CNAME records exactly as shownWait for certificate validation (usually 5-15 minutes)  For Traffic Routing​  Sleakops provides ALB endpoint You'll see the ALB DNS name:  ALB: my-alb-123456.us-east-1.elb.amazonaws.com   Create CNAME record Go to your DNS management for external.comCreate a CNAME record:  Record Type: CNAME Name: api Value: my-alb-123456.us-east-1.elb.amazonaws.com TTL: 300   Verify Test the domain: curl https://api.external.comShould return your service response    ","version":"Next","tagName":"h3"},{"title":"Scenario B: Alias doesn't match any hosted zone​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#scenario-b-alias-doesnt-match-any-hosted-zone","content":" Example: Your alias is anything.com and this domain is not managed in Sleakops.    For SSL Certificate​  Sleakops creates SSL certificate Certificate validation records are providedExample:  _acme-challenge.anything.com → _validation456.acme.aws.com  Add validation records Log into your domain provider for anything.comAdd the CNAME records for certificate validationWait for validation (5-15 minutes)  For Traffic Routing​  Sleakops provides ALB endpoint  ALB: my-alb-789012.us-east-1.elb.amazonaws.com  Configure DNS at your provider Option 1: CNAME (for subdomains)  Record Type: CNAME Name: www (or subdomain) Value: my-alb-789012.us-east-1.elb.amazonaws.com   Option 2: A Record with ALIAS (for root domain)  Some providers support ALIAS records (Route 53, Cloudflare)  Record Type: A (ALIAS) Name: @ (root) Value: my-alb-789012.us-east-1.elb.amazonaws.com   Option 3: A Record with IP (not recommended)  Lookup ALB IPs and create A records⚠️ IPs may change - use CNAME when possible  Verify Test: curl https://anything.comEnsure SSL certificate is valid    ","version":"Next","tagName":"h3"},{"title":"Verification Checklist​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#verification-checklist","content":" ","version":"Next","tagName":"h2"},{"title":"Provider/Environment Domain​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#providerenvironment-domain","content":"  Nameservers updated at registrar &quot;Check Delegate&quot; button shows success DNS lookup returns correct nameservers: dig NS yourdomain.com  ","version":"Next","tagName":"h3"},{"title":"Webservice Domain​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#webservice-domain","content":"  Webservice is deployed and running Domain resolves: curl https://api.qa.sleakops.com SSL certificate is valid (no browser warnings) DNS lookup returns correct CNAME: dig CNAME api.qa.sleakops.com  ","version":"Next","tagName":"h3"},{"title":"Alias Domain​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#alias-domain","content":"  Certificate validation records added Certificate shows as validated in Sleakops CNAME/A record points to ALB Domain resolves: curl https://your-alias.com DNS lookup returns correct CNAME: dig CNAME your-alias.com SSL certificate is valid    ","version":"Next","tagName":"h3"},{"title":"Troubleshooting​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#troubleshooting","content":" ","version":"Next","tagName":"h2"},{"title":"\"Check Delegate\" fails​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#check-delegate-fails","content":"   Issue: Nameservers not properly delegated  Solutions:  Verify you added ALL 4 nameserversCheck for typos in nameserver valuesWait longer (DNS propagation can take up to 48 hours)Clear DNS cache: dig @8.8.8.8 yourdomain.comVerify at registrar that changes were saved    ","version":"Next","tagName":"h3"},{"title":"Certificate validation stuck​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#certificate-validation-stuck","content":" Issue: SSL certificate not validating  Solutions:  Verify CNAME records are added correctly (no extra dots, correct values)Check TTL hasn't expiredRemove any conflicting DNS recordsWait 15-30 minutes for DNS propagationCheck DNS: dig _acme-challenge.yourdomain.com    ","version":"Next","tagName":"h3"},{"title":"Domain not resolving​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#domain-not-resolving","content":" Issue: Domain doesn't load your service  Solutions:  Verify CNAME/A record points to correct ALB endpointCheck ALB is healthy and receiving trafficVerify webservice is deployed and runningTest with curl -v https://yourdomain.com for detailed errorsCheck security groups allow traffic on port 443    ","version":"Next","tagName":"h3"},{"title":"SSL certificate errors in browser​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#ssl-certificate-errors-in-browser","content":" Issue: Browser shows &quot;Not Secure&quot; or certificate warnings  Solutions:  Verify certificate is validated in SleakopsCheck certificate includes your domain nameClear browser cacheVerify correct certificate is attached to ALB listenerCheck certificate hasn't expired    ","version":"Next","tagName":"h3"},{"title":"DNS Propagation Time​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#dns-propagation-time","content":" Change Type\tTypical Time\tMaximum TimeNameserver update\t15-30 minutes\t48 hours CNAME record\t5-15 minutes\t24 hours A record\t5-15 minutes\t24 hours Certificate validation\t5-15 minutes\t30 minutes  💡 Tip: Use https://dnschecker.org to check DNS propagation globally    ","version":"Next","tagName":"h2"},{"title":"Need Help?​","type":1,"pageTitle":"Domain Delegation Guide","url":"/preview-docs/docs/domain/delegation#need-help","content":" Check Domain Levels &amp; StrategiesContact Sleakops support with your domain configuration details ","version":"Next","tagName":"h2"},{"title":"Project","type":0,"sectionRef":"#","url":"/preview-docs/docs/project","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Project","url":"/preview-docs/docs/project#faqs","content":" What is a Project or Namespace?​ A Project is the combination of a repository and an environment. It acts as a Kubernetes Namespace in the cluster and contains all the services and resources related to the project within that environment.  How do I create a Project in SleakOps?​ The Project and the Project will be created at the same time. You need to connect your Git account (e.g., GitHub, GitLab, or Bitbucket) to SleakOps, select a repository, choose a branch, and specify the location of the Dockerfile. Once these steps are completed, a ProjectEnv is created, and the first image build is triggered. Follow the steps below.  What happens when I create a Project?​ When a Project is created, the following resources are set up: AWS Elastic Container Registry (ECR) to store container images and Helm charts.A Kubernetes Namespace to manage services in isolation.A Service Account to handle permissions and secure connections with AWS resources.A Dockerfile analysis to verify its correctness and build a container image using Kaniko  How do I add the Dockerfile Args?​ If any build-time Docker Args (arguments) are required, SleakOps will prompt you to enter them before running the initial build. These arguments can be modified for future builds.  What is the purpose of the Dockerfile in my project?​ The Dockerfile defines how your application is built into a container image. During Project creation, SleakOps analyzes the Dockerfile to ensure it's correctly configured, and then builds the image using Kaniko.  Where are the Docker images stored?​ Docker images are stored in the AWS ECR (Elastic Container Registry) associated with your project. The images are named after the Project, which combines the environment name and project name.  What is the role of the Service Account?​ The Service Account manages permissions for resources inside the Kubernetes cluster. It allows services deployed in the Project to securely interact with AWS resources like S3, RDS, or any other service your application may require.  Can I update the repository, branch, or Dockerfile path after creating a Project?​ Just the Branch and the Dockerfile Path can be updated. If you need to work with a different Environment, Repository or Name, you will need to create a new record.  How does SleakOps handle the initial image build?​ SleakOps automates the first image build as part of the Project creation process. This initial build ensures faster deployment by utilizing the existing infrastructure. Afterward, future image builds are triggered when services are published in deployments or manually via the Build Form.  How do I control project’s expenses?​ SleakOps allows you to see all your project expenses in one place, classified by account, resources, dates. Access Projects, select one and click the button:  How do I monitor my project?​ You can monitor your project by accessing Projects, selecting one **and clicking into the button:   How do I create a Kubernetes Volume?​ When editing a Project, you can enable and define Kubernetes Volumes by specifying the mount path and storage capacity. SleakOps uses the AWS EFS CSI Driver to manage these volumes as EFS file systems in the EKS cluster.  🚩 How do I manage future builds and deployments?​ Future builds and deployments can be managed manually via the SleakOps interface or automated using the SleakOps CLI.  ","version":"Next","tagName":"h2"},{"title":"Lets create your first Project on SleakOps​","type":1,"pageTitle":"Project","url":"/preview-docs/docs/project#lets-create-your-first-project-on-sleakops","content":" warning You must have your Git Repository connected. See Connect your Git Account  ","version":"Next","tagName":"h2"},{"title":"1. Navigate to Create Project section​","type":1,"pageTitle":"Project","url":"/preview-docs/docs/project#1-navigate-to-create-project-section","content":" Into the Left Pane, access Projects option and then, at the top right corner, click on the Create button.    ","version":"Next","tagName":"h3"},{"title":"2. Set up your Project​","type":1,"pageTitle":"Project","url":"/preview-docs/docs/project#2-set-up-your-project","content":" You will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Setting\tDescriptionName\tIdentify your Project. Environment\tThe environment represents a specific stage or setup within your infrastructure where your project will be deployed (e.g., Development, Staging, Production). You are associating your project’s code with a particular environment in your Kubernetes cluster. Repository\tThe repository is the Git repository that holds the codebase for your project. SleakOps will access this repository to manage code updates, builds, and deployments. Ensure that you have connected your Git provider (e.g., GitHub, GitLab, Bitbucket) and that the selected repository contains all necessary files for your project. Nodepool\tIs the resource in charge of provision the server where your services will run. More info here. Branch\tThe branch represents a specific version or line of development within the repository. This allows you to deploy a particular version of your code (e.g., main, develop, or a feature-specific branch). The branch you select will determine the code that gets built and deployed within the associated environment. Dockerfile Path\tThe Dockerfile is a critical component used to build your project into a container. The Dockerfile Path field requires the relative file path to your Dockerfile within the repository (e.g., /Dockerfile, /src/Dockerfile, or /app/Dockerfile). This file contains the instructions needed to create the container image, which SleakOps will build and later use for deployments.  Once you've completed the form, click on Submit in order to trigger the Dockerfile validation and then the build.  ","version":"Next","tagName":"h3"},{"title":"ProjectAccess​","type":1,"pageTitle":"Project","url":"/preview-docs/docs/project#projectaccess","content":" ProjectAccess allows you to configure custom IAM policies and roles for your project, providing fine-grained control over AWS resource permissions. This feature enables you to define specific access patterns that align with your security requirements and operational needs.  ","version":"Next","tagName":"h2"},{"title":"Custom Policies​","type":1,"pageTitle":"Project","url":"/preview-docs/docs/project#custom-policies","content":" Custom policies allow you to create tailored IAM policies that grant specific permissions to your project's workloads. These policies should be created in the same AWS account where your project is deployed.  Creating Custom Policies​  Navigate to AWS IAM Console in your project's AWS accountCreate a new policy with the specific permissions your application requiresReference the policy in SleakOps using the policy ARN  Policy Best Practices Follow the principle of least privilege - grant only the minimum permissions necessaryUse resource-specific ARNs when possible to limit access scopeRegularly review and audit policy permissions  Referencing Custom Policies in SleakOps​  When configuring ProjectAccess, you can reference your custom policies by providing the policy ARN:  arn:aws:iam::ACCOUNT_ID:policy/YourCustomPolicyName   ","version":"Next","tagName":"h3"},{"title":"AWS Managed Policies​","type":1,"pageTitle":"Project","url":"/preview-docs/docs/project#aws-managed-policies","content":" SleakOps also supports AWS managed policies, which are pre-configured policies maintained by AWS. These policies provide common permission sets for various AWS services.  Common AWS Managed Policies​  AmazonS3ReadOnlyAccess: Read-only access to S3 bucketsAmazonRDSReadOnlyAccess: Read-only access to RDS instancesCloudWatchReadOnlyAccess: Read-only access to CloudWatch metrics and logsAmazonEC2ReadOnlyAccess: Read-only access to EC2 resources  Policy Association When associating roles or policies with your project, it's recommended to use the minimum number of policies necessary. This approach: Reduces complexity in permission managementImproves security by limiting potential attack vectorsMakes troubleshooting easier when permission issues arise  ","version":"Next","tagName":"h3"},{"title":"Best Practices for Policy Management​","type":1,"pageTitle":"Project","url":"/preview-docs/docs/project#best-practices-for-policy-management","content":" Minimize Policy Count: Associate the fewest number of policies possible while meeting your requirementsRegular Audits: Periodically review and audit the policies associated with your projectsEnvironment-Specific Policies: Consider using different policies for different environments (dev, staging, prod)Documentation: Maintain clear documentation of why specific policies are required for each project ","version":"Next","tagName":"h3"},{"title":"Access Configuration","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/access_config","content":"","keywords":"","version":"Next"},{"title":"Configuration Steps​","type":1,"pageTitle":"Access Configuration","url":"/preview-docs/docs/project/access_config#configuration-steps","content":" Navigate to Project → SettingsSelect Access Configuration from the settings menuConfigure external dependencies and extra policies as neededClick Apply changes to save your configuration    ","version":"Next","tagName":"h2"},{"title":"External Dependencies​","type":1,"pageTitle":"Access Configuration","url":"/preview-docs/docs/project/access_config#external-dependencies","content":" ","version":"Next","tagName":"h2"},{"title":"Dependencies Already Assigned​","type":1,"pageTitle":"Access Configuration","url":"/preview-docs/docs/project/access_config#dependencies-already-assigned","content":" This section shows dependencies that have already been linked to your current project. These dependencies are available for your workloads to use and are marked with a blue checkbox to indicate they are active.  Features:  View all currently assigned external dependenciesSee dependency type and project informationDependencies are automatically configured with appropriate permissions  ","version":"Next","tagName":"h3"},{"title":"Available External Dependencies​","type":1,"pageTitle":"Access Configuration","url":"/preview-docs/docs/project/access_config#available-external-dependencies","content":" This section displays dependencies from other projects that you can grant access to your current project. This enables cross-project resource sharing and collaboration.  How it works:  Select dependencies from other projects that you wish to grant access to this projectOnly dependencies from projects you have access to will be displayedOnce selected, the dependency becomes available in the &quot;Dependencies Already Assigned&quot; section  ","version":"Next","tagName":"h3"},{"title":"Extra Policies​","type":1,"pageTitle":"Access Configuration","url":"/preview-docs/docs/project/access_config#extra-policies","content":" The Extra Policies section allows you to attach additional IAM policies to your project, providing enhanced permissions beyond the default project access.  ","version":"Next","tagName":"h2"},{"title":"Adding Extra Policies​","type":1,"pageTitle":"Access Configuration","url":"/preview-docs/docs/project/access_config#adding-extra-policies","content":" Click the &quot;Attach more policies&quot; buttonSelect from available IAM policies in your AWS accountReview the policy permissions before attachingThe policies will be applied to grant additional permissions to the project  ","version":"Next","tagName":"h3"},{"title":"Policy Management​","type":1,"pageTitle":"Access Configuration","url":"/preview-docs/docs/project/access_config#policy-management","content":" Custom Policies: Attach policies you've created in your AWS IAM consoleAWS Managed Policies: Use pre-configured AWS policies for common use casesPolicy Review: All attached policies are listed and can be reviewedRemoval: Policies can be detached if no longer needed  Cross-Project Access External dependencies enable teams to share resources across different projects, improving collaboration and resource utilization.  Security Considerations Review all attached policies to ensure they follow the principle of least privilegeRegularly audit external dependencies to ensure they're still neededMonitor access patterns to identify any unusual activity ","version":"Next","tagName":"h3"},{"title":"Build","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/build","content":"","keywords":"","version":"Next"},{"title":"Build creation​","type":1,"pageTitle":"Build","url":"/preview-docs/docs/project/build#build-creation","content":" To create a Build you only need four parameters, only the Project field is required as the other three are, if not set, wait until this access is automatically enabled are chosen by default:  Project: Refers to what we call ProjectEnv, here you choose which ProjectEnv you want to build.Branch: Lets you choose any branch of the repository that you've chosen as Project. Defaults to Environment name.Commit hash: You can also choose the commit has to build a specific commit and not the last one as we do by default. Defaults to last commit.Tag: Just a tag to differentiate builds. Defaults to 'latest'.  ","version":"Next","tagName":"h3"},{"title":"Why do we need to Build a Docker image?​","type":1,"pageTitle":"Build","url":"/preview-docs/docs/project/build#why-do-we-need-to-build-a-docker-image","content":" As we use Helm charts we need the image because is what they use to deploy a Kubernetes Release.  info Remember that you need a Build to update the code that the Deployment runs inside the Kubernetes Cluster.  CI/CD integration with SleakOps SleakOps has its own CLI Tool that you can use to automate Builds and Deployments in your CI/CD. More info here. ","version":"Next","tagName":"h2"},{"title":"Deploy Build Resources","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/build_resources","content":"","keywords":"","version":"Next"},{"title":"Resource Configuration​","type":1,"pageTitle":"Deploy Build Resources","url":"/preview-docs/docs/project/build_resources#resource-configuration","content":"   Access the Deploy Build Resources settings:  Navigate to Project → SettingsSelect Deploy Build Resources from the settings menuConfigure the resource values according to your project's requirementsClick Save to apply the changes  ","version":"Next","tagName":"h2"},{"title":"Build Request Resources​","type":1,"pageTitle":"Deploy Build Resources","url":"/preview-docs/docs/project/build_resources#build-request-resources","content":" Configure the resources allocated during the build process:  Build Request CPU: Specifies the CPU allocation for build processes (measured in millicores)Build Request Memory: Specifies the memory allocation for build processes (measured in GiB)  ","version":"Next","tagName":"h3"},{"title":"Deploy Request Resources​","type":1,"pageTitle":"Deploy Build Resources","url":"/preview-docs/docs/project/build_resources#deploy-request-resources","content":" Configure the resources allocated during the deployment process:  Deploy Request CPU: Specifies the CPU allocation for deployment processes (measured in millicores)Deploy Request Memory: Specifies the memory allocation for deployment processes (measured in GiB)  Resource Optimization Start with default values and adjust based on build performanceMonitor build times and resource usage to optimize allocationsHigher resource allocations can reduce build times but increase costs  Resource Limits Ensure your cluster has sufficient resources to accommodate the requested allocations ","version":"Next","tagName":"h3"},{"title":"Chart","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/chart","content":"","keywords":"","version":"Next"},{"title":"Accessing the Chart Configuration​","type":1,"pageTitle":"Chart","url":"/preview-docs/docs/project/chart#accessing-the-chart-configuration","content":" You can find the Chart section by navigating to Project → Settings:    NodePool Requirements SleakOps uses NodePools to determine where resources are deployed. You must configure the tolerations parameter to target an existing NodePool for all deployed resources.    ","version":"Next","tagName":"h2"},{"title":"Default Values​","type":1,"pageTitle":"Chart","url":"/preview-docs/docs/project/chart#default-values","content":" SleakOps automatically applies default values to its Charts. You can view these values by clicking the designated area:    This opens a drawer on the right side displaying the default values for all Project workloads.  ","version":"Next","tagName":"h2"},{"title":"Workload-Specific Values​","type":1,"pageTitle":"Chart","url":"/preview-docs/docs/project/chart#workload-specific-values","content":" For example, here are the default values for an 'api' WebService:    ","version":"Next","tagName":"h3"},{"title":"Global Valuess​","type":1,"pageTitle":"Chart","url":"/preview-docs/docs/project/chart#global-valuess","content":" Values that apply across the entire Project:    ","version":"Next","tagName":"h3"},{"title":"Frequently Asked Questions​","type":1,"pageTitle":"Chart","url":"/preview-docs/docs/project/chart#frequently-asked-questions","content":" Where can I find my Project's Chart?​ Currently, Charts are not viewable directly in the platform. However, you can download the Chart from the ECR repository created for your Project in the corresponding AWS Account.  Can I modify the Chart deployed by a Project?​ Yes, with some limitations. You can: Add custom templates using Extra TemplatesAdd chart dependencies using Chart Dependencies, similar to Helm Chart Dependencies   Can I add a custom Ingress to my Project?​ Yes, this is one of the primary use cases for the Extra Templates feature. See the Extra Templates documentation for detailed instructions.  Can I modify existing Kubernetes Service templates?​ No, modifying SleakOps built-in templates is not currently supported. We are working on enabling modifications to built-in templates in future releases. ","version":"Next","tagName":"h2"},{"title":"Chart Dependencies","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/chart/chart_dependencies","content":"","keywords":"","version":"Next"},{"title":"Supported Chart Repositories​","type":1,"pageTitle":"Chart Dependencies","url":"/preview-docs/docs/project/chart/chart_dependencies#supported-chart-repositories","content":" Currently, SleakOps supports Bitnami Charts exclusively. You can browse available charts on ArtifactHub to find suitable dependencies for your project.  ","version":"Next","tagName":"h2"},{"title":"Adding Chart Dependencies​","type":1,"pageTitle":"Chart Dependencies","url":"/preview-docs/docs/project/chart/chart_dependencies#adding-chart-dependencies","content":" To add a new Chart Dependency, click the Create button in the Chart Configuration section:    ","version":"Next","tagName":"h2"},{"title":"Configuration Steps​","type":1,"pageTitle":"Chart Dependencies","url":"/preview-docs/docs/project/chart/chart_dependencies#configuration-steps","content":" Search and Select: Use the first two fields to search for the chart name and select your desired versionConfigure Values: Modify the values section below to customize the deploymentSet Tolerations: Critical - Update all tolerations fields in the chart values to target your NodePool    Important Ensure every tolerations field in the chart values is properly configured to use a NodePool. Without this configuration, Kubernetes cannot determine where to schedule the pods, leading to deployment failures.  ","version":"Next","tagName":"h3"},{"title":"Frequently Asked Questions​","type":1,"pageTitle":"Chart Dependencies","url":"/preview-docs/docs/project/chart/chart_dependencies#frequently-asked-questions","content":" My deployment succeeded but pods aren't working. What's wrong?​ The most common cause is incorrect NodePool configuration. Verify that: All tolerations fields are properly set to target existing NodePoolsThe NodePool has sufficient resourcesThe NodePool is in a healthy state  I can't find the chart I need. What are my options?​ Currently, only Bitnami repository charts are supported. If you need a chart not available in Bitnami's repository, please contact our support team to discuss alternatives or request additional repository support.  How do I troubleshoot dependency deployment issues?​ Common troubleshooting steps: Verify NodePool tolerations are correctly configuredCheck that the chart version is compatibleEnsure required values are properly setReview pod logs for specific error messages  My resources won't mount EBS volumes correctly. What should I check?​ Ensure that the EBS CSI Driver is installed and functioning in your cluster. You can refer to the Addon documentation for guidance on setting up EBS.Ensure you completed the values with the appropriate storageClass that is created with the EBS addon. For example a persistence value for a chart could look like this: persistence: enabled: true storageClass: &quot;ebs-csi-default-sc&quot; accessModes: - ReadWriteOnce size: 5Gi In case you need another storageClass, you can define it as an extra template and use it. Remember to set the provisioner to ebs.csi.aws.com.In case the pods are not starting, check the logs of the EBS CSI Controller for errors  My resources won't mount EFS volumes correctly. What should I check?​ Ensure that the EFS CSI Driver is installed and functioning in your cluster. Sleakops installs this addon when you create a volume for a project. You can create and then delete a volume to complete the installation.Ensure you completed the values with the appropriate storageClass that you prefer for this data. Sleakops creates two StorageClasses when installing the EFS addon: efs-sc-retain and efs-sc-delete. For example a persistence value for a chart could look like this: persistence: enabled: true storageClass: &quot;efs-sc-retain&quot; accessModes: - ReadWriteMany size: 5Gi In case you need another storageClass, you can define it as an extra template and use it. Remember to set the provisioner to efs.csi.aws.com.In case the pods are not starting, check the logs of the EFS CSI Controller for errors  Pods won't start due to image pull errors. What should I check?​ Verify that the image name and tag specified in the chart values are correct.Verify that the repository is bitnamilegacy instead of bitnami.Verify if there is a value allowInsecureImages: false and change it to allowInsecureImages: true. ","version":"Next","tagName":"h2"},{"title":"Configure your Dockerfile","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/configure_your_dockerfile","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Configure your Dockerfile","url":"/preview-docs/docs/project/configure_your_dockerfile#faqs","content":" What do I need to specify when configuring the Dockerfile in SleakOps?​ When configuring your Dockerfile in SleakOps, you need to: Set the Dockerfile Path: Provide the relative path of the Dockerfile within your repository.Provide Docker Arguments: If your Dockerfile requires specific build arguments (e.g., environment variables, configurations), you must provide these values during the Docker image build process.  How do I add the Dockerfile arguments?​ Once you specify the Dockerfile path, SleakOps analyzes it to identify any build arguments that are required. If necessary, SleakOps will prompt you to provide values for these arguments. You can update these arguments at any time through the SleakOps interface. DockerArgs from CLI You can also define DockerArgs when using the SleakOps CLI for builds. Use the --docker-args parameter to pass build arguments directly from the command line: sleakops build -p myproject -b main --docker-args &quot;ARG1=value1,ARG2=value2&quot; This is particularly useful for CI/CD pipelines where you want to pass different arguments based on the environment or build context.  What are Docker build arguments?​ Docker build arguments are variables that are passed during the Docker build process to customize the build according to different environments or configurations. They are defined in the Dockerfile using the ARG keyword. SleakOps will identify these arguments and ask you to provide the required values. You can also update these arguments later if needed.  How do I update the Dockerfile path and arguments?​ You can add the by following the steps below.  ","version":"Next","tagName":"h2"},{"title":"Set up your Dockerfile​","type":1,"pageTitle":"Configure your Dockerfile","url":"/preview-docs/docs/project/configure_your_dockerfile#set-up-your-dockerfile","content":" ","version":"Next","tagName":"h2"},{"title":"1. Access to your project settings​","type":1,"pageTitle":"Configure your Dockerfile","url":"/preview-docs/docs/project/configure_your_dockerfile#1-access-to-your-project-settings","content":"   Complete the Dockerfile Path: To enable SleakOps to search for the needed arguments, specify the Dockerfile Path and save the changes. SleakOps will then analyze your Dockerfile and render the required build arguments for you to provide.  Dockerfile Path\tThe Dockerfile is a critical component used to build your project into a container. The Dockerfile Path field requires the relative file path to your Dockerfile within the repository (e.g., /Dockerfile, /src/Dockerfile, or /app/Dockerfile). This file contains the instructions needed to create the container image, which SleakOps will build and later use for deployments.  Add Arguments Before Saving: If you already know the required arguments, you can enter them before saving. This allows you to provide necessary values upfront rather than waiting for SleakOps to analyze the Dockerfile.  tip If you choose to add the argument using the text option: Each argument should be added on a new line, separated by an equal sign (=), with no extra spaces. ARGUMENT_NAME = VALUE ARGUMENT_TWO = VALUE ARGUMENT_ONE = VALUE ","version":"Next","tagName":"h3"},{"title":"Extra Templates","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/chart/extra_templates","content":"","keywords":"","version":"Next"},{"title":"Use Cases​","type":1,"pageTitle":"Extra Templates","url":"/preview-docs/docs/project/chart/extra_templates#use-cases","content":" Custom Ingress configurations for specialized routingTesting pods for debugging and developmentAdditional ConfigMaps or SecretsCustom networking policiesSpecialized monitoring or logging components  NodePool Configuration Required Since SleakOps uses NodePools for resource placement, all custom resources must include proper tolerations configuration targeting an existing NodePool.  ","version":"Next","tagName":"h2"},{"title":"Deploying a Custom Ingress​","type":1,"pageTitle":"Extra Templates","url":"/preview-docs/docs/project/chart/extra_templates#deploying-a-custom-ingress","content":" To deploy a custom Ingress, add your Kubernetes YAML configuration in the Templates section. Here's a complete example you can use as a starting point:  apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: coreexampledjangocelerysleakopscom namespace: example-django-celery-myenv labels: app.kubernetes.io/name: example-django-celery annotations: alb.ingress.kubernetes.io/certificate-arn: &gt;- arn:aws:acm:REGION:ACCOUNT_ID:certificate/XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX alb.ingress.kubernetes.io/group.name: example-django-celery-public alb.ingress.kubernetes.io/healthcheck-path: /health alb.ingress.kubernetes.io/healthcheck-port: '8000' alb.ingress.kubernetes.io/listen-ports: '[{&quot;HTTP&quot;: 80}, {&quot;HTTPS&quot;:443}]' alb.ingress.kubernetes.io/ssl-redirect: '443' alb.ingress.kubernetes.io/success-codes: '200' alb.ingress.kubernetes.io/target-type: ip meta.helm.sh/release-name: example-django-celery-myenv meta.helm.sh/release-namespace: example-django-celery-myenv spec: ingressClassName: alb-ingressclass-public tls: - hosts: - core.example-django-celery.sleakops.com rules: - host: core.example-django-celery.sleakops.com http: paths: - path: /api/public/ pathType: Prefix backend: service: name: example-django-celery-myenv-api-public-svc port: number: 8000   Once you have defined your Ingress template, you can deploy it using the interface:    ","version":"Next","tagName":"h2"},{"title":"Frequently Asked Questions​","type":1,"pageTitle":"Extra Templates","url":"/preview-docs/docs/project/chart/extra_templates#frequently-asked-questions","content":" How do I use custom values in my templates?​ You can define custom values in the Values section on the right side of the interface. These values can then be referenced in your templates using Helm templating syntax. The example above shows how to create a Pod template that uses custom values and how to reference them in your YAML configuration.  What types of Kubernetes resources can I deploy?​ SleakOps supports namespace-scoped resources only due to security and isolation requirements. Each project operates within its own namespace with namespace-scoped permissions. Supported resources include: Pods, Deployments, ServicesIngresses, NetworkPoliciesConfigMaps, SecretsPersistentVolumeClaimsJobs, CronJobs Not supported: ClusterRoles, ClusterRoleBindingsCustomResourceDefinitionsPersistentVolumesAny cluster-scoped resources  How do I troubleshoot template deployment issues?​ Common troubleshooting steps: Validate YAML syntax - Ensure your template is valid Kubernetes YAMLCheck NodePool tolerations - Verify tolerations target existing NodePoolsReview resource quotas - Ensure sufficient resources are availableValidate references - Check that referenced services, secrets, or configmaps existCheck logs - Review deployment logs for specific error messages ","version":"Next","tagName":"h2"},{"title":"Dependencies: Integrating Databases, Caching, and Messaging Services","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Dependencies: Integrating Databases, Caching, and Messaging Services","url":"/preview-docs/docs/project/dependency#faqs","content":" What types of dependencies are included in SleakOps?​ Here’s the updated list of dependencies included in SleakOps: Databases Amazon RDS: Managed relational databases such as MySQL, PostgreSQL, and others. Caching Services Amazon ElastiCache for Redis: In-memory data store for caching frequently accessed data.Amazon ElastiCache for Memcached: In-memory caching service for improved performance and reduced database load. Object Storage Amazon S3: Scalable and secure object storage for storing and retrieving any amount of data. Search and Analytics Amazon OpenSearch: A powerful search and analytics engine for exploring and visualizing data, enabling real-time insights and decision-making. Message Queuing Amazon SQS: Fully managed message queuing service that enables you to decouple components and enhance application scalability and reliability.RabbitMQ: A widely used open-source message broker that facilitates reliable messaging and integration between application components. These dependencies integrate seamlessly with SleakOps, providing a comprehensive suite of AWS and open-source services to enhance your application's functionality, performance, and scalability.  Can I modify dependency configurations after initial setup?​ Yes, you can update dependency configurations at any time. Make sure to save any changes in the SleakOps interface to apply the updates.  Can the same dependency be used for multiple Projects?​ At the moment this is not possible, you need one dependency per each project.  How do I delete a Dependency?​ By accessing the Dependency Listing and clicking the delete option.  What happens when I delete a dependency?​ By deleting a dependency, SleakOps will remove all the information related to it and all what is related to it will stop working. To solve that SleakOps create a Deployment in PENDING_APPROVAL status, that must be run manually ASAP to stop the downtime. In case you delete a database, SleakOps will generate a final snapshot before its deletion.  ","version":"Next","tagName":"h2"},{"title":"Lets add a Dependency for your Project​","type":1,"pageTitle":"Dependencies: Integrating Databases, Caching, and Messaging Services","url":"/preview-docs/docs/project/dependency#lets-add-a-dependency-for-your-project","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navigate to create Dependency section​","type":1,"pageTitle":"Dependencies: Integrating Databases, Caching, and Messaging Services","url":"/preview-docs/docs/project/dependency#1-navigate-to-create-dependency-section","content":" Into the Left Pane, access Dependencies option and then, at the top right corner, click on the Create button.    ","version":"Next","tagName":"h3"},{"title":"2. Select the kind of dependency you want to create​","type":1,"pageTitle":"Dependencies: Integrating Databases, Caching, and Messaging Services","url":"/preview-docs/docs/project/dependency#2-select-the-kind-of-dependency-you-want-to-create","content":"   ","version":"Next","tagName":"h3"},{"title":"3. Select the kind of dependency you want to create​","type":1,"pageTitle":"Dependencies: Integrating Databases, Caching, and Messaging Services","url":"/preview-docs/docs/project/dependency#3-select-the-kind-of-dependency-you-want-to-create","content":" In Sleakops all dependecies start with the same step. So, complete these attributes and click Next to continue.  Setting\tDescriptionName\tIdentify your Project. Project\tSelect between the existent projects.    ","version":"Next","tagName":"h3"},{"title":"4. Follow each dependency guide​","type":1,"pageTitle":"Dependencies: Integrating Databases, Caching, and Messaging Services","url":"/preview-docs/docs/project/dependency#4-follow-each-dependency-guide","content":" To move forward choose between the following guides.  S3 Bucket.MySQL.PostgreSQL.Redis.Memcached.OpenSearch.SQS. ","version":"Next","tagName":"h3"},{"title":"AWS Aurora MySQL","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/aurora-mysql-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS Aurora MySQL","url":"/preview-docs/docs/project/dependency/aurora-mysql-aws#faqs","content":" How does SleakOps manage Aurora MySQL credentials?​ When you create an Aurora MySQL dependency in SleakOps, it automatically generates a Vargroup for your database cluster. This Variable Group securely stores the Aurora MySQL credentials and other important configuration details, such as the cluster endpoint and user access information. You'll be able to manage them from the Vargroups section.  Can I change the Aurora MySQL version after the cluster is deployed?​ Yes, Aurora MySQL supports engine version upgrades. However, the upgrade process requires careful planning and may involve downtime. It's recommended to test the upgrade process in a non-production environment first.  What happens if I need more storage for my Aurora MySQL cluster?​ Aurora MySQL automatically scales storage from 10 GB up to 128 TB without requiring you to provision storage in advance. The storage scales automatically as your data grows, and you only pay for the storage you use.  How do I create an Aurora MySQL database dump?​ To create a dump of your Aurora MySQL database: Run the mysqldump Command: mysqldump -h AURORA_MYSQL_ADDRESS -u AURORA_MYSQL_USERNAME -p --all-databases &gt; dump.sql Replace AURORA_MYSQL_ADDRESS, AURORA_MYSQL_USERNAME, and dump.sql with the appropriate values. Consult Documentation: For more information on how to create a dump, refer to the official MySQL documentation .  How do I import an existent dump using docker?​ To import a database dump into your Aurora MySQL cluster: Connect to the VPN: Ensure you are connected to the VPN of the AWS account where the Aurora cluster is located.Prepare the dump file: Place your database dump file (e.g., dump.sql) in the ./initial_data/ directory on your local machine.Run Docker Container (Recommended): Install Docker on your local machine if not already installed.Leave your dump in an &quot;initial_data&quot; folder.Run a MySQL Docker container with the following command: docker run -it --name aurora-mysql-container -v ./initial_data/:/tmp/data/ -e MYSQL_ROOT_PASSWORD=AURORA_MYSQL_PASSWORD -d mysql bash Attach to the container's terminal: docker exec -t -i aurora-mysql-container bash Import the dump file: mysql -h AURORA_MYSQL_ADDRESS -u AURORA_MYSQL_USERNAME -p &lt; /tmp/data/dump.sql Replace AURORA_MYSQL_ADDRESS, AURORA_MYSQL_USERNAME, and dump.sql with your specific details.  How do I import an existent dump to my local machine?​ Alternatively, you can use a MySQL client installed on your local machine to import the dump: mysql -h AURORA_MYSQL_ADDRESS -u AURORA_MYSQL_USERNAME -p &lt; dump.sql   What should I do if I encounter connection issues with my Aurora MySQL cluster?​ Check the following: Ensure the cluster endpoint, username, and password are correct.Verify that your security groups and firewall rules allow access.Ensure the cluster is running and has enough resources (CPU, memory).Check if the cluster is in an available state. Otherwise, contact us.  What are the benefits of Aurora MySQL over standard RDS MySQL?​ Aurora MySQL offers several advantages: Performance: Up to 5x faster than standard MySQL on RDSScalability: Automatic storage scaling up to 128 TBAvailability: Continuous backup to S3 with point-in-time recoveryDurability: 6-way replication across 3 Availability ZonesCompatibility: MySQL-compatible with minimal code changesCost-effective: Pay only for the storage you use  info AWS documentation: Amazon Aurora MySQL Documentation  ","version":"Next","tagName":"h2"},{"title":"Set up your Aurora MySQL​","type":1,"pageTitle":"AWS Aurora MySQL","url":"/preview-docs/docs/project/dependency/aurora-mysql-aws#set-up-your-aurora-mysql","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add Aurora MySQL as a Dependency​","type":1,"pageTitle":"AWS Aurora MySQL","url":"/preview-docs/docs/project/dependency/aurora-mysql-aws#1-add-aurora-mysql-as-a-dependency","content":" To integrate Aurora MySQL with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;Aurora MySQL&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your Aurora MySQL.​","type":1,"pageTitle":"AWS Aurora MySQL","url":"/preview-docs/docs/project/dependency/aurora-mysql-aws#2-set-up-your-aurora-mysql","content":" You will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Attribute\tDescriptionDatabase Name\tName for the Aurora MySQL database. Must follow pattern: lowercase letters and numbers, cannot be &quot;db&quot; or &quot;database&quot;. Database Engine Version\tSelect the specific version of the Aurora MySQL database engine. Version 3 is compatible with MySQL 8, Version 2 with MySQL 5. Database Engine Mode\tChoose between Serverless (auto-scaling, pay-per-use for unpredictable workloads) or Provisioned (fixed capacity, better for consistent workloads). Database Master Username\tMaster username for the Aurora MySQL cluster. Cannot be &quot;admin&quot;, &quot;user&quot;, &quot;database&quot;, or &quot;name&quot;. Auto-generate Password\tIf enabled, the backend will generate a strong password automatically. Database Master Password\tPassword for the master user. Required if auto-generate is disabled. Cannot contain @, ', &quot;, or / characters. Database Instance Class\tServerless mode: Fixed to db.serverless Provisioned mode: Choose from db.t3.medium, db.t4g.medium, db.t3.large, db.t4g.large, db.r8g.large, db.r8g.xlarge, db.r7i.large, db.r7i.xlarge.t3.medium. Minimum Aurora Capacity\t(Serverless only) Minimum Aurora Capacity Units (0.5-256). Each unit ≈ 2GB RAM. Maximum Aurora Capacity\t(Serverless only) Maximum Aurora Capacity Units (1-256). Each unit ≈ 2GB RAM. Create a RDS from a snapshot\tMark this if restoring from a database snapshot. Snapshot Identifier\t(Required if restoring from snapshot) RDS snapshot identifier to restore from. Backup Retention Period\tNumber of days (1-35) for which automatic backups are kept. Backup Window\tPeriod for automated backups in HH:MM-HH:MM format (UTC). Read Replicas\tConfiguration for database read replicas. Each replica requires a name and publicly accessible setting.  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable's name for your Aurora MySQL cluster.​","type":1,"pageTitle":"AWS Aurora MySQL","url":"/preview-docs/docs/project/dependency/aurora-mysql-aws#3-customize-your-variables-name-for-your-aurora-mysql-cluster","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"AWS Memcached","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/memcached-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS Memcached","url":"/preview-docs/docs/project/dependency/memcached-aws#faqs","content":" What are the key use cases for Memcached?​ Memcached is ideal for caching frequently accessed database queries, storing temporary user session data, and caching API responses to reduce database load.  When should I use Memcached?​ Memcached is ideal for: Simple Caching Needs: If you need a basic, high-speed cache for frequently accessed data.Non-Persistent Data: When you don’t need data to be persisted and can tolerate data loss upon node failure or restart.Horizontal Scalability: For applications that benefit from adding multiple caching nodes to distribute load efficiently.Cost-Sensitive Applications: Memcached is more cost-effective than Redis because it lacks advanced features like persistence and replication.  Why should I choose Memcached over Redis?​ Memcached is a simpler and more cost-effective caching solution if you don't need data persistence, replication, or advanced data types. It's suitable for applications that prioritize fast, distributed caching.  How does Memcached scale in SleakOps?​ Memcached scales horizontally by adding more nodes to your cluster, allowing you to distribute the caching load across multiple nodes.  Does Memcached offer data persistence?​ No, Memcached does not support data persistence. All cached data is stored in memory and will be lost if the node is restarted or fails.  What happens to the cached data if a node fails?​ Cached data in Memcached is volatile, meaning it will be lost if a node fails or is restarted. For critical applications, Redis (which supports data persistence) might be a better choice.  ","version":"Next","tagName":"h2"},{"title":"Set up your AWS Memcached​","type":1,"pageTitle":"AWS Memcached","url":"/preview-docs/docs/project/dependency/memcached-aws#set-up-your-aws-memcached","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add AWS Memcached as a Dependency​","type":1,"pageTitle":"AWS Memcached","url":"/preview-docs/docs/project/dependency/memcached-aws#1-add-aws-memcached-as-a-dependency","content":" To integrate Memcached with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;AWS Redis&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your Memcached database.​","type":1,"pageTitle":"AWS Memcached","url":"/preview-docs/docs/project/dependency/memcached-aws#2-set-up-your-memcached-database","content":" When adding Memcached as a dependency in SleakOps, you need to configure several key attributes:    Attribute\tDescriptionNode Type\tInstance class that determines the performance and memory capacity of the Redis instance. Examples: cache.t3.micro, cache.m5.large, cache.r6g.large Nodes Quantity\tDefines the number of Memcached nodes for horizontal scaling. Adding more nodes increases scalability. Example: 1 or more Port\tThe communication port used by Redis to interact with your application. Default: 11121 (can be customized)  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable names for your Memcached.​","type":1,"pageTitle":"AWS Memcached","url":"/preview-docs/docs/project/dependency/memcached-aws#3-customize-your-variable-names-for-your-memcached","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"AWS MSK (Managed Streaming for Apache Kafka)","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/msk-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS MSK (Managed Streaming for Apache Kafka)","url":"/preview-docs/docs/project/dependency/msk-aws#faqs","content":" How does SleakOps manage MSK credentials?​ When you create an MSK dependency in SleakOps, it automatically generates a Vargroup for your Kafka cluster. This Variable Group securely stores the MSK credentials and other important configuration details, such as the cluster endpoints and authentication information. You'll be able to manage them from the Vargroups section.  Can I change the Kafka version after the cluster is deployed?​ Yes, Amazon MSK supports Kafka version upgrades. Choose from the versions supported. However, the upgrade process requires careful planning and may involve downtime. It's recommended to test the upgrade process in a non-production environment first.  What happens if I need more storage for my MSK cluster?​ For Provisioned mode: You configure the storage size per broker node (1-16384 GB) during cluster creation. This storage is automatically provisioned and managed by AWS. If you need more storage, you'll need to modify the cluster configuration, which may require downtime. For Serverless mode: Storage is automatically managed and scaled by AWS based on your usage patterns. You don't need to configure storage size as it scales automatically.  How do I connect to my MSK cluster?​ To connect to your MSK cluster: Get the Bootstrap Servers: Use the bootstrap server endpoints provided by SleakOps in the vargroup.Configure Authentication: MSK supports various authentication methods including SASL/SCRAM, IAM, and TLS.Use Kafka Clients: Connect using standard Kafka clients and libraries.VPN Connection: Ensure you are connected to the VPN of the AWS account where the MSK cluster is located. Note: Both Provisioned and Serverless modes use the same connection methods, but Serverless mode may have different performance characteristics and scaling behavior.  How do I create topics in my MSK cluster?​ To create topics in your MSK cluster: Using Kafka Tools: kafka-topics.sh --create --topic my-topic --bootstrap-server MSK_BOOTSTRAP_SERVERS --partitions 3 --replication-factor 3 Using Kafka Admin Client: Use the Kafka Admin Client in your application code.Replace Variables: Replace MSK_BOOTSTRAP_SERVERS with the actual bootstrap server endpoints from your vargroup. Note: For Provisioned mode, set the replication factor to match your number of broker nodes (minimum 3 for production). For Serverless mode, AWS manages the replication automatically.  How do I produce and consume messages?​ To produce and consume messages: Producer Example: kafka-console-producer.sh --topic my-topic --bootstrap-server MSK_BOOTSTRAP_SERVERS Consumer Example: kafka-console-consumer.sh --topic my-topic --bootstrap-server MSK_BOOTSTRAP_SERVERS --from-beginning Application Integration: Use Kafka clients in your application code for production use.  What should I do if I encounter connection issues with my MSK cluster?​ Check the following: Ensure the bootstrap server endpoints, username, and password are correct.Verify that your security groups and firewall rules allow access.Ensure the cluster is running and has enough resources.Check if the cluster is in an available state.Verify your authentication configuration (SASL/SCRAM, IAM, or TLS). Otherwise, contact us.  What are the benefits of Amazon MSK over self-managed Kafka?​ Amazon MSK offers several advantages: Managed Operations: No need to manage Kafka infrastructureHigh Availability: Built-in replication and failover capabilitiesSecurity: Integrated with AWS security servicesMonitoring: CloudWatch integration for monitoring and alertingScalability: Easy scaling of broker instances and storageCompatibility: Fully compatible with Apache Kafka  info AWS documentation: Amazon MSK Documentation  ","version":"Next","tagName":"h2"},{"title":"Set up your MSK​","type":1,"pageTitle":"AWS MSK (Managed Streaming for Apache Kafka)","url":"/preview-docs/docs/project/dependency/msk-aws#set-up-your-msk","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add MSK as a Dependency​","type":1,"pageTitle":"AWS MSK (Managed Streaming for Apache Kafka)","url":"/preview-docs/docs/project/dependency/msk-aws#1-add-msk-as-a-dependency","content":" To integrate MSK with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;MSK&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your MSK.​","type":1,"pageTitle":"AWS MSK (Managed Streaming for Apache Kafka)","url":"/preview-docs/docs/project/dependency/msk-aws#2-set-up-your-msk","content":" You will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Attribute\tDescriptionDeployment Mode\tChoose between Provisioned (fixed capacity, full control over configuration) or Serverless (auto-scaling, pay-per-use for variable workloads). Provisioned mode is ideal for consistent workloads with specific performance requirements, while Serverless is perfect for development and variable traffic patterns. Kafka Version\t(Required for Provisioned mode) Select the specific version of Apache Kafka for your MSK cluster. Choose from versions 2.8.1, 3.2.0, 3.3.2, 3.4.0, or 3.5.1. Each version includes specific Kafka features, performance improvements, and security updates. Instance Type\t(Required for Provisioned mode) Define the instance type that specifies the hardware configuration for your Kafka brokers. Choose from t3 (burstable performance) or m5 (general purpose) instance types. This controls CPU, memory, and network performance for your streaming workloads. Broker Nodes\t(Required for Provisioned mode) Number of broker nodes in your MSK cluster (2-15 nodes). Use 2 nodes for development environments. For production, use 3 or more nodes (must be multiple of 3) to ensure high availability and fault tolerance. More nodes provide better performance and availability. Storage Size (GB)\t(Required for Provisioned mode) Storage size in GB per broker node (1-16384 GB). This determines how much data each broker can store locally. Consider your data retention requirements and throughput needs when setting this value.  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable's name for your MSK cluster.​","type":1,"pageTitle":"AWS MSK (Managed Streaming for Apache Kafka)","url":"/preview-docs/docs/project/dependency/msk-aws#3-customize-your-variables-name-for-your-msk-cluster","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"AWS Aurora PostgreSQL","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/aurora-postgresql-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS Aurora PostgreSQL","url":"/preview-docs/docs/project/dependency/aurora-postgresql-aws#faqs","content":" How does SleakOps manage Aurora PostgreSQL credentials?​ When you create an Aurora PostgreSQL dependency in SleakOps, it automatically generates a Vargroup for your database cluster. This Variable Group securely stores the Aurora PostgreSQL credentials and other important configuration details, such as the cluster endpoint and user access information. You'll be able to manage them from the Vargroups section.  Can I change the Aurora PostgreSQL version after the cluster is deployed?​ Yes, Aurora PostgreSQL supports engine version upgrades. However, the upgrade process requires careful planning and may involve downtime. It's recommended to test the upgrade process in a non-production environment first.  What happens if I need more storage for my Aurora PostgreSQL cluster?​ Aurora PostgreSQL automatically scales storage from 10 GB up to 128 TB without requiring you to provision storage in advance. The storage scales automatically as your data grows, and you only pay for the storage you use.  How do I create an Aurora PostgreSQL database dump?​ To create a dump of your Aurora PostgreSQL database: Run the pg_dump Command: pg_dump -h AURORA_POSTGRESQL_ADDRESS -U AURORA_POSTGRESQL_USERNAME -W &gt; dump.sql Replace AURORA_POSTGRESQL_ADDRESS, AURORA_POSTGRESQL_USERNAME, and dump.sql with the appropriate values. Consult Documentation: For more information on how to create a dump, refer to the official PostgreSQL documentation .  How do I import an existent dump using docker?​ To import a database dump into your Aurora PostgreSQL cluster: Connect to the VPN: Ensure you are connected to the VPN of the AWS account where the Aurora cluster is located.Run Docker Container (Recommended): Install Docker on your local machine if not already installed.Run a PostgreSQL Docker container with the following command: docker run -it --name aurora-postgresql-container -v ./initial_data/:/tmp/data/ -e POSTGRESQL_ROOT_PASSWORD=AURORA_POSTGRESQL_PASSWORD -d postgres bash Attach to the container's terminal: docker exec -t -i aurora-postgresql-container bash Import the dump file: psql -h AURORA_POSTGRESQL_ADDRESS -U AURORA_POSTGRESQL_USERNAME -W -f /tmp/data/dump.sql Replace AURORA_POSTGRESQL_ADDRESS, AURORA_POSTGRESQL_USERNAME, and dump.sql with your specific details.  How do I import an existent dump to my local machine?​ Alternatively, you can use a PostgreSQL client installed on your local machine to import the dump: psql -h AURORA_POSTGRESQL_ADDRESS -U AURORA_POSTGRESQL_USERNAME -W -f /tmp/data/dump.sql   What should I do if I encounter connection issues with my Aurora PostgreSQL cluster?​ Check the following: Ensure the cluster endpoint, username, and password are correct.Verify that your security groups and firewall rules allow access.Ensure the cluster is running and has enough resources (CPU, memory).Check if the cluster is in an available state. Otherwise, contact us.  What are the benefits of Aurora PostgreSQL over standard RDS PostgreSQL?​ Aurora PostgreSQL offers several advantages: Performance: Up to 3x faster than standard PostgreSQL on RDSScalability: Automatic storage scaling up to 128 TBAvailability: Continuous backup to S3 with point-in-time recoveryDurability: 6-way replication across 3 Availability ZonesCompatibility: PostgreSQL-compatible with minimal code changes  info AWS documentation: Amazon Aurora PostgreSQL Documentation  ","version":"Next","tagName":"h2"},{"title":"Set up your Aurora PostgreSQL​","type":1,"pageTitle":"AWS Aurora PostgreSQL","url":"/preview-docs/docs/project/dependency/aurora-postgresql-aws#set-up-your-aurora-postgresql","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add Aurora PostgreSQL as a Dependency​","type":1,"pageTitle":"AWS Aurora PostgreSQL","url":"/preview-docs/docs/project/dependency/aurora-postgresql-aws#1-add-aurora-postgresql-as-a-dependency","content":" To integrate Aurora PostgreSQL with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;Aurora PostgreSQL&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your Aurora PostgreSQL.​","type":1,"pageTitle":"AWS Aurora PostgreSQL","url":"/preview-docs/docs/project/dependency/aurora-postgresql-aws#2-set-up-your-aurora-postgresql","content":" You will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Attribute\tDescriptionDatabase Name\tName for the Aurora PostgreSQL database. Must follow pattern: lowercase letters and numbers, cannot be &quot;db&quot; or &quot;database&quot;. Database Engine Version\tSelect the specific version of the Aurora PostgreSQL database engine. Choose from versions supports. Each version includes specific PostgreSQL features and security updates. Database Engine Mode\tAurora PostgreSQL is available only in Serverless mode, which provides automatic scaling based on your application's needs. This mode scales compute capacity up and down automatically, making it cost-effective for variable workloads. Database Master Username\tMaster username for the Aurora PostgreSQL cluster. This is the main user with administrative privileges. Cannot be &quot;admin&quot;, &quot;user&quot;, &quot;database&quot;, or &quot;name&quot;. Must start with a letter and contain only alphanumeric characters. Auto-generate Password\tIf enabled, the backend will generate a strong password automatically for enhanced security. This is recommended for production environments. Database Master Password\tPassword for the master user. Required if auto-generate is disabled. Must be at least 8 characters long and cannot contain @, ', &quot;, or / characters. Minimum Aurora Capacity\tMinimum Aurora Capacity Units (0.5-256) for the serverless cluster. Each unit is approximately equal to 2GB of RAM. This sets the baseline performance level and ensures minimum resources are always available. Maximum Aurora Capacity\tMaximum Aurora Capacity Units (1-256) for the serverless cluster. Each unit is approximately equal to 2GB of RAM. This prevents the cluster from scaling beyond your budget limits while allowing performance optimization. Backup Retention Period\tNumber of days (1-35) for which automatic backups are kept. Aurora PostgreSQL automatically backs up your database and stores the backups in Amazon S3. Longer retention periods provide more recovery options but increase storage costs. Backup Window\tTime period for automated backups in HH:MM-HH:MM format (UTC). Choose a time when your database activity is typically low to minimize performance impact. Aurora performs backups during this window without affecting your application. Read Replicas\tConfiguration for database read replicas to improve read performance and provide additional availability. Each replica requires a unique name and can be configured as publicly accessible or private. Read replicas help distribute read traffic and provide failover capabilities.  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable's name for your Aurora PostgreSQL cluster.​","type":1,"pageTitle":"AWS Aurora PostgreSQL","url":"/preview-docs/docs/project/dependency/aurora-postgresql-aws#3-customize-your-variables-name-for-your-aurora-postgresql-cluster","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"AWS MariaDB","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/mariadb-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS MariaDB","url":"/preview-docs/docs/project/dependency/mariadb-aws#faqs","content":" How does SleakOps manage MariaDB credentials?​ When you create a MariaDB dependency in SleakOps, it automatically generates a Vargroup for your database. This Variable Group securely stores the MariaDB credentials and other important configuration details, such as the database endpoint and user access information. You'll be able to manage them from the Vargroups section.  What is Multi-AZ deployment and should I enable it?​ Multi-AZ (Availability Zone) deployment ensures high availability and failover support by replicating your database in another availability zone. It's recommended for production environments to prevent downtime. Keep in mind that it increases costs.  Can I change the MariaDB version after the database is deployed?​ Yes, MariaDB supports engine version upgrades. However, the upgrade process requires careful planning and may involve downtime. It's recommended to test the upgrade process in a non-production environment first.  What happens if I need more storage for my MariaDB database?​ You can adjust the storage size when configuring your database. If you need more storage after deployment, SleakOps allows you to scale the storage size without downtime.  How do I create a MariaDB database dump?​ To create a dump of your MariaDB database: Run the mysqldump Command: mysqldump -h MARIADB_ADDRESS -u MARIADB_USERNAME -p --all-databases &gt; dump.sql Replace MARIADB_ADDRESS, MARIADB_USERNAME, and dump.sql with the appropriate values. Consult Documentation: For more information on how to create a dump, refer to the official MariaDB documentation .  How do I import an existent dump using docker?​ To import a database dump into your MariaDB RDS instance: Connect to the VPN: Ensure you are connected to the VPN of the AWS account where the RDS instance is located.Run Docker Container (Recommended): Install Docker on your local machine if not already installed.Run a MariaDB Docker container with the following command: docker run -it --name mariadb-container -v ./initial_data/:/tmp/data/ -e MARIADB_ROOT_PASSWORD=MARIADB_PASSWORD -d mariadb bash Attach to the container's terminal: docker exec -t -i mariadb-container bash Import the dump file: mysql -h MARIADB_ADDRESS -u MARIADB_USERNAME -p &lt; /tmp/data/dump.sql Replace MARIADB_ADDRESS, MARIADB_USERNAME, and dump.sql with your specific details.  How do I import an existent dump to my local machine?​ Alternatively, you can use a MariaDB client installed on your local machine to import the dump: mysql -h MARIADB_ADDRESS -u MARIADB_USERNAME -p &lt; dump.sql   What should I do if I encounter connection issues with my MariaDB database?​ Check the following: Ensure the database endpoint, username, and password are correct.Verify that your security groups and firewall rules allow access.Ensure the database is running and has enough resources (CPU, memory). Otherwise, contact us.  info AWS documentation: Amazon RDS MariaDB Documentation  ","version":"Next","tagName":"h2"},{"title":"Set up your MariaDB​","type":1,"pageTitle":"AWS MariaDB","url":"/preview-docs/docs/project/dependency/mariadb-aws#set-up-your-mariadb","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add MariaDB as a Dependency​","type":1,"pageTitle":"AWS MariaDB","url":"/preview-docs/docs/project/dependency/mariadb-aws#1-add-mariadb-as-a-dependency","content":" To integrate MariaDB with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;MariaDB&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your MariaDB.​","type":1,"pageTitle":"AWS MariaDB","url":"/preview-docs/docs/project/dependency/mariadb-aws#2-set-up-your-mariadb","content":" You will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Attribute\tDescriptionDatabase Name\tName for the MariaDB database. Must follow pattern: lowercase letters and numbers, cannot be &quot;db&quot; or &quot;database&quot;. This identifies your specific database within the MariaDB instance. Database Engine Version\tSelect the specific version of the MariaDB database engine. Choose from versions supported. Each version includes specific MariaDB features, performance improvements, and security updates. Database Master Username\tMaster username for the MariaDB database instance. This is the main user with administrative privileges. Cannot be &quot;admin&quot;, &quot;user&quot;, &quot;database&quot;, or &quot;name&quot;. Must start with a letter and contain only alphanumeric characters. Auto-generate Password\tIf enabled, the backend will generate a strong password automatically for enhanced security. This is recommended for production environments to ensure password complexity. Database Master Password\tPassword for the master user. Required if auto-generate is disabled. Must be at least 8 characters long and cannot contain @, ', &quot;, or / characters. Create a RDS from a snapshot\tMark this if restoring from a database snapshot. When enabled, you'll need to provide the snapshot identifier and some fields become read-only. Snapshot Identifier\t(Required if restoring from snapshot) RDS snapshot identifier to restore from. This allows you to restore your database from a previous backup point. Database Instance Class\tDefine the instance class that specifies the hardware configuration for your MariaDB database. Choose from t4g/t3 (burstable performance) or m7i/m8g (memory optimized) instance types. This controls CPU, memory, and network performance. Database Storage\tSpecify the amount of storage allocated for the database in GiB (20-6144 GB). MariaDB uses General Purpose SSD storage by default. This is the initial storage allocation for your database. Storage Autoscaling Enabled\tEnable automatic storage scaling for the RDS instance. When enabled, AWS will automatically increase storage when needed, up to the maximum allocated storage limit. Maximum Allocated Storage\t(Required if storage autoscaling is enabled) Maximum storage size in GiB (20-65536 GB) when storage autoscaling is enabled. This prevents unexpected costs by setting an upper limit for automatic scaling. Database Multi-AZ\tEnable Multi-Availability Zone deployment for high availability. This creates a standby replica in a different AZ and provides automatic failover capability. Recommended for production environments. Automated Backup\tEnable automatic backups for the RDS instance. When enabled, MariaDB will perform daily snapshots and transaction log backups, providing point-in-time recovery capabilities. Backup Retention Period\t(Required if automated backup is enabled) Number of days (1-35) for which automatic backups are kept. Longer retention periods provide more recovery options but increase storage costs. Backup Window\t(Required if automated backup is enabled) Time period for automated backups in HH:MM-HH:MM format (UTC). Choose a time when your database activity is typically low to minimize performance impact. Read Replicas\t(Required if automated backup is enabled) Configuration for database read replicas to improve read performance and provide additional availability. Each replica requires a name, instance class, and publicly accessible setting.  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable's name for your MariaDB database.​","type":1,"pageTitle":"AWS MariaDB","url":"/preview-docs/docs/project/dependency/mariadb-aws#3-customize-your-variables-name-for-your-mariadb-database","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"AWS MySQL","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/mysql-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS MySQL","url":"/preview-docs/docs/project/dependency/mysql-aws#faqs","content":" How does SleakOps manage MySQL credentials?​ When you create a MySQL dependency in SleakOps, it automatically generates a Vargroup for your database. This Variable Group securely stores the MySQL credentials and other important configuration details, such as the database endpoint and user access information. You’ll be able of manage them from Vargroups section.  What is Multi-AZ deployment and should I enable it?​ Multi-AZ (Availability Zone) deployment ensures high availability and failover support by replicating your database in another availability zone. It’s recommended for production environments to prevent downtime. Keep in mind that it increases costs.  Can I change the MySQL version after the database is deployed?​ No, the database engine version cannot be changed after deployment. You would need to create a new MySQL instance with the desired version and migrate your data. Or change it manually into the AWS Console.  What happens if I need more storage for my MySQL database?​ You can adjust the storage size when configuring your database. If you need more storage after deployment, you can scale modifying the settings in AWS as at the moment SleakOps does not support it.  How do I create a MySQL database dump?​ To create a dump of your MySQL database, use the following command: sh mysqldump -h MYSQL_ADDRESS -u MYSQL_USERNAME -p MYSQL_PASSWORD &gt; dump.sql Replace MYSQL_ADDRESS, MYSQL_USERNAME, and MYSQL_PASSWORD with the appropriate values. For additional information on creating a MySQL dump, refer to the official MySQL documentation. Another option is creating it directly from the AWS Console and then import it. See Restoring to a DB instance.  How do I import an existent dump using docker?​ For more details: MySQL Dump Documentation To import a database dump into your MySQL RDS instance: Connect to the VPN: Ensure you are connected to the VPN of the AWS account where the RDS instance is located.Run Docker Container (Recommended): Install Docker on your local machine if not already installed.Run a MySQL Docker container with the following command: sh docker run -it --name mysql-container -v ./initial_data/:/tmp/data/ -e MYSQL_ROOT_PASSWORD=MYSQL_PASSWORD -d mysql bash Attach to the container’s terminal: sh docker exec -t -i mysql-container bash Import the dump file: sh mysql -h MYSQL_ADDRESS -u MYSQL_USERNAME -p &lt; /tmp/data/dump.sql Replace MYSQL_ADDRESS, MYSQL_USERNAME, and MYSQL_PASSWORD with your RDS instance details.  How do I import an existent dump to my local machine ?​ Alternatively, you can use a MySQL client installed on your local machine to import the dump. mysql -h MYSQL_ADDRESS -u MYSQL_USERNAME -p MYSQL_PASSWORD &lt; /tmp/data/dump.sql   What should I do if I encounter connection issues with my MySQL database?​ Ensure the database endpoint, username, and password are correct.Verify that your security groups and firewall rules allow access.Ensure the database is running and has enough resources (CPU, memory). Otherwise, contact us.  What is an RDS Read Replica?​ An RDS Read Replica is a read-only copy of your primary database instance in Amazon RDS. It helps distribute read-heavy workloads and improves the performance and scalability of your database by offloading read operations from the primary database. RDS Read Replicas are ideal when you need to: Offload read-heavy operations from your primary instance.Scale your read operations as your application grows.Distribute database reads across multiple geographic locations.Have a backup solution that can quickly be promoted to a primary instance in case of failure. info Keep in mind that Read replicas have a delay performing updates.  How do I configure a Read Replica in SleakOps?​ In SleakOps, when creating a read replica for your RDS database, you will need to provide the following information: Name of the replicaReplica Instance Class, which determines the instance type for the replica.Replica Publicly Accessible, to decide if the replica should have a public IP or be accessible only within your private network.  Can I delete a replica?​ At the moment, the only way is to delete the dependency.  info AWS documentation: Amazon RDS MySQL Documentation  ","version":"Next","tagName":"h2"},{"title":"Set up your MySQL​","type":1,"pageTitle":"AWS MySQL","url":"/preview-docs/docs/project/dependency/mysql-aws#set-up-your-mysql","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add MySQL as a Dependency​","type":1,"pageTitle":"AWS MySQL","url":"/preview-docs/docs/project/dependency/mysql-aws#1-add-mysql-as-a-dependency","content":" To integrate MySQL with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;MySQL&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your MySQL.​","type":1,"pageTitle":"AWS MySQL","url":"/preview-docs/docs/project/dependency/mysql-aws#2-set-up-your-mysql","content":" You will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Attribute\tDescriptionDatabase Engine Version\tSelect the specific version of the MySQL database engine you wish to use. This ensures compatibility with your application requirements. Example: MySQL 8.0.2, MySQL 5.7.1 Database Instance Class\tDefine the instance class that specifies the hardware configuration for your MySQL database. This controls CPU, memory, and network performance. Example: db.m6g.large, db.t3.medium. See AWS detail. Database Storage\tSpecify the amount of storage allocated for the database. Example: 100 GB, 500 GB. Username\tProvide the master username for the MySQL database. This is the main user with administrative privileges. Example: admin, root. Password\tPassword for the master user to access the database. Multi-Availability Zone\tEnable or disable Multi-AZ deployment. This ensures high availability and failover support by replicating the database across multiple availability zones. Recommended for production environments. Automated Backup\tConfigure automated backups for the MySQL database. This ensures data protection by enabling daily snapshots and transaction log backups. Set up the Backup Retention Period and the Backup Window. Recommended for production environments. Backup Retention Period\tSet the number of days to retain automated backups. Backup Window\tPeriod of time while the backup will be done.  warning SleakOps allow the creation of replicas only during the creation of the dependency.  After that basic data, you need to decide if a replica will be created. To do that:  Into the form, look for the section Definition of RDS Read Replicas and click on + Add Item.Complete the following data:  Setting\tDescriptionName\tA name for the replica Replica Instance Class\tDefine the instance class that specifies the hardware configuration for your MySQL database. This controls CPU, memory, and network performance. Example: db.m6g.large, db.t3.medium. Replica Publicly Accessible\tDecide if the replica should have a public IP or be accessible only within your private network.  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable's name for your MySQL data base.​","type":1,"pageTitle":"AWS MySQL","url":"/preview-docs/docs/project/dependency/mysql-aws#3-customize-your-variables-name-for-your-mysql-data-base","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"AWS OpenSearch","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/opensearch-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS OpenSearch","url":"/preview-docs/docs/project/dependency/opensearch-aws#faqs","content":" What are the use cases for OpenSearch?​ OpenSearch is commonly used for full-text search, real-time analytics, monitoring and observability, and log analysis. It is also ideal for powering search functionalities on websites and applications.  What does &quot;Dedicated Master Enabled&quot; mean?​ When enabled, SleakOps sets up dedicated master nodes that help with managing the OpenSearch domain. They provide enhanced stability by separating management tasks from data nodes. This is highly recommended for production workloads.  What is the recommended configuration for master nodes in production?​ For production environments, SleakOps recommends using 3 dedicated master nodes to improve the stability and performance of your OpenSearch cluster.  ","version":"Next","tagName":"h2"},{"title":"Set up your OpenSearch​","type":1,"pageTitle":"AWS OpenSearch","url":"/preview-docs/docs/project/dependency/opensearch-aws#set-up-your-opensearch","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add AWS OpenSearch as a Dependency​","type":1,"pageTitle":"AWS OpenSearch","url":"/preview-docs/docs/project/dependency/opensearch-aws#1-add-aws-opensearch-as-a-dependency","content":" To integrate OpenSearch with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;SQS&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your OpenSearch.​","type":1,"pageTitle":"AWS OpenSearch","url":"/preview-docs/docs/project/dependency/opensearch-aws#2-set-up-your-opensearch","content":" When adding OpenSearch as a dependency in SleakOps, you need to configure several key attributes:    Attribute\tDescriptionFIFO Queue\tSpecifies the type of SQS queue. Where Standard Queue (for most use cases) or FIFO Queue (if message ordering is required)` FIFO Deduplication\tOnly for FIFO Queues, in order to avoid duplicates. Message Retention Period\tSpecifies the amount of time a message will be retained in the queue if it hasn't been consumed. Maximum Message Size\tThe maximum size of a message that can be sent to the SQS queue. Delivery Delay in Seconds\tThe delay between the message being sent to SQS and it being visible in the queue. No delay by default. Receive Message Wait Time\tDetermines how long a ReceiveMessage call waits if no messages are available in the queue. Visibility Timeout\tThe duration that a message remains invisible after a receiving component reads it from the queue. Dead-Letter Queue (DLQ)\tAdd a queue where messages that fail to be processed multiple times are sent for additional analysis.  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable names for your SQS.​","type":1,"pageTitle":"AWS OpenSearch","url":"/preview-docs/docs/project/dependency/opensearch-aws#3-customize-your-variable-names-for-your-sqs","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"AWS Oracle","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/oracle-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS Oracle","url":"/preview-docs/docs/project/dependency/oracle-aws#faqs","content":" License​ When creating an Oracle DB using Sleakops License Included (LI). Currently Bring Your Own License (BYOL) is not supported, however, contact support for more information.  How does SleakOps manage Oracle credentials?​ When you create an Oracle dependency in SleakOps, it automatically generates a Vargroup for your database. This Variable Group securely stores the Oracle credentials and other important configuration details, such as the database endpoint and user access information. You'll be able of manage them from Vargroups section.  What is Multi-AZ deployment and should I enable it?​ Multi-AZ (Availability Zone) deployment ensures high availability and failover support by replicating your database in another availability zone. It's recommended for production environments to prevent downtime. Keep in mind that it increases costs.  Can I change the Oracle version after the database is deployed?​ No, the database engine version cannot be changed after deployment. You would need to create a new Oracle instance with the desired version and migrate your data. Or change it manually into the AWS Console.  What happens if I need more storage for my Oracle database?​ You can adjust the storage size when configuring your database. If you need more storage after deployment, you can scale modifying the settings in AWS as at the moment SleakOps does not support it.  How do I create a Oracle database dump?​ warning The client is only available for x86-64 Linux distributions. tip Follow this link to install the client To create a dump of your Oracle database, use the following command: exp ${ORACLE_USERNAME}/${ORACLE_PASSWORD}@${ORACLE_ENDPOINT}/${ORACLE_NAME} FILE=exp_file.dmp LOG=exp_file.log Replace ORACLE_USERNAME, ORACLE_ENDPOINT, ORACLE_NAME and ORACLE_PASSWORD with the appropriate values. For additional information on creating an Oracle dump, refer to the official Oracle documentation . Another option is creating it directly from the AWS Console and then import it. See Restoring to a DB instance.  How do I import an existent dump ?​ warning The client is only available for x86-64 Linux distributions. tip Follow this link to install the client You can use a Oracle client installed on your local machine to import the dump. imp ${ORACLE_USERNAME}/${ORACLE_PASSWORD}@${ORACLE_ENDPOINT}/${ORACLE_NAME} FROMUSER=cust_schema TOUSER=cust_schema FILE=exp_file.dmp LOG=imp_file.log Replace ORACLE_USERNAME, ORACLE_ENDPOINT, ORACLE_NAME and ORACLE_PASSWORD with the appropriate values. For additional information on importing an Oracle dump, refer to the official Oracle documentation . Another option is creating it directly from the AWS Console and then import it. See Restoring to a DB instance.  What should I do if I encounter connection issues with my Oracle database?​ Ensure the database endpoint, username, and password are correct.Verify that your security groups and firewall rules allow access.Ensure the database is running and has enough resources (CPU, memory). Otherwise, contact us.  info AWS documentation: Amazon RDS Oracle Documentation  ","version":"Next","tagName":"h2"},{"title":"Set up your Oracle​","type":1,"pageTitle":"AWS Oracle","url":"/preview-docs/docs/project/dependency/oracle-aws#set-up-your-oracle","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add Oracle as a Dependency​","type":1,"pageTitle":"AWS Oracle","url":"/preview-docs/docs/project/dependency/oracle-aws#1-add-oracle-as-a-dependency","content":" To integrate Oracle with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;Oracle&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your Oracle.​","type":1,"pageTitle":"AWS Oracle","url":"/preview-docs/docs/project/dependency/oracle-aws#2-set-up-your-oracle","content":" You will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Attribute\tDescriptionDatabase Engine Version\tSelect the specific version of the Oracle database engine you wish to use. This ensures compatibility with your application requirements. Example: 19.0.0.0.ru-2024-01.rur-2024-01.r1 Database Instance Class\tDefine the instance class that specifies the hardware configuration for your Oracle database. This controls CPU, memory, and network performance. Example: db.m6g.large, db.t3.medium. See AWS detail. Database Storage\tSpecify the amount of storage allocated for the database. Example: 100 GB, 500 GB. Username\tProvide the master username for the Oracle database. This is the main user with administrative privileges. Example: admin, root. Password\tPassword for the master user to access the database. Multi-Availability Zone\tEnable or disable Multi-AZ deployment. This ensures high availability and failover support by replicating the database across multiple availability zones. Recommended for production environments. Automated Backup\tConfigure automated backups for the Oracle database. This ensures data protection by enabling daily snapshots and transaction log backups. Set up the Backup Retention Period and the Backup Window. Recommended for production environments. Backup Retention Period\tSet the number of days to retain automated backups. Backup Window\tPeriod of time while the backup will be done.  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable's name for your Oracle data base.​","type":1,"pageTitle":"AWS Oracle","url":"/preview-docs/docs/project/dependency/oracle-aws#3-customize-your-variables-name-for-your-oracle-data-base","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"AWS Redis","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/redis-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS Redis","url":"/preview-docs/docs/project/dependency/redis-aws#faqs","content":" What features make Redis a good choice for my application?​ Redis offers several advanced features that make it suitable for a wide range of applications: Data Persistence: Redis can save data to disk, ensuring that information is not lost in the event of a restart.Advanced Data Structures: Redis supports more complex data structures than simple key-value stores, such as lists, sets, hashes, sorted sets, and more.High Availability: Through replication and automatic failover, Redis ensures that your application remains operational even if a node fails.Scalability: Redis can be scaled both vertically (with larger instances) and horizontally (using sharding and clusters).Pub/Sub Messaging: Redis offers native support for publish/subscribe messaging patterns, useful for building real-time applications.  What are the common use cases for Redis?​ Redis is versatile and can be used in a variety of scenarios, including: Session Management: Redis is commonly used for storing user session data due to its low-latency data access and persistence features.Caching: Redis is ideal for caching frequently accessed data, reducing load on primary databases and improving response times.Real-Time Analytics: Redis's fast in-memory processing capabilities make it perfect for real-time analytics, leaderboards, and counters.Message Queues: With Redis’s pub/sub functionality, you can use it for messaging systems and event streaming.Job Queues: Redis is used for managing background job queues in large-scale applications.  How does Redis differ from Memcached?​ Redis is more feature-rich than Memcached. Redis supports a variety of data structures like lists, sets, and hashes, while Memcached is limited to simple key-value pairs. Redis also supports data persistence and replication, making it suitable for applications where durability and high availability are critical. However, Memcached is typically more lightweight and faster for basic caching scenarios.  ","version":"Next","tagName":"h2"},{"title":"Set up your AWS Redis​","type":1,"pageTitle":"AWS Redis","url":"/preview-docs/docs/project/dependency/redis-aws#set-up-your-aws-redis","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add AWS Redis as a Dependency​","type":1,"pageTitle":"AWS Redis","url":"/preview-docs/docs/project/dependency/redis-aws#1-add-aws-redis-as-a-dependency","content":" To integrate Redis with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;AWS Redis&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your Redis database.​","type":1,"pageTitle":"AWS Redis","url":"/preview-docs/docs/project/dependency/redis-aws#2-set-up-your-redis-database","content":" You will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Attribute\tDescriptionNode Type\tInstance class that determines the performance and memory capacity of the Redis instance. Examples: cache.t3.micro, cache.m5.large, cache.r6g.large Port\tThe communication port used by Redis to interact with your application. Default: 6379 (can be customized)  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable names for your Redis.​","type":1,"pageTitle":"AWS Redis","url":"/preview-docs/docs/project/dependency/redis-aws#3-customize-your-variable-names-for-your-redis","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"AWS S3 Bucket","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/s3bucket-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS S3 Bucket","url":"/preview-docs/docs/project/dependency/s3bucket-aws#faqs","content":" When should I use Amazon S3?​ You should use Amazon S3 when you need: Scalable storage for files, media, backups, or static assets.Highly durable and available storage for critical data.Data archiving solutions or disaster recovery.A cost-effective solution for storing large amounts of unstructured data.  How do I create a S3 dump?​ To create a backup of your S3 bucket data, follow these steps: Ensure Admin Access: Verify that you have admin access to the AWS account where the S3 bucket is located.Install AWS CLI: Ensure AWS CLI is installed on your local machine. For installation instructions, refer to the official AWS CLI documentation .Configure AWS CLI: Ensure that your Access and Secret keys are configured in the default profile. If they are under a different profile, use the --profile PROFILE_NAME option with the commands.Run Backup Commands: ```sh aws sts assume-role --role-arn arn:aws:iam::ACCOUNT_ID:role/SleakopsAdminRole aws s3 sync s3://BUCKET_NAME /path/to/local/directory``` Replace ACCOUNT_ID, BUCKET_NAME, and /path/to/local/directory with your specific details.  Does SleakOps create Variable Groups for S3 dependencies?​ Yes, when you configure an S3 bucket in SleakOps, it will automatically create a Variable Group. This securely stores the access keys and other sensitive information needed to manage and interact with your S3 bucket.  What is an S3 Access Control List (ACL)?​ An S3 Access Control List (ACL) defines the permissions for who can access your S3 bucket and its contents. It controls the level of access granted to users, groups, or predefined AWS entities. You can choose an ACL that defines who can access the bucket and what level of permission they have. The available options are: private: Only the bucket owner has full access. (Default)public-read: Anyone can read the objects in the bucket.public-read-write: Anyone can read and write to the bucket.aws-exec-read: Grants read access to AWS services like CloudFront.authenticated-read: Grants read access to authenticated AWS users.log-delivery-write: Grants write access to the bucket for logging purposes. For further details, you can refer to AWS S3 ACL documentation .  What is Amazon CloudFront?​ Amazon CloudFront is a Content Delivery Network (CDN) that speeds up the delivery of your static and dynamic content (like HTML, CSS, images, and videos) by caching it at edge locations closer to your users around the world.  Can I use a custom domain name with CloudFront?​ Yes, SleakOps allows you to set a custom alias (subdomain) for your CloudFront distribution. For example, you could use cdn.mydomain.com as the URL for your CloudFront distribution instead of the default CloudFront URL.  What is a Custom Header in CloudFront?​ Custom Headers allow you to include additional information in every request that CloudFront makes to your S3 bucket. This feature provides more control over how your S3 content is accessed and delivered by attaching specific metadata to the requests. SleakOps allows you to define custom headers for CloudFront, which will be included in all requests sent to your S3 bucket. This is useful for adding security measures, managing permissions, or tracking requests. custom_headers: - key: &quot;X-Custom-Header&quot; value: &quot;MyCustomValue&quot;   ","version":"Next","tagName":"h2"},{"title":"Set up your S3 Bucket​","type":1,"pageTitle":"AWS S3 Bucket","url":"/preview-docs/docs/project/dependency/s3bucket-aws#set-up-your-s3-bucket","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add S3 Bucket as a Dependency​","type":1,"pageTitle":"AWS S3 Bucket","url":"/preview-docs/docs/project/dependency/s3bucket-aws#1-add-s3-bucket-as-a-dependency","content":" To integrate S3 Bucket with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;S3 Bucket&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your S3 Bucket.​","type":1,"pageTitle":"AWS S3 Bucket","url":"/preview-docs/docs/project/dependency/s3bucket-aws#2-set-up-your-s3-bucket","content":" When adding an S3 bucket as a dependency in SleakOps, you will be required to configure the following attributes:  Attribute\tDescriptionS3 Access Control List (ACL)\tSpecifies the level of access for the S3 bucket and its contents. Options: private, public-read, public-read-write, aws-exec-read, authenticated-read, log-delivery-write Enable CloudFront\tAllows you to enable Amazon CloudFront, a CDN for delivering S3 bucket content globally. Alias\tThe alias for the S3 bucket or CloudFront distribution (e.g., cdn.mydomain.com). Price Class\tDefines the set of global CloudFront edge locations used to serve content. Options: Use all edge locations (best performance), Use North America, Europe, Asia, Middle East, and Africa, Use only North America and Europe. Check AWS Price Class . Custom Headers\tCustom headers that CloudFront includes in all requests sent to the S3 bucket. - Key: The header key, such as X-Custom-Header. - Value: The value you wish to assign to the header, like MyCustomValue. Override\tSpecify whether CloudFront should override existing headers in requests from the origin.    After that basic data, if you activated the Cloudfront, you will be able of customize its headers. To do that:  Into the form, look for the field CloudFront custom headers and click on + Add Item.Complete Key and ValueYou can add as many as you need.    ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable names for your S3.​","type":1,"pageTitle":"AWS S3 Bucket","url":"/preview-docs/docs/project/dependency/s3bucket-aws#3-customize-your-variable-names-for-your-s3","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes.    In this step you can change the name of the attributes in case it is needed but SleakOps completes the values automatically. After this step, your dependency is created. ","version":"Next","tagName":"h3"},{"title":"AWS SQS","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/sqs-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS SQS","url":"/preview-docs/docs/project/dependency/sqs-aws#faqs","content":" What is the difference between a Standard Queue and a FIFO Queue?​ A Standard Queue supports high throughput with at-least-once message delivery. Message ordering is not guaranteed but it's ideal for scenarios where message order isn't critical.A FIFO Queue ensures message ordering and exactly-once delivery. It's suitable for applications where message order is crucial.  What is Multi-AZ deployment and should I enable it?​ Multi-AZ (Availability Zone) deployment ensures high availability and failover support by replicating your database in another availability zone. It’s recommended for production environments to prevent downtime. Keep in mind that it increases costs.  What is a Dead-Letter Queue (DLQ), and when should I use it?​ A DLQ is a secondary queue where messages that can't be processed successfully after a certain number of attempts are sent. You should configure a DLQ to help with error handling and to prevent message loss. See AWS SQS DLQ .  What is Deduplication in a FIFO Queue?​ In an SQS FIFO Queue, deduplication ensures that duplicate messages are automatically removed, preserving strict message ordering.  ","version":"Next","tagName":"h2"},{"title":"Set up your SQS​","type":1,"pageTitle":"AWS SQS","url":"/preview-docs/docs/project/dependency/sqs-aws#set-up-your-sqs","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add SQS as a Dependency​","type":1,"pageTitle":"AWS SQS","url":"/preview-docs/docs/project/dependency/sqs-aws#1-add-sqs-as-a-dependency","content":" To integrate SQS with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;SQS&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your SQS database.​","type":1,"pageTitle":"AWS SQS","url":"/preview-docs/docs/project/dependency/sqs-aws#2-set-up-your-sqs-database","content":" You will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Attribute\tDescriptionFifo Queue\tSelect if the queue is standard or fifo. Read more on FAQs Fifo Deduplication\tSelect if deduplication is activated. Read more on FAQs Message Delay Seconds\tSeconds of delivery delay to messages on queue. Message Max Size\tBytes maximum limit per message Message Retention Seconds\tSeconds that a message is retained by SQS Receive WaitTime Seconds\tThe time for which a ReceiveMessage call will wait for a message to arrive (long polling) before returning Visibility Timeout Seconds\tSeconds that a message is retained by SQS Dead Letter Queue\tSelect if dead letter queue is enabled. Read more on FAQs  By activating the Dead Letter Queue feature, you need to complete the same information for the second queue.  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable names for your SQS.​","type":1,"pageTitle":"AWS SQS","url":"/preview-docs/docs/project/dependency/sqs-aws#3-customize-your-variable-names-for-your-sqs","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"AWS PosgreSQL","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dependency/postgresql-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS PosgreSQL","url":"/preview-docs/docs/project/dependency/postgresql-aws#faqs","content":" How does SleakOps manage PostgreSQL credentials?​ When you create a PostgreSQL dependency in SleakOps, it automatically generates a Vargroup for your database. This Variable Group securely stores the PostgreSQL credentials and other important configuration details, such as the database endpoint and user access information. You’ll be able of manage them from Vargroups section.  What is Multi-AZ deployment and should I enable it?​ Multi-AZ (Availability Zone) deployment ensures high availability and failover support by replicating your database in another availability zone. It’s recommended for production environments to prevent downtime. Keep in mind that it increases costs.  Can I change the PostgreSQL version after the database is deployed?​ No, the database engine version cannot be changed after deployment. You would need to create a new PostgreSQL instance with the desired version and migrate your data. Or change it manually into the AWS Console.  What happens if I need more storage for my PostgreSQL database?​ You can adjust the storage size when configuring your database. If you need more storage after deployment, SleakOps allows you to scale the storage size without downtime.  How do I create a PostgreSQL database dump?​ To create a dump of your PostgreSQL database: Run the pg_dump Command: sh pg_dump -h POSTGRESQL_ADDRESS -U POSTGRESQL_USERNAME -W &gt; dump.sql Replace POSTGRESQL_ADDRESS, POSTGRESQL_USERNAME, and dump.sql with the appropriate values. 2. Consult Documentation: For more information on how to create a dump, refer to the official PostgreSQL documentation..  How do I import an existent dump using docker?​ To import a database dump into your PostgreSQL RDS instance: Connect to the VPN: Ensure you are connected to the VPN of the AWS account where the RDS instance is located.Run Docker Container (Recommended): Install Docker on your local machine if not already installed.Run a PostgreSQL Docker container with the following command: sh docker run -it --name postgresql-container -v ./initial_data/:/tmp/data/ -e POSTGRESQL_ROOT_PASSWORD=POSTGRESQL_PASSWORD -d postgres bash Attach to the container’s terminal: sh docker exec -t -i postgresql-container bash Import the dump file: pg_dump -h POSTGRESQL_ADDRESS -U POSTGRESQL_USERNAME -W &lt; /tmp/data/dump.sql Replace POSTGRESQL_ADDRESS, POSTGRESQL_USERNAME, and dump.sql with your specific details.  How do I import an existent dump to my local machine ?​ Alternatively, you can use a PostgreSQL client installed on your local machine to import the dump. sh psql -h POSTGRESQL_ADDRESS -U POSTGRESQL_USERNAME -W -f /tmp/data/dump.sql   What should I do if I encounter connection issues with my PostgreSQL database?​ Check the following: Ensure the database endpoint, username, and password are correct.Verify that your firewall rules allow access.Ensure the database is running and has enough resources (CPU, memory). Otherwise, contact us.  What is an RDS Read Replica?​ An RDS Read Replica is a read-only copy of your primary database instance in Amazon RDS. It helps distribute read-heavy workloads and improves the performance and scalability of your database by offloading read operations from the primary database. RDS Read Replicas are ideal when you need to: Offload read-heavy operations from your primary instance.Scale your read operations as your application grows.Distribute database reads across multiple geographic locations.Have a backup solution that can quickly be promoted to a primary instance in case of failure. info Keep in mind that Read replicas have a delay performing updates.  How do I configure a Read Replica in SleakOps?​ In SleakOps, when creating a read replica for your RDS database, you will need to provide the following information: Name of the replicaReplica Instance Class, which determines the instance type for the replica.Replica Publicly Accessible, to decide if the replica should have a public IP or be accessible only within your private network.  Can I delete a replica?​ At the moment, the only way is to delete the dependency.  info AWS documentation: Amazon RDS PostgreSQL Documentation  ","version":"Next","tagName":"h2"},{"title":"Set up your PostgreSQL​","type":1,"pageTitle":"AWS PosgreSQL","url":"/preview-docs/docs/project/dependency/postgresql-aws#set-up-your-postgresql","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add PostgreSQL as a Dependency​","type":1,"pageTitle":"AWS PosgreSQL","url":"/preview-docs/docs/project/dependency/postgresql-aws#1-add-postgresql-as-a-dependency","content":" To integrate PostgreSQL with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;PostgreSQL&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your PostgreSQL database.​","type":1,"pageTitle":"AWS PosgreSQL","url":"/preview-docs/docs/project/dependency/postgresql-aws#2-set-up-your-postgresql-database","content":" You will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Attribute\tDescriptionDatabase Engine Version\tSelect the specific version of the MySQPostgreSQLL database engine you wish to use. This ensures compatibility with your application requirements. Example: PostgreSQL 14.9, PostgreSQL 16.5 Database Instance Class\tDefine the instance class that specifies the hardware configuration for your PostgreSQL database. This controls CPU, memory, and network performance. Example: db.m6g.large, db.t3.medium. See AWS detail. Database Storage\tSpecify the amount of storage allocated for the database. Example: 100 GB, 500 GB. Username\tProvide the master username for the PostgreSQL database. This is the main user with administrative privileges. Example: admin, root. Password\tPassword for the master user to access the database. Multi-Availability Zone\tEnable or disable Multi-AZ deployment. This ensures high availability and failover support by replicating the database across multiple availability zones. Recommended for production environments. Automated Backup\tConfigure automated backups for the PostgreSQL database. This ensures data protection by enabling daily snapshots and transaction log backups. Set up the Backup Retention Period and the Backup Window. Recommended for production environments. Backup Retention Period\tSet the number of days to retain automated backups. Backup Window\tPeriod of time while the backup will be done.  warning SleakOps allow the creation of replicas only during the creation of the dependency.  After that basic data, you need to decide if a replica will be created. To do that:  Into the form, look for the section Definition of RDS Read Replicas and click on + Add Item.Complete the following data:  Setting\tDescriptionName\tA name for the replica Replica Instance Class\tDefine the instance class that specifies the hardware configuration for your PostgreSQL database. This controls CPU, memory, and network performance. Example: db.m6g.large, db.t3.medium. Replica Publicly Accessible\tDecide if the replica should have a public IP or be accessible only within your private network.  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable’s name for your PostgreSQL data base.​","type":1,"pageTitle":"AWS PosgreSQL","url":"/preview-docs/docs/project/dependency/postgresql-aws#3-customize-your-variables-name-for-your-postgresql-data-base","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"Deployment","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/deployment","content":"","keywords":"","version":"Next"},{"title":"Deploying your ProjectEnv​","type":1,"pageTitle":"Deployment","url":"/preview-docs/docs/project/deployment#deploying-your-projectenv","content":" Upon creating a Deployment, we fetch the image corresponding to the Build to be deployed. Before this, we execute the Helm Release in the appropriate cluster namespace. This Helm release includes necessary Kubernetes services, ingresses, workers, and other services.  Various methods exist to generate a Deployment. These are outlined below. Note that we force certain Deployments. For details, refer to More on Deployment.  Workloads: Provides a switcher allowing you to decide whether to run a new Deployment.VariableGroup: Operates similarly to Workloads but doesn't create a new Release. Instead, it only updates the values of the Deployment.Dependency: Triggers a Deployment automatically. Delve deeper into this at More on Deployment.    ","version":"Next","tagName":"h2"},{"title":"Manual Deployment​","type":1,"pageTitle":"Deployment","url":"/preview-docs/docs/project/deployment#manual-deployment","content":" If you skip deploying your changes immediately, or if your modification doesn't enforces a deployment, you have three methods to execute a Deployment:  Build section: Utilizing the Deploy button, you can determine which Build to deploy.    Unpublished banner​    Unpublished Changes Banner: This banner is shown when there's content pending that was not yet deployed on the cluster. Through this banner, you have the choice to deploy only the VariableGroups or if you want to deploy everything, including the Services in the 'draft' state.    Via the CLI . ","version":"Next","tagName":"h3"},{"title":"More on Deployments","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/deployment/more_on_deployment","content":"","keywords":"","version":"Next"},{"title":"How SleakOps Handles Deployments​","type":1,"pageTitle":"More on Deployments","url":"/preview-docs/docs/project/deployment/more_on_deployment#how-sleakops-handles-deployments","content":" To execute a deployment, SleakOps utilizes the Build images stored in your project's image repository (AWS ECR), which are created either with the ProjectEnv entity during the Initial Build or with the creation of a Build entity that pushes to the ECR. Whenever a Deployment is initiated, we fetch the image corresponding to the designated Build.  The next phase involves constructing and deploying the Helm chart. This is accomplished using generally purpose-built templates. Once constructed, we upload the Helm chart to the same ECR utilized for the Build images and proceed to deploy a Helm Release into the Kubernetes cluster, specifically within the ProjectEnv namespace.  info All these resources reside in your own AWS Accounts. Sleakops does not exclusively store any data.  ","version":"Next","tagName":"h2"},{"title":"Forced Deployments​","type":1,"pageTitle":"More on Deployments","url":"/preview-docs/docs/project/deployment/more_on_deployment#forced-deployments","content":" Forced Deployment Hace in mind that under certain circumstances, SleakOps forces a Deploy.  While multiple methods for generating a Deployment were highlighted in the primary Deployment documentation, it's crucial to understand that SleakOps sometimes enforces Deployments. The rationale behind this is to optimize uptime, safeguard the current state of the deployed infrastructure, and mitigate potential service downtimes on the Cluster. This imperative arises because Helm templates should always synchronize with the Kubernetes Secrets present in the namespace to avert deployment failures.  As you may already know, if it's not a 'forced' deployment, you'll be presented with an option (switcher) to determine if you wish to deploy your modifications. Deployments are forced in the following scenarios.  Workloads Alias Configuration Changes: A Deployment is forced if any alterations are made to the 'alias' configuration.Dependency: Always forces a Deployment to synchronize its associated VariableGroup state with the templates of the Helm Chart ensuring that Services operation is not affected.VariableGroup Deletion: Same case as Dependency deletion. ","version":"Next","tagName":"h3"},{"title":"Release","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/deployment/release","content":"","keywords":"","version":"Next"},{"title":"What is a Release?​","type":1,"pageTitle":"Release","url":"/preview-docs/docs/project/deployment/release#what-is-a-release","content":" In Sleakops, a release represents a deployable state of all the Workloads (web services, workers, cron jobs, hooks) of a project in an environment.  ","version":"Next","tagName":"h2"},{"title":"Release Creation​","type":1,"pageTitle":"Release","url":"/preview-docs/docs/project/deployment/release#release-creation","content":" Sleakops administers releases for you. Every time you modify, delete, or add a web service, worker, hook, or cron job, Sleakops gives you the option to publish the changes. Each time you publish those changes, Sleakops creates a new release with auto-incremented versions.  ","version":"Next","tagName":"h2"},{"title":"Helm Chart Resources​","type":1,"pageTitle":"Release","url":"/preview-docs/docs/project/deployment/release#helm-chart-resources","content":" Web Service:​  A Kubernetes deploymentA Kubernetes serviceA Kubernetes HPA (Horizontal Pod Autoscaler)A Kubernetes ingress  The ingress generates its hosts using &lt;service_name&gt;.&lt;environment_name&gt;.&lt;organization_name&gt;.&lt;yourdomain.com&gt;  Worker:​  A Kubernetes deploymentA Kubernetes HPA  Hook:​  A Kubernetes job  This job uses Kubernetes hooks to start.  Cron Job:​  A Kubernetes cron job ","version":"Next","tagName":"h3"},{"title":"Technical Documentation - Dockertron","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/dockertron","content":"","keywords":"","version":"Next"},{"title":"Executive Summary​","type":1,"pageTitle":"Technical Documentation - Dockertron","url":"/preview-docs/docs/project/dockertron#executive-summary","content":" Dockertron is an automated dockerization system that analyzes your source code and automatically generates the necessary infrastructure to run your application in Docker containers. The system uses artificial intelligence to understand your project structure and create the appropriate configuration files.  You can find it in SleakOps in the Projects &gt; Configuration &gt; Dockertron section.      ## What Does Dockertron Do?  Dockertron automates the containerization process of your application following these steps:  Repository Analysis: Examines your source code structureService Identification: Detects which components of your application need to runDockerfile Generation: Creates optimized Dockerfiles for each serviceDocker Compose Creation: Generates a docker-compose.yml file that orchestrates all servicesInfrastructure Configuration: Prepares the configuration for deployment on SleakOps    ","version":"Next","tagName":"h2"},{"title":"Dockerization Process Flow​","type":1,"pageTitle":"Technical Documentation - Dockertron","url":"/preview-docs/docs/project/dockertron#dockerization-process-flow","content":" 1. Submit the Project​ To start the dockerization process, you must complete the Dockertron form in three steps: Step 1: Language Information​ Specify the main programming language of your project: Language Name: Language name (e.g., Python, Node.js, Java, Go)Language Version: Specific language version (e.g., 3.12, 18.0, 11) Step 2: Application Frameworks​ Configure the frameworks your application uses. You can add multiple frameworks: Framework Name: Framework name (e.g., Django, Express, Spring Boot)Command: Command to run the framework (e.g., python manage.py runserver 0.0.0.0)Framework Version: Framework version (e.g., 5.2, 4.18.2) You can add more frameworks by clicking &quot;+ Add Item&quot;.  2. Intelligent Analysis​ The system performs a deep analysis of your project: Phase 1: Repository Audit​ Confirms the main programming languageConfirms frameworks and libraries usedAnalyzes folder structureIdentifies configuration files (package.json, requirements.txt, etc.) Phase 2: Service Identification​ The system automatically detects: Web applications (frontend, backend)APIs and microservicesWorkers and background processesRequired databasesCache services (Redis, Memcached)Message queues (RabbitMQ, SQS)  3. File Generation​ Dockerfiles​ For each service that requires building, a Dockerfile is generated that includes: Appropriate base imageDependency installationEnvironment configurationStartup commandsHealthchecksSecurity and performance optimizations Docker Compose​ A docker-compose.yml file is generated that: Defines all servicesConfigures networks between servicesEstablishes volumes for data persistenceDefines environment variablesConfigures ports and service exposureEstablishes dependencies between services README​ Documentation is generated with: Instructions to run the projectNecessary commandsRequired configurationsBasic troubleshooting  4. SleakOps Preparation​ The system generates the infrastructure configuration for SleakOps, identifying: WorkloadsDependenciesEnvironment Variables  5. Pull Request Generation​ Once the analysis and file generation is complete, Dockertron automatically creates a Pull Request in your repository with all generated configuration files: Dockerfilesdocker-compose.ymlREADME.md with instructionsAdditional configuration files This allows you to: Review all proposed changes before integrating themComment and request adjustments if necessaryApprove and merge when satisfied with the configurationMaintain a clear history of changes in your repository  Repository Integration​ Upon completion of the process, Dockertron: Generates a Pull Request in your repository with all Docker configuration filesSends the information to SleakOps so you can easily deploy from the console with the configurations recommended by the AI agent This way, you maintain full control over changes to your code while leveraging SleakOps automation.  Complete Example​ Input Project​ my-app/ ├── backend/ ├── package.json ├── server.js └── ... Generated Output​ Detected Services: Backend (Node.js API)Frontend (React App)Worker (Python) Identified Dependencies: PostgreSQL (for backend)Redis (for cache and queues) Generated Files: backend/Dockerfiledocker-compose.ymlREADME.md    ","version":"Next","tagName":"h2"},{"title":"Frequently Asked Questions​","type":1,"pageTitle":"Technical Documentation - Dockertron","url":"/preview-docs/docs/project/dockertron#frequently-asked-questions","content":" How long does the process take?​ Typically between 5-30 minutes, depending on the size and complexity of the project.  What if my project has special configurations?​ You can provide additional context in the contexts field when submitting the request, indicating specific frameworks, versions, or special configurations.  Can I review the files before deployment?​ Yes, all generated files are sent back and can be reviewed before proceeding with deployment.  What happens if the process fails?​ The system sends a detailed error message indicating what went wrong, allowing adjustments, retries, and modifications to the submitted information so the AI agent can generate the correct configuration.  Can the generated files be modified?​ Yes, the generated files are completely editable and can be adjusted according to your specific needs.  Document version: 1.0Last update: November 2025 ","version":"Next","tagName":"h2"},{"title":"VariableGroups","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/vargroup","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"VariableGroups","url":"/preview-docs/docs/project/vargroup#faqs","content":" Can I edit a VariableGroup created by SleakOps?​ Yes, you can access and manage the Variable Group for your MySQL instance from the SleakOps console. You can modify values such as usernames, passwords, or any other environment-specific credentials.  How are Vargroups used by my applications?​ Vargroups are securely injected into your application's environment when it is deployed. Your applications can access these credentials and other variables without exposing sensitive information in the code.  How does SleakOps ensure the security of Vargroups?​ SleakOps securely stores vargroups as Kubernetes secrets inside your EKS cluster. Access is controlled via Kubernetes Service Accounts, ensuring that only authorized components can access the sensitive information.  Can I delete a Variable Group?​ Yes, they can be deleted or updated as needed. However, be cautious when deleting them, as it may disrupt your application.  What is the difference between a Global and a Workload-Scoped Vargroup?​ Global: Available to all workload within the namespace. It is created without selecting a specific workload. To create them select “global”Workload-Scoped Variable Group: Only applies to the selected workload within the project and environment. It overrides global var group values if they have the same key.  What happens if there are duplicate keys in different Vargroups?​ If duplicate keys exist across different var groups: If the key exists in both a global and a workload-scoped var group, the workload-scoped value takes precedence.If two global vargroups have the same key, the most recently created one will be used.  ","version":"Next","tagName":"h2"},{"title":"Create a VarGroup​","type":1,"pageTitle":"VariableGroups","url":"/preview-docs/docs/project/vargroup#create-a-vargroup","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navigate to create Vargroup section​","type":1,"pageTitle":"VariableGroups","url":"/preview-docs/docs/project/vargroup#1-navigate-to-create-vargroup-section","content":" Into the Left Pane, access Vargroups option under Projects and then, at the top right corner, click on the Create button.    ","version":"Next","tagName":"h3"},{"title":"2. Select a Project and complete the needed attributes​","type":1,"pageTitle":"VariableGroups","url":"/preview-docs/docs/project/vargroup#2-select-a-project-and-complete-the-needed-attributes","content":" Complete the following attributes to create a new vargroup:  Attribute\tDescriptionProject\tThe specific application or workload within SleakOps. Determines the scope of the variable group. Workload\tA microservice or component within the project. If selected, the vargroup is limited to it; otherwise, by selecting global it'll be accessible into the namespace. Name\tA unique identifier for the var group, used to differentiate it within the project. Should be descriptive of the group's purpose. Deploy\tEnable this option if you want SleakOps to automatically publish and deploy your workloads into the project.  info If you choose to add the argument using the text option: Each argument should be added on a new line, separated by an equal sign (=), with no extra spaces. ARGUMENT_NAME = VALUE ARGUMENT_TWO = VALUE ARGUMENT_ONE = VALUE    Submit to create and Deploy your vargroup. ","version":"Next","tagName":"h3"},{"title":"Volumes","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/volumes","content":"","keywords":"","version":"Next"},{"title":"Creating Volumes​","type":1,"pageTitle":"Volumes","url":"/preview-docs/docs/project/volumes#creating-volumes","content":"   To create a new volume for your project:  Click on &quot;Create Volumes&quot; in the Project settingsAdd the mount path - Specify the directory path where the volume will be mounted in your containersSet storage capacity - Define the amount of storage space allocated to the volumeChoose retention policy - Select between: Delete: Volume will be removed when deleted from SleakOpsRetain: Volume will persist in AWS even if removed from SleakOps  Volume Configuration Mount paths should be absolute paths (e.g., /app/data, /var/logs)Storage capacity is specified in GBThe retain policy determines data persistence when volumes are removed  ","version":"Next","tagName":"h2"},{"title":"Deleting Volumes​","type":1,"pageTitle":"Volumes","url":"/preview-docs/docs/project/volumes#deleting-volumes","content":"   To remove a volume from your project:  Click the &quot;X&quot; button next to the volume you want to deleteConfirm the deletion when prompted  Data Loss Warning Deleting a volume will permanently remove all data stored in it. Make sure to backup any important data before deletion.  Retain Policy Behavior Delete Policy: Volume and all data are permanently removed from AWSRetain Policy: Volume remains in AWS but is detached from the project, preserving your data ","version":"Next","tagName":"h2"},{"title":"Workloads","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/workload","content":"","keywords":"","version":"Next"},{"title":"Which workload type is right for me?​","type":1,"pageTitle":"Workloads","url":"/preview-docs/docs/project/workload#which-workload-type-is-right-for-me","content":"   Web Service: Choose this if you need your application or service to be available 24/7 to respond to HTTP requests.Worker: Use this for background processing tasks, such as message queues or data pipelines, with no direct HTTP interaction.CronJob: Ideal for recurring maintenance or reporting tasks scheduled at specific times.Job: Suitable for one-time or on-demand tasks (e.g., manual database migrations).Hook: Perfect if you want to automate certain actions (like database migrations or analytics) on every deployment. ","version":"Next","tagName":"h2"},{"title":"Hooks","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/workload/hook","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Hooks","url":"/preview-docs/docs/project/workload/hook#faqs","content":" How can I configure memory and CPU settings for my Hook?​ You can configure the CPU Request and CPU Limit values to set the minimum and maximum CPU resources each instance in your cluster can use. Similarly, you set Memory Request and Memory Limit for memory allocation per instance.  ","version":"Next","tagName":"h2"},{"title":"Lets add a Hook for your Project​","type":1,"pageTitle":"Hooks","url":"/preview-docs/docs/project/workload/hook#lets-add-a-hook-for-your-project","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navigate to create Hook section​","type":1,"pageTitle":"Hooks","url":"/preview-docs/docs/project/workload/hook#1-navigate-to-create-hook-section","content":" Into the Left Pane, access Workloads. Then select the Hook tab and then, at the top right corner, click on the Create button.    ","version":"Next","tagName":"h3"},{"title":"2. Select a Project and a Name for the hook​","type":1,"pageTitle":"Hooks","url":"/preview-docs/docs/project/workload/hook#2-select-a-project-and-a-name-for-the-hook","content":" Start with the basic information, complete these attributes and click Next to continue.  Attribute\tDescriptionName\tIdentify your web service. Project\tSelect between the existent projects. Command\tThe command that the workload runs.  Once those attributes are completed, click the Next button to move forward.    ","version":"Next","tagName":"h3"},{"title":"3. Define the deploy event​","type":1,"pageTitle":"Hooks","url":"/preview-docs/docs/project/workload/hook#3-define-the-deploy-event","content":" Select when your hook will execute and click Next.  Attribute\tDescriptionEvent\tDefine when execute the hook. Check available events    ","version":"Next","tagName":"h3"},{"title":"5. Finish the set up​","type":1,"pageTitle":"Hooks","url":"/preview-docs/docs/project/workload/hook#5-finish-the-set-up","content":" This step outlines the key attributes for configuring the resources of a Hook in SleakOps, allowing for flexible management of CPU, memory, and scaling behaviors.  Attribute\tDescriptionCPU Request\tThe minimum amount of CPU resources allocated for each instance in the cluster. This ensures that each instance always has this amount of CPU available. CPU Limit\tThe maximum CPU resources that each instance in the cluster can use. This cap helps prevent any single instance from consuming too much CPU. Memory Request\tThe minimum amount of memory allocated for each instance in the cluster. This guarantees that the instance has enough memory to operate efficiently. Memory Limit\tThe maximum amount of memory each instance in the cluster can utilize. It limits the memory usage to prevent any single instance from overconsuming resources.    Submit to create and Deploy your hook. ","version":"Next","tagName":"h3"},{"title":"Job","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/workload/job","content":"","keywords":"","version":"Next"},{"title":"Cronjobs","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/workload/cronjob","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/docs/project/workload/cronjob#faqs","content":" How can I configure memory and CPU settings for my Cronjob?​ You can configure the CPU Request and CPU Limit values to set the minimum and maximum CPU resources each instance in your cluster can use. Similarly, you set Memory Request and Memory Limit for memory allocation per instance.  ","version":"Next","tagName":"h2"},{"title":"Lets add a Cronjob for your Project​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/docs/project/workload/cronjob#lets-add-a-cronjob-for-your-project","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navigate to create Cronjob section​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/docs/project/workload/cronjob#1-navigate-to-create-cronjob-section","content":" Into the Left Pane, access Workloads. Then select the Cronjob tab and then, at the top right corner, click on the Create button.    ","version":"Next","tagName":"h3"},{"title":"2. Select a Project and a Name for the cronjob​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/docs/project/workload/cronjob#2-select-a-project-and-a-name-for-the-cronjob","content":" Start with the basic information, complete these attributes and click Next to continue.  Attribute\tDescriptionName\tIdentify your cronjob. Project\tSelect between the existent projects. Command\tThe command that runs the cronjob.  Once those attributes are completed, click the Next button to move forward.    ","version":"Next","tagName":"h3"},{"title":"3. Define the periodicity​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/docs/project/workload/cronjob#3-define-the-periodicity","content":" Select how will be your connection and click on Next.  Attribute\tDescriptionCrontab\tCron expresion to determine the schedule to execute the cronjob    ","version":"Next","tagName":"h3"},{"title":"5. Finish the set up​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/docs/project/workload/cronjob#5-finish-the-set-up","content":" This step outlines the key attributes for configuring the resources of a Cronjob in SleakOps, allowing for flexible management of CPU, memory, and scaling behaviors.  Attribute\tDescriptionCPU Request\tThe minimum amount of CPU resources allocated for each instance in the cluster. This ensures that each instance always has this amount of CPU available. CPU Limit\tThe maximum CPU resources that each instance in the cluster can use. This cap helps prevent any single instance from consuming too much CPU. Memory Request\tThe minimum amount of memory allocated for each instance in the cluster. This guarantees that the instance has enough memory to operate efficiently. Memory Limit\tThe maximum amount of memory each instance in the cluster can utilize. It limits the memory usage to prevent any single instance from overconsuming resources.    Submit to create and Deploy your cronjob. ","version":"Next","tagName":"h3"},{"title":"FAQs​","type":1,"pageTitle":"Job","url":"/preview-docs/docs/project/workload/job#faqs","content":" How can I configure memory and CPU settings for my Job?​ You can configure the CPU Request and CPU Limit values to set the minimum and maximum CPU resources each instance in your cluster can use. Similarly, you set Memory Request and Memory Limit for memory allocation per instance.  ","version":"Next","tagName":"h2"},{"title":"Lets add a Job for your Project​","type":1,"pageTitle":"Job","url":"/preview-docs/docs/project/workload/job#lets-add-a-job-for-your-project","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navigate to create Job section​","type":1,"pageTitle":"Job","url":"/preview-docs/docs/project/workload/job#1-navigate-to-create-job-section","content":" Into the Left Pane, access Workloads. Then select the Job tab and then, at the top right corner, click on the Create button.    ","version":"Next","tagName":"h3"},{"title":"2. Select a Project and a Name for the job​","type":1,"pageTitle":"Job","url":"/preview-docs/docs/project/workload/job#2-select-a-project-and-a-name-for-the-job","content":" Start with the basic information, complete these attributes and click Next to continue.  Attribute\tDescriptionName\tIdentify your job. Project\tSelect between the existent projects. Command\tThe command that runs the job. Image\tBy default the job usage the image of your project, but you can override that with another Image tag\tYou can specify the tag of image.  Once those attributes are completed, click the Next button to move forward.    ","version":"Next","tagName":"h3"},{"title":"3. Finish the set up​","type":1,"pageTitle":"Job","url":"/preview-docs/docs/project/workload/job#3-finish-the-set-up","content":" This step outlines the key attributes for configuring the resources of a Job in SleakOps, allowing for flexible management of CPU, memory, and scaling behaviors.  Attribute\tDescriptionCPU Request\tThe minimum amount of CPU resources allocated for each instance in the cluster. This ensures that each instance always has this amount of CPU available. CPU Limit\tThe maximum CPU resources that each instance in the cluster can use. This cap helps prevent any single instance from consuming too much CPU. Memory Request\tThe minimum amount of memory allocated for each instance in the cluster. This guarantees that the instance has enough memory to operate efficiently. Memory Limit\tThe maximum amount of memory each instance in the cluster can utilize. It limits the memory usage to prevent any single instance from overconsuming resources.    Submit to create and Deploy your job. ","version":"Next","tagName":"h3"},{"title":"Worker","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/workload/worker","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Worker","url":"/preview-docs/docs/project/workload/worker#faqs","content":" How do I set up auto-scaling for my Worker?​ To enable auto-scaling, you can set the Autoscaling option to enabled and define the Memory Target and CPU Target. These targets determine the resource usage thresholds that trigger auto-scaling. You must also specify the minimum and maximum number of replicas to be maintained when auto-scaling is enabled.  How can I configure memory and CPU settings for my Worker?​ You can configure the CPU Request and CPU Limit values to set the minimum and maximum CPU resources each instance in your cluster can use. Similarly, you set Memory Request and Memory Limit for memory allocation per instance.  ","version":"Next","tagName":"h2"},{"title":"Lets add a Worker for your Project​","type":1,"pageTitle":"Worker","url":"/preview-docs/docs/project/workload/worker#lets-add-a-worker-for-your-project","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navigate to create Worker section​","type":1,"pageTitle":"Worker","url":"/preview-docs/docs/project/workload/worker#1-navigate-to-create-worker-section","content":" Into the Left Pane, access Workloads. Then select the Worker tab and then, at the top right corner, click on the Create button.    ","version":"Next","tagName":"h3"},{"title":"2. Select a Project and a Name for the worker​","type":1,"pageTitle":"Worker","url":"/preview-docs/docs/project/workload/worker#2-select-a-project-and-a-name-for-the-worker","content":" Start with the basic information, complete these attributes and click Next to continue.  Attribute\tDescriptionName\tIdentify your worker. Project\tSelect between the existent projects. Command\tThe command that runs the worker.  Once those attributes are completed, click the Next button to move forward.    ","version":"Next","tagName":"h3"},{"title":"3. Finish the set up​","type":1,"pageTitle":"Worker","url":"/preview-docs/docs/project/workload/worker#3-finish-the-set-up","content":" This step outlines the key attributes for configuring the resources of a Worker in SleakOps, allowing for flexible management of CPU, memory, and scaling behaviors.  Attribute\tDescriptionCPU Request\tThe minimum amount of CPU resources allocated for each instance in the cluster. This ensures that each instance always has this amount of CPU available. CPU Limit\tThe maximum CPU resources that each instance in the cluster can use. This cap helps prevent any single instance from consuming too much CPU. Memory Request\tThe minimum amount of memory allocated for each instance in the cluster. This guarantees that the instance has enough memory to operate efficiently. Memory Limit\tThe maximum amount of memory each instance in the cluster can utilize. It limits the memory usage to prevent any single instance from overconsuming resources. Autoscaling\tToggle to enable or disable auto-scaling. When enabled, it allows the workload to adjust the number of replicas based on demand and resource usage. CPU Target\tThe CPU usage percentage target that initiates auto-scaling. If usage exceeds this target, additional replicas may be deployed to balance the load. Memory Target\tThe memory usage percentage target that triggers auto-scaling adjustments. When instances exceed this target, the system scales up to accommodate demand. Replicas Min\tThe minimum number of replicas to maintain when auto-scaling is active. A minimum of 2 replicas ensures high availability and prevents downtime. Replicas Max\tThe maximum number of replicas that can be deployed when auto-scaling is enabled. It sets an upper limit on the number of instances to avoid over-provisioning.    Submit to create and Deploy your worker. ","version":"Next","tagName":"h3"},{"title":"Web Service","type":0,"sectionRef":"#","url":"/preview-docs/docs/project/workload/webservice","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Web Service","url":"/preview-docs/docs/project/workload/webservice#faqs","content":" What is the difference between Public, Private, and Internal service schemas?​ Public: Accessible over the internet and is open to anyone.Private: Restricted access, available only when connected to the VPN.Internal: Only accessible within the same Kubernetes cluster and is used for internal communication between services.  How do I set up auto-scaling for my Web Service?​ To enable auto-scaling, you can set the Autoscaling option to enabled and define the Memory Target and CPU Target. These targets determine the resource usage thresholds that trigger auto-scaling. You must also specify the minimum and maximum number of replicas to be maintained when auto-scaling is enabled.  What are the default success codes for a Web Service, and can I change them?​ The default success code is 200, indicating the service is healthy. You can change this code based on your application’s requirements, as some services might return different success codes based on specific actions.  What happens if my health check fails repeatedly?​ If the health check fails consecutively and reaches the Failure Threshold (default is 60), the service is marked as unhealthy, and Kubernetes might restart or terminate the service instance to attempt a recovery.  How can I configure memory and CPU settings for my Web Service?​ You can configure the CPU Request and CPU Limit values to set the minimum and maximum CPU resources each instance in your cluster can use. Similarly, you set Memory Request and Memory Limit for memory allocation per instance.  What are some best practices when configuring a Web Service in SleakOps?​ Always set a minimum of 2 replicas to avoid downtime.Ensure your health check paths and success codes are correctly configured to reflect the true health of your service.Use auto-scaling where possible to optimize resources dynamically based on demand.Review and set memory and CPU usage targets appropriately to prevent overloading your infrastructure.  What should I do if my service shows response times longer than 10 seconds?​ Long response times may indicate issues such as resource constraints, application inefficiencies, or network problems. You should check your service logs, ensure your resources (CPU, memory) are adequately allocated, and review your application code for potential optimizations.  How can I deploy my static web service?​ At the moment, Sleakops doesn’t natively support static sites, but you can still deploy them using the same flow as other sites, by containerizing them with a web server like Nginx. Below is a simple example of a Dockerfile and the corresponding nginx.conf to serve your static content. FROM node:20.11.0-alpine AS base WORKDIR /app FROM base AS build ARG BACKEND_URL WORKDIR /app COPY package.json package-lock.json ./ RUN npm install COPY . ./ RUN npm run build FROM nginx:1.25.3-alpine AS production COPY --from=build /app/config/nginx.conf /etc/nginx/conf.d/default.conf COPY --from=build /app/dist /usr/share/nginx/html EXPOSE 80 CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] And here is a sample config/nginx.conf: server { listen 80; location = /health { access_log off; add_header 'Content-Type' 'application/json'; return 200 '{&quot;status&quot;:&quot;OK&quot;}'; } location / { root /usr/share/nginx/html; index index.html index.htm; try_files $uri $uri/ /index.html =404; add_header Last-Modified $date_gmt; add_header Cache-Control 'no-store, no-cache'; if_modified_since off; expires off; etag off; } } Using this Docker-based approach, you can serve your static site with Nginx, all within a container.  ","version":"Next","tagName":"h2"},{"title":"Lets add a Web Service for your Project​","type":1,"pageTitle":"Web Service","url":"/preview-docs/docs/project/workload/webservice#lets-add-a-web-service-for-your-project","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navigate to create Web Service section​","type":1,"pageTitle":"Web Service","url":"/preview-docs/docs/project/workload/webservice#1-navigate-to-create-web-service-section","content":" Into the Left Pane, access Workloads. Then select the Web Services tab and then, at the top right corner, click on the Create button.    ","version":"Next","tagName":"h3"},{"title":"2. Select a Project and a Name for the web service​","type":1,"pageTitle":"Web Service","url":"/preview-docs/docs/project/workload/webservice#2-select-a-project-and-a-name-for-the-web-service","content":" Start with the basic information, complete these attributes and click Next to continue.  Attribute\tDescriptionName\tIdentify your web service. Project\tSelect between the existent projects. Command\tThe command that runs the service. Port\tThe port number where the service runs. Default: 8000  Once those attributes are completed, click the Next button to move forward.    ","version":"Next","tagName":"h3"},{"title":"3. Define the connection​","type":1,"pageTitle":"Web Service","url":"/preview-docs/docs/project/workload/webservice#3-define-the-connection","content":" Select how will be your connection and click on Next.  Attribute\tDescriptionService Schema\tDefines the accessibility of the service: public, private, or internal. URL\tThe URL assigned to the service based on the environment and project settings. Format: name.myenv.sleakops.com.    ","version":"Next","tagName":"h3"},{"title":"4. Specify your workload settings​","type":1,"pageTitle":"Web Service","url":"/preview-docs/docs/project/workload/webservice#4-specify-your-workload-settings","content":" You’ll see the following for to specify the conditions.    Attribute\tDescriptionPath\tThe path where Kubernetes checks if the web service is operational. Default: / Success Code\tThe HTTP success code indicating the service’s health. Default: 200. Initial Delay Seconds\tNumber of seconds after startup before health checks begin. Default: 10. Timeout Seconds\tNumber of seconds after startup before health checks begin. Default: 1. Period Seconds\tInterval (in seconds) between each health check probe. Default: 5. Success Threshold\tMinimum number of consecutive successes required for the probe to be considered successful after it has failed. Default: 1. Failure Threshold\tNumber of consecutive failures before the probe is considered to have failed. Default: 60.  Once those attributes are completed, click the Next button to move to the next step.  ","version":"Next","tagName":"h3"},{"title":"5. Finish the set up​","type":1,"pageTitle":"Web Service","url":"/preview-docs/docs/project/workload/webservice#5-finish-the-set-up","content":" This step outlines the key attributes for configuring the resources of a Web Service in SleakOps, allowing for flexible management of CPU, memory, and scaling behaviors.  Attribute\tDescriptionCPU Request\tThe minimum amount of CPU resources allocated for each instance in the cluster. This ensures that each instance always has this amount of CPU available. CPU Limit\tThe maximum CPU resources that each instance in the cluster can use. This cap helps prevent any single instance from consuming too much CPU. Memory Request\tThe minimum amount of memory allocated for each instance in the cluster. This guarantees that the instance has enough memory to operate efficiently. Memory Limit\tThe maximum amount of memory each instance in the cluster can utilize. It limits the memory usage to prevent any single instance from overconsuming resources. Autoscaling\tToggle to enable or disable auto-scaling. When enabled, it allows the service to adjust the number of replicas based on demand and resource usage. CPU Target\tThe CPU usage percentage target that initiates auto-scaling. If usage exceeds this target, additional replicas may be deployed to balance the load. Memory Target\tThe memory usage percentage target that triggers auto-scaling adjustments. When instances exceed this target, the system scales up to accommodate demand. Replicas Min\tThe minimum number of replicas to maintain when auto-scaling is active. A minimum of 2 replicas ensures high availability and prevents downtime. Replicas Max\tThe maximum number of replicas that can be deployed when auto-scaling is enabled. It sets an upper limit on the number of instances to avoid over-provisioning.    Submit to create and Deploy your web service. ","version":"Next","tagName":"h3"},{"title":"Providers","type":0,"sectionRef":"#","url":"/preview-docs/docs/provider","content":"","keywords":"","version":"Next"},{"title":"Let's create your provider on SleakOps​","type":1,"pageTitle":"Providers","url":"/preview-docs/docs/provider#lets-create-your-provider-on-sleakops","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navigate to the providers section​","type":1,"pageTitle":"Providers","url":"/preview-docs/docs/provider#1-navigate-to-the-providers-section","content":" Into the Left Pane, access the Setting option and then Providers and then, at the top right corner, click on the Create button.    ","version":"Next","tagName":"h3"},{"title":"2. Set up basic Information​","type":1,"pageTitle":"Providers","url":"/preview-docs/docs/provider#2-set-up-basic-information","content":"   These are the settings you must define:  Setting\tDescriptionName\tSelect a name for the Organizative Unit into AWS under the needed accounts will be created. Region\tAWS region to use. If you want to know more about them, you can visit this documentation https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html. Domain\tHere you must provide the domain you own in which the different environments will be deployed. It must be delegated to the Primary Route53 of SleakOps manually. Follow the steps described on this https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/MigratingDNS.html. Email\tBy default SleakOps uses the email from the root account provided, If you want to use other email to register your SleakOps accounts in AWS, fill in this field.  Once you've completed the form, click on Next to move forward.  ","version":"Next","tagName":"h3"},{"title":"3. Connect to your AWS Root Account​","type":1,"pageTitle":"Providers","url":"/preview-docs/docs/provider#3-connect-to-your-aws-root-account","content":" warning You must be logged into your AWS Root Account.  To start installing your application, we need to connect to your AWS Root Account. Here's how to do it:  By clicking the Next button, you’ll be redirected to AWS to create an IAM role in your main account called &quot;SleakopsIntegrationRole&quot;.  This role lets us access necessary resources, making installation quick and smooth.After installation, we will remove this role to keep your account secure.    ","version":"Next","tagName":"h3"},{"title":"4. Ongoing Organizative Unit process started​","type":1,"pageTitle":"Providers","url":"/preview-docs/docs/provider#4-ongoing-organizative-unit-process-started","content":" note Creating your Organizative Unit doesn't generate any cost on your AWS account 😃  Once the connection is established role is created, SleakOps will automatically start the Organizative Unit creation.  This process will take a few minutes.    ","version":"Next","tagName":"h3"},{"title":"5. Learn about the infrastructure architecture created by SleakOps for you.​","type":1,"pageTitle":"Providers","url":"/preview-docs/docs/provider#5-learn-about-the-infrastructure-architecture-created-by-sleakops-for-you","content":" In order to understand what was created on your AWS, please see Accounts. ","version":"Next","tagName":"h3"},{"title":"Common errors on Providers","type":0,"sectionRef":"#","url":"/preview-docs/docs/provider/common-errors","content":"","keywords":"","version":"Next"},{"title":"1. The Account ID set does not have root access​","type":1,"pageTitle":"Common errors on Providers","url":"/preview-docs/docs/provider/common-errors#1-the-account-id-set-does-not-have-root-access","content":" In this case, by clicking the Fix button, you’ll be redirected to AWS again.  Be sure to be logged as a Root user.    ","version":"Next","tagName":"h3"},{"title":"2. Maximum Number of AWS Accounts Reached​","type":1,"pageTitle":"Common errors on Providers","url":"/preview-docs/docs/provider/common-errors#2-maximum-number-of-aws-accounts-reached","content":" AWS has an account limit that can prevent new ones.  Before retrying the process, increase that limit. Otherwise, the process will fail again.    ","version":"Next","tagName":"h3"},{"title":"3. Other errors​","type":1,"pageTitle":"Common errors on Providers","url":"/preview-docs/docs/provider/common-errors#3-other-errors","content":" Other issues might happen and usually, they'll be solved by running the Connection to AWS again.  If the error remains and you've tried deleting the provider and creating a new one. Please, do not hesitate and report us an issue.   ","version":"Next","tagName":"h3"},{"title":"Accounts","type":0,"sectionRef":"#","url":"/preview-docs/docs/provider/accounts","content":"","keywords":"","version":"Next"},{"title":"Provider's Accounts​","type":1,"pageTitle":"Accounts","url":"/preview-docs/docs/provider/accounts#providers-accounts","content":" Sleakops implements a well-defined infrastructure architecture designed to optimize operational excellence while ensuring a secure and scalable environment for users. The architecture consists of four accounts, each serving distinct purposes and isolated from one another.  Each account has a VPN instance generated upon the creation of the first cluster.  Once the Accounts are up, we set to each one of them what we call Network Module it contains a lot of different AWS services that are used to make the network connections inside accounts.    ","version":"Next","tagName":"h2"},{"title":"Security Account​","type":1,"pageTitle":"Accounts","url":"/preview-docs/docs/provider/accounts#security-account","content":" The Security Account serves as a centralized hub for managing IAM users and their access to the system. Learn how to switch between accounts in AWS Console Autentication.  ","version":"Next","tagName":"h3"},{"title":"Management Account​","type":1,"pageTitle":"Accounts","url":"/preview-docs/docs/provider/accounts#management-account","content":" Designed to maintain internal services used for application maintenance, regardless of whether they are shared across accounts. Example: Sentry.  Contains an EKS cluster with integrated CI/CD (GitHub and HashiCorp Vault).Vault manages credentials for CloudWatch, enhancing monitoring capabilities.VPC Peering enables private connections to other accounts.  ","version":"Next","tagName":"h3"},{"title":"Development Account​","type":1,"pageTitle":"Accounts","url":"/preview-docs/docs/provider/accounts#development-account","content":" For the different stages of your application before it goes into production.  Contains three environments: dev, QA, and staging.Replicas of the prod environment for code writing, testing, and pre-releases.Ensures isolated testing to prevent issues for external users.Similar architecture to prod but without RDS Slave for reduced high availability requirements.  ","version":"Next","tagName":"h3"},{"title":"Production Account​","type":1,"pageTitle":"Accounts","url":"/preview-docs/docs/provider/accounts#production-account","content":" This account is intended for your application to be installed in a production environment, isolated from the rest of your application's stages.  Supports external users and requires a fully functional database (RDS Master).Utilizes Private DB Subnet for RDS Master, RDS Slave, and ElastiCache, each on different Availability Zones (AZs) for high availability.Backend Deployment with replicas distributed across different AZs.Frontend Deployment with LoadBalancer for even distribution of network load.Route53 serves as DNS and performs health checks for the application.AWS CloudFront serves static frontend content from an S3 bucket.RDS Slave acts as a replica of RDS Master for failover scenarios, maximizing uptime.  ","version":"Next","tagName":"h3"},{"title":"Selecting an Account in SleakOps​","type":1,"pageTitle":"Accounts","url":"/preview-docs/docs/provider/accounts#selecting-an-account-in-sleakops","content":" To select an account and be able to work on it, select it from the left pane. The left icon refers to the Provider that groups the accounts. ","version":"Next","tagName":"h3"},{"title":"Deleting a Provider","type":0,"sectionRef":"#","url":"/preview-docs/docs/provider/deleting-a-provider","content":"","keywords":"","version":"Next"},{"title":"How to delete a Provider​","type":1,"pageTitle":"Deleting a Provider","url":"/preview-docs/docs/provider/deleting-a-provider#how-to-delete-a-provider","content":" ","version":"Next","tagName":"h2"},{"title":"1. Select the provider to be deleted​","type":1,"pageTitle":"Deleting a Provider","url":"/preview-docs/docs/provider/deleting-a-provider#1-select-the-provider-to-be-deleted","content":" Once you are in the Providers section, choose a provider and click on the Three Dots **button to display the Delete option. Click on it.    ","version":"Next","tagName":"h3"},{"title":"2. Confirm the procedure​","type":1,"pageTitle":"Deleting a Provider","url":"/preview-docs/docs/provider/deleting-a-provider#2-confirm-the-procedure","content":" You'll see a modal to confirm the action. Remember this action will remove all the infrastructure created on AWS under this Provider.    ","version":"Next","tagName":"h3"},{"title":"3. Manually remove the Organization and its Accounts​","type":1,"pageTitle":"Deleting a Provider","url":"/preview-docs/docs/provider/deleting-a-provider#3-manually-remove-the-organization-and-its-accounts","content":" As it was mentioned before the created Organization and its accounts (management, development, production, and security) will not be automatically deleted.  Access your AWS Root Account to manually remove them by going to AWS Organizations.   ","version":"Next","tagName":"h3"},{"title":"Designing your Infra","type":0,"sectionRef":"#","url":"/preview-docs/docs/provider/schemas","content":"","keywords":"","version":"Next"},{"title":"Single Schema Vs. Multi Schema​","type":1,"pageTitle":"Designing your Infra","url":"/preview-docs/docs/provider/schemas#single-schema-vs-multi-schema","content":" SleakOps provides the flexibility and control necessary to build infrastructure tailored to your specific requirements.  While we recommend adopting a Multiple Schema configuration to align with best practices, we understand that different stages of your project may require alternative schema configurations.    Here a comparative with two options:  \tMulti Schema ⭐️\tSingle SchemaDescription\tAligned with best practices. You'll set first the Development account.\tCentralizes your environments within a single cluster. Account to be used\tUse all accounts as described here\tOnly the Production account Pros\tIncreases Security by granting access per account Production remains isolated.\tReduces costs, as it is just one cluster. Cons\tMore expensive as each environment'll have it own cluster and VPN.\tLess secure, ass all environments shares the account.  These are just two options; you have the freedom to create the schema that best suits your needs.  ","version":"Next","tagName":"h2"},{"title":"Multi-Schema Example​","type":1,"pageTitle":"Designing your Infra","url":"/preview-docs/docs/provider/schemas#multi-schema-example","content":"   ","version":"Next","tagName":"h2"},{"title":"Single-Schema Example​","type":1,"pageTitle":"Designing your Infra","url":"/preview-docs/docs/provider/schemas#single-schema-example","content":"  ","version":"Next","tagName":"h2"},{"title":"Shared Responsibility Model","type":0,"sectionRef":"#","url":"/preview-docs/docs/responsability-model","content":"Shared Responsibility Model We transparently utilize all AWS services, which means the responsibility extends to the guidelines set by AWS. To safeguard your data and ensure it doesn't get lost due to potential service disruptions, it's advisable to have backup policies in place. Currently, we don't support backups for our dependencies (RDS, S3, RabbitMQ, etc.). To set this up, you can access via your AWS client and define your backup policies. [Learn more about AWS's Shared Responsibility Model] (https://aws.amazon.com/compliance/shared-responsibility-model/)","keywords":"","version":"Next"},{"title":"Django + Celery","type":0,"sectionRef":"#","url":"/preview-docs/docs/quickstart/django_celery","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#prerequisites","content":" Account in SleakopsA Cluster in this account. If you don't have it, here is the documentation on how to do it.A Environment configured. If you don't have it, here is the documentation on how to do itDjango project configured with celery (This project needs to have docker).  ","version":"Next","tagName":"h2"},{"title":"Let's Start​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#lets-start","content":" For this example, we are going to use this project . It is a Django project with Celery that already has Docker configured to run. We are also going to configure a Postgresql database, S3 bucket and Rabbitmq needed for this project.  ","version":"Next","tagName":"h2"},{"title":"Create a project​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#create-a-project","content":" To start, we are going to create a new project. To do this, click the &quot;Projects&quot; button in the left panel:    Inside the Projects panel you will be able to see all the projects you have and manage them from here. We want to create a new one so let's click on the “create” button at the top right:    In the project creation screen we have the following fields:  Setting\tDescriptionEnvironment\tWe have to select the previously created environment. Nodepool\tWe will leave the default one. Repositories\tWe will select our repository that we want to deploy. In our case example-django-celery. Project Name\tWe can define a project name. For the example we will leave the default. Branch\tIt has to coincide with the one we have in our project. In our case it is “Main”. Dockerfile path\tIt is the relative path to the dockerfile in your project.  Once configured all that we create the project with the “Submit” button at the bottom right:    With that, the project begins to be created. In the meantime we go to the workloads with the “Workloads” button in the left panel:    ","version":"Next","tagName":"h3"},{"title":"Create a Web Service​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#create-a-web-service","content":" Here what we are going to do is to create a web service so we go to the web service section and create one:    In this page we are going to complete the first form with the following fields:  Setting\tDescriptionProject\tWe select the project we created previously, in our case “example-django-celery”. Name\tWe define a name for the web service. Command\tBy default this will take the value that is in the dockerfile, in our case this is fine. Port\tThe same as the command.  Then we continue by clicking on the “Next” button up to step 3:    In step 3 we have to edit the path field and put the endpoint of healthcheck which in our case is “/healthcheck/”. Then click on the “Next” button until the web service is created:    ","version":"Next","tagName":"h3"},{"title":"Deploy celery worker​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#deploy-celery-worker","content":" Well, with this we can see our web service deploying. Now we are going to deploy the celery. For this we have to go to the workers section inside the same workloads screen:    And click on the “Create” button to create a new one:    In the workers creation screen we will have to complete the following fields:  Setting\tDescriptionProject\tSelect the previously created project. In our case “example-django-celery”. Name\tWe define the name that we are going to give to the worker. In our case “celery”. Command\tHere we set the command to run celery, in our case it is: bash celery -A core.celery_app worker -l INFO --concurrency 1 --max-tasks-per-child 1 --prefetch-multiplier 1 -n celery@%h --queues default,build,deployment,cluster,canvas,billing  With these fields filled in we will click on the “Next” button at the bottom right and then “Submit” as we do not need to edit anything else:    With this we will see our celery published. Now we have to configure the hooks. For this we go to the hooks section:    ","version":"Next","tagName":"h3"},{"title":"Create a migration hook​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#create-a-migration-hook","content":" In the hook creation screen we will have the following fields:  Setting\tDescriptionProject\tSelect the previously created project. In our case “example-django-celery”. Name\tWe define the name that we are going to give to the worker. In our case “migrations”. Command\tHere we set the command to run celery, in our case it is: bash python manage.py migrate --no-input   With these fields filled in we will click on the “Next” button at the bottom right and then “Submit” as we do not need to edit anything else:    ","version":"Next","tagName":"h3"},{"title":"Create a collect static hook​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#create-a-collect-static-hook","content":" Now we proceed to create another hook that we need for the statics:    In this form we are going to do the same as the previous one but modifying the command. We click next until we create the hook (without modifying anything else):    The command we use is as follows:  python manage.py collectstatic --no-input   ","version":"Next","tagName":"h3"},{"title":"Create a Postgresql Database​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#create-a-postgresql-database","content":" Once we have created the hooks we have to go to create our database. To do this we go to the “Dependencies” section:    Inside this section we click on the “Create” button at the top right and then select “Postgresql”:      In the 1st postgresql creation form we will have to select our previously created project and define a name for it, then click on the “Next” button at the bottom right:    In the 2nd form we are going to have a lot of fields, the only ones that matter to us are the following:  Setting\tDescriptionDatabase Master Username\tHere we assign a root user name to our database. Database Master Password\tA password for this root user.  With these fields filled in, we are ready to move on. Click on the “Next” button at the bottom right to proceed to the third form:    In this last form, we are going to adjust the environment variables we have in our project with respect to the database. To do this, we need to change the following variables to our own:  Before\tAfter*_POSTGRESQL_NAME\tDB_NAME *_POSTGRESQL_USERNAME\tDB_USER *_POSTGRESQL_PASSWORD\tDB_PASSWORD *_POSTGRESQL_ADDRESS\tDB_HOST *_POSTGRESQL_PORT\tDB_PORT  It should look something like the image below. Then click on the “Submit” button and your database should be created:    ","version":"Next","tagName":"h3"},{"title":"Create S3 Bucket​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#create-s3-bucket","content":" In the same page of dependencies we have to create our s3 bucket, for it we are going to go to the “Create” button again:    And select S3 Bucket:    In the first form we have to select our previously created project and define a name for the bucket, we have to take into account that the name of the bucket is global so it has to be unique. Now click on the “Next” button and go to step 3:    Here we are going to see some environment variables defined for the bucket. We are going to edit the one that says COLLECTSTATICEXAMPLEDJANGOCELERY_BUCKET_NAME and we are going to call it DJANGO_AWS_STORAGE_BUCKET_NAME. With this simple change we click on the “Submit” button at the bottom right to finish creating the bucket:    ","version":"Next","tagName":"h3"},{"title":"Create Rabbitmq​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#create-rabbitmq","content":" Now we need one more dependency. Our Rabbitmq to queue celery tasks, so let's get to it:    And select Rabbitmq:    In the first form we will have to select our project and define a name for it. Then click on the “Next” button at the bottom right:    In the following form we have several fields but the only ones that matter to us for this example are the username and password, we can define whatever we want. For this example I chose admin as username and for the password I generated it randomly with the dice button. Then we click on the “Next” button to go to the next form:    In this last form we have to change the name of the variable that ends in *_BROKER_AUTH_URL to CELERY_BROKER_URL (as shown in the image). Then we click on the “Submit” button at the bottom right to finish creating rabbitmq:    ","version":"Next","tagName":"h3"},{"title":"Create yours environment variables​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#create-yours-environment-variables","content":" Once the dependencies are deployed we have to configure our environment variables. We are going to go to the Vargroups section:    Here you will see all your environment variables that you created grouped in groups, for example you should have created one with the data for the database (which is the one you see in the image). Now we are going to create another one for our django environment variables, for this we click on the “Create” button at the top right:    In this form we have the following fields:  Project: we select the project we created previously.Workload: We select “global” that makes reference to be used by all our workloads.Name: We define a name for this group of variables.Type: If we want to load it by file or by variable.Vars: Here we enable the textmode and copy the following environment variables:  CELERY_RESULT_BACKEND=django-db DJANGO_ADMIN_URL=admin/ DJANGO_DEBUG=False DJANGO_SECRET_KEY=secret_key DJANGO_SETTINGS_MODULE=core.settings.production DJANGO_STATIC_STORAGE=storages.backends.s3boto3.S3StaticStorage DB_ENGINE=django.db.backends.postgresql_psycopg2 ENVIRONMENT=production LOGS_LEVEL=INFO PYTHONPATH=.   These environment variables are required for our example project. Finally click on the “Submit” button at the bottom right to create the variable group.    ","version":"Next","tagName":"h3"},{"title":"Deployments​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#deployments","content":" As last step we are going to see our project deployed, for this we go to the “Deployments” section of the left panel:    Here we are going to see all the deploys that we do. In our case it is the first one and we can see that it has been created correctly, in case you see any error if you click on “error” you can see a description of it. If we do not see any error then it means that the project is already deployed, we could begin to use it from the url that the web service provided us.    This concludes our project deployment process. We leave you an optional step which is to configure the ci with github.  ","version":"Next","tagName":"h3"},{"title":"Optional​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#optional","content":" ","version":"Next","tagName":"h2"},{"title":"CI with Github​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/docs/quickstart/django_celery#ci-with-github","content":" Every time you make a change in your code and want to deploy it you will have to do a build and a deploy, this eventually becomes tedious. That's why to avoid this we have to implement ci on github.  For this we are going to go to “Projects” in the left panel:    Let's locate our project and click on the gear to access the project configuration:    In the project configuration we locate the one that says “Git pipelines” and click on it:    Here we are going to find what we need to do this. Basically we need to set up a file in the root of our project .github/workflows/ called ci_sleakops_demo.yml and in that file we are going to paste the content that appears in this page.    This needs to have an environment variable SLEAKOPS_KEY, if you don't have it you have to go to the link that appears there Settings -&gt; CLI, get it and save it as an environment variable.  With this configured and deployed every time you do a push to your “main” branch a new version of your application will be launched automatically. ","version":"Next","tagName":"h3"},{"title":"AWS Console Authentication","type":0,"sectionRef":"#","url":"/preview-docs/docs/user/aws_console_authentication","content":"AWS Console Authentication ::: tip[VIDEO] How to enter to any of your Accounts. ::: As described in the Architecture Overview. You'll have to enter the 'security' account, then, assume the role on the account you want. The easiest way to do this is by using the Sleakops Dashboard: First, use the AWS Login button: This will open the AWS login form. The Account ID field should be automatically filled with the 'security' account ID. If this doesn't happen, it might be because another service is attempting to fill the fields. Once logged into the 'security' account, it will appear as shown in the following image: Now, in the AWS console, you need to return to the SleakOps dashboard, select 'Get Access' and use the drawer, on it, select the account you want to log in to. This will prompt a new AWS tab to switch the role from your 'security' Account into the account you've selected, you'll leave the 'security account' and enter the selected one. info If you're in 'security' or another account you can directly use the account switchers, AWS understands that you are already inside the 'security' account. For more information about this process, you can read its AWS documentation .","keywords":"","version":"Next"},{"title":"User","type":0,"sectionRef":"#","url":"/preview-docs/docs/user","content":"","keywords":"","version":"Next"},{"title":"User Creation​","type":1,"pageTitle":"User","url":"/preview-docs/docs/user#user-creation","content":" Sleakops has three fundamental fields of user permissions:  Viewer (Read Only)​  Objective: Provide read-only access to monitor and review infrastructure without making changesScope: View all projects, clusters, and environmentsAccess monitoring dashboards and logsReview deployment history and configurationsCannot create, modify, or delete any resources AWS IAM Policy: ReadOnlyAccess Examples: DevOps engineers who need to monitor production environmentsSecurity auditors reviewing infrastructure complianceTeam leads who need visibility into project status  Editor (Power User)​  Objective: Enable infrastructure management and deployment capabilities while maintaining security boundariesScope: Create and manage projects, clusters, and environmentsDeploy applications and manage infrastructure resourcesConfigure environments, dependencies, and networkingCannot manage other users and billing AWS IAM Policy: PowerUserAccess Examples: Senior developers deploying applicationsDevOps engineers managing infrastructureTeam members responsible for specific project deployments  Admin (Administrator)​  Objective: Provide complete platform control including user management and billingScope: All Editor capabilities plus user management and billing sectionCreate, modify, and delete user accountsAssign roles and permissions to other usersAccess to all AWS accounts without restrictionsPlatform configuration and settings management AWS IAM Policy: AdministratorAccess Examples: Platform administratorsTeam leads managing multiple projectsDevOps managers with cross-team responsibilities  ","version":"Next","tagName":"h2"},{"title":"Access Configuration​","type":1,"pageTitle":"User","url":"/preview-docs/docs/user#access-configuration","content":" AWS Account Access: This field shows you every account, here you select to which accounts the user (Editor or Read-only) will have access.  VPN Account Access: It's similar to the AWS account accesses field but here you set if a user it's also created on the VPN Server of the account you give. More information can be checked on VPN documentation    For access into the AWS accounts SleakOps initially sets a random password and sends it to the email of the created user. The user can login with that password but it will be obligated to change its password on the first login. For SleakOps platform access we use the password that was set on the User form.  After this user creation an AWS User will be created on the 'security' Account, this account is where we control acesses to all the SleakOps AWS accounts. We will also create, depending on the configuration, users on the VPN servers, read how to use them on the corresponding documentation and on the SleakOps user.  ","version":"Next","tagName":"h3"},{"title":"Users Without SleakOps Access​","type":1,"pageTitle":"User","url":"/preview-docs/docs/user#users-without-sleakops-access","content":" Some users in your organization may not have direct access to the SleakOps platform but still interact with the infrastructure:  ","version":"Next","tagName":"h2"},{"title":"External Collaborators​","type":1,"pageTitle":"User","url":"/preview-docs/docs/user#external-collaborators","content":" Scenario: Third-party contractors or consultants who need temporary access to specific AWS resourcesAccess Method: Direct AWS console access with limited IAM permissionsManagement: Handled through AWS IAM directly, not through SleakOps user management  ","version":"Next","tagName":"h3"},{"title":"Read-Only Observers​","type":1,"pageTitle":"User","url":"/preview-docs/docs/user#read-only-observers","content":" Scenario: Stakeholders who need visibility into infrastructure costs and usage without operational accessAccess Method: AWS Cost Explorer, CloudWatch dashboards, or custom reporting toolsManagement: AWS billing and monitoring permissions only  ","version":"Next","tagName":"h3"},{"title":"VPN-Only Consumers​","type":1,"pageTitle":"User","url":"/preview-docs/docs/user#vpn-only-consumers","content":" Scenario: Users who need to consume workloads and applications within the VPN but don't require infrastructure administration or monitoring capabilitiesAccess Method: VPN access only, with limited permissions to access specific applications and servicesManagement: VPN user accounts with restricted access to designated workloads and environments ","version":"Next","tagName":"h3"},{"title":"Connect into the VPN","type":0,"sectionRef":"#","url":"/preview-docs/docs/user/vpn","content":"Connect into the VPN To handle VPN connections we use Pritunl. You can download the client here. Once you've created a Provider , go to SleakOps dashboard and select the account for which you want to get VPN access. Remember, to do this, you need to have access to the VPN of that account, but the VPN must also be created. We create the VPN of a specific account when the first cluster of that account is created. This will prompt you with what is called the URI profile. It has a validation period of 24 hours, and you must load it into the Pritunl client. Copy it and import it into the Pritunl client, and you'll be able to connect to it:","keywords":"","version":"Next"},{"title":"n8n + Worker Mode","type":0,"sectionRef":"#","url":"/preview-docs/docs/quickstart/n8n","content":"","keywords":"","version":"Next"},{"title":"Why Self-host n8n?​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#why-self-host-n8n","content":" Self-hosting n8n provides numerous advantages over cloud-hosted solutions:  ","version":"Next","tagName":"h2"},{"title":"🔒 Security and Privacy​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#-security-and-privacy","content":" Complete data control: Your workflows, credentials, and sensitive data never leave your infrastructureCustom security policies: Implement your organization's specific security requirementsNetwork isolation: Keep n8n within your private network, reducing external attack vectorsCompliance: Meet strict regulatory requirements (GDPR, HIPAA, SOC2) with on-premises deployment  ","version":"Next","tagName":"h3"},{"title":"💰 Cost Optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#-cost-optimization","content":" No execution limits: Run unlimited workflows without usage-based pricingPredictable costs: Fixed infrastructure costs regardless of usage volumeResource efficiency: Scale resources based on actual needs, not vendor pricing tiersLong-term savings: Significant cost reduction for high-volume automation scenarios  ","version":"Next","tagName":"h3"},{"title":"⚡ Performance and Scalability​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#-performance-and-scalability","content":" Custom resource allocation: Assign CPU and memory based on your specific workload requirementsLow latency: Direct access to internal systems without internet round tripsHigh availability: Design redundant systems with multiple replicas and failover mechanismsCustom integrations: Connect to internal APIs and systems not accessible from cloud providers  ","version":"Next","tagName":"h3"},{"title":"🎛️ Total Control and Customization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#️-total-control-and-customization","content":" Version control: Choose when to update and test new versions in your environmentCustom nodes: Install and develop proprietary nodes for your specific use casesEnvironment variables: Complete access to system-level configurations and secret managementBackup strategies: Implement your own backup and disaster recovery procedures  ","version":"Next","tagName":"h3"},{"title":"Benefits of Kubernetes Scaling​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#benefits-of-kubernetes-scaling","content":" Deploying n8n on a Kubernetes cluster with Sleakops provides enterprise-level scalability:  ","version":"Next","tagName":"h2"},{"title":"🚀 Horizontal Scaling​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#-horizontal-scaling","content":" Worker pods: Automatically scale worker instances based on queue depth and CPU usageLoad distribution: Distribute workflow execution across multiple worker nodesAuto-scaling: Kubernetes HPA (Horizontal Pod Autoscaler) automatically adjusts worker countResource optimization: Scale different components independently (web UI vs workers)  ","version":"Next","tagName":"h3"},{"title":"🏗️ Infrastructure Resilience​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#️-infrastructure-resilience","content":" High availability: Multiple replicas ensure zero downtime during node failuresRolling updates: Deploy new versions without service interruptionHealth checks: Kubernetes automatically restarts failed pods and routes traffic to healthy instancesMulti-zone deployment: Distribute workload across availability zones for disaster recovery  ","version":"Next","tagName":"h3"},{"title":"📊 Monitoring and Observability​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#-monitoring-and-observability","content":" Real-time metrics: Monitor workflow execution, queue depth, and resource usageCentralized logging: Aggregate logs from all n8n components in one placePerformance insights: Track execution times, error rates, and throughputAlerts: Proactive notifications for system issues and performance bottlenecks  ","version":"Next","tagName":"h3"},{"title":"🔧 DevOps Integration​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#-devops-integration","content":" GitOps workflows: Version control your n8n infrastructure as codeCI/CD pipelines: Automated testing and deployment of n8n configurationsSecret management: Integrate with Kubernetes secrets and external secret managersNetwork policies: Fine-grained network security controls  ","version":"Next","tagName":"h3"},{"title":"Prerequisites​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#prerequisites","content":" Sleakops accountA Cluster in this account. If you don't have one, here's the documentation on how to do it.A configured Environment. If you don't have one, here's the documentation on how to do itn8n project configured with Docker. If you don't have it, you can fork or copy from n8n-code. This project includes a docker-compose so you can deploy it locally as well, allowing you to have distributed environments as you want.  Let's Get Started  For this example, we're going to deploy an n8n project in distributed mode with workers. This configuration includes the main n8n service (web interface) and worker processes to execute workflows. We'll also configure a PostgreSQL database and Redis for queue management required for this project.  ","version":"Next","tagName":"h2"},{"title":"Create Project​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#create-project","content":" Projects are our code repositories. The only thing Sleakops needs to execute commands is a Dockerfile. For more information, you can see our project documentation  To start, we'll create a new project:  Click the &quot;Projects&quot; button in the left panelThen click &quot;Create&quot; in the top right corner    Within the Projects panel, you'll be able to see all the projects you have and manage them from here. We want to create a new one, so let's click the &quot;create&quot; button in the top right:  On the project creation screen, we have the following fields:  Configuration\tDescriptionEnvironment\tWe need to select the previously created environment. Nodepool\tWe'll leave the default. Repositories\tWe'll select our repository containing the n8n project. Project Name\tWe can define a project name. For example &quot;n8n-server&quot;. Branch\tIt must match what we have in our project. In our case it's &quot;main&quot;. Dockerfile path\tIt's the relative path to the dockerfile in your project.  Once everything is configured, we create the project with the &quot;Submit&quot; button in the bottom right:    With that, the project begins to be created. Meanwhile, let's go to workloads with the &quot;Workloads&quot; button in the left panel:    ","version":"Next","tagName":"h2"},{"title":"Create Workloads​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#create-workloads","content":" Workloads are the processes that run your project. For the case of n8n that we're going to run in queue mode, we'll create a webservice for the web interface and a worker. For more information, you can see our workloads documentation  ","version":"Next","tagName":"h2"},{"title":"Create the Web Service​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#create-the-web-service","content":" Here we're going to create the main n8n web service that will handle the user interface and API:  On this page, we'll complete the first form with the following fields:  Configuration\tDescriptionProject\tWe select the project we created previously, in our case &quot;n8n-server&quot;. Name\tWe define a name for the web service, for example &quot;n8n-main&quot;. Command\tDefault Dockerfile command (usually n8n start). Port\tPort 5678 (n8n default port).    In the second step, we'll configure the webservice as private:  What does this mean?  The n8n service will be within the VPCIt will only be accessible from services on the same networkRequires VPN for external access  Alternative for public webhooks:If you need to connect public webhooks (Jira, Slack, Google Drive, etc.), you can:  Leave this service as public, ORCreate an additional public webservice with the webhook command    Continue to step 3 &quot;Service settings&quot; and configure the healthcheck  For this, we only need to properly define the healthcheck path that n8n provides /healthz, and continue until finishing the flow and creating the web service.    This healthcheck is important so Kubernetes knows when the service is ready to start receiving HTTP traffic. This is useful to avoid downtime between each deploy or node rotation.  The last step of the form, where we define memory, CPU, and scaling conditions, we won't modify for now, we'll leave it as the platform offers it.  ","version":"Next","tagName":"h3"},{"title":"Create the n8n Worker​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#create-the-n8n-worker","content":" Good, with this we can see our web service deploying. Now we're going to deploy the n8n worker for distributed execution. For this, we need to go to the workers section within the same workloads screen and click the &quot;Create&quot; button.    On the worker creation screen, we'll need to complete the following fields:  Configuration\tDescriptionProject\tSelect the previously created project. In our case &quot;n8n-server&quot;. Name\tWe define the name we'll give to the worker. In our case &quot;n8n-worker&quot;. Command\tHere we establish the command to execute the n8n worker: worker  With these fields completed, we'll click the &quot;Next&quot; button in the bottom right and then &quot;Submit&quot; since we don't need to edit anything else:    With this, we'll see our n8n worker deployed.  ","version":"Next","tagName":"h3"},{"title":"Create Dependencies (Redis and PostgreSQL)​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#create-dependencies-redis-and-postgresql","content":" Dependencies are necessary resources for your application to function. In the case of n8n in queue mode, it needs a database and Redis. Sleakops leverages AWS services to offer you alternatives. You can see more information in dependencies documentation  Let's go to the dependencies section:    ","version":"Next","tagName":"h2"},{"title":"Create Redis Dependency​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#create-redis-dependency","content":" First, we need to create Redis for the task queue. On the dependency creation screen, we select Redis and we'll have the following fields:  Configuration\tDescriptionDependency Type\tSelect &quot;Redis&quot; from available options. Project\tSelect the previously created project. In our case &quot;n8n-server&quot;. Name\tWe define the name for Redis. In our case &quot;n8n-redis&quot;.    With these fields completed, we'll click the &quot;Next&quot; button in the bottom right and in the last step, before doing &quot;Submit&quot;, we'll change the environment variable names to what n8n expects.  We need to configure the Redis connection variables to match what n8n expects:  Variable\tValueQUEUE_BULL_REDIS_HOST\t(Redis dependency host) QUEUE_BULL_REDIS_PORT\t6379    With this, we tell Sleakops with what name we want it to publish the variables generated by the &quot;Redis&quot; dependency.  Make sure the variable names match what your n8n configuration expects.  ","version":"Next","tagName":"h3"},{"title":"Create PostgreSQL Database​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#create-postgresql-database","content":" Now we proceed to create the PostgreSQL database for n8n data storage:    You can vary between &quot;production&quot; and &quot;non-production&quot; - this gives you default configuration values in the next step for each environment. For example: for the production environment it leaves multi A-Z active, automatic backups, etc. As an example in this guide, we'll leave it on &quot;non-production&quot;.  Same as for Redis, we need to configure the environment variable names as n8n expects them. Let's go to the last step and before pressing submit, we change the names to the following:  Before\tAfter*_POSTGRESQL_NAME\tDB_POSTGRESDB_DATABASE *_POSTGRESQL_USERNAME\tDB_POSTGRESDB_USER *_POSTGRESQL_PASSWORD\tDB_POSTGRESDB_PASSWORD *_POSTGRESQL_ADDRESS\tDB_POSTGRESDB_HOST *_POSTGRESQL_PORT\tDB_POSTGRESDB_PORT  It should look something like the image below. Then click the &quot;Submit&quot; button and your database should be created:    ","version":"Next","tagName":"h3"},{"title":"Configure n8n Environment Variables​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#configure-n8n-environment-variables","content":" Now we need to create the environment variables that were pending. We can see in the code repository the variables we have in .env.example. There are variables we've already been configuring in each dependency, but others remain to be defined. For this, we go to the &quot;Variablegroups&quot; section.    We're going to create a new variable group, put it in text mode to copy from .env.example the missing variables and adjust the values according to our case.  In this form we have the following fields:  Project: we select the project we created previously.Workload: We select &quot;global&quot; which refers to being used by all our workloads.Name: We define a name for this variable group.Type: Whether we want to load it by file or by variable.Vars: Here we enable text mode and copy the following environment variables:  Variable\tDescriptionDB_TYPE\tSet to &quot;postgresdb&quot; EXECUTIONS_MODE\tSet to &quot;queue&quot; for worker mode N8N_ENCRYPTION_KEY\tGenerate a secure encryption key OFFLOAD_MANUAL_EXECUTIONS_TO_WORKERS\tSet to &quot;true&quot; N8N_HOST\tdefine the host you configured in your webservice, for this example it would be n8n.demo.sleakops.com N8N_WEBHOOK_URL\tThis variable is not strictly necessary to define, in case of adding a separate webservice instance to handle webhooks with another URL you need to specify which is the URL that handles the webhooks.https://n8n.demo.sleakops.com/ N8N_EDITOR_BASE_URL\thttps://n8n.demo.sleakops.com  If you want to see all the environment variables available to configure n8n you can go to the following n8n documentation page    ","version":"Next","tagName":"h2"},{"title":"Deployments​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#deployments","content":" As the last step, let's see our deployed project. For this, we go to the &quot;Deployments&quot; section in the left panel:    Here we'll see all the deployments we make. In our case, it's the first one and we can see it has been created correctly. If you see any error, if you click on &quot;error&quot; you can see a description of it. If we don't see any error, then it means the project is already deployed, we could start using it from the URL provided by the web service.  This concludes our project deployment process. We leave you with an optional step which is configuring CI with GitHub.  ","version":"Next","tagName":"h2"},{"title":"CI/CD Configuration (Optional but Recommended)​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#cicd-configuration-optional-but-recommended","content":" ","version":"Next","tagName":"h2"},{"title":"Why configure CI/CD?​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#why-configure-cicd","content":" Without CI/CD, each change in your code requires:  Manual build from SleakOpsManual deployManual verification  With CI/CD configured:  ✅ Push to main → Automatic deploy✅ Automatic rollback in case of error✅ Deploy status notifications  ","version":"Next","tagName":"h3"},{"title":"Steps to configure:​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#steps-to-configure","content":" Go to your project in SleakOpsClick on the ⚙️ (settings)Select &quot;Git pipelines&quot;Copy the provided YAMLAdd SLEAKOPS_KEY to GitHub secrets      This needs to have a SLEAKOPS_KEY environment variable. If you don't have it, you need to go to the link that appears there Settings -&gt; CLI, get it and save it as an environment variable.  With this configured and deployed, every time you push to your &quot;main&quot; branch, a new version of your application will be automatically launched.  ","version":"Next","tagName":"h3"},{"title":"🎯 Next Steps​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#-next-steps","content":" Once the installation is complete:  ","version":"Next","tagName":"h2"},{"title":"Initial n8n configuration​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#initial-n8n-configuration","content":" First access: Use your webservice URLCreate admin user: n8n will ask you to create the first userConfigure webhooks: If you need them, configure public URLs  ","version":"Next","tagName":"h3"},{"title":"Monitoring and optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#monitoring-and-optimization","content":" Review metrics: Use the integrated Grafana dashboardAdjust resources: Modify CPU/memory according to actual usageConfigure alerts: Define performance thresholds  ","version":"Next","tagName":"h3"},{"title":"Backup and security​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#backup-and-security","content":" Automatic backups: Configure PostgreSQL backupsSecrets management: Review credential handlingUpdates: Plan regular updates  ","version":"Next","tagName":"h3"},{"title":"Update and Extend n8n​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#update-and-extend-n8n","content":" We now have our own n8n installed and running on the cluster. We have the definition of our n8n in a Dockerfile.  To update the version​  This process is very simple, we'll modify the Dockerfile and change the image tag. We can see the available images in the official n8n dockerhub repository  To keep in mind, read the changelog in case there are any breaking changes or something that breaks between versions. Make database backups beforehand just in case.  To add new dependencies within your nodes​  As we did to update the version, in this case we'll take advantage of having our Dockerfile and we can install whatever we want inside it, this will be available to use in our n8n nodes.  You can see examples of this in the repository README.  ","version":"Next","tagName":"h2"},{"title":"Best Scaling Practices (Bonus)​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#best-scaling-practices-bonus","content":" Once your n8n deployment is running, consider these scaling strategies:  ","version":"Next","tagName":"h2"},{"title":"🎯 Worker Optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#-worker-optimization","content":" Queue monitoring: Monitor Redis queue depth to determine when to scale workersResource allocation: Assign sufficient CPU and memory based on workflow complexityConcurrency tuning: Adjust worker concurrency based on workflow types (CPU vs I/O intensive)Dedicated workers: Create specialized worker pools for different workflow categories  ","version":"Next","tagName":"h3"},{"title":"📈 Performance Monitoring​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#-performance-monitoring","content":" Adjust the memory and CPU of your workloads to what your processes actually need. This is useful to avoid over-dimensioned infrastructure and also to make decisions when scaling horizontally based on memory or CPU.  How do we do it from Sleakops?​  Simple, we go to the detail of your worker or webservices that we created earlier and touch the &quot;grafana&quot; icon. This will open a dashboard within Grafana with the historical consumption of your process, make sure to look at a long time range to cover all your cases.    ","version":"Next","tagName":"h3"},{"title":"🔧 Database Optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#-database-optimization","content":" Connection pooling: Configure PostgreSQL connection pools for high concurrency.Read replicas: Use read replicas for reporting and analytics queries. (You can do this from Sleakops from the Postgres configuration)Indexing: Optimize database indexes for workflow execution queriesBackup strategies: Implement automated backups with point-in-time recovery. (You can do this from Sleakops from the Postgres configuration)  ","version":"Next","tagName":"h3"},{"title":"🚀 Advanced Configurations​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/docs/quickstart/n8n#-advanced-configurations","content":" Node affinity: Schedule workers on appropriate node types (CPU vs memory optimized). (You can do this from Sleakops using Nodepools)Pod disruption budgets: Ensure minimum availability during cluster maintenance. (This is already covered by Sleakops)Resource quotas: Set appropriate limits to prevent resource exhaustion. (You can do this from Sleakops by defining limits in your Workloads and in your Nodepools)Network policies: Ensure inter-pod communication. (This is already done by Sleakops) ","version":"Next","tagName":"h3"},{"title":"Loki's Dashboard is not responding","type":0,"sectionRef":"#","url":"/preview-docs/tutorial/dashboard-loki-not-responding","content":"Loki's Dashboard is not responding QUICK SOLUTION Remove the 'loki-read' pod. After 60 seconds, it will start working again, along with the Loki DataSource and its related dashboards. info This error is more common in clusters with low availability because they generate more node and pod turnover. You can reduce the frequency of this error by increasing the number of loki-read pods in the Loki add-on settings. Loki may be running, as in the following image: If, due to some Kubernetes rotation, the loki-backend pod is reset WITHOUT the loki-read pod being reset, it starts to fail, such as when I force it by restarting the loki-backend StatefulSet, which leads to the following situation: It can be seen that the 'Age' of loki-backend is less than the 'Age' of loki-read. In these cases, this error occurs, causing the Loki DataSource to malfunction and, consequently, the dashboards that use it to stop working. The error arises because the 'loki-read' pods do not attempt to reconnect to 'loki-backend' and remain in this state where they do not respond to requests from 'loki-backend'. It can be seen that the error was successfully forced, and now the dashboard is unresponsive: The way to fix it is by restarting the 'loki-read' Deployment or by removing the running Pod. Once that is done, we return to the desired situation, which is as follows: As you can see, the Age of loki-read is now less than the Age of loki-backend, which confirms that loki-read is connected and the Dashboard is working correctly again, as shown in the following image: The frequency of this error can be reduced by increasing the number of active 'loki-read' pods. This can be done in the Loki Addon settings.","keywords":"","version":"Next"},{"title":"El nuevo tuto Title","type":0,"sectionRef":"#","url":"/preview-docs/tutorial/el-nuevo-tuto-title","content":"El nuevo tuto Title El nuevo Body","keywords":"","version":"Next"},{"title":"Django + Celery","type":0,"sectionRef":"#","url":"/preview-docs/tutorial/django-celery","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#prerequisites","content":" Account in SleakopsA Cluster in this account. If you don't have it, here is the documentation on how to do it.An Environment configured. If you don't have it, here is the documentation on how to do itDjango project configured with celery (This project needs to have docker).  ","version":"Next","tagName":"h2"},{"title":"Let's Start​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#lets-start","content":" For this example, we are going to use this project . It is a Django project with Celery that already has Docker configured to run. We are also going to configure a Postgresql database, S3 bucket and Rabbitmq needed for this project.  ","version":"Next","tagName":"h2"},{"title":"Create a project​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#create-a-project","content":" To start, we are going to create a new project. To do this, click the &quot;Projects&quot; button in the left panel:    Inside the Projects panel you will be able to see all the projects you have and manage them from here. We want to create a new one so let's click on the “create” button at the top right:    In the project creation screen we have the following fields:  Setting\tDescriptionEnvironment\tWe have to select the previously created environment. Nodepool\tWe will leave the default one. Repositories\tWe will select our repository that we want to deploy. In our case example-django-celery. Project Name\tWe can define a project name. For the example we will leave the default. Branch\tIt has to coincide with the one we have in our project. In our case it is “Main”. Dockerfile path\tIt is the relative path to the dockerfile in your project.  Once configured all that we create the project with the “Submit” button at the bottom right:    With that, the project begins to be created. In the meantime we go to the workloads with the “Workloads” button in the left panel:    ","version":"Next","tagName":"h3"},{"title":"Create a Web Service​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#create-a-web-service","content":" Here what we are going to do is to create a web service so we go to the web service section and create one:    In this page we are going to complete the first form with the following fields:  Setting\tDescriptionProject\tWe select the project we created previously, in our case “example-django-celery”. Name\tWe define a name for the web service. Command\tBy default this will take the value that is in the dockerfile, in our case this is fine. Port\tThe same as the command.  Then we continue by clicking on the “Next” button up to step 3:    In step 3 we have to edit the path field and put the endpoint of healthcheck which in our case is “/healthcheck/”. Then click on the “Next” button until the web service is created:    ","version":"Next","tagName":"h3"},{"title":"Deploy celery worker​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#deploy-celery-worker","content":" Well, with this we can see our web service deploying. Now we are going to deploy the celery. For this we have to go to the workers section inside the same workloads screen:    And click on the “Create” button to create a new one:    In the workers creation screen we will have to complete the following fields:  Setting\tDescriptionProject\tSelect the previously created project. In our case “example-django-celery”. Name\tWe define the name that we are going to give to the worker. In our case “celery”. Command\tHere we set the command to run celery, in our case it is: bash celery -A core.celery_app worker -l INFO --concurrency 1 --max-tasks-per-child 1 --prefetch-multiplier 1 -n celery@%h --queues default,build,deployment,cluster,canvas,billing  With these fields filled in we will click on the “Next” button at the bottom right and then “Submit” as we do not need to edit anything else:    With this we will see our celery published. Now we have to configure the hooks. For this we go to the hooks section:    ","version":"Next","tagName":"h3"},{"title":"Create a migration hook​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#create-a-migration-hook","content":" In the hook creation screen we will have the following fields:  Setting\tDescriptionProject\tSelect the previously created project. In our case “example-django-celery”. Name\tWe define the name that we are going to give to the worker. In our case “migrations”. Command\tHere we set the command to run celery, in our case it is: bash python manage.py migrate --no-input   With these fields filled in we will click on the “Next” button at the bottom right and then “Submit” as we do not need to edit anything else:    ","version":"Next","tagName":"h3"},{"title":"Create a collect static hook​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#create-a-collect-static-hook","content":" Now we proceed to create another hook that we need for the statics:        In this form we are going to do the same as the previous one but modifying the command. We click next until we create the hook (without modifying anything else):    The command we use is as follows:  bash python manage.py collectstatic --no-input   ","version":"Next","tagName":"h3"},{"title":"Create a Postgresql Database​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#create-a-postgresql-database","content":" Once we have created the hooks we have to go to create our database. To do this we go to the “Dependencies” section:    Inside this section we click on the “Create” button at the top right and then select “Postgresql”:      In the 1st postgresql creation form we will have to select our previously created project and define a name for it, then click on the “Next” button at the bottom right:    In the 2nd form we are going to have a lot of fields, the only ones that matter to us are the following:  Setting\tDescriptionDatabase Master Username\tHere we assign a root user name to our database. Database Master Password\tA password for this root user.  With these fields filled in, we are ready to move on. Click on the “Next” button at the bottom right to proceed to the third form:    In this last form, we are going to adjust the environment variables we have in our project with respect to the database. To do this, we need to change the following variables to our own:  Before\tAfter*_POSTGRESQL_NAME\tDB_NAME *_POSTGRESQL_USERNAME\tDB_USER *_POSTGRESQL_PASSWORD\tDB_PASSWORD *_POSTGRESQL_ADDRESS\tDB_HOST *_POSTGRESQL_PORT\tDB_PORT  It should look something like the image below. Then click on the “Submit” button and your database should be created:    ","version":"Next","tagName":"h3"},{"title":"Create S3 Bucket​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#create-s3-bucket","content":" In the same page of dependencies we have to create our s3 bucket, for it we are going to go to the “Create” button again:    And select S3 Bucket:    In the first form we have to select our previously created project and define a name for the bucket, we have to take into account that the name of the bucket is global so it has to be unique. Now click on the “Next” button and go to step 3:    Here we are going to see some environment variables defined for the bucket. We are going to edit the one that says COLLECTSTATICEXAMPLEDJANGOCELERY_BUCKET_NAME and we are going to call it DJANGO_AWS_STORAGE_BUCKET_NAME. With this simple change we click on the “Submit” button at the bottom right to finish creating the bucket:    ","version":"Next","tagName":"h3"},{"title":"Create Rabbitmq​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#create-rabbitmq","content":" Now we need one more dependency. Our Rabbitmq to queue celery tasks, so let's get to it:    And select Rabbitmq:    In the first form we will have to select our project and define a name for it. Then click on the “Next” button at the bottom right:    In the following form we have several fields but the only ones that matter to us for this example are the username and password, we can define whatever we want. For this example I chose admin as username and for the password I generated it randomly with the dice button. Then we click on the “Next” button to go to the next form:    In this last form we have to change the name of the variable that ends in *_BROKER_AUTH_URL to CELERY_BROKER_URL (as shown in the image). Then we click on the “Submit” button at the bottom right to finish creating rabbitmq:    ","version":"Next","tagName":"h3"},{"title":"Create your environment variables​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#create-your-environment-variables","content":" Once the dependencies are deployed we have to configure our environment variables. We are going to go to the Vargroups section:    Here you will see all your environment variables that you created grouped in groups, for example you should have created one with the data for the database (which is the one you see in the image). Now we are going to create another one for our django environment variables, for this we click on the “Create” button at the top right:    In this form we have the following fields:  Project: we select the project we created previously.Workload: We select “global” that makes reference to be used by all our workloads.Name: We define a name for this group of variables.Type: If we want to load it by file or by variable.Vars: Here we enable the textmode and copy the following environment variables:  CELERY_RESULT_BACKEND=django-db DJANGO_ADMIN_URL=admin/ DJANGO_DEBUG=False DJANGO_SECRET_KEY=secret_key DJANGO_SETTINGS_MODULE=core.settings.production DJANGO_STATIC_STORAGE=storages.backends.s3boto3.S3StaticStorage DB_ENGINE=django.db.backends.postgresql_psycopg2 ENVIRONMENT=production LOGS_LEVEL=INFO PYTHONPATH=.   These environment variables are required for our example project. Finally click on the “Submit” button at the bottom right to create the variable group.    ","version":"Next","tagName":"h3"},{"title":"Deployments​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#deployments","content":" As last step we are going to see our project deployed, for this we go to the “Deployments” section of the left panel:    Here we are going to see all the deploys that we do. In our case it is the first one and we can see that it has been created correctly, in case you see any error if you click on “error” you can see a description of it. If we do not see any error then it means that the project is already deployed, we could begin to use it from the url that the web service provided us.    This concludes our project deployment process. We leave you an optional step which is to configure the ci with github.  ","version":"Next","tagName":"h3"},{"title":"Optional​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#optional","content":" ","version":"Next","tagName":"h2"},{"title":"CI with Github​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/tutorial/django-celery#ci-with-github","content":" Every time you make a change in your code and want to deploy it you will have to do a build and a deploy, this eventually becomes tedious. That's why to avoid this we have to implement ci on github.  For this we are going to go to “Projects” in the left panel:    Let's locate our project and click on the gear to access the project configuration:    In the project configuration we locate the one that says “Git pipelines” and click on it:    Here we are going to find what we need to do this. Basically we need to set up a file in the root of our project .github/workflows/ called ci_sleakops_demo.yml and in that file we are going to paste the content that appears in this page.    This needs to have an environment variable SLEAKOPS_KEY, if you don't have it you have to go to the link that appears there Settings -&gt; CLI, get it and save it as an environment variable.  With this configured and deployed every time you do a push to your “main” branch a new version of your application will be launched automatically. ","version":"Next","tagName":"h3"},{"title":"Getting Started","type":0,"sectionRef":"#","url":"/preview-docs/tutorial/getting-started","content":"","keywords":"","version":"Next"},{"title":"Sign in with your email​","type":1,"pageTitle":"Getting Started","url":"/preview-docs/tutorial/getting-started#sign-in-with-your-email","content":" Sign in to our web app.    info In case you do not have an account with us, you need to subscribe using AWS. Follow How to subscribe to SleakOps using AWS.  ","version":"Next","tagName":"h2"},{"title":"Requirements to Join​","type":1,"pageTitle":"Getting Started","url":"/preview-docs/tutorial/getting-started#requirements-to-join","content":" You need to have a root user on AWS. It is the initial account created with full permissions to manage all resources and services, serving as the primary account for AWS Organizations. Go to AWS Organizations.You need access to your code repositories (GitLab, Bitbucket or GitHub).You need your services in Docker files.You need to be able to manage your domains. ","version":"Next","tagName":"h3"},{"title":"Install KEDA","type":0,"sectionRef":"#","url":"/preview-docs/tutorial/install-keda","content":"","keywords":"","version":"Next"},{"title":"Installation Methods​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/tutorial/install-keda#installation-methods","content":" ","version":"Next","tagName":"h2"},{"title":"Using Lens Interface (option 1)​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/tutorial/install-keda#using-lens-interface-option-1","content":" In the Lens menu or the Kubernetes IDE you use, go to Helm &gt; Charts.In the search box, type keda. The official Bitnami chart should appear: bitnami/keda Select the version you want (for example, the most recent available).Click on Install and in the next window review the values (YAML) for installation if you want to customize something (by default, it is usually sufficient).Confirm the installation by pressing Install again.  ","version":"Next","tagName":"h3"},{"title":"Using Helm via Terminal (option 2)​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/tutorial/install-keda#using-helm-via-terminal-option-2","content":" If you prefer the command line or do not have the Helm section in Lens, you can install it like this:  helm repo add bitnami https://charts.bitnami.com/bitnami helm repo update # Create a namespace (optional) kubectl create namespace keda # Install KEDA helm install keda bitnami/keda --namespace keda   ","version":"Next","tagName":"h3"},{"title":"Installation Verification​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/tutorial/install-keda#installation-verification","content":" After installation, you should see that the KEDA resources have been created:  ","version":"Next","tagName":"h2"},{"title":"In Lens​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/tutorial/install-keda#in-lens","content":" Select the namespace where you installed KEDA (by default, keda if you created it manually).You will see a Deployment called keda-operator, one or more Pods, and other CRD (Custom Resource Definitions) type resources such as ScaledObjects and TriggerAuthentications.  ","version":"Next","tagName":"h3"},{"title":"Via Terminal (optional)​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/tutorial/install-keda#via-terminal-optional","content":" kubectl get all -n keda   You should see the operator running, for example:  NAME READY STATUS RESTARTS AGE pod/keda-operator-xxxxx-xxxxx 1/1 Running 0 1m   If everything is in order, you can now use KEDA for your first autoscaling based on events or custom metrics.  ","version":"Next","tagName":"h3"},{"title":"Define ScaledObject in KEDA​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/tutorial/install-keda#define-scaledobject-in-keda","content":" Now we will create a ScaledObject. This resource is what tells KEDA how and when to scale the deployment. In this example, we will use a CPU trigger, although KEDA handles it internally via HorizontalPodAutoscaler (HPA), but the logic integrates with the KEDA CRD.  You can review all possible triggers that KEDA offers in the official documentation here.  ","version":"Next","tagName":"h2"},{"title":"Creating the ScaledObject​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/tutorial/install-keda#creating-the-scaledobject","content":" To create this object we will use the extend-charts function in Sleakops. To get there from the project list in Sleakops, go to Settings &gt; Chart Configuration.      Once you are on the Chart Configuration screen, you can add your ScaledObjects.  To complete the ScaledObject values, you will need some values such as the namespace and the deployment object name (generated by Sleakops) in the cluster.  For the namespace, you could use the following annotation, as in the following example: {{ .Values.global.namespace }} to extract it from the values that Sleakops already generatesFor the deployment name, we do not currently provide it. To get it, you can enter Lens or your Kubernetes IDE and go to the Workloads &gt; Deployments section  apiVersion: keda.sh/v1alpha1 kind: ScaledObject metadata: name: http-echo-scaledobject namespace: { { .Values.global.namespace } } spec: scaleTargetRef: # Must match the Deployment name name: http-echo-deployment # minReplicaCount and maxReplicaCount determine scaling limits minReplicaCount: 1 maxReplicaCount: 5 # Trigger that defines the scaling condition (in this case CPU) triggers: - type: cpu metadata: type: Utilization # or AverageValue value: &quot;50&quot; # scales above 50% CPU  ","version":"Next","tagName":"h3"},{"title":"Configure AWS WAF","type":0,"sectionRef":"#","url":"/preview-docs/tutorial/config-aws-waf","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/tutorial/config-aws-waf#prerequisites","content":" An AWS account with access to WAF and Application Load BalancerAn Application Load Balancer already configured in your AWS accountBasic understanding of AWS console navigation  ","version":"Next","tagName":"h2"},{"title":"Estimated Cost​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/tutorial/config-aws-waf#estimated-cost","content":" The cost of AWS WAF depends on:  The number of active rulesThe number of requests processed by WAF  ","version":"Next","tagName":"h2"},{"title":"Cost Breakdown:​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/tutorial/config-aws-waf#cost-breakdown","content":" Component\tCostCost per rule\t$1 USD/month per rule Cost per WebACL\t$5 USD/month per WebACL Cost per request\t$0.60 USD per million requests  ","version":"Next","tagName":"h3"},{"title":"Example Cost Calculation:​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/tutorial/config-aws-waf#example-cost-calculation","content":" If you have 5 active rules and process 10 million requests per month, the cost would be:  WebACL: $5 USDRules: $5 USD (5 rules × $1 USD)Requests: $6 USD (10 million × $0.60 USD)  Approximate total cost: $16 USD/month    ","version":"Next","tagName":"h3"},{"title":"Step 1: Create a Web ACL​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/tutorial/config-aws-waf#step-1-create-a-web-acl","content":" Go to the AWS console and search for WAFClick on Create web ACLEnter the name of your Web ACL (for example, waf-alb-prod)Choose the region where your ALB is locatedSelect Regional if your ALB is in a specific region (usually the case), or CloudFront if you're using a CloudFront distributionIn the Associated AWS resources (optional) section, select your Application Load Balancer so all traffic passes through WAFClick Next  ","version":"Next","tagName":"h2"},{"title":"Step 2: Configure Basic Rules​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/tutorial/config-aws-waf#step-2-configure-basic-rules","content":" Click Add rules and rule groupsSelect AWS Managed Rules and choose some of the following rules as examples:  Rule\tDescriptionAWSManagedRulesCommonRuleSet\tFor basic protection against common web vulnerabilities AWSManagedRulesBotControl\tTo block known bots and automated traffic AWSManagedRulesAnonymousIPList\tTo block IP addresses associated with services that hide user identity (VPN, proxies, Tor) AWSManagedRulesAmazonIpReputationList\tTo block traffic from IPs known for malicious behavior AWSManagedRulesSQLiRuleSet\tTo protect against SQL injection attacks  These are just examples, as there are many other options depending on the nature of your application and the threats you want to mitigate. We recommend exploring all available options and selecting the rules that best fit your needs.    ","version":"Next","tagName":"h2"},{"title":"Verification​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/tutorial/config-aws-waf#verification","content":" Go back to the WAF service and select your Web ACLReview the metrics and statistics to verify that the rules are blocking unwanted trafficYou can create custom rules if you notice suspicious traffic    ","version":"Next","tagName":"h2"},{"title":"Updating Rules​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/tutorial/config-aws-waf#updating-rules","content":" If you need to add or modify rules:  Go to the AWS WAF consoleSelect your Web ACLClick Rules and Add rule or Edit ruleSave the changes and verify the traffic again    ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/tutorial/config-aws-waf#conclusion","content":" AWS WAF is a powerful tool to protect your application against malicious or unwanted traffic. With this basic configuration, you can block common bots and ensure that only legitimate traffic reaches your ALB.  If you have more questions or need additional support, don't hesitate to ask for help! ","version":"Next","tagName":"h2"},{"title":"Make RDS Database Public","type":0,"sectionRef":"#","url":"/preview-docs/tutorial/make-rds-public","content":"","keywords":"","version":"Next"},{"title":"Introduction and Current Case​","type":1,"pageTitle":"Make RDS Database Public","url":"/preview-docs/tutorial/make-rds-public#introduction-and-current-case","content":" Currently, all databases deployed with SleakOps have the same access configuration:  Publicly Accessible ❌Allocated in a SubnetGroup composed of &quot;Persistence&quot; subnets created in the SleakOps VPC.  Under this configuration, there is no direct way to make the database publicly accessible, so a small workaround must be performed.  Why can't a database be made public directly?  A SubnetGroup of RDS cannot be edited.AWS does not allow editing the SubnetGroup associated with an RDS without a VPC change. Therefore, it forces us to do it using an external VPC.    ","version":"Next","tagName":"h2"},{"title":"Solution with Workaround​","type":1,"pageTitle":"Make RDS Database Public","url":"/preview-docs/tutorial/make-rds-public#solution-with-workaround","content":" ","version":"Next","tagName":"h2"},{"title":"Prerequisites:​","type":1,"pageTitle":"Make RDS Database Public","url":"/preview-docs/tutorial/make-rds-public#prerequisites","content":" Approximately 30 minutes. Have the default VPC created with Subnets where the DB will be located. If you don't have it, you'll need to create a new one from scratch on your own, as well as subnets within it that will be used for this change. Let's call it &quot;transitory&quot;. Create the SubnetGroup that uses Subnets from the transitory VPC. It doesn't matter which subnets it uses. It is used to migrate to the other VPC. In my case, I created the following. Note that both the VPC and the Subnets are from the Default VPC. Create the SubnetGroup that uses the Public Subnets from the VPC deployed by SleakOps. This is the one the DB will use at the end of the flow. Create a SecurityGroup that allows public access, or edit the existing one. In both cases, it must belong to the VPC where the Database is located. In my case, I created the following.  ","version":"Next","tagName":"h3"},{"title":"Step by Step:​","type":1,"pageTitle":"Make RDS Database Public","url":"/preview-docs/tutorial/make-rds-public#step-by-step","content":" With the prerequisites completed, only perform the modifications to the configurations.  Change the SubnetGroup to the one corresponding to the Transitory VPC and remove the current SG. Click next and review the changes. Make sure to select 'Apply Immediately'. Once this is done, you must wait for the change to be applied before continuing with the following steps where we return to the initial VPC, which is the one created by SleakOps. After the VPC change is completed. Change the SubnetGroup to the public one that was created, which is composed of the Public Subnets from the SleakOps VPC. Again, remove the default SG that is automatically linked. Make the DB Publicly Accessible. Review the changes. They should be as follows. Click next and Apply Immediately. Wait again for the change to complete for the last step: Add the SecurityGroup created in the prerequisites. Review the change. Click next and Apply Immediately again.    ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Make RDS Database Public","url":"/preview-docs/tutorial/make-rds-public#conclusion","content":" With this, our DB is completely public for all requests on the port used by the DB. For PostgreSQL, this is port 5432. ","version":"Next","tagName":"h2"},{"title":"S3 Batch","type":0,"sectionRef":"#","url":"/preview-docs/tutorial/s3-batch","content":"","keywords":"","version":"Next"},{"title":"1. Enable and configure an inventory or manifest (list of objects)​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#1-enable-and-configure-an-inventory-or-manifest-list-of-objects","content":" ","version":"Next","tagName":"h2"},{"title":"Create an S3 Inventory (optional, but recommended)​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#create-an-s3-inventory-optional-but-recommended","content":" In the Amazon S3 console, select the source bucket.In the &quot;Management&quot; (or &quot;Administration&quot;) section, create an S3 Inventory that generates a periodic report (CSV or Parquet) of all objects.Verify that the inventory includes &quot;Object version&quot; information (if applicable) and &quot;ETag&quot;.  ","version":"Next","tagName":"h3"},{"title":"Or use a custom manifest (custom CSV)​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#or-use-a-custom-manifest-custom-csv","content":" Alternatively, you can create your own CSV file with the following structure on each line:  s3://SOURCE_BUCKET_NAME/object1.txt s3://SOURCE_BUCKET_NAME/object2.txt ...   Upload this CSV file (manifest) to an S3 bucket that you have access to.  Note This inventory or CSV is the &quot;manifest&quot; that S3 Batch will use to know which objects to copy.  ","version":"Next","tagName":"h3"},{"title":"2. Configure permissions and roles in source and destination accounts​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#2-configure-permissions-and-roles-in-source-and-destination-accounts","content":" ","version":"Next","tagName":"h2"},{"title":"S3 Batch Execution Role​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#s3-batch-execution-role","content":" In the source account, create an IAM Role that allows S3 Batch Operations (service batchoperations.s3.amazonaws.com) to read the source bucket and write to the destination bucket at the same time.Make sure the policy includes the s3:GetObject action for the source bucket and s3:PutObject for the destination bucket.  ","version":"Next","tagName":"h3"},{"title":"Policy on the destination bucket (cross-account)​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#policy-on-the-destination-bucket-cross-account","content":" If the destination bucket is in another account, add a bucket policy that allows the s3:PutObject action for the ARN of the IAM role from the previous step.  ","version":"Next","tagName":"h3"},{"title":"3. Create the S3 Batch Operations Job​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#3-create-the-s3-batch-operations-job","content":" ","version":"Next","tagName":"h2"},{"title":"Basic Job Configuration​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#basic-job-configuration","content":" Enter the S3 console and select Batch Operations in the side menu.Create a new Job with the following basic configuration: Manifest: Indicate where the inventory or CSV (manifest) containing the list of objects is located.Operation: Select Copy.Destination Bucket: Choose the destination bucket (in the other account).IAM Role: Select the role created for this purpose (step 2.1).  ","version":"Next","tagName":"h3"},{"title":"Additional options (optional)​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#additional-options-optional","content":" Storage Class: Select the storage class you want for the destination bucket (Standard, IA, etc.).Object Tags: If you want to replicate or modify tags in the process.Retention/Legal Hold: If compliance applies.  ","version":"Next","tagName":"h3"},{"title":"Review and create Job​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#review-and-create-job","content":" Verify that the settings are correct and launch the Job.  ","version":"Next","tagName":"h3"},{"title":"4. Monitor the process​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#4-monitor-the-process","content":" In the S3 Batch Operations console, locate your Job and review the status.Depending on the volume of objects, copying can take from minutes to several hours/days (for millions of files).Review progress reports and possible errors (for example, objects with access denied).  ","version":"Next","tagName":"h2"},{"title":"5. Validate the transfer​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#5-validate-the-transfer","content":" Object count: Verify that the total number of files in the destination bucket matches what is expected.Error logs: Check error output or review CloudTrail/S3 Logs for objects that were not copied correctly.Re-run for failed objects: You can generate a new manifest with only the failed objects and launch another Job.  ","version":"Next","tagName":"h2"},{"title":"Summary of key points​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/tutorial/s3-batch#summary-of-key-points","content":" Manifest: Properly prepare the inventory or list of objects.Permissions: Ensure you have an IAM role with policies that allow GetObject in source and PutObject in destination (cross-account).Batch Job: Configure the &quot;Copy&quot; operation with the correct role.Monitoring: Review S3 Batch logs and reports, and retry failed objects if necessary. ","version":"Next","tagName":"h2"},{"title":"S3 Replication","type":0,"sectionRef":"#","url":"/preview-docs/tutorial/s3-replication","content":"","keywords":"","version":"Next"},{"title":"1. Create IAM Role in the account where the source bucket is located​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/tutorial/s3-replication#1-create-iam-role-in-the-account-where-the-source-bucket-is-located","content":" ","version":"Next","tagName":"h2"},{"title":"Trust Policy​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/tutorial/s3-replication#trust-policy","content":" You need a trust policy that allows the S3 service to assume the role:  { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: { &quot;Service&quot;: &quot;s3.amazonaws.com&quot; }, &quot;Action&quot;: &quot;sts:AssumeRole&quot; } ] }   ","version":"Next","tagName":"h3"},{"title":"Permissions Policy​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/tutorial/s3-replication#permissions-policy","content":" A permissions policy that allows:  Read objects and metadata from the source bucket (Account A).Put objects in the destination bucket (Account B).  { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;ReadSourceBucket&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:GetObject&quot;, &quot;s3:GetObjectAcl&quot;, &quot;s3:GetObjectVersion&quot;, &quot;s3:GetObjectVersionAcl&quot; ], &quot;Resource&quot;: &quot;arn:aws:s3:::&lt;SOURCE_BUCKET_NAME&gt;/*&quot; }, { &quot;Sid&quot;: &quot;WriteDestBucket&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:PutObject&quot;, &quot;s3:PutObjectAcl&quot;, &quot;s3:ReplicateObject&quot;, &quot;s3:ReplicateDelete&quot;, &quot;s3:ReplicateTags&quot;, &quot;s3:GetObjectVersionTagging&quot;, &quot;s3:PutObjectVersionTagging&quot; ], &quot;Resource&quot;: &quot;arn:aws:s3:::&lt;DESTINATION_BUCKET_NAME&gt;/*&quot; } ] }   ","version":"Next","tagName":"h3"},{"title":"2. Add policy to the destination bucket​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/tutorial/s3-replication#2-add-policy-to-the-destination-bucket","content":" In the destination bucket details, go to the permissions tab and add the following policy:  { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;AllowReplicationFromAccountA&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: { &quot;AWS&quot;: &quot;arn:aws:iam::&lt;ACCOUNT_A_ID&gt;:role/&lt;ROLE_NAME&gt;&quot; }, &quot;Action&quot;: [ &quot;s3:PutObject&quot;, &quot;s3:PutObjectAcl&quot;, &quot;s3:ReplicateObject&quot;, &quot;s3:ReplicateDelete&quot;, &quot;s3:ReplicateTags&quot; ], &quot;Resource&quot;: [&quot;arn:aws:s3:::&lt;DESTINATION_BUCKET_NAME&gt;/*&quot;] } ] }   ","version":"Next","tagName":"h2"},{"title":"3. Configure the replication rule in the source bucket​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/tutorial/s3-replication#3-configure-the-replication-rule-in-the-source-bucket","content":" In the source bucket details, go to the &quot;Management&quot; (or &quot;Properties&quot; depending on console version) tab and look for the Replication section.Create a new replication rule and define: Rule name: A descriptive name.Status: Enabled.Source bucket: The current bucket (already selected).Prefix/Filter: You can choose to replicate the entire bucket or only a specific prefix.Destination: Bucket: specify the ARN of the destination bucket in Account B. IAM role: choose the role you created in the first step, which allows replication.  ","version":"Next","tagName":"h2"},{"title":"Optional​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/tutorial/s3-replication#optional","content":" If the &quot;Transfer to destination bucket owner&quot; option is activated, the action must be added to both AllowReplicationFromAccountA (destination bucket policy) and WriteDestBucket (IAM role):&quot;s3:ObjectOwnerOverrideToBucketOwner&quot;  ","version":"Next","tagName":"h2"},{"title":"Ways to copy existing files​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/tutorial/s3-replication#ways-to-copy-existing-files","content":" There are 3 different ways to copy existing files from the bucket:  ","version":"Next","tagName":"h2"},{"title":"1. Do it along with replication​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/tutorial/s3-replication#1-do-it-along-with-replication","content":" When activating replication, it gives you an option to copy all existing files.  ","version":"Next","tagName":"h3"},{"title":"2. Use the S3 migration option provided by Sleakops​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/tutorial/s3-replication#2-use-the-s3-migration-option-provided-by-sleakops","content":" In the detail of the S3 type dependency, you can find this function that guides you step by step on what needs to be done.    ","version":"Next","tagName":"h3"},{"title":"3. Use the Batch Operation service​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/tutorial/s3-replication#3-use-the-batch-operation-service","content":" Once the replication rule is created, following these guides:   Batch Operations IAM role policies Replication metrics and events  Add to the S3ReplicationRolePolicy the following actions:  &quot;s3:PutObjectTagging&quot; to &quot;Sid&quot;: &quot;WriteDestBucket&quot;&quot;s3:GetObjectTagging&quot; and &quot;s3:ListBucket&quot; to &quot;Sid&quot;: &quot;ReadSourceBucket&quot;  { &quot;Sid&quot;: &quot;ReadReportBucket&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [&quot;s3:GetObject&quot;, &quot;s3:GetObjectVersion&quot;], &quot;Resource&quot;: [&quot;arn:aws:s3:::bucket-reports/*&quot;] }   And add the &quot;s3:InitiateReplication&quot; permission to both WriteDestBucket and SourceBucket. ","version":"Next","tagName":"h3"},{"title":"Third Party VPN Integration","type":0,"sectionRef":"#","url":"/preview-docs/tutorial/third-party-integration-vpn","content":"","keywords":"","version":"Next"},{"title":"Transit Gateway (~$197/month in the described scenario)​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/tutorial/third-party-integration-vpn#transit-gateway-197month-in-the-described-scenario","content":" Higher fixed cost per attachment.Excellent option for larger topologies, multiple VPCs and scalability with minimal routing complexity.  ","version":"Next","tagName":"h3"},{"title":"Site-to-Site VPN + EC2 (~$80/month estimated)​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/tutorial/third-party-integration-vpn#site-to-site-vpn--ec2-80month-estimated","content":" Easy configuration (native AWS solution).Suitable for a moderate number of tunnels, although less flexible than TGW for large topologies.  ","version":"Next","tagName":"h3"},{"title":"VPN on EC2 (StrongSwan + Nginx) (~$20–21/month with 1 instance, or ~$40–42/month for HA)​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/tutorial/third-party-integration-vpn#vpn-on-ec2-strongswan--nginx-2021month-with-1-instance-or-4042month-for-ha","content":" Significantly lower cost.Higher administration and maintenance complexity (instance management, patches, manual failover).Suitable if total traffic is low and if you have staff to operate/monitor the instance.  ","version":"Next","tagName":"h3"},{"title":"Transit Gateway​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/tutorial/third-party-integration-vpn#transit-gateway","content":" Acts as a centralized router that allows interconnection between multiple VPCs, on-premises networks and third-party networks.  VPN connections are established through IPsec tunnels, which can be configured to provide high availability and redundancy (two tunnels per VPN connection are generally configured to achieve automatic failover).    ","version":"Next","tagName":"h2"},{"title":"Cost Analysis​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/tutorial/third-party-integration-vpn#cost-analysis","content":" Hypothesis:  3 attachments in the Transit Gateway, corresponding for example to: VPC (Dev)VPN (Prod)VPN (Contingency) 730 hours of monthly usage (24/7).2 GB monthly transfer per attachment, totaling 6 GB monthly.AWS rates (in most regions): $0.09/hour/attachment.$0.002/GB of data transfer.  Costs:  Attachment costs: ~$197.10/monthData transfer cost: ~$0.01/month  Total sum: ~$197.11/month (rounded to ~$197.22/month in the original example).  ","version":"Next","tagName":"h3"},{"title":"Site-to-Site VPN​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/tutorial/third-party-integration-vpn#site-to-site-vpn","content":" A Site-to-Site VPN connection offers two VPN tunnels between a virtual private gateway or transit gateway on the AWS side and a customer gateway on the remote side (on-premise).  Two tunnels for automatic failover or maintenance that AWS usually does that could briefly disable one of the tunnels —&gt; Site-to-Site VPN tunnel endpoint replacement      ","version":"Next","tagName":"h2"},{"title":"Cost Analysis​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/tutorial/third-party-integration-vpn#cost-analysis-1","content":" Hypothesis:  3 connections (VPN) (equivalent to the 3 &quot;attachments&quot; you mentioned: Dev, Main, Contingency).Each VPN is an AWS-managed Site-to-Site tunnel.Site-to-Site VPN cost: $0.05 per hour per VPN730 hours monthly (24/7).2 GB monthly transfer per VPN.  Costs:  VPN (3 connections): ~$109.50Data transfer (6 GB total): ~$0.54Network Load Balancer: ~$20–25  Total sum: ~$130–135 monthly.  ","version":"Next","tagName":"h3"},{"title":"VPN on EC2​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/tutorial/third-party-integration-vpn#vpn-on-ec2","content":" In this solution, an EC2 instance is launched on which StrongSwan is installed to establish IPsec tunnels and Nginx as a proxy (normally to route traffic at the application layer towards an Application Load Balancer or other VPC resources).    ","version":"Next","tagName":"h2"},{"title":"Cost Analysis​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/tutorial/third-party-integration-vpn#cost-analysis-2","content":" Hypothesis:  3 tunnels (VPN) configured on the same instance (or on two instances for redundancy).EC2 instance of small size, for example, t3.small (with approx. cost $0.02–0.023/h).  Costs:  EC2 + EBS: ~$18–20/month (1 instance)Data transfer: ~$0.54/month  Total sum: ~$20–21/month (In case of 2 instances for HA =&gt; ~$40–42/month.)  Configuration of nginx and ipsec to achieve the connection setup.  nginx.conf  load_module /usr/lib/nginx/modules/ngx_stream_module.so; worker_processes 1; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; access_log /var/log/nginx/access.log main; sendfile on; keepalive_timeout 65; server_tokens off; } stream { server { listen 8180; proxy_pass **&lt;URL-ALB&gt;**; } }   iptables.conf  *mangle :PREROUTING ACCEPT [8165:7991805] :INPUT ACCEPT [7883:7958068] :FORWARD ACCEPT [282:33737] :OUTPUT ACCEPT [5933:572312] :POSTROUTING ACCEPT [6215:606049] COMMIT *nat :PREROUTING ACCEPT [159:9540] :INPUT ACCEPT [159:9540] :OUTPUT ACCEPT [168:10720] :POSTROUTING ACCEPT [168:10720] -A PREROUTING -i eth0 -p tcp -m tcp --dport 2222 -j DNAT --to-destination &lt;IP-BIND&gt;:22 -A PREROUTING -i eth0 -p tcp -m tcp --dport 443 -j DNAT --to-destination &lt;IP-BIND&gt;:443 -A POSTROUTING -p tcp -m tcp --dport 22 -j SNAT --to-source &lt;IP-TUNNEL-BIND&gt; -A POSTROUTING -p tcp -m tcp --dport 443 -j SNAT --to-source &lt;IP-TUNNEL-BIND&gt; COMMIT *filter :INPUT ACCEPT [6016:538920] :FORWARD ACCEPT [123:22565] :OUTPUT ACCEPT [4614:432344] -A FORWARD -d &lt;IP-BIND&gt;/32 -p tcp -m tcp --dport 443 -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT -A FORWARD -d &lt;IP-BIND&gt;/32 -p tcp -m tcp --dport 22 -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT -A FORWARD -d &lt;IP-BIND&gt;/32 -p tcp -m tcp --dport 44301 -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT -A FORWARD -d &lt;IP-BIND&gt;/32 -p tcp -m tcp --dport 22 -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT -A FORWARD -d &lt;IP-BIND&gt;/32 -p tcp -m tcp --dport 8180 -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT COMMIT  ","version":"Next","tagName":"h3"},{"title":"n8n + Worker Mode","type":0,"sectionRef":"#","url":"/preview-docs/tutorial/n8n-worker","content":"","keywords":"","version":"Next"},{"title":"Why Self-Hosted n8n?​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#why-self-hosted-n8n","content":" Self-hosting n8n provides numerous advantages over cloud-hosted solutions:  ","version":"Next","tagName":"h2"},{"title":"🔒 Security and Privacy​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#-security-and-privacy","content":" Complete Data Control: Your workflows, credentials, and sensitive data never leave your infrastructure.Customized Security Policies: Implement your organization's specific security requirements.Network Isolation: Keep n8n within your private network, reducing external attack vectors.Compliance: Meet strict regulatory requirements (GDPR, HIPAA, SOC2) with on-premises deployment.  ","version":"Next","tagName":"h3"},{"title":"💰 Cost Optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#-cost-optimization","content":" No limits per run: Run unlimited workflows without usage-based pricingPredictable costs: Fixed infrastructure costs regardless of usage volumeResource efficiency: Scale resources based on actual needs, not vendor pricing tiersLong-term savings: Significant cost reductions for high-volume automation scenarios  ","version":"Next","tagName":"h3"},{"title":"⚡ Performance and Scalability​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#-performance-and-scalability","content":" Custom Resource Allocation: Allocate CPU and memory based on your specific workload requirementsLow Latency: Direct access to internal systems without internet roundtripsHigh Availability: Design redundant systems with multiple replicas and failover mechanismsCustom Integrations: Connect to internal APIs and systems not accessible from cloud providers  ","version":"Next","tagName":"h3"},{"title":"🎛️ Total Control and Customization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#️-total-control-and-customization","content":" Version Control: Choose when to update and test new versions in your environmentCustom Nodes: Install and develop proprietary nodes for your specific use casesEnvironment Variables: Full access to system-level configurations and secret managementBackup Strategies: Implement your own backup and disaster recovery procedures  ","version":"Next","tagName":"h3"},{"title":"Benefits of Scaling in Kubernetes​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#benefits-of-scaling-in-kubernetes","content":" Deploying n8n on a Kubernetes cluster with Sleakops provides enterprise-level scalability:  ","version":"Next","tagName":"h2"},{"title":"🚀 Horizontal Scaling​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#-horizontal-scaling","content":" Worker Pods: Automatically scale worker instances based on queue depth and CPU usageLoad Distribution: Distribute workflow execution across multiple worker nodesAuto-Scaling: Kubernetes HPA (Horizontal Pod Autoscaler) automatically adjusts worker countResource Optimization: Scale different components independently (web UI vs. workers)  ","version":"Next","tagName":"h3"},{"title":"🏗️ Infrastructure Resilience​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#️-infrastructure-resilience","content":" High Availability: Multiple replicas ensure zero downtime during node failuresContinuous Upgrades: Deploy new versions without service interruptionHealth Checks: Kubernetes automatically restarts failed pods and routes traffic to healthy instancesMulti-Zone Deployment: Distribute workload across availability zones for disaster recovery  ","version":"Next","tagName":"h3"},{"title":"📊 Monitoring and Observability​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#-monitoring-and-observability","content":" Real-time metrics: Monitor workflow execution, queue depth, and resource usageCentralized logging: Aggregate logs from all n8n components in one placePerformance insights: Track execution times, error rates, and throughputAlerts: Proactive notifications for system issues and performance bottlenecks  ","version":"Next","tagName":"h3"},{"title":"🔧 DevOps Integration​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#-devops-integration","content":" GitOps Workflows: Version control of your n8n infrastructure as codeCI/CD Pipelines: Automated testing and deployment of n8n configurationsSecret Management: Integrates with Kubernetes secrets and external secret managersNetwork Policies: Fine-grained network security controls  ","version":"Next","tagName":"h3"},{"title":"Prerequisite​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#prerequisite","content":" A Sleakops accountA cluster in this account. If you don't have one, here's the documentation on how to create one.A configured environment. If you don't have one, here's the documentation on how to create one.An n8n project configured with Docker. If you don't have it, you can fork or copy n8n-code. This project includes a Docker Compose package so you can also deploy it locally, allowing you to have distributed environments as you wish.  Let's begin  For this example, we'll deploy an n8n project in distributed mode with worker processes. This configuration includes the main n8n service (web interface) and worker processes to execute workflows. We'll also configure a PostgreSQL database and Redis for queue management, which are necessary for this project.  ","version":"Next","tagName":"h2"},{"title":"Create Project​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#create-project","content":" Projects are our code repositories. All Sleakops needs to run commands is a Dockerfile.  For more information, see our project documentation.  To begin, we will create a new project:  Click the &quot;Projects&quot; button in the left panel.Then click &quot;Create&quot; in the upper right corner.    Within the Projects panel, you can see all your projects and manage them from here. We want to create a new one, so let's click the &quot;create&quot; button in the upper right corner.  On the project creation screen, we have the following fields:  Configuration\tDescriptionEnvironment\tWe need to select the previously created environment. Nodepool\tWe'll leave the default. Repositories\tWe'll select our repository that contains the n8n project. Project Name\tWe can define a project name. For example, &quot;n8n-server&quot;. Branch\tIt must match the branch in our project. In our case, it's &quot;main&quot;. Dockerfile path\tThis is the relative path to the Dockerfile in your project.  Once all that is configured, we create the project using the &quot;Submit&quot; button in the bottom right corner:    With that, the project begins to be created. In the meantime, let's go to the workloads using the &quot;Workloads&quot; button in the left panel:    ","version":"Next","tagName":"h2"},{"title":"Create Workloads​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#create-workloads","content":" Workloads are the processes that your project runs. In the case of n8n, which we'll run in queue mode, we'll create a web service for the web interface and a worker. For more information, see our workloads documentation  ","version":"Next","tagName":"h2"},{"title":"Create the Web Service​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#create-the-web-service","content":" Here we will create the main n8n web service that will handle the user interface and API:  On this page, we will complete the first form with the following fields:  Configuration\tDescriptionProject\tSelect the project we created previously, in our case &quot;n8n-server&quot;. Name\tDefine a name for the web service, for example &quot;n8n-main&quot;. Command\tDefault command from the Dockerfile (usually n8n start). Port\tPort 5678 (n8n's default port).    In the second step, we'll configure the web service as private:  What does this mean?  The n8n service will be inside the VPCIt will only be accessible from services on the same networkIt requires a VPN for external access  Alternative for public webhooks:If you need to connect to public webhooks (Jira, Slack, Google Drive, etc.), you can:  Leave this service as public, ORCreate an additional public web service using the webhook command    Continue to step 3, &quot;Service settings,&quot; and configure the health check.  To do this, simply define the path for the health check, which comes with n8n /healthz, and click &quot;Next&quot; until the flow is complete and the web service is created.    This health check is important so Kubernetes knows when the service is ready to start delivering HTTP traffic. This is useful for avoiding downtime between deployments or node rotations.  We won't modify the last step of the form, where we define memory, CPU, and scaling conditions, for now; we'll leave it as the platform provides.  ","version":"Next","tagName":"h3"},{"title":"Creating the n8n Worker​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#creating-the-n8n-worker","content":" Great, with this we can see our web service being deployed. Now let's deploy the n8n worker for distributed execution. To do this, we need to go to the Workers section within the same Workloads screen and click the &quot;Create&quot; button.    On the worker creation screen, we will need to complete the following fields:  Configuration\tDescriptionProject\tSelect the previously created project. In our case, &quot;n8n-server&quot;. Name\tDefine the name we will give to the worker. In our case, &quot;n8n-worker&quot;. Command\tHere we set the command to run the n8n worker: worker  With these fields completed, we will click the &quot;Next&quot; button in the lower right corner and then &quot;Submit,&quot; as we do not need to edit anything else.    This will show our n8n worker deployed.  ","version":"Next","tagName":"h3"},{"title":"Create dependencies (Redis and PostgreSQL)​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#create-dependencies-redis-and-postgresql","content":" Dependencies are resources necessary for your application to function. In the case of n8n in queue mode, it needs a database and Redis. Sleakops leverages AWS services to provide you with alternatives. You can find more information in the dependencies documentation (/project/dependency).  Let's go to the dependencies section:    ","version":"Next","tagName":"h2"},{"title":"Creating a Redis Dependency​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#creating-a-redis-dependency","content":" First, we need to create a Redis dependency for the task queue. On the dependency creation screen, select Redis, and you will see the following fields:  Configuration\tDescriptionDependency Type\tSelect &quot;Redis&quot; from the available options. Project\tSelect the previously created project. In our case, &quot;n8n-server&quot;. Name\tDefine the name for Redis. In our case, &quot;n8n-redis&quot;.    With these fields completed, we'll click the &quot;Next&quot; button in the bottom right corner. In the last step, before clicking &quot;Submit,&quot; we'll change the environment variable names to match what n8n expects.  We need to configure the Redis connection variables to match what n8n expects:  Variable\tValueQUEUE_BULL_REDIS_HOST\t(Redis Host of the dependency) QUEUE_BULL_REDIS_PORT\t6379    This tells Sleakops what name we want it to use to publish the variables generated by the &quot;Redis&quot; dependency.  Make sure the variable names match what your n8n configuration expects.  ","version":"Next","tagName":"h3"},{"title":"Create PostgreSQL Database​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#create-postgresql-database","content":" Now we proceed to create the PostgreSQL database for n8n data storage:    You can switch between &quot;production&quot; and &quot;non-production&quot; environments. This gives you default configuration values ​​in the next step for each environment. For example, in a production environment, it enables multi-A-Z, automatic backups, etc. As an example in this guide, we'll leave it as &quot;non-production.&quot;  Just like with Redis, we need to configure the environment variable names as n8n expects. Go to the last step and before clicking submit, change the names to the following:  Before\tAfter*_POSTGRESQL_NAME\tDB_POSTGRESDB_DATABASE *_POSTGRESQL_USERNAME\tDB_POSTGRESDB_USER *_POSTGRESQL_PASSWORD\tDB_POSTGRESDB_PASSWORD *_POSTGRESQL_ADDRESS\tDB_POSTGRESDB_HOST *_POSTGRESQL_PORT\tDB_POSTGRESDB_PORT  It should look something like the image below. Then click the &quot;Submit&quot; button and your database should be created:    ","version":"Next","tagName":"h3"},{"title":"Configuring Environment Variables​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#configuring-environment-variables","content":" Now we need to create the remaining environment variables. We can see the variables we have in .env.example in the code repository. Some variables have already been configured in each dependency, but others still need to be defined. To do this, we go to the &quot;Variablegroups&quot; section.    We're going to create a new variable group. We'll switch to text mode to copy the missing variables from the .env.example file and adjust the values ​​accordingly.  This form has the following fields:  Project: Select the project we created earlier. Workload: Select &quot;global,&quot; which means it will be used by all our workloads. Name: Define a name for this variable group. Type: Choose whether to load it by file or by variable. Vars: Here, enable text mode and copy the following environment variables:  Variable\tDescriptionDB_TYPE\tSet to &quot;postgresdb&quot; EXECUTIONS_MODE\tSet to &quot;queue&quot; for worker mode N8N_ENCRYPTION_KEY\tGenerate a secure encryption key OFFLOAD_MANUAL_EXECUTIONS_TO_WORKERS\tSet to &quot;true&quot; N8N_HOST\tDefine the host you configured in your web service; for this example, it would be n8n.demo.sleakops.com N8N_WEBHOOK_URL\tThis variable is not strictly necessary to define; if you add a separate web service instance to handle webhooks with a different URL, you must specify which URL will handle the webhooks. https://n8n.demo.sleakops.com/ N8N_EDITOR_BASE_URL\thttps://n8n.demo.sleakops.com  If you want to see all the environment variables available to configure n8n, you can go to the following page of n8n documentation    ","version":"Next","tagName":"h2"},{"title":"Deployments​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#deployments","content":" As a final step, let's view our deployed project. To do this, go to the &quot;Deployments&quot; section in the left panel:    Here we'll see all the deployments we perform. In our case, it's the first one, and we can see that it was created successfully. If you see any errors, clicking on &quot;error&quot; will show you a description.  If we don't see any errors, then the project is already deployed, and we can start using it from the URL provided by the web service.  This concludes our project deployment process. We've included an optional step: configuring CI/CD with GitHub.  ","version":"Next","tagName":"h2"},{"title":"CI/CD Configuration (Optional but Recommended)​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#cicd-configuration-optional-but-recommended","content":" ","version":"Next","tagName":"h2"},{"title":"Why Configure CI/CD?​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#why-configure-cicd","content":" Without CI/CD, every change to your code requires:  Manual build from SleakOpsManual deploymentManual verification  With CI/CD configured:  ✅ Push to main → Automatic deployment✅ Automatic rollback in case of error✅ Deployment status notifications  ","version":"Next","tagName":"h3"},{"title":"Setup steps:​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#setup-steps","content":" Go to your project in SleakOpsClick the ⚙️ (settings)Select &quot;Git pipelines&quot;Copy the provided YAML fileAdd SLEAKOPS_KEY to your GitHub secrets      This requires an environment variable called SLEAKOPS_KEY. If you don't have it, go to the link provided in Settings -&gt; CLI, retrieve it, and save it as an environment variable.  With this configured and deployed, every time you push to your &quot;main&quot; branch, a new version of your application will be automatically released.  ","version":"Next","tagName":"h3"},{"title":"🎯 Next Steps​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#-next-steps","content":" Once the installation is complete:  ","version":"Next","tagName":"h2"},{"title":"Initial n8n Configuration​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#initial-n8n-configuration","content":" First Access: Use your web service URLCreate Administrator User: n8n will prompt you to create the first userConfigure Webhooks: If needed, configure the public URLs  ","version":"Next","tagName":"h3"},{"title":"Monitoring and Optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#monitoring-and-optimization","content":" Review Metrics: Use the integrated Grafana dashboardAdjust Resources: Modify CPU/memory based on actual usageConfigure Alerts: Define performance thresholds  ","version":"Next","tagName":"h3"},{"title":"Backup and Security​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#backup-and-security","content":" Automatic Backups: Configure PostgreSQL backupsSecrets Management: Review credential managementUpdates: Schedule regular updates  ","version":"Next","tagName":"h3"},{"title":"Updating and Extending n8n​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#updating-and-extending-n8n","content":" We now have our own n8n installed and running on the cluster. We have our n8n definition in a Dockerfile.  To update the version​  This process is very simple. We'll modify the Dockerfile and change the image tag. You can see the available images in the official n8n repository on Docker Hub.  Note: Read the changelog in case there are any breaking changes or anything that might break between versions. Make backups of the database beforehand, just in case.  To add new dependencies to your nodes​  As we did to update the version, in this case we'll take advantage of having our Dockerfile and install whatever we want inside it. This will be available for use on our n8n nodes.  You can see examples of this in the repository's README.  ","version":"Next","tagName":"h2"},{"title":"Scaling Best Practices (Bonus)​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#scaling-best-practices-bonus","content":" Once your n8n deployment is up and running, consider these scaling strategies:  ","version":"Next","tagName":"h2"},{"title":"🎯 Worker Optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#-worker-optimization","content":" Queue Monitoring: Monitor the Redis queue depth to determine when to scale workers.Resource Allocation: Allocate sufficient CPU and memory based on workflow complexity.Concurrency Tuning: Tune worker concurrency based on workflow types (CPU-intensive vs. I/O-intensive).Dedicated Workers: Create pools of specialized workers for different workflow categories.  ","version":"Next","tagName":"h3"},{"title":"📈 Performance Monitoring​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#-performance-monitoring","content":" Adjust the memory and CPU of your workloads to what your processes actually need.  This is useful for avoiding oversized infrastructure and also for making decisions when scaling horizontally based on memory or CPU.  How do we do it from Sleakops?​  Simple, go to the details of your worker or web service that we created earlier and click on the &quot;Grafana&quot; icon. This will open a dashboard within Grafana showing the historical consumption of your process. Be sure to look at a long time range to cover all your scenarios.    ","version":"Next","tagName":"h3"},{"title":"🔧 Database Optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#-database-optimization","content":" Connection Pooling: Configure PostgreSQL connection pools for high concurrency. Read Replicas: Use read replicas for reporting and analytics queries. (This can be done from Sleakops in the Postgres configuration.) Indexing: Optimize database indexes for workflow execution queries. Backup Strategies: Implement automated backups with point-in-time recovery. (This can be done from Sleakops in the Postgres configuration.)  ","version":"Next","tagName":"h3"},{"title":"🚀 Advanced Configurations​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/tutorial/n8n-worker#-advanced-configurations","content":" Node Affinity: Schedule workers on appropriate node types (CPU vs. memory-optimized). (You can do this from Sleakops using Nodepools)Pod Disruption Budgets: Ensures minimum availability during cluster maintenance. (Sleakops already handles this)Resource Quotas: Sets appropriate limits to prevent resource exhaustion. (You can do this from Sleakops by defining limits on your Workloads and Nodepools)Network Policies: Ensures inter-pod communication. (Sleakops already handles this) ","version":"Next","tagName":"h3"}],"options":{"languages":["en","es"],"indexBaseUrl":true,"id":"default"}}