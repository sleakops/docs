{"searchDocs":[{"title":"Test2","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/Testset-dasd-sad-","content":"SADdasd","keywords":"","version":null},{"title":"Test","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/testset-test","content":"Test","keywords":"","version":null},{"title":"Versión 1.0.1","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-0-1","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.0.1","url":"/preview-docs/es/changelog/v1-0-1#nuevas-funcionalidades","content":" Gestión de Suscripciones: El login y actualizaciones de token se controlan según el estado de la suscripción. Adicionalmente, se implementó una nueva API para registrar usuarios y empresas, validando suscripciones pendientes, con un nuevo modelo para mejor gestión de suscripciones, integrando AwsClient.Onboarding de Marketplace: Proceso simplificado para crear usuarios que vienen de un marketplace. ","version":null,"tagName":"h2"},{"title":"Versión 1.0.3","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-0-3","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.0.3","url":"/preview-docs/es/changelog/v1-0-3#nuevas-funcionalidades","content":" Botones de Gestión y Mejoras en Formularios: Agregados botones para gestión de recursos y mejorados formularios de mapeo de variables.Cronjobs y Regeneración de Dominio: Ahora puedes detener o activar cronjobs y regenerar dominios.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.0.3","url":"/preview-docs/es/changelog/v1-0-3#correcciones-de-errores","content":" Resuelto el problema de obtener el URI de VPN en Pritunl.Corregido el problema de selección de cuenta para usuarios viewer.Mejorado el manejo de información de health check enviada al backend. ","version":null,"tagName":"h2"},{"title":"Versión 1.0.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-0-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.0.0","url":"/preview-docs/es/changelog/v1-0-0#nuevas-funcionalidades","content":" Configuración de Volúmenes: Ahora puedes configurar volúmenes en environments de proyecto directamente desde el formulario.Apagado Nocturno con Zona Horaria: Agregado soporte para seleccionar zonas horarias en el apagado nocturno.Inicio Manual de Cluster: Nuevo botón para iniciar clusters manualmente.Integración con CloudFront: Soporte para usar CloudFront para mejorar la entrega de contenido.Backups Automáticos: Puedes configurar backups automáticos para dependencies.Instancias Graviton: Soporte para usar instancias Graviton en nodos.Encriptación: Implementada encriptación en StackSettings para mayor seguridad.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.0.0","url":"/preview-docs/es/changelog/v1-0-0#correcciones-de-errores","content":" Resuelto un problema en la API de facturación y estimación de costos.Corregidos errores al eliminar Providers y VPNs.Ahora puedes eliminar certificados ACM usados por un Load Balancer sin problemas. ","version":null,"tagName":"h2"},{"title":"Versión 1.0.2","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-0-2","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.0.2","url":"/preview-docs/es/changelog/v1-0-2#nuevas-funcionalidades","content":" Optimización de Deployment: Simplificado el proceso de deployment y edición de environment de proyecto (ProjectEnv), facilitando configuración y deployment.Ajustes de Recursos y Configuración: Ahora puedes crear aliases personalizados para buckets.Mejoras en Health Check: La sonda de readiness para servicios en la cuenta de desarrollo ahora es opcional.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.0.2","url":"/preview-docs/es/changelog/v1-0-2#correcciones-de-errores","content":" Resueltos problemas relacionados con VPN y configuración de parámetros de seguridad. ","version":null,"tagName":"h2"},{"title":"Versión 1.0.4","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-0-4","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.0.4","url":"/preview-docs/es/changelog/v1-0-4#nuevas-funcionalidades","content":" Refactorización y Mejoras: Refactorizado el dashboard y mejorada la visualización de logs y la gestión de eliminación de entidades.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.0.4","url":"/preview-docs/es/changelog/v1-0-4#correcciones-de-errores","content":" Corregidos problemas de edición de usuarios.Corregida la gestión del estado del cluster.Resueltos problemas con dominios de environment.Corregido el manejo de errores en respuestas S3 con CloudFront. ","version":null,"tagName":"h2"},{"title":"Versión 1.1.1","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-1-1","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.1.1","url":"/preview-docs/es/changelog/v1-1-1#nuevas-funcionalidades","content":" Visor de Logs en Jobs: Agregado un visor de logs en la lista de jobs, similar al que ya existe para deployments.Dashboard v2: Mejoras en la segunda versión del Dashboard, con más opciones y mejor organización de información.Certificados de Cluster: Los certificados de cluster ahora se eliminan y actualizan automáticamente para prevenir problemas de expiración. ","version":null,"tagName":"h2"},{"title":"Versión 1.0.5","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-0-5","content":"","keywords":"","version":null},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.0.5","url":"/preview-docs/es/changelog/v1-0-5#correcciones-de-errores","content":" Resueltos problemas de deployment y corregido Karpenter con instancias spot.Corregidos problemas al eliminar entidades y validar URLs de servicios. ","version":null,"tagName":"h2"},{"title":"Versión 1.1.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-1-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.1.0","url":"/preview-docs/es/changelog/v1-1-0#nuevas-funcionalidades","content":" Gestión de Vargroups: Agregada la opción de mostrar vargroups en los formularios para servicios, workers, hooks y cronjobs.Kubecost: Integrado Kubecost con Prometheus-stack.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.1.0","url":"/preview-docs/es/changelog/v1-1-0#correcciones-de-errores","content":" Resuelto el problema con Karpenter en instancias spot.Corregidos roles de usuario y edición de usuarios.Corregidos problemas al eliminar un environment y la eliminación incorrecta de dominios.Corregido el error al intentar iniciar manualmente el cluster.Resuelto un error en la generación de hooks. ","version":null,"tagName":"h2"},{"title":"Versión 1.2.2","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-2-2","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.2.2","url":"/preview-docs/es/changelog/v1-2-2#nuevas-funcionalidades","content":" Botón de Validación de Dominio: Se ha agregado un botón &quot;verificar validación&quot; al drawer de dominio para facilitar la gestión de dominios.Tabla de Log de Actividad: Se ha creado una tabla de log de actividad.Encriptación de Access Keys: Las access keys para proveedores de versión de código (GIT) ahora están encriptadas.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.2.2","url":"/preview-docs/es/changelog/v1-2-2#correcciones-de-errores","content":" Se ha corregido un problema donde la API no recreaba correctamente el módulo ACM durante la regeneración. ","version":null,"tagName":"h2"},{"title":"Versión 1.2.1","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-2-1","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.2.1","url":"/preview-docs/es/changelog/v1-2-1#nuevas-funcionalidades","content":" Optimización de Formulario de Vargroup: Se han realizado mejoras de usabilidad en los formularios de Vargroup.Eliminación de Provider y Cuenta de Usuario: Eliminar un provider ahora también elimina las cuentas de usuario asociadas.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.2.1","url":"/preview-docs/es/changelog/v1-2-1#correcciones-de-errores","content":" Se ha corregido un bug en la regeneración de certificados ACM.Se ha corregido un problema de eliminación de provider. ","version":null,"tagName":"h2"},{"title":"Versión 1.2.4","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-2-4","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.2.4","url":"/preview-docs/es/changelog/v1-2-4#nuevas-funcionalidades","content":" Optimización de Cluster Switcher: El comportamiento del selector de cluster ha sido optimizado.Login en Flujo de Suscripción AWS: El flujo de suscripción AWS ahora incluye la capacidad de iniciar sesión directamente.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.2.4","url":"/preview-docs/es/changelog/v1-2-4#correcciones-de-errores","content":" Se han resuelto problemas de callback para integraciones Git y ruta de archivo Docker para GitLab.Se han corregido bugs menores relacionados con la pantalla de facturación. ","version":null,"tagName":"h2"},{"title":"Versión 1.2.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-2-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.2.0","url":"/preview-docs/es/changelog/v1-2-0#nuevas-funcionalidades","content":" Logs en Grafana: Se ha configurado una fuente de datos en Grafana para mostrar logs desde S3.Botón de Actualización de Cluster: Se ha agregado un botón para permitir actualizaciones de cluster desde la interfaz.Log de Actividad de Usuario: Se ha creado un log de actividad para acciones de usuario.Deploy de Validación de Dominio: Ahora puedes crear un deploy que se ejecuta una vez que los dominios están validados.Autenticación de Dos Factores: Se ha agregado autenticación de dos factores (2FA) al login para mayor seguridad.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.2.0","url":"/preview-docs/es/changelog/v1-2-0#correcciones-de-errores","content":" Se ha corregido un problema con builds usando la misma rama que la predeterminada.Se ha mejorado la lectura de logs para procesamiento más rápido.Se han realizado varias optimizaciones de frontend, incluyendo estilos, búsqueda y visibilidad de recursos pendientes. ","version":null,"tagName":"h2"},{"title":"Versión 1.4.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-4-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.4.0","url":"/preview-docs/es/changelog/v1-4-0#nuevas-funcionalidades","content":" Configuración de Grafana: Se configuró la base de datos para el addon de Grafana, junto con DataSources y Dashboards.Persistencia de Métricas de Prometheus con Thanos: Agregado soporte para persistir métricas de Prometheus usando Thanos.Nueva API de Volumen: Implementado soporte para la nueva API de volumen, mostrando estados y aplicando configuración para deployments.La opción de actualización en addons ha sido deshabilitada.Ahora, cuando se elimina una dependency, se creará un deploy con &quot;pending-approval&quot; en lugar de uno automático.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.4.0","url":"/preview-docs/es/changelog/v1-4-0#correcciones-de-errores","content":" Corregido un problema donde pre-hooks y nuevos volúmenes se agregaban durante deploys, impidiendo que se generaran.Los subdominios ahora se marcan correctamente como delegados si los dominios padre ya están delegados. ","version":null,"tagName":"h2"},{"title":"Versión 1.2.3","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-2-3","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.2.3","url":"/preview-docs/es/changelog/v1-2-3#nuevas-funcionalidades","content":" Desacoplamiento de Alias en Web Services: La creación de aliases ahora está separada del formulario de web services.Restablecimiento de Contraseña IAM: Ahora es posible restablecer la contraseña IAM para un usuario.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.2.3","url":"/preview-docs/es/changelog/v1-2-3#correcciones-de-errores","content":" Se ha corregido un problema menor con tareas de release. ","version":null,"tagName":"h2"},{"title":"Versión 1.4.1","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-4-1","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.4.1","url":"/preview-docs/es/changelog/v1-4-1#nuevas-funcionalidades","content":" Monitoreo de Dependencies y OpenSearch: Se creó una nueva página de monitoreo para dependencies, facilitando el seguimiento de su estado. OpenSearch fue incluido.Política de Ciclo de Vida de ECR: Se configuró una política de ciclo de vida para ECR, mejorando la gestión de imágenes.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.4.1","url":"/preview-docs/es/changelog/v1-4-1#correcciones-de-errores","content":" Corregido el problema de nombres duplicados entre cluster y nodo en Redis.Resueltos varios errores de frontend que afectaban la experiencia del usuario.Corregido el problema donde se mostraba un error al intentar publicar un vargroup sin un servicio asociado.Se corrigieron problemas al realizar múltiples deployments y releases consecutivos. ","version":null,"tagName":"h2"},{"title":"Versión 1.3.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-3-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.3.0","url":"/preview-docs/es/changelog/v1-3-0#nuevas-funcionalidades","content":" Vista de Detalles de Project: Una vista detallada de proyecto ahora está disponible en la nueva interfaz.API de Métricas RDS: Se ha agregado una nueva API para mostrar métricas RDS, mejorando la visibilidad de recursos.LogViewer Mejorado: La carga de LogViewer ahora es más rápida y eficiente.Onboarding Mejorado: Se ha implementado un nuevo proceso de onboarding para facilitar la configuración.Monitoreo de Redis: Se ha agregado monitoreo de Redis, mejorando la supervisión de infraestructura.Configuración de Réplica RDS: Se ha agregado la opción de configurar réplicas en la Dependency RDS para mayor flexibilidad.Estado de Eliminación de Dominio: La eliminación de dominio ahora crea un deploy con estado pending-approval, en lugar de un deploy automático.Mejoras en Workload de Job: El workload de Job ha sido mejorado, permitiendo reintentos automáticos en caso de fallo inicial.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.3.0","url":"/preview-docs/es/changelog/v1-3-0#correcciones-de-errores","content":" Se han resuelto problemas de integración con Bitbucket.Se han corregido problemas con valores indefinidos en Vargroups. ","version":null,"tagName":"h2"},{"title":"Versión 1.4.3","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-4-3","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.4.3","url":"/preview-docs/es/changelog/v1-4-3#nuevas-funcionalidades","content":" Mejoras en Gestión de Dashboard: Se mejoró la carga del dashboard, permitiendo que se visualice incluso si no hay cuenta seleccionada.Mejoras en Pantallas de Facturación y Project: Se realizaron mejoras en la pantalla de facturación, incluyendo una nueva sección &quot;otros&quot; para contabilizar costos previamente no considerados. La pantalla de environment de proyecto también fue mejorada.Actualizaciones de Políticas: La política de CloudFormation ha sido actualizada para mejorar gestión y seguridad.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.4.3","url":"/preview-docs/es/changelog/v1-4-3#correcciones-de-errores","content":" Corregido un error crítico que impedía la creación de providers.Revisado y resuelto un problema relacionado con la integración de NewRelic.Corregido un problema con el refresh token al solicitar el URI de VPN.Pantalla de Validación ACM y Errores de Logs de Builds: Correcciones realizadas en la tabla de validación ACM y visualización de logs para builds en estado de creación. ","version":null,"tagName":"h2"},{"title":"Versión 1.4.2","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-4-2","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.4.2","url":"/preview-docs/es/changelog/v1-4-2#nuevas-funcionalidades","content":" Nuevas Métricas: Agregadas nuevas métricas para buckets S3 y RabbitMQ, mejorando el monitoreo de servicios. También se implementó un sistema de monitoreo de métricas de OpenSearch.Reorganización de Esquema de Monitoreo: Las estructuras de esquema de monitoreo fueron reorganizadas para mejor gestión y visualización. La pantalla de monitoreo de Dependencies ahora soporta diferentes tipos de recursos, proporcionando una vista más detallada.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.4.2","url":"/preview-docs/es/changelog/v1-4-2#correcciones-de-errores","content":" Se ha resuelto un problema crítico con vargroups, asegurando su funcionamiento adecuado. ","version":null,"tagName":"h2"},{"title":"Versión 1.5.1","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-5-1","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.5.1","url":"/preview-docs/es/changelog/v1-5-1#nuevas-funcionalidades","content":" Configuración Avanzada de Recursos: Se han implementado opciones avanzadas para configuración de recursos en environments de proyecto.Optimización de Scripts de Recolección de Datos: Mejorada la eficiencia de scripts de recolección de datos para workload más rápido.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.5.1","url":"/preview-docs/es/changelog/v1-5-1#correcciones-de-errores","content":" Se han resuelto varios errores de interfaz que afectaban la usabilidad del sistema. ","version":null,"tagName":"h2"},{"title":"Versión 1.5.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-5-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.5.0","url":"/preview-docs/es/changelog/v1-5-0#nuevas-funcionalidades","content":" Creación de Múltiples Environments de Project: Ahora puedes crear múltiples environments de proyecto usando el mismo repositorio y rama.Validación de Dominio para Aliases: Mejorada la validación de creación de dominio para aliases usando un ACM existente utilizable para ingress.Configuración de Recursos en Project Env: Agregada la capacidad de configurar recursos de build y deploy por environment de proyecto.Configuración de Request de Deploy y Build: Agregada la opción de configurar requests de deploy y build en un ProjectEnv.Dashboard de Grafana: Se incorporó un dashboard de Grafana para visualizar consumo por namespace.Configuración de Loki: Los logs ahora pueden buscarse por namespace con la nueva configuración de Loki.Recolección de Datos: Mejorado el script de recolección de facturación para ser idempotente y ejecutable para fechas específicas.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.5.0","url":"/preview-docs/es/changelog/v1-5-0#correcciones-de-errores","content":" Corregido un error al crear dependencies S3 y resuelto un problema crítico con vargroups durante actualizaciones de apagado de cluster.Corregido un error crítico al invitar colaboradores. ","version":null,"tagName":"h2"},{"title":"Versión 1.6.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-6-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.6.0","url":"/preview-docs/es/changelog/v1-6-0#nuevas-funcionalidades","content":" Soporte para Instancias ARM y Versiones Adicionales de RDS: Agregadas instancias ARM y versiones extra en RDS.EKS Actualizado a Versión 1.29: EKS ha sido actualizado a la versión 1.29. Los changelogs de actualizaciones de EKS ahora se muestran.Mejoras en Creación y Edición de Provider: Pantallas y campos para formularios de provider fueron actualizados, incluyendo cambios en estados y visualización.Búsqueda de Repositorio Mejorada: Agregado soporte para búsqueda asíncrona en el selector de repositorio y mejorada la función de búsqueda para GitHub, GitLab y Bitbucket.Parametrización de Healthcheck: Las propiedades de healthcheck ahora pueden parametrizarse con JSONSchema.Nuevo Dashboard: Se ha agregado un nuevo dashboard para ver consumo por namespace.Corrección de un error al regenerar certificados, así como problemas con builds que no se ejecutaban correctamente.Errores de frontend relacionados con listados y problemas de API que causaban errores de filtrado han sido corregidos.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.6.0","url":"/preview-docs/es/changelog/v1-6-0#correcciones-de-errores","content":" Corregido un error al regenerar certificados, así como problemas con builds que no se ejecutaban correctamente.Errores de frontend relacionados con listados y problemas de API que causaban errores de filtrado han sido corregidos. ","version":null,"tagName":"h2"},{"title":"Versión 1.6.1","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-6-1","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.6.1","url":"/preview-docs/es/changelog/v1-6-1#nuevas-funcionalidades","content":" Actualizaciones de Versión de Dependencies: Actualizadas versiones de dependencies MQ, Elasticsearch, Memcache y Redis.Mejoras en Autenticación: Agregado soporte para almacenar tokens de autenticación vía cookies en lugar de almacenamiento local.Agregada impresión de registro de validación ACM en la pantalla de detalle de ACM, y el estado de ACM ahora está incluido en el sistema.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.6.1","url":"/preview-docs/es/changelog/v1-6-1#correcciones-de-errores","content":" Se han resuelto problemas con el flujo de provider. ","version":null,"tagName":"h2"},{"title":"Versión 1.6.2","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-6-2","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.6.2","url":"/preview-docs/es/changelog/v1-6-2#nuevas-funcionalidades","content":" Actualizaciones: Actualizado Prometheus, Loki, y EBS CSI Driver a las últimas versiones a partir de agosto de 2024.Migración de EBS CSI Driver: SleakOps ahora usa el Addon EKS gestionado por AWS para el EBS CSI Driver, reemplazando la versión auto-gestionada.Prometheus y Loki con EBS: Prometheus ahora utiliza volúmenes EBS para persistencia de datos, previniendo pérdida de datos incluso si los pods fallan.Loki con SimpleScalable: Adopta una estructura SimpleScalable con almacenamiento TSDB para logs, mejorando el rendimiento.Colas Dead-letter de SQS: Ahora soporta la creación de colas SQS con colas dead-letter asociadas para mejor manejo de errores.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.6.2","url":"/preview-docs/es/changelog/v1-6-2#correcciones-de-errores","content":" Varias correcciones menores de errores y mejoras en los flujos de workload de la plataforma. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.1","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-1","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.1","url":"/preview-docs/es/changelog/v1-7-1#nuevas-funcionalidades","content":" Creación de Environment y Dominio: Mejorado el proceso para crear environments y dominios. Ahora puedes usar un dominio diferente al configurado globalmente sin limitaciones.Notificaciones: Agregado un sistema de notificaciones para informar a los usuarios sobre acciones manuales pendientes y actualizaciones de infraestructura programadas.Documentación: Actualizada documentación sobre gestión de dominios, proyectos, dependencies y variables de entorno.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.1","url":"/preview-docs/es/changelog/v1-7-1#correcciones-de-errores","content":" Varias correcciones menores de errores. ","version":null,"tagName":"h2"},{"title":"Versión 1.6.3","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-6-3","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.6.3","url":"/preview-docs/es/changelog/v1-6-3#nuevas-funcionalidades","content":" Registro: Implementado un nuevo flujo de registro.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.6.3","url":"/preview-docs/es/changelog/v1-6-3#correcciones-de-errores","content":" Varias correcciones menores de errores y mejoras. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.0","url":"/preview-docs/es/changelog/v1-7-0#nuevas-funcionalidades","content":" Gestión Avanzada de Nodos: Introducida gestión de node pools para proporcionar mayor control sobre los tipos de nodos donde se ejecutan los workloads.Migración de Módulos de Cluster: Todos los módulos creados con el cluster ahora se ejecutan en instancias Graviton, mejorando el rendimiento y reduciendo costos.Add-ons de Cluster: Todos los add-ons ahora se ejecutan en instancias Graviton, mejorando aún más el rendimiento y reduciendo costos.Nodos de Build Aislados: Los builds ahora se ejecutan en nodos dedicados separados de los nodos de aplicación, mejorando la estabilidad de los nodos que ejecutan aplicaciones.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.0","url":"/preview-docs/es/changelog/v1-7-0#correcciones-de-errores","content":" Varias correcciones menores de errores. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.10","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-10","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.10","url":"/preview-docs/es/changelog/v1-7-10#nuevas-funcionalidades","content":" Control de Permisos Mejorado: Los proyectos ahora pueden tener permisos adicionales asociados, ya sean Políticas IAM de AWS o permisos personalizados.Detalles de Dependencies: Los detalles de configuración de cada dependency ahora se muestran dentro de su vista de detalle.Mejoras en Pantalla de Actualización de Cluster: El análisis de EKS Insights ahora se incluye directamente en SleakOps para agilizar las actualizaciones de cluster.Mejoras en Builds y Projects: Información adicional durante builds y flujos de trabajo de validación de proyectos mejorados.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.10","url":"/preview-docs/es/changelog/v1-7-10#correcciones-de-errores","content":" Entrada de Texto Mejorada: Resueltos problemas que afectaban las entradas de texto en formularios.Datos de Acceso a Cluster: Corrección de un bug al recuperar datos de conexión de cluster bajo una cuenta seleccionada diferente.Filtros de Lista de Dominios: Agregados filtros por cuenta a la lista de dominios.Mejoras en Lista de Nodepool: Refinados los visuales para la vista de lista de nodepool.Actualizaciones de Instalación de Add-ons: La lista de add-ons ahora se actualiza correctamente después de la instalación.Edición de Variable Groups: Corrección de un problema con la edición de grupos de variables.Adjunto de Suscripción: Solucionado un bug que impedía que nuevas suscripciones se adjuntaran correctamente.Pronóstico de Costos: Corrección de problemas de pronóstico para mejores estimaciones de costos. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.11","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-11","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.11","url":"/preview-docs/es/changelog/v1-7-11#nuevas-funcionalidades","content":" Kubernetes 1.31 &amp; Karpenter 1.3: SleakOps ahora provisiona clusters en EKS 1.31 y actualiza el autoscaler a Karpenter 1.3.Gestión de Secretos Más Fuerte: Todos los secretos ahora también se almacenan encriptados en AWS Systems Manager Parameter Store, agregando una capa adicional de durabilidad más allá de la copia en-cluster.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.11","url":"/preview-docs/es/changelog/v1-7-11#correcciones-de-errores","content":" Workers de Dev-Cluster: Eliminado el PodDisruptionBudget mejorando la confiabilidad de workers en clusters de desarrollo cuando el cluster tenía el scheduler de apagado habilitado.Builds: Los builds ya no se activan por cada edición menor de proyecto.Deployments: Cambiados los jobs de deployments fuera de Fargate; los logs de builds ahora se persisten para facilitar la resolución de problemas.Detalles de Web Service: Refinada la página de detalles del servicio para mejor visibilidad de endpoints, estado y métricas.Add-on de Kubecost: Mejoras de estabilidad. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.13","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-13","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.13","url":"/preview-docs/es/changelog/v1-7-13#nuevas-funcionalidades","content":" Monitoreo de Dependencies: Mejora en visualización y seguimiento de dependencies.Control de Servicios: Nuevo toggle para encender o apagar webservices y workers.Builds con o sin caché: Opción para ejecutar builds usando caché o desde cero.Importación de Bucket S3 con Versionado: Agregado soporte para importar Buckets S3 con versionado activo.Variable Groups: Interfaz mejorada para gestionar grupos de variables.Validación de Dockerfile: Nuevas validaciones para asegurar la confiabilidad de Dockerfiles.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.13","url":"/preview-docs/es/changelog/v1-7-13#correcciones-de-errores","content":" Logs de Jobs: Corrección de enlaces rotos de logs para Jobs.Nombres de Ramas: Agregado soporte para ramas con / en sus nombres.Pipelines de GitLab: Corrección de problemas que afectaban la ejecución de pipelines. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.12","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-12","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.12","url":"/preview-docs/es/changelog/v1-7-12#nuevas-funcionalidades","content":" Nuevo Flujo de Soporte: Introducido un chatbot de soporte y sistema de tickets para proporcionar mejor trazabilidad y tiempos de respuesta más rápidos.Gestión de Suscripciones y Planes: Herramientas mejoradas para gestionar suscripciones y planes de servicio.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.12","url":"/preview-docs/es/changelog/v1-7-12#correcciones-de-errores","content":" Mejoras en Formularios: Mejoras generales en usabilidad y validación de formularios.Consola de Project: Mejoras de UI/UX en la pantalla de consola de proyecto. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.14","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-14","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.14","url":"/preview-docs/es/changelog/v1-7-14#nuevas-funcionalidades","content":" Mejoras en Transiciones de Estado: Cambios de estado más fluidos para addons de cluster y formularios.Soporte con Imágenes: Los usuarios ahora pueden subir imágenes en el chat de soporte.Jobs desde Cronjobs o Jobs Existentes: Capacidad de lanzar un Job desde un cronjob o Job existente.Errores de Infraestructura: Mejora en el análisis y visualización de errores de infraestructura para facilitar la resolución de problemas.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.14","url":"/preview-docs/es/changelog/v1-7-14#correcciones-de-errores","content":" Volúmenes Duplicados: Corrección del problema al crear volúmenes con el mismo nombre.Usuarios Duplicados: Prevención de creación de usuarios con el mismo email.Dependencies Duplicadas: Bloqueo de creación de dependencies con nombres duplicados.Monitoreo de Dependencies: Corrección de problemas de rango de fechas en la pantalla de monitoreo de dependencies. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.15","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-15","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.15","url":"/preview-docs/es/changelog/v1-7-15#nuevas-funcionalidades","content":" Resiliencia de Nodegroup Spot: Los nodegroups Spot ahora previenen fallos cuando no hay instancias Spot disponibles.VariableGroups Basados en Archivos: Agregado soporte para crear variablegroups de tipo archivo.Agent Bot (beta): Bot agente experimental lanzado en beta.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.15","url":"/preview-docs/es/changelog/v1-7-15#correcciones-de-errores","content":" Configuración de dominio dependiente: Generar registros DNS cuando el dominio padre ya está creado.Estado de Cluster con apagado nocturno: Corrección de visualización incorrecta del estado para clusters con apagado nocturno habilitado.Filtros de VariableGroups: Filtrar por proyectos en la lista de variablegroups.Eliminar cluster: Corrección del flujo de eliminación de cluster.Estado de ticket de soporte: Corrección del estado de cierre de ticket de soporte. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.16","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-16","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.16","url":"/preview-docs/es/changelog/v1-7-16#nuevas-funcionalidades","content":" Projects con Repositorios Públicos: Ahora puedes crear y gestionar proyectos vinculados a repositorios públicos.Excluir Builds de Métricas: Los builds pueden excluirse del dashboard de métricas de Grafana para reportes más precisos.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.16","url":"/preview-docs/es/changelog/v1-7-16#correcciones-de-errores","content":" Deployments de Nuevos Projects: Corrección de problemas que impedían el despliegue exitoso de proyectos recién creados. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.3","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-3","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.3","url":"/preview-docs/es/changelog/v1-7-3#nuevas-funcionalidades","content":" Soporte para Oracle RDS (Beta): Ahora puedes gestionar instancias Oracle RDS como dependencies dentro de SleakOps.Soporte para Aurora PostgreSQL Serverless (Beta): Agregada la capacidad de crear y gestionar bases de datos Aurora PostgreSQL Serverless.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.3","url":"/preview-docs/es/changelog/v1-7-3#correcciones-de-errores","content":" Varias correcciones menores de errores. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.2","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-2","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.2","url":"/preview-docs/es/changelog/v1-7-2#nuevas-funcionalidades","content":" Eliminación de Bucket S3: Introducida la capacidad de eliminar buckets S3 que contienen una gran cantidad de archivos.VPN: Actualizado el módulo Pritunl a la última versión para mayor seguridad y rendimiento.Mejoras en Gestión de Suscripciones: Mejorada la gestión de suscripciones para una mejor experiencia de usuario.Registro de Usuarios: Habilitado el registro de nuevos usuarios en la plataforma.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.2","url":"/preview-docs/es/changelog/v1-7-2#correcciones-de-errores","content":" Varias correcciones menores de errores. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.4","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-4","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.4","url":"/preview-docs/es/changelog/v1-7-4#nuevas-funcionalidades","content":" Accesibilidad de Add-on: Agregados enlaces en SleakOps para fácil acceso a visualizar logs, APM o métricas para recursos específicos.OpenTelemetry (Beta): Introducido un add-on para mejorar la observabilidad en aplicaciones desplegadas con SleakOps. Con OpenTelemetry, puedes tener tu propio APM para monitorear métricas como tasa de solicitudes, latencia y tasa de errores de tu aplicación.Configuraciones de Disponibilidad de Add-on: Agregadas varias configuraciones de disponibilidad para cada add-on.Documentación: Actualizada la documentación de add-ons y disponible en español.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.4","url":"/preview-docs/es/changelog/v1-7-4#correcciones-de-errores","content":" Revisión de Integración Kubecost: Revisada la integración Prometheus-Kubecost. Kubecost ahora mapea correctamente los nombres de recursos desplegados a sus costos, mejorando enormemente la precisión de sus estimaciones. Ahora es posible habilitar análisis aproximado de costos de tráfico de red dentro del cluster en Kubecost (Beta). ","version":null,"tagName":"h2"},{"title":"Versión 1.7.5","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-5","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.5","url":"/preview-docs/es/changelog/v1-7-5#nuevas-funcionalidades","content":" Manejo de Errores de Integración AWS:: Implementado un mecanismo para manejar retrasos en activaciones de cuentas AWS creadas por SleakOps.Enlaces de Add-on en Builds: Agregados enlaces para visualizar fácilmente logs y métricas durante el proceso de build. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.6","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-6","content":"","keywords":"","version":null},{"title":"Versión 1.7.8","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-8","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.8","url":"/preview-docs/es/changelog/v1-7-8#nuevas-funcionalidades","content":" Kubernetes 1.30: Actualizado soporte de EKS a la versión 1.30.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.8","url":"/preview-docs/es/changelog/v1-7-8#correcciones-de-errores","content":" Mejoras Menores de UI: Mejorado el diseño visual para pantallas de proyecto y workload. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.7","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-7","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.7","url":"/preview-docs/es/changelog/v1-7-7#nuevas-funcionalidades","content":" Importación desde Buckets Externos: Copiar rápidamente archivos desde un Bucket S3 externo a SleakOps mediante la nueva función Import Bucket.Revisión de Vista de Project: Ver logs e información clave en una sola pantalla para mejor visibilidad.Executions Renombrados a Workloads: Terminología actualizada para alinearse con la notación interna de cluster.Optimización de Eliminación de Cluster: Agregada validación adicional para un proceso de eliminación más seguro y estable.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.7","url":"/preview-docs/es/changelog/v1-7-7#correcciones-de-errores","content":" Permisos de Project para Jobs: Corrección de un problema donde los Jobs usaban permisos de nodo de cluster en lugar de permisos de Project.Modificación de Docker Args: Los builds ahora aplican correctamente cualquier Docker Args cambiado justo antes de ejecutarse.Generación de Perfil VPN: Resuelto un problema que impedía que los perfiles de usuario de terceros se generaran exitosamente. ","version":null,"tagName":"h2"},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.6","url":"/preview-docs/es/changelog/v1-7-6#nuevas-funcionalidades","content":" Nuevas Configuraciones de Nodepool: Ahora puedes establecer parámetros adicionales, como tamaños mínimos de instancia y más.Job con Imágenes Específicas: Al crear un job, puedes especificar la imagen exacta y el tag que deseas ejecutar (ej: postgres:16.4).(BETA) Extensión de Chart por Project: SleakOps ahora puede extender los charts usados para desplegar workloads de proyecto, permitiéndote agregar dependencies. Para más información, consulta la documentación de Helm.Mejoras en CI/CD: El archivo para configurar CI/CD ha sido simplificado y optimizado.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.6","url":"/preview-docs/es/changelog/v1-7-6#correcciones-de-errores","content":" URL de Web Service Interna: Corrección de un problema que causaba URLs incorrectas para web services de tipo &quot;interno&quot;.Eliminación de Volumen: Resueltos problemas relacionados con la eliminación de volúmenes bajo varias políticas de retención.Mejoras de UX/UI: Mejoras en la interfaz para Projects, Volumes y Variable Groups. ","version":null,"tagName":"h2"},{"title":"Versión 1.7.9","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v1-7-9","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 1.7.9","url":"/preview-docs/es/changelog/v1-7-9#nuevas-funcionalidades","content":" Mejoras en Cronjobs: Configurar políticas de cronjob y filtrar fácilmente entre cronjobs activos e inactivos.Emails de Soporte en Notificaciones: Cuando SleakOps genera una notificación, los usuarios ahora la reciben por email.EKS Insights: Durante las actualizaciones de cluster, SleakOps verifica EKS Insights para asegurar que todo funcione correctamente.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 1.7.9","url":"/preview-docs/es/changelog/v1-7-9#correcciones-de-errores","content":" Mejoras en Flujo de Project: Mejorados varios ajustes, formularios y otros elementos para una gestión de proyectos más fluida.Flujo de Creación de Cuenta AWS: Ahora soporta cuentas AWS inactivas, proporcionando orientación clara sobre cómo activarlas manualmente antes de reanudar el proceso en SleakOps. ","version":null,"tagName":"h2"},{"title":"Versión 2.0.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v2-0-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 2.0.0","url":"/preview-docs/es/changelog/v2-0-0#nuevas-funcionalidades","content":" Rediseño Completo de Consola: UI modernizada para una experiencia más limpia e intuitiva.Soporte para Tema Claro: Soporte completo para modo claro.Bot de Soporte: Respuestas automatizadas para preguntas comunes de soporte.Documentación Integral: Guías ampliadas cubriendo todas las funcionalidades.Actualización de lambdas: Actualización de versiones de Python para lambdas.Project Chart: Promovido a estable.Project Access: Promovido a estable.Dependency Aurora MySQL: Promovido a estable.Dependency Oracle: Promovido a estable.Dependency MariaDB: Promovido a estable.Dependency Aurora PostgreSQL: Promovido a estable.Edición de Dependencies: Capacidad de editar dependencies existentes.Dockertron (beta): Dockerización automática impulsada por IA.Cancelación de Builds: Posibilidad de cancelar builds pendientes.Nueva Dependency MSK: Soporte para Kafka vía AWS MSK.Webservices Mejorados: Configurar anotaciones de ingress personalizadas y healthchecks opcionales.Nodepools Avanzados: Nuevas estrategias de fallback y mezcla de instancias (reservadas, spot, on-demand) para mejor control de costos y rendimiento.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 2.0.0","url":"/preview-docs/es/changelog/v2-0-0#correcciones-de-errores","content":" GitLab self-hosted: Corrección de validación de URL.Eliminación de Cluster: Mejoras en el manejo de eliminación en cascada. ","version":null,"tagName":"h2"},{"title":"Versión 2.1.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v2-1-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 2.1.0","url":"/preview-docs/es/changelog/v2-1-0#nuevas-funcionalidades","content":" Actualización de Cluster: Soporte para actualización de Cluster de 1.31 a 1.32.Tour de Dependencies: Nuevo tour guiado para la pantalla de Dependencies.Tour de Workloads: Nuevo tour guiado para la pantalla de Workloads.Tour de Variable Groups: Nuevo tour guiado para la pantalla de Variable Groups.Tour de Cluster: Nuevo tour guiado para la pantalla de Cluster.Tour de Projects: Nuevo tour guiado para la pantalla de Projects.Optimización de Actualización de Cluster: Optimización de tareas de actualización de Cluster.Carga de Pantallas: Mejoras en la carga de drawers y pantallas secundarias.Actualización Programada: Nuevo flujo para programar actualizaciones de Cluster.Onboarding: Nuevo flujo de onboarding para usuarios nuevos.Configuración de Nodepool: Soporte para más parámetros de configuración de Nodepool (tipos de instancia, fallbacks, etc.).Monitoreo de Actualización: Nuevo flujo de monitoreo de servicios durante la actualización de Cluster con reporte de errores.Logs de Builds: Mejoras en logs de builds con más contexto.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 2.1.0","url":"/preview-docs/es/changelog/v2-1-0#correcciones-de-errores","content":" Certificado SSL para S3: Corrección de errores de certificado SSL para S3 con CloudFront.Logs de Actividad: Corrección de nombres en algunos Logs de Actividad.Creación de Usuarios: Corrección de errores en el flujo de creación de usuarios.Tickets de Soporte: Corrección del estado de tickets de soporte.Build con CLI: Corrección de parámetros al construir usando el CLI.Apagado Nocturno: Corrección del estado de Cluster con apagado nocturno habilitado.Resoluciones de Pantalla: Ajustes para algunas resoluciones en la pantalla principal de la consola.Eliminar Web Services: Corrección de errores al eliminar un Web Service desde la tabla. ","version":null,"tagName":"h2"},{"title":"Versión 2.2.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v2-2-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 2.2.0","url":"/preview-docs/es/changelog/v2-2-0#nuevas-funcionalidades","content":" Visor de Código: Nuevo componente para visualizar código dentro de la consola.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 2.2.0","url":"/preview-docs/es/changelog/v2-2-0#correcciones-de-errores","content":" Usuarios Eliminados: Corrección de errores con usuarios eliminados.Actualización de Ramas: Corrección del flujo para actualizar ramas en Project.Información Incompleta: Corrección del flujo cuando la información del Project está incompleta.Políticas Extra: Corrección del flujo para configurar políticas extra en Project. ","version":null,"tagName":"h2"},{"title":"Versión 2.0.1","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v2-0-1","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 2.0.1","url":"/preview-docs/es/changelog/v2-0-1#nuevas-funcionalidades","content":" Tabla de Builds y Deploys: Mejoras en los datos mostrados en la tabla de builds y deploys.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 2.0.1","url":"/preview-docs/es/changelog/v2-0-1#correcciones-de-errores","content":" Cron de Apagado Nocturno: Corrección de visualización del cron de apagado nocturno.Estado de Cluster: Corrección de actualización del estado de Cluster durante la actualización.Notificaciones Largas: Corrección de visualización de notificaciones largas.VPN de Terceros: Corrección de acceso VPN para terceros.Cancelación de Deploy: Corrección del flujo de cancelación de deploy.Creación de Provider: Corrección de jerarquías de texto en el flujo de creación de Provider.Información Faltante: Corrección de redirección en el flujo de información faltante para Project.Usuario Viewer: Corrección de navegación para usuarios viewer.Toggles de Modo Claro: Mejora de visibilidad de toggles en modo claro.Contraseña de Dependency MQ: Corrección de auto-generación de contraseña para Dependency MQ.Carga de Iconos: Mejoras en la carga de iconos.Pantallas de Transición: Corrección de pantallas de transición durante la carga de datos.Tablas de Consola de Project: Mejora de visualización de tablas en la pantalla &quot;Consola de Project&quot;.Errores de Infraestructura: Corrección de mensajes de error cuando falla la ejecución de módulos de infraestructura.Selector de Cuenta Móvil: Soporte para selector de cuenta en dispositivos móviles. ","version":null,"tagName":"h2"},{"title":"Versión 2.3.1","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v2-3-1","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 2.3.1","url":"/preview-docs/es/changelog/v2-3-1#nuevas-funcionalidades","content":" Análisis de Imágenes en Soporte: Soporte para análisis de imágenes en el bot de soporte.Documentación: Nueva documentación para Dockertron y gestión de charts.Valores Personalizados en Addons: Capacidad de usar valores personalizados al instalar un addon.Cambio de Nodegroup: Capacidad de cambiar el nodegroup de clusters no productivos.Flujo de Soporte: Flujo de conversación para soporte entre bot y humano.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 2.3.1","url":"/preview-docs/es/changelog/v2-3-1#correcciones-de-errores","content":" Modales de Confirmación: Corrección de posición de modales de confirmación de eliminación.Tabla de Builds: Corrección de errores de datos y columnas en la tabla de builds.Notificaciones del Dashboard: Corrección de mensajes de notificación en el dashboard.Nombres de Workloads: Ajuste de tamaños de nombres para Workloads.Dependencia de Chart: Corrección del flujo de dependencia de charts.Alertas de Consola: Corrección de alertas de notificación en la consola. ","version":null,"tagName":"h2"},{"title":"Versión 2.3.0","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v2-3-0","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 2.3.0","url":"/preview-docs/es/changelog/v2-3-0#nuevas-funcionalidades","content":" Clonación de Environments: Nueva función para clonar Environments.Clonación de Projects: Nueva función para clonar Projects.Clonación de Dependencies: Nueva función para clonar Dependencies.Clonación de Workloads: Nueva función para clonar Workloads.Clonación de Variable Groups: Nueva función para clonar Variable Groups.Filtros de Monitoreo de Cluster: Agregados filtros para navegar eventos de Cluster en Cluster Monitoring.Búsqueda de Variable Groups: Capacidad de buscar Variable Groups por nombres de claves internas desde la búsqueda general.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 2.3.0","url":"/preview-docs/es/changelog/v2-3-0#correcciones-de-errores","content":" Cuenta Seleccionada: La cuenta seleccionada ahora persiste al cambiar de usuario.Apagado de Web Services: Mejoras en el apagado de Web Services. ","version":null,"tagName":"h2"},{"title":"Versión 2.3.2","type":0,"sectionRef":"#","url":"/preview-docs/es/changelog/v2-3-2","content":"","keywords":"","version":null},{"title":"Nuevas Funcionalidades​","type":1,"pageTitle":"Versión 2.3.2","url":"/preview-docs/es/changelog/v2-3-2#nuevas-funcionalidades","content":" CLI de SleakOps: Mejoras y nuevas funcionalidades, incluyendo la posibilidad de abrir una shell de Workload de forma local.S3 con CloudFront: Mejoras en la integración de S3 con CloudFront.Python en Lambdas: Actualización de versiones de Python para Lambdas.Charts en Projects: Mejoras en la pantalla de configuración de charts en Projects.Tags de Subnet: Mejoras en el manejo de tags de subnet para autodiscovery.Restauración de DB: Mejoras en el flujo de restauración de base de datos desde un snapshot.Ingress en Web Services: Soporte para configurar URL y anotaciones de ingress en Web Services.Performance de APIs: Optimización del rendimiento de las APIs.Errores de Dominios: Mejoras en el manejo de errores de dominios.Botones de Addons: Mejoras visuales en los botones de addons.Notificaciones: Mejoras visuales al mostrar notificaciones.Opciones de Botones: Mejoras visuales en las opciones de botones (configuración, copiar, etc.).Versiones de RDS: Actualización de versiones disponibles de RDS.Módulos de Infraestructura: Optimización de tiempos de ejecución para módulos de infraestructura.  ","version":null,"tagName":"h2"},{"title":"Correcciones de Errores​","type":1,"pageTitle":"Versión 2.3.2","url":"/preview-docs/es/changelog/v2-3-2#correcciones-de-errores","content":" Eliminación de Roles: Manejo de la eliminación de roles al eliminar un Project.Facturación Multi-Proveedor: Corrección en la pantalla de facturación con múltiples proveedores.Registro y Login: Manejo del flujo de registro y login con diferentes estados de suscripciones.Formulario de Nodepool: Manejo de errores en el formulario de Nodepool.Cambio de Cuentas: Manejo de errores al cambiar entre cuentas.Caracteres en Variables: Manejo de caracteres inválidos en nombres de variables en Variable Groups.Acceso a Cluster: Manejo del acceso a Cluster para diferentes tipos de usuarios.Acceso a VPN: Manejo de errores al obtener acceso a VPN para diferentes tipos de usuarios.Textos en Listados: Corrección de textos en listados y formularios.Conexión con AWS: Corrección de textos en la guía paso a paso para conectarse con AWS.Deployments Pendientes: Indicador de alerta para deployments pendientes de aprobación.Actualización de Postgres: Manejo de errores en la actualización de PostgreSQL de 14 a 17.Security Group de RDS: Corrección del security group para réplicas públicas y privadas de RDS.Chat de Soporte: Corrección en la delegación en el chat de soporte. ","version":null,"tagName":"h2"},{"title":"¡Bienvenido a SleakOps!","type":0,"sectionRef":"#","url":"/preview-docs/es/docs","content":"","keywords":"","version":"Next"},{"title":"Principios Fundamentales​","type":1,"pageTitle":"¡Bienvenido a SleakOps!","url":"/preview-docs/es/docs#principios-fundamentales","content":" Respetar las bases Well-Architected de AWS.Mantener siempre el control de los costos.Tú tienes el control completo: es tu repositorio y tu nube.  ","version":"Next","tagName":"h2"},{"title":"Funcionalidades Principales​","type":1,"pageTitle":"¡Bienvenido a SleakOps!","url":"/preview-docs/es/docs#funcionalidades-principales","content":" Integración con GitHub, Bitbucket y GitLab.Basado en tu repositorio y Dockerfiles.Gestiona múltiples entornos utilizando nuestra estructura propuesta (desarrollo, pruebas y producción) o personaliza la tuya.Configura tu pipeline de CI/CD.Stack completo de observabilidad para logging, monitoreo y rastreo.Gestión de secretos y variables de entorno.Conexiones seguras mediante TLS.Configuración automatizada de tus servicios detrás de un balanceador de carga e ingreso seguro.Agrega complementos a tu clúster fácilmente.Gran cantidad de dependencias listas para usar (RDS, S3, Redis, SQL, Rabbit, etc.).Gestión de acceso de usuarios a servicios.VPN automatizadas.  Proveedores Cuenta de proveedor de nube. Comienza aquí Clusters Un conjunto de máquinas de trabajo, llamadas nodos, que ejecutan aplicaciones en contenedores. Comienza aquí Entornos Una abstracción que nos permite aislar los diferentes recursos. Comienza aquí Proyectos Representa una base de código y es gestionado por un repositorio git. Comienza aquí Dependencias Infraestructura subyacente que tus aplicaciones necesitan para funcionar en la nube, como bases de datos, servicios de almacenamiento o caches. Comienza aquí Servicios Una manera abstracta de exponer una aplicación en ejecución en un conjunto de Pods como un servicio de red. Comienza aquí Despliegues ... Comienza aquí Build Representa un estado desplegable de todos los servicios. Comienza aquí Grupo de Variables Un diccionario que proporciona configuración para los servicios. Comienza aquí ","version":"Next","tagName":"h2"},{"title":"Hay que hacer un nuevo test","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/a-new-test-must-be-done","content":"Hay que hacer un nuevo test Nuevo test debe ser hecho perro","keywords":"","version":"Next"},{"title":"Conceptos Básicos","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/basicconcepts","content":"","keywords":"","version":"Next"},{"title":"Proveedor​","type":1,"pageTitle":"Conceptos Básicos","url":"/preview-docs/es/docs/basicconcepts#proveedor","content":" El primer paso para iniciar una infraestructura es decidir qué proveedor de nube utilizar (AWS, Azure o GCP, etc.). En SleakOps, un Proveedor representa la selección de uno de estos proveedores de nube, las credenciales otorgadas a SleakOps para su uso, y el conjunto de cuentas creadas para gestionar la infraestructura adecuadamente. Está compuesto por una Unidad Organizativa en AWS y sus cuentas asociadas.  ","version":"Next","tagName":"h3"},{"title":"Clúster​","type":1,"pageTitle":"Conceptos Básicos","url":"/preview-docs/es/docs/basicconcepts#clúster","content":" Un clúster de Kubernetes es un sistema distribuido para gestionar aplicaciones en contenedores. Consiste en nodos (máquinas físicas o virtuales) que ejecutan pods (grupos de uno o más contenedores). Un plano de control central, compuesto por varios componentes de software, coordina la actividad de los nodos y gestiona el ciclo de vida de los pods.  ","version":"Next","tagName":"h3"},{"title":"Entorno​","type":1,"pageTitle":"Conceptos Básicos","url":"/preview-docs/es/docs/basicconcepts#entorno","content":" En informática, un entorno o namespace se refiere típicamente a un área aislada donde operan de forma independiente recursos, aplicaciones o servicios específicos. Esta separación mejora la organización, la seguridad y la gestión de recursos dentro de sistemas o plataformas de mayor tamaño.  ","version":"Next","tagName":"h3"},{"title":"Proyecto​","type":1,"pageTitle":"Conceptos Básicos","url":"/preview-docs/es/docs/basicconcepts#proyecto","content":" Un proyecto es una colección de archivos y código gestionados con Git, que representa una base de código dentro de un repositorio git.  ","version":"Next","tagName":"h3"},{"title":"Servicio​","type":1,"pageTitle":"Conceptos Básicos","url":"/preview-docs/es/docs/basicconcepts#servicio","content":" Un servicio es una unidad funcional fundamental que puede implementarse y gestionarse de forma independiente dentro de un entorno. Los servicios realizan tareas o procesos específicos e interactúan con otros servicios mediante interfaces definidas. Son escalables y modulares, formando los componentes básicos de arquitecturas como microservicios y arquitecturas orientadas a servicios (SOA), permitiendo un desarrollo de sistemas flexible y eficiente.  ","version":"Next","tagName":"h3"},{"title":"Dependencia​","type":1,"pageTitle":"Conceptos Básicos","url":"/preview-docs/es/docs/basicconcepts#dependencia","content":" Una dependencia es un recurso o servicio externo que una aplicación necesita para funcionar correctamente en un entorno de nube. Estas dependencias incluyen diversos componentes de infraestructura, como bases de datos relacionales, servicios de almacenamiento y caches. Cada dependencia se asocia con servicios específicos del proveedor, asegurando una integración y operación fluida dentro de la plataforma en la nube.  ","version":"Next","tagName":"h3"},{"title":"Grupo de Variables​","type":1,"pageTitle":"Conceptos Básicos","url":"/preview-docs/es/docs/basicconcepts#grupo-de-variables","content":" En SleakOps, un grupo de variables (o var group) es un conjunto de pares clave-valor, similar a un diccionario, que proporciona configuraciones para los servicios dentro de un proyecto y entorno específico.  ","version":"Next","tagName":"h3"},{"title":"Build​","type":1,"pageTitle":"Conceptos Básicos","url":"/preview-docs/es/docs/basicconcepts#build","content":" Un build es el proceso de crear una nueva versión del código de tu aplicación como una imagen de contenedor a partir de un Dockerfile, incorporando el código compilado y las dependencias necesarias.  ","version":"Next","tagName":"h3"},{"title":"Despliegue​","type":1,"pageTitle":"Conceptos Básicos","url":"/preview-docs/es/docs/basicconcepts#despliegue","content":" En tecnología, desplegar significa lanzar una aplicación de software, servicio o actualización en un entorno de producción, haciéndolo disponible para su uso por los usuarios finales. ","version":"Next","tagName":"h3"},{"title":"teeeest EES","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster","content":"teeeest EES asdasdasdasd","keywords":"","version":"Next"},{"title":"Accede a tu Clúster","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/access-cluster","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Accede a tu Clúster","url":"/preview-docs/es/docs/cluster/access-cluster#preguntas-frecuentes","content":" ¿Qué es Kubeconfig?​ Kubeconfig es un archivo de configuración utilizado por la herramienta de línea de comandos de Kubernetes kubectl para interactuar con los clústeres de Kubernetes. Contiene información sobre los clústeres, usuarios, contextos y namespaces que kubectl utiliza para comunicarse con uno o más clústeres de Kubernetes.  ¿Qué es un IDE?​ Un IDE para Kubernetes es un entorno de software que proporciona herramientas y funciones específicamente diseñadas para ayudar a los desarrolladores a crear, gestionar y desplegar aplicaciones en clústeres de Kubernetes. Integra comandos de Kubernetes, gestión de recursos y edición de YAML/Helm Charts en el flujo de trabajo de desarrollo. Lens es un IDE de código abierto para Kubernetes que ofrece una interfaz gráfica de usuario fácil de usar para gestionar, monitorear y solucionar problemas en múltiples clústeres en tiempo real.  ","version":"Next","tagName":"h2"},{"title":"1. Ve a la configuración de Acceso al Clúster​","type":1,"pageTitle":"Accede a tu Clúster","url":"/preview-docs/es/docs/cluster/access-cluster#1-ve-a-la-configuración-de-acceso-al-clúster","content":" Haz clic en Clusters, selecciona uno y accede a su configuración.  Dirígete a la opción Access Cluster.    ","version":"Next","tagName":"h3"},{"title":"2. Instala las siguientes Dependencias​","type":1,"pageTitle":"Accede a tu Clúster","url":"/preview-docs/es/docs/cluster/access-cluster#2-instala-las-siguientes-dependencias","content":" AWS CLI: Documentación de AWSKubectl: Documentación de KubernetesLens: Documentación de K8SLensCliente VPN de Pritunl: Página de Pritunl  ","version":"Next","tagName":"h3"},{"title":"3. Configura una VPN​","type":1,"pageTitle":"Accede a tu Clúster","url":"/preview-docs/es/docs/cluster/access-cluster#3-configura-una-vpn","content":" Abre el Cliente VPN de Pritunl.Genera una URI de VPN, cópiala y configúrala en el cliente.    ","version":"Next","tagName":"h3"},{"title":"4. Genera tus Claves de AWS y crea el archivo kubeconfig​","type":1,"pageTitle":"Accede a tu Clúster","url":"/preview-docs/es/docs/cluster/access-cluster#4-genera-tus-claves-de-aws-y-crea-el-archivo-kubeconfig","content":" Inicia sesión en AWS con tu usuario.Luego, dirígete al Asistente de Claves de Acceso de AWS para generar las claves en AWS.Pega las claves en el formulario y genera el archivo kubeconfig.Copia el resultado.    ","version":"Next","tagName":"h3"},{"title":"5. Agrégalo a Lens​","type":1,"pageTitle":"Accede a tu Clúster","url":"/preview-docs/es/docs/cluster/access-cluster#5-agrégalo-a-lens","content":" Abre Lens, localiza la opción 'Import Kubeconfig' e importa el archivo YAML obtenido de la sección Access Cluster.   ","version":"Next","tagName":"h3"},{"title":"Addons","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/addons","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Addons","url":"/preview-docs/es/docs/cluster/addons#preguntas-frecuentes","content":" ¿Cuáles son los Add-ons esenciales?​ Por defecto, SleakOps incluye en tu infraestructura: Metric Server: SleakOps instala el Metric Server para recopilar métricas del clúster y a nivel de nodos, permitiendo el monitoreo del rendimiento y decisiones informadas sobre escalado.External-DNS: SleakOps despliega External-DNS para la gestión automática de registros DNS, asegurando conectividad sin problemas con nombres de dominio amigables.Load Balancer Automático: SleakOps aprovisiona balanceadores de carga automáticamente, distribuyendo el tráfico de manera eficiente y manteniendo alta disponibilidad.Despliegue de Karpenter: SleakOps implementa Karpenter para el aprovisionamiento inteligente de nodos, escalando tu clúster según las necesidades reales de recursos para optimizar el rendimiento.  ¿Qué Add-ons opcionales están disponibles?​ Grafana: Visualiza y analiza datos con los tableros de Grafana, facilitando el monitoreo del rendimiento del sistema y la resolución de problemas. Ideal para rastrear el uso de memoria y CPU de las aplicaciones.LOKI: Usa Loki para la agregación de logs rentable. Simplifica la gestión de logs etiquetando flujos de logs sin indexar el contenido, ideal para navegar y monitorear logs de aplicaciones.Kubecost: Obtén información en tiempo real sobre los costos de la nube en Kubernetes con Kubecost. Este Add-on te ayuda a monitorear y reducir gastos en los proyectos de tu clúster.Prometheus: SleakOps implementa Prometheus para monitoreo y alertas, proporcionando información detallada sobre el rendimiento del clúster y la utilización de recursos.OTEL: Usa OpenTelemetry para recolectar y analizar trazas distribuidas, permitiéndote monitorear y optimizar el rendimiento de aplicaciones en tu clúster.EFS Controller: El EFS Controller permite gestionar volúmenes de EFS dentro de tu clúster EKS, proporcionando almacenamiento escalable y compartido para tus aplicaciones. Para más detalles, consulta la documentación de EFS.EBS Controller: El EBS Controller permite gestionar volúmenes de EBS dentro de tu clúster EKS, proporcionando almacenamiento de bloques persistente para tus aplicaciones. Para más detalles, consulta la documentación de EBS.  ¿Cómo configuro un Add-on?​ Para configurar un Add-on, sigue estos pasos: Ve a la sección Add-ons en la sección Cluster.Selecciona el Add-on deseado de la lista de opciones disponibles.Configura los ajustes del Add-on según sea necesario.Haz clic en &quot;Deploy&quot; para instalar el Add-on en tu clúster EKS. Para instrucciones más detalladas, consulta la guía de configuración de Add-ons. ","version":"Next","tagName":"h2"},{"title":"CLI","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cli","content":"","keywords":"","version":"Next"},{"title":"Optimiza tu CI/CD con la CLI de SleakOps​","type":1,"pageTitle":"CLI","url":"/preview-docs/es/docs/cli#optimiza-tu-cicd-con-la-cli-de-sleakops","content":" La CLI de SleakOps es un paquete de Python diseñado para simplificar tus flujos de trabajo de CI/CD. Con solo dos subcomandos sencillos, puedes crear compilaciones y desplegar tus aplicaciones con facilidad, garantizando un proceso de desarrollo fluido y eficiente. Para comenzar, simplemente instala SleakOps usando pip:  pip install sleakops   ","version":"Next","tagName":"h2"},{"title":"1. Autenticación​","type":1,"pageTitle":"CLI","url":"/preview-docs/es/docs/cli#1-autenticación","content":" Para autenticarte con el SleakOps CLI, necesitas una API_KEY. Puedes obtener esta clave desde la consola haciendo clic en Generar API-Key. Cada empresa puede tener solo una API_KEY activa a la vez. Si solicitas una nueva API_KEY, la antigua será revocada automáticamente. En la página se muestran las claves de la empresa y quién las generó.  Una vez que tengas tu API_KEY, puedes usarla como argumento al ejecutar comandos de SleakOps o configurarla como una variable de entorno llamada SLEAKOPS_KEY.  Configurando SLEAKOPS_KEY en Pipelines de CI/CD Para pipelines de CI/CD, se recomienda configurar SLEAKOPS_KEY como una variable de entorno secreta en tu proveedor de Git: GitHub: Agrégala como un secreto de repositorio en Settings → Secrets and variables → ActionsGitLab: Agrégala como una variable de CI/CD en Settings → CI/CD → VariablesBitbucket: Agrégala como una variable de repositorio en Repository settings → Pipelines → Repository variables Esto asegura el acceso seguro a los servicios de SleakOps sin exponer tu clave API en los archivos de configuración de tu pipeline.  ","version":"Next","tagName":"h3"},{"title":"2. Crear un Build​","type":1,"pageTitle":"CLI","url":"/preview-docs/es/docs/cli#2-crear-un-build","content":" Para crear una compilación de tu aplicación, usa el siguiente comando:  sleakops build [options]   Este comando inicia el proceso de compilación, y SleakOps se encarga de compilar tu código, ejecutar pruebas y empaquetar la aplicación para su despliegue. Puedes especificar opciones adicionales para adaptar el proceso de compilación a tus necesidades específicas.  Hay dos argumentos obligatorios: project y branch, que se utilizan para saber qué compilar. Además, puedes añadir un commit para compilar un commit anterior, una tag para la imagen y el proveedor si necesitas especificarlo.  Como se mencionó anteriormente, la clave puede ser un entrada aquí o una variable de entorno.  También puedes indicar si quieres que el proceso espere a que la compilación termine o no.  DockerArgs desde CLI También puedes definir DockerArgs cuando uses la CLI de SleakOps para builds. Usa el parámetro --docker-args para pasar argumentos de construcción directamente desde la línea de comandos: sleakops build -p myproject -b main --docker-args &quot;ARG1=value1,ARG2=value2&quot; Esto es particularmente útil para pipelines de CI/CD donde quieres pasar diferentes argumentos basados en el entorno o contexto de construcción.  ","version":"Next","tagName":"h3"},{"title":"3. Realizar un Despliegue​","type":1,"pageTitle":"CLI","url":"/preview-docs/es/docs/cli#3-realizar-un-despliegue","content":" Una vez que tu compilación esté lista, puedes desplegar tu aplicación fácilmente usando el siguiente comando:  sleakops deploy [options]   SleakOps gestiona de manera transparente el proceso de despliegue, asegurando que tu aplicación esté en funcionamiento en poco tiempo. Puedes especificar opciones de despliegue para ajustar el proceso según tus requisitos.  Aquí, project y environment son los argumentos obligatorios. El usuario puede añadir una build o tag de imagen para especificar una imagen. Aquí también están presentes las opciones de wait y key, su uso es el mismo que en el comando de compilación.  ","version":"Next","tagName":"h3"},{"title":"Ejemplos de CI/CD​","type":1,"pageTitle":"CLI","url":"/preview-docs/es/docs/cli#ejemplos-de-cicd","content":" Con la CLI de SleakOps, puedes integrar tus tuberías de CI/CD, automatizar el proceso de compilación y despliegue, y concentrarte en entregar aplicaciones excepcionales sin la molestia de intervención manual. Disfruta de una experiencia de desarrollo fluida con SleakOps y crea flujos de trabajo de CI/CD personalizados.  GitHubGitLabBitBucket name: Deploy on: push: branches: - main jobs: build: runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 - name: Install SleakOps CLI run: pip install sleakops - name: Run SleakOps build env: SLEAKOPS_KEY: ${{ secrets.SLEAKOPS_KEY }} run: sleakops build -p core -b main -w deploy: needs: [build] runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 - name: Install SleakOps CLI run: pip install sleakops - name: Run SleakOps deploy env: SLEAKOPS_KEY: ${{ secrets.SLEAKOPS_KEY }} run: sleakops deploy -p core -e main -w  ","version":"Next","tagName":"h2"},{"title":"EBS (Elastic Block Store)","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/addons/ebs","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"EBS (Elastic Block Store)","url":"/preview-docs/es/docs/cluster/addons/ebs#preguntas-frecuentes","content":" ¿Qué es AWS EBS?​ AWS EBS es un servicio de almacenamiento en bloque de AWS diseñado para proporcionar almacenamiento persistente para instancias EC2. Los volúmenes EBS se replican automáticamente dentro de su Zona de Disponibilidad, ofreciendo alta disponibilidad y durabilidad, y protegiendo contra fallos de hardware.  ¿Cómo se utiliza EBS en SleakOps?​ En SleakOps, EBS se utiliza para proporcionar almacenamiento persistente a aplicaciones que se ejecutan en instancias EC2. Cada volumen EBS puede estar conectado a una sola instancia EC2 a la vez, aunque se pueden conectar múltiples volúmenes a una sola instancia. Dentro de Kubernetes, EBS se utiliza para volúmenes persistentes, garantizando la consistencia de los datos a través de reinicios de pods y reprogramaciones. SleakOps gestiona y configura EBS automáticamente para adaptarse a las necesidades de tus aplicaciones.  ¿Cuáles son los beneficios de usar EBS?​ EBS ofrece varios beneficios clave para aplicaciones de alto rendimiento: Alto rendimiento: EBS proporciona un rendimiento consistente y de baja latencia, ideal para aplicaciones que requieren acceso rápido a los datos.Durabilidad: Los volúmenes EBS se replican dentro de su Zona de Disponibilidad para garantizar alta durabilidad.Escalabilidad: Los volúmenes pueden redimensionarse fácilmente para satisfacer las crecientes demandas de las aplicaciones.  ¿Cómo configuro volúmenes con EBS en SleakOps?​ Para configurar y gestionar volúmenes utilizando EBS dentro de SleakOps, consulta la documentación de volúmenes. Esta guía proporciona instrucciones sobre cómo crear y gestionar volúmenes EBS para satisfacer los requisitos de almacenamiento de tus aplicaciones.  ¿Cómo utilizo volúmenes EBS en mis propios charts?​ Para usar volúmenes EBS, debes pasar al archivo de valores del chart el nombre de la 'StorageClass' como 'default-sc'. Puedes verificar tus StorageClasses actuales con: kubectl get storageclass --all-namespaces   ¿Cuándo debo usar EBS?​ Debes usar EBS cuando necesites un volumen que solo se monte en un pod, por ejemplo, una base de datos que se ejecute en el clúster sin réplicas. ","version":"Next","tagName":"h2"},{"title":"EFS (Elastic File System)","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/addons/efs","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"EFS (Elastic File System)","url":"/preview-docs/es/docs/cluster/addons/efs#preguntas-frecuentes","content":" ¿Qué es AWS EFS?​ AWS EFS es un servicio de almacenamiento en la nube de AWS que proporciona almacenamiento compartido y escalable para aplicaciones y servicios. Es ideal para cargas de trabajo que requieren acceso concurrente a un sistema de archivos común entre diferentes servicios.  ¿Cómo se utiliza EFS en SleakOps?​ En SleakOps, EFS se utiliza para los volúmenes de los Proyectos. Cada Proyecto puede tener uno o más volúmenes, que se implementan como sistemas de archivos EFS dentro del clúster EKS, proporcionando almacenamiento compartido al que pueden acceder diferentes servicios y pods.  ¿Cuáles son los beneficios de usar EFS?​ EFS ofrece varias ventajas, convirtiéndolo en una opción poderosa para almacenamiento compartido en aplicaciones distribuidas: Escalabilidad: Escala automáticamente a medida que se agregan o eliminan archivos.Alta disponibilidad: Diseñado para ser altamente disponible y duradero, con datos replicados en múltiples zonas de disponibilidad.Acceso concurrente: Varias instancias EC2 pueden montar el mismo sistema de archivos EFS simultáneamente, soportando cargas de trabajo que requieren acceso concurrente.  ¿Qué es la política de retención de EFS en SleakOps?​ SleakOps aplica una política de retención para los volúmenes EFS, lo que evita que se elimine un volumen EFS en AWS cuando se elimina un volumen de SleakOps. Esto garantiza la persistencia de los datos incluso si el volumen se desvincula del clúster.  ¿Cómo configuro volúmenes con EFS en SleakOps?​ Para configurar y gestionar volúmenes con EFS dentro de SleakOps, sigue las instrucciones en la documentación de volúmenes. Esta guía cubre la creación y gestión de volúmenes para tus Proyectos y la configuración de ajustes de EFS dentro de tu clúster.  ¿Cómo utilizo volúmenes EFS en mis propios charts?​ Para usar volúmenes EFS, debes pasar al archivo de valores del chart el nombre de la 'StorageClass' como 'efs-sc-delete' o 'efs-sc-retain', dependiendo de la política de retención que necesites. Puedes verificar tus StorageClasses actuales con: kubectl get storageclass --all-namespaces   ¿Cuándo debo usar EFS?​ Debes usar EFS cuando necesites un volumen que sea montado en más de un pod, por ejemplo, una aplicación ejecutándose en el clúster con dos réplicas o más. ","version":"Next","tagName":"h2"},{"title":"Grafana","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/addons/grafana","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Grafana","url":"/preview-docs/es/docs/cluster/addons/grafana#preguntas-frecuentes","content":" Acceso a Grafana​ Para acceder a Grafana, primero necesitas estar conectado a la VPN, luego simplemente haz clic en el botón de Grafana en la consola de SleakOps. tip Cuando creas el complemento de Grafana, SleakOps te proporciona el usuario y la contraseña necesarios. Serás redirigido a la página de inicio de sesión de Grafana. Una vez que inicies sesión, la interfaz de Grafana te presentará un panel como este:  ¿Cómo funciona?​ Grafana, como herramienta de monitoreo, te permite conectar directamente a las fuentes de datos dentro de tu clúster sin necesidad de una configuración extensa. Al instalar Grafana, SleakOps configura automáticamente la fuente de datos de Prometheus, brindando acceso rápido a métricas esenciales a través de una interfaz centralizada. Cuando se instalan Loki u OTEL, estas fuentes de datos también se conectan automáticamente.  Paneles Preconfigurados​ Grafana en SleakOps incluye una serie de paneles prácticos. Estos cubren métricas generales del sistema, ofreciendo vistas organizadas para monitorear diversos aspectos del rendimiento de aplicaciones y el uso de recursos. Los paneles están listos para usar y proporcionan visualizaciones de datos consistentes que simplifican el monitoreo y la gestión continua del sistema. SleakOps incluye los siguientes paneles para monitorear asignaciones de recursos: Kubernetes / Compute Resources / ClusterKubernetes / Compute Resources / Namespaces (Pods)Kubernetes / Compute Resources / Namespaces (Workloads)Kubernetes / Compute Resources / Nodes (Pods) Y estos para monitoreo de redes: Kubernetes / Networking / ClusterKubernetes / Networking / Namespaces (Pods)Kubernetes / Networking / Namespaces (Workloads) Además, incluye otros paneles como CoreDNS, que monitorean el sistema interno de DNS y descubrimiento de servicios. Todos estos paneles son útiles para monitorear la salud de tu clúster y las aplicaciones que se ejecutan en él, especialmente para redimensionar Wrokloads, investigar si se necesitan más réplicas o si los recursos están bien asignados. Los paneles son personalizables, permitiéndote ajustar el diseño y los datos mostrados según tus necesidades específicas de monitoreo. También puedes crear tus propios paneles.  Visualización de Recursos de Despliegues​ Para observar los recursos utilizados por un despliegue, navega al panel de monitoreo de recursos en Grafana. Una vez que inicies sesión, ve a: Inicio -&gt; Dashboards -&gt; Kubernetes / Compute Resources / Namespace (Pods) Este panel está configurado para mostrar datos en tiempo real sobre el uso de CPU, memoria y disco, permitiéndote rastrear y gestionar los recursos asignados a cada despliegue dentro de tu clúster. ","version":"Next","tagName":"h2"},{"title":"Kubecost: Monitoreo de Costos del Clúster","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/addons/kubecost","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Kubecost: Monitoreo de Costos del Clúster","url":"/preview-docs/es/docs/cluster/addons/kubecost#preguntas-frecuentes","content":" ¿Qué significa la métrica idle?​ El valor 'idle' que se muestra en todas las métricas de Kubecost indica cuánto de la capacidad de todas las opciones filtradas no se está utilizando. Este valor debe ser analizado cuidadosamente, ya que gran parte de esta capacidad &quot;idle&quot; puede corresponder a un nodo que aún no está completamente asignado o que debería estar disponible para tus workloads.  ¿Debería preocuparme si el valor idle es muy alto?​ No necesariamente. Podrías optimizar este valor reduciendo las solicitudes de CPU y Memoria de las Workloads desplegadas en tu Proyecto. Sin embargo, ten en cuenta que gran parte de esta capacidad está asignada como un límite máximo para la utilización de recursos, incluso si no se está usando. Esto proporciona espacio para el escalado interno de cada workload en caso de ser necesario. Por otro lado, muchas de estas workloads son críticas para el clúster, por lo que tendrán una capacidad &quot;idle&quot; para permitirles escalar libremente.  ¿Puedo revisar un Namespace de manera más detallada?​ Kubecost permite un análisis granular de los costos. Por ejemplo, además de los costos por Namespace, puedes profundizar haciendo clic en el Namespace y analizar los costos de los pods, despliegues y otros elementos asignados a él.  ¿Puedo analizar algo más aparte de los Namespaces?​ Sí. Desde el panel principal puedes analizar específicamente los costos de un Nodo como entidad individual. También permite revisar los costos de almacenamiento que se están utilizando. Por ejemplo, para un nodo específico podrías ver esto:  ¿Kubecost tiene alguna función para analizar costos de red?​ En este momento, SleakOps ofrece la capacidad de habilitar 'NetworkCosts', una función de Kubecost que estima el costo del tráfico de red de cada workload. Esta función es una excelente opción si deseas analizar más profundamente el tráfico de red del clúster. Puede habilitarse en el formulario de instalación de Kubecost: ","version":"Next","tagName":"h2"},{"title":"Loki","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/addons/loki","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Loki","url":"/preview-docs/es/docs/cluster/addons/loki#preguntas-frecuentes","content":" ¿Qué paneles me permiten leer logs?​ Actualmente, SleakOps proporciona dos paneles para consultar los logs recolectados por Loki: Log Explorer: Es un panel simple que te permite filtrar por Namespace, Pod, Contenedor y Stream, donde puedes elegir entre 'stdout' y 'stderr'. También te permite buscar expresiones mediante el campo 'Search Query' en la parte superior.Container Log Dashboard: Similar al anterior, pero más orientado a analizar casos complejos. Es más lento porque requiere más procesamiento, y para consultas generales no será necesario.  ¿Cuál es la mejor manera de usar Loki?​ Minimizar el rango de tiempo que se consulta es la mejor forma de revisar logs de manera rápida y sin errores, ya que este parámetro tiene la mayor influencia en el peso de la respuesta. Recomendamos primero obtener una visión general de cuándo ocurrió el problema y luego buscar en Loki los logs de un rango de tiempo más específico, ya que, generalmente, la cantidad de logs puede ser muy alta. Ten en cuenta que Loki utiliza pequeñas unidades de procesamiento para lectura, escritura y como controlador (backend), por lo que las consultas grandes pueden ser lentas si no hay suficientes réplicas de lectura o capacidad de procesamiento. Esto se puede modificar mediante SleakOps, pero también incrementará los costos.  ¿Cómo puedo modificar la capacidad de procesamiento de Loki?​ SleakOps te permite modificar la capacidad de procesamiento de Loki a través de la configuración del Addon. Una forma de aumentar su capacidad es modificando la cantidad de réplicas desplegadas.  ¿Cómo captura y almacena logs Loki?​ Loki recolecta logs de cada nodo del clúster y, por lo tanto, de cada contenedor que se ejecuta en él. Para lograr esto, SleakOps utiliza Promtail, que es el colector de logs predeterminado para Loki. Por esta razón, cada nodo del clúster tendrá una instancia de Promtail desplegada, encargada de recopilar y enviar los logs a la instancia de escritura de Loki, que después de un cierto período los transfiere a S3 para almacenamiento a largo plazo.  ¿Cómo es el proceso de recolección de logs?​ El colector de logs, Promtail, recopila y transmite a Loki todos los logs generados a través de 'stdout' o 'stderr' de cada contenedor en ejecución en el clúster. ","version":"Next","tagName":"h2"},{"title":"Prometheus: Sistema de Monitoreo","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/addons/prometheus","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Prometheus: Sistema de Monitoreo","url":"/preview-docs/es/docs/cluster/addons/prometheus#preguntas-frecuentes","content":" ¿Prometheus almacena métricas?​ Prometheus tiene dos unidades de almacenamiento relacionadas: Depende del Addon EBS CSI Driver para el almacenamiento a corto plazo.Utiliza S3 para almacenamiento a largo plazo. Este S3 se crea en tu cuenta en paralelo con Prometheus.  ¿Cómo almacena SleakOps las métricas de Prometheus?​ Prometheus no se encarga directamente de enviar métricas a S3; esto lo realiza una entidad relacionada llamada Thanos.  ¿Puedo usar Prometheus de forma independiente?​ Su propósito principal es recopilar métricas, pero también incluye un frontend que se puede consumir mediante el reenvío de puertos (port-forwarding) desde su Pod para realizar consultas específicas a sus datos o visualizar algunas métricas. Sin embargo, es mucho más fácil y cómodo verlas con Grafana. ","version":"Next","tagName":"h2"},{"title":"Registro de Cambios","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/changelog","content":"","keywords":"","version":"Next"},{"title":"Versión 2.4.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-240","content":" 🗓️ 08/01/2026  🚀 Novedades:  Autodiagnóstico en Workloads: Con la ayuda de IA, ahora puedes descubrir de manera fácil y rápida qué está pasando con tus Workloads. Con solo presionar un botón desde la consola, obtendrás un diagnóstico completo.Grace Period en Workloads: Soporte para configurar grace period en Workloads.Notificaciones de Cost Tags: Se agregan notificaciones para configurar etiquetas de costos.Eliminación en Cascada: Mejoras en el flujo de eliminación en cascada con Dependencies activas.Variable Groups de Archivos: Mejoras en el formulario de Variable Groups de tipo archivo.Selector de Project: Mejoras en formularios con selector de Project.Navegación en Activity Logs: Se agregan enlaces para navegar entre Activity Logs y recursos.Sidebar: Mejora visual del sidebar.Pantalla de Billing: Mejoras en la pantalla de facturación.Edición de Dominios: Posibilidad de modificar dominios en Environments ya creados.Nombres de Variables: Manejo de longitud de nombres de variables en Variable Groups.Nombres de Environment: Ajustes en nombres por defecto de Environment.Monitoreo de Dependencies: Mejoras en el monitoreo de Dependencies.Resoluciones Pequeñas: Mejoras de UI para resoluciones bajas o pantallas pequeñas.Variables Modificadas: Mejoras en el formulario de Variable Groups para marcar qué variables fueron modificadas.Target Port en Web Services: Soporte para configurar targetPort en servicios de Web Services.  🐞 Correcciones:  Nombres de Environments: Manejo de longitud de nombres de Environments.Filtros Persistentes: Los filtros de Project y Environment ahora persisten entre pantallas.Iconos de Projects: Mejora en los iconos de Projects.Addons con Atributos Custom: Corrección en la edición de addons con atributos personalizados.Réplicas RDS: Validación de longitud de réplicas en RDS.URL en Web Services: Corrección en la autogeneración de URL al editar un Web Service.Selector de Projects: Corrección en la visibilidad del selector de Projects.Formularios de Nodepool: Corrección de errores en formularios de edición y creación de Nodepools.Transición de Estados: Corrección en la transición de estado de pendiente a finalizado.Certificado SSL: Corrección en alertas para validación de certificado SSL.Clonado con Versiones: Corrección en el clonado con versiones de Dependencies.Email de Notificaciones: Corrección de errores visuales en el email de notificaciones.URL en Clonado: Corrección de URL de Web Services en flujo de clonado.Eliminación de Project con RDS: Corrección al eliminar un Project con una RDS con protección de eliminación activa.  ","version":"Next","tagName":"h2"},{"title":"Versión 2.3.2​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-232","content":" 🗓️ 19/12/2025  🚀 Novedades:  SleakOps CLI: Mejoras y nuevas funciones, incluyendo la posibilidad de abrir una shell de un Workload en local.S3 con CloudFront: Mejoras en la integración de S3 con CloudFront.Python en Lambdas: Actualización de versiones de Python para Lambdas.Charts en Projects: Mejoras en la pantalla de configuración de charts en Projects.Tags de Subnet: Mejoras en el manejo de tags de subnet para autodiscovery.Restauración de DB: Mejoras en el flujo de restauración de base de datos desde un snapshot.Ingress en Web Services: Soporte para configurar URL y annotations de ingress en Web Services.Performance de APIs: Optimización en el rendimiento de las APIs.Errores en Domains: Mejoras en el manejo de errores en dominios.Botones de Addons: Mejora visual en los botones de addons.Notificaciones: Mejora visual al mostrar notificaciones.Opciones de Botones: Mejora visual en opciones de botones (configuración, copiar, etc.).Versiones de RDS: Actualización de versiones disponibles de RDS.Módulos de Infraestructura: Optimización de tiempos en la ejecución de módulos de infraestructura.  🐞 Correcciones:  Eliminación de Roles: Manejo en la eliminación de roles al eliminar un Project.Billing Multi-Provider: Corrección en pantalla de billing con múltiples proveedores.Registro y Login: Manejo del flujo de registro y login con diferentes estados de suscripciones.Formulario de Nodepools: Manejo de errores en el formulario de Nodepools.Cambio de Cuentas: Manejo de errores al cambiar entre cuentas.Caracteres en Variables: Manejo de caracteres inválidos en nombres de variables en Variable Groups.Acceso a Cluster: Manejo de acceso a Cluster para diferentes tipos de usuarios.Acceso a VPN: Manejo de errores al obtener acceso a VPN para diferentes tipos de usuarios.Textos en Listados: Corrección de textos en listados y formularios.Conexión con AWS: Corrección de textos en el paso a paso para conectarse con AWS.Deployments Pendientes: Alerta indicadora de deployments pendientes de aprobación.Actualización de Postgres: Manejo de error en actualización de PostgreSQL de 14 a 17.Security Group en RDS: Corrección de security group para réplicas de RDS públicas y privadas.Chat de Soporte: Corrección al delegar conversación en el chat de soporte.  ","version":"Next","tagName":"h2"},{"title":"Versión 2.3.1​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-231","content":" 🗓️ 01/12/2025  🚀 Novedades:  Análisis de Imágenes en Soporte: Soporte de análisis de imágenes en el bot de soporte.Documentación: Nueva documentación para Dockertron y manejo de charts.Valores Custom en Addons: Posibilidad de usar valores personalizados al instalar un addon.Cambio de Nodegroup: Posibilidad de cambiar el nodegroup de clusters no productivos.Flujo de Soporte: Flujo de conversación de soporte entre bot y humano.  🐞 Correcciones:  Modales de Confirmación: Corrección en la posición de modales de confirmación de eliminación.Tabla de Builds: Corrección de errores de datos y columnas en la tabla de builds.Notificaciones en Dashboard: Corrección de mensajes de notificaciones en el dashboard.Nombres de Workloads: Ajuste de tamaños de nombres para Workloads.Chart Dependency: Corrección del flujo de chart dependency.Alertas en Console: Corrección de alertas de notificaciones en la consola.  ","version":"Next","tagName":"h2"},{"title":"Versión 2.3.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-230","content":" 🗓️ 18/11/2025  🚀 Novedades:  Clonado de Environments: Nueva función de clonado de Environments.Clonado de Projects: Nueva función de clonado de Projects.Clonado de Dependencies: Nueva función de clonado de Dependencies.Clonado de Workloads: Nueva función de clonado de Workloads.Clonado de Variable Groups: Nueva función de clonado de Variable Groups.Filtros en Cluster Monitoring: Se agregan filtros para navegación de eventos de Cluster en Cluster Monitoring.Búsqueda de Variable Groups: Posibilidad de buscar Variable Groups por nombres de claves internas desde el buscador general.  🐞 Correcciones:  Cuenta Seleccionada: Se persiste la cuenta seleccionada al cambiar de usuario.Apagado de Web Services: Mejora en el apagado de Web Services.  ","version":"Next","tagName":"h2"},{"title":"Versión 2.2.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-220","content":" 🗓️ 13/11/2025  🚀 Novedades:  Visualizador de Código: Nuevo componente para visualizar código dentro de la consola.  🐞 Correcciones:  Usuarios Eliminados: Corrección de errores en usuarios eliminados.Actualizar Ramas: Corrección en el flujo de actualizar ramas en Project.Información Incompleta: Corrección del flujo cuando falta completar información de un Project.Extra Policies: Corrección del flujo para configurar políticas adicionales en Project.  ","version":"Next","tagName":"h2"},{"title":"Versión 2.1.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-210","content":" 🗓️ 10/11/2025  🚀 Novedades:  Actualización de Cluster: Soporte para actualización de Cluster de 1.31 a 1.32.Tour de Dependency: Nuevo tour guiado para la pantalla de Dependency.Tour de Workload: Nuevo tour guiado para la pantalla de Workload.Tour de Variable Group: Nuevo tour guiado para la pantalla de Variable Group.Tour de Cluster: Nuevo tour guiado para la pantalla de Cluster.Tour de Project: Nuevo tour guiado para la pantalla de Project.Actualización de Cluster: Optimización en tareas de actualización de Cluster.Carga de Pantallas: Mejoras en la carga de drawers y pantallas secundarias.Programar Actualización: Nuevo flujo para programar la actualización de Cluster.Onboarding: Nuevo flujo de onboarding para usuarios nuevos.Configuración de Nodepool: Soporte de más parámetros de configuración para Nodepool (tipo de instancias, fallbacks, etc.).Monitoreo de Upgrade: Nuevo flujo de monitoreo de servicios durante el upgrade de Cluster con reporte de errores.Logs de Builds: Mejoras en los logs de builds con más contexto.  🐞 Correcciones:  Certificado SSL en S3: Corrección de errores de certificado SSL para S3 con CloudFront.Activity Logs: Corrección de nombres en algunos Activity Logs.Creación de Usuarios: Corrección de errores en el flujo de creación de usuarios.Tickets de Soporte: Corrección del estado de tickets de soporte.Build con CLI: Corrección de parámetros al hacer build usando la CLI.Apagado Nocturno: Corrección del estado de Cluster con apagado nocturno activado.Resoluciones de Pantalla: Ajustes para algunas resoluciones en la pantalla principal de la consola.Eliminar Web Services: Corrección de errores al eliminar un Web Service en la tabla.  ","version":"Next","tagName":"h2"},{"title":"Versión 2.0.1​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-201","content":" 🗓️ 15/10/2025  🚀 Novedades:  Tabla de Builds y Deploys: Mejoras en los datos mostrados en la tabla de builds y deploys.  🐞 Correcciones:  Cron de Apagado Nocturno: Corrección en la visualización del cron del apagado nocturno.Estado de Cluster: Corrección en la actualización de estado de un Cluster mientras se está actualizando.Notificaciones Largas: Corrección en la visualización de notificaciones largas.VPN para Terceros: Corrección en el acceso a VPN para terceros.Cancelación de Deploy: Corrección en el flujo de cancelación de deploy.Creación de Provider: Corrección de jerarquías de texto en el flujo de creación de Provider.Missing Information: Corrección de redirección en el flujo de información faltante en Project.Usuario Viewer: Corrección de navegación para usuario viewer.Toggles en Modo Light: Mejora de visibilidad de toggles en modo claro.Password en Dependency MQ: Corrección en la autogeneración de password para Dependency MQ.Carga de Iconos: Mejoras en la carga de iconos.Pantallas de Transición: Corrección de pantallas de transición durante carga de datos.Tablas en Project Console: Mejoras de visualización de tablas en la pantalla &quot;Project Console&quot;.Errores de Infraestructura: Corrección de mensaje de errores al fallar la ejecución de módulo de infraestructura.Selector de Cuentas Mobile: Soporte de selector de cuentas para dispositivos móviles.  ","version":"Next","tagName":"h2"},{"title":"Version 2.0.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-200","content":" 🗓️ 01/10/2025  🚀 New Features:  Rediseño completo de la consola: Interfaz modernizada para una experiencia más limpia, ágil e intuitiva.Soporte de tema claro: Compatibilidad total con modo claro en la interfaz.Bot de soporte: Respuestas automáticas para consultas frecuentes.Documentación ampliada: Guías detalladas y cobertura completa de todas las funcionalidades.Actualización lambdas: Actualización de versiones de Python utilizadas en las Lambdas.Project Chart: Promovido a versión estable.Project Access: Promovido a versión estable.Dependency Aurora MySQL: Promovido a versión estable.Dependency Oracle: Promovido a versión estable.Dependency MariaDB: Promovido a versión estable.Dependency Aurora PostgreSQL: Promovido a versión estable.Edición de dependencias: Ahora es posible editar dependencias existentes.Dockertron (beta): Dockerización automática impulsada por IA.Cancelar builds pendientes: Opción para detener builds en cola.Nueva dependencia MSK: Soporte para Kafka con AWS MSK.Mejoras en Webservices: Configuración de custom ingress annotations y healthcheck opcional.Nodepools avanzados: Nuevas opciones de fallback y mezcla de instancias (reservadas, spot y bajo demanda) para un mayor control de costos y rendimiento.  🐞 Bug Fixes:  GitLab self-hosted: Validación de URL corregida.Cluster deletion: Manejo mejorado de la eliminación en cascada.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.16​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-1716","content":" 🗓️ 21/07/2025  🚀 New Features:  Proyectos con repositorios públicos: Ahora es posible crear y gestionar proyectos vinculados a repositorios públicos.Exclusión de builds en métricas: Se pueden excluir builds del dashboard de métricas en Grafana para mayor precisión en los reportes.  🐞 Bug Fixes:  Deploy de nuevos proyectos: Se solucionaron problemas que impedían el despliegue correcto de proyectos recién creados.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.15​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-1715","content":" 🗓️ 07/07/2025  🚀 Novedades:  Resiliencia en nodegroups con Spot: Ahora los nodegroups Spot evitan caídas cuando no hay instancias disponibles.VariableGroups tipo archivo: Se incorpora la opción de crear variablegroups basados en archivos.Agente Bot (beta): Nueva funcionalidad experimental de agente bot en versión beta.  🐞 Correcciones:  Dominios dependientes Genera registros DNS automaticos cuando existe un dominio ya creado.Cluster con apagado nocturno: orrección en el estado mostrado de clusters con apagado automático.Filtros en grupo de variables: Arreglo de filtro por proyecto en listado de group de variablesEliminacion de cluster: Arreglo de flujo de eliminación de clusterEstados de tickets de soporte: Arreglo de transicion de estados en tickets de soporte.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.14​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-1714","content":" 🗓️ 26/06/2025  🚀 Novedades:  Mejoras en transición de estados: Optimización en el cambio de estado de cluster addons y formularios.Soporte con imágenes: Posibilidad de subir imágenes en el chat de soporte.Jobs desde cronjobs o existentes: Ahora es posible lanzar un Job a partir de un cronjob o de un Job ya creado.Errores de infraestructura: Mejor interpretación y visualización de errores para facilitar la resolución.  🐞 Correcciones:  Volúmenes duplicados: Solucionado el error al crear volúmenes con el mismo nombre.Usuarios duplicados: Corrección para evitar la creación de usuarios con correos electrónicos repetidos.Dependencias duplicadas: Se evita la creación de dependencias con nombres repetidos.Monitoreo de dependencias: Corrección en el rango de fechas de la pantalla de monitoreo de dependencias.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.13​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-1713","content":" 🗓️ 02/06/2025  🚀 Novedades:  Monitoreo de dependencias: Mejoras en la visualización y seguimiento de dependencias.Control de servicios: Nuevo toggle para apagar o encender webservices y workers.Builds con o sin caché: Opción de ejecutar builds utilizando caché o desde cero.Importación de Buckets con versionado: Soporte para importar Buckets S3 con versionado activo.Variable Groups: Mejoras en la interfaz de gestión de grupos de variables.Validaciones en Dockerfile: Se agregan validaciones para mejorar la confiabilidad de los Dockerfiles.  🐞 Correcciones:  Logs de Jobs: Ahora los enlaces de logs funcionan correctamente en los Jobs.Nombres de ramas: Soporte para branches con / en el nombre.Pipelines de GitLab: Se resolvieron errores en la ejecución de pipelines.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.12​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-1712","content":" 🗓️ 14/05/2025  🚀 Novedades:  Nuevo Flujo de Soporte: Se incorporó un chatbot y un sistema de tickets para brindar mayor trazabilidad y agilidad en la atención.Gestión de Subscripciones y Planes: Nuevas mejoras para administrar subscripciones y planes de servicio.  🐞 Correcciones:  Mejoras en Formularios: Optimización en la usabilidad y validación de formularios.Consola de Proyectos: Mejoras de UI/UX en la pantalla de la consola de proyectos.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.11​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-1711","content":" 🗓️ 24/04/2025  🚀 Novedades:  Kubernetes 1.31 y Karpenter 1.3 : SleakOps ahora aprovisiona clusters en EKS 1.31 y actualiza el autoscaler a Karpenter 1.3.Gestión de Secrets Mejorada: Todos los secrets se guardan cifrados en AWS Systems Manager Parameter Store, además de la copia dentro del cluster, añadiendo una capa extra de seguridad  🐞 Correcciones:  Workers en Clúster de Desarrollo: Se eliminó el PodDisruptionBudget el desescalado en entorno con apagado nocturno, mejorando la fiabilidad de los workers en entornos de desarrollo.Mejoras en builds: Ya no se dispara un build por cada cambio menor en un proyecto.Mejoras en deploys: Los jobs de build dejaron de usar Fargate y los logs ahora se persisten.Detalles de Web Services: Pantalla refinada con mayor claridad sobre endpoints, estado y métricas.Add-on Kubecost: Mejoras de estabilidad.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.10​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-1710","content":" 🗓️ 01/04/2025  🚀 Novedades:  Mayor Control sobre Permisos: Ahora los proyectos pueden contar con permisos adicionales, ya sean políticas de IAM de AWS o permisos personalizados.Detalles de Dependencias: Se muestran los detalles de configuración de cada dependencia en su vista correspondiente.Mejoras en la Pantalla de Actualización de Clusters: Se incluye el análisis de EKS Insights directamente en SleakOps para optimizar las actualizaciones de los clusters.Mejoras en Build &amp; Proyectos: Más detalles en el proceso de build y un flujo de validaciones de proyectos optimizado.  🐞 Correcciones:  Datos de Acceso al Cluster: Solucionado un error al acceder a la información de conexión de un cluster cuando se seleccionaba una cuenta diferente.Listado de Dominios: Se agregó un filtro por cuenta al listar los dominios.Mejoras Visuales en el Listado de Nodepools: Se optimizó la presentación del listado de nodepools.Instalación de Add-ons: Ahora se actualiza correctamente el listado de add-ons después de una instalación.Edición de Variable Groups: Corregido un problema que impedía editar los grupos de variables.Adjuntar Nuevas Suscripciones: Solucionado un error que evitaba la correcta vinculación de nuevas suscripciones.Pronóstico de Costos (Forecast Cost): Se corrigieron problemas para mejorar la estimación de costos.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.9​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-179","content":" 🗓️ 17/02/2025  🚀 Novedades:  Mejoras en Cronjobs: Ahora puedes configurar las políticas de cronjobs y filtrar entre cronjobs activos e inactivos.Notificaciones por Correo: Cuando SleakOps genera una notificación, los usuarios la reciben por correo electrónico.EKS Insights: Durante la actualización de clusters, SleakOps consulta los Insights de EKS para verificar que todo funcione correctamente.  🐞 Correcciones:  Mejoras en los Flujos de Proyectos: Se han mejorado varios ajustes, formularios y otros elementos para una gestión de proyectos más ágil.Flujo de Creación de Cuentas AWS: Ahora se admiten cuentas inactivas de AWS, proporcionando una guía clara para activarlas manualmente antes de retomar el proceso en SleakOps.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.8​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-178","content":" 🗓️ 10/02/2025  🚀 Novedades:  Kubernetes 1.30: Se actualizó la versión de EKS a la 1.30.  🐞 Correcciones:  Mejoras Estéticas Menores: Se optimizó el diseño visual de las pantallas de proyectos y workloads.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.7.7​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-177","content":" 🗓️ 05/02/2025  🚀 Novedades:  Importación desde buckets externos: Copia fácilmente archivos de un bucket S3 externo a SleakOps con la nueva función Import Bucket.Rediseño de vista de Proyectos: Accede a logs e información clave en una sola pantalla para mayor visibilidad.Cambio de “Executions” a “Workloads”: Se actualiza la terminología para alinearla con la notación interna del clúster.Optimización de eliminación de Clusters: Se agregó una validación adicional para un proceso de eliminación más seguro y estable.  🐞 Correcciones:  Permisos de Proyectos para Jobs: Solucionado un problema donde los Jobs usaban permisos del nodo del clúster en lugar de los permisos del Proyecto.Modificación de Docker Args: Ahora los builds aplican correctamente los cambios de Docker Args hechos justo antes de su ejecución.Generación de Perfiles VPN: Resuelto un inconveniente que impedía generar perfiles para usuarios de terceros.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.7.6​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-176","content":" 🗓️ 06/01/2025  🚀 Novedades:  Nuevas configuraciones de Nodepool: Ahora puedes establecer parámetros adicionales, como tamaños mínimos de instancia y más.Job con imágenes específicas: Al crear un job, puedes especificar la imagen y el tag exactos que deseas ejecutar (por ejemplo, postgres:16.4).(BETA) Extensión de Charts por Proyecto: SleakOps ahora puede extender los charts utilizados para desplegar carga de trabajo de proyectos, permitiéndote agregar dependencias. Para más información, consulta la documentación de Helm.Mejoras en CI/CD: Se ha simplificado y optimizado el archivo de configuración de CI/CD.  🐞 Correcciones:  URL de Web Services internos: Se corrigió un problema que causaba URLs incorrectas para los servicios web de tipo “interno”.Eliminación de Volúmenes: Se resolvieron problemas relacionados con la eliminación de volúmenes bajo varias políticas de retención.Mejoras en UX/UI: Mejoras en la interfaz para Proyectos, Volúmenes y Grupos de Variables.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.5​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-175","content":" 🗓️ 09/12/2024  🚀 New Features:  Manejo de error en integracion con AWS:: Se agrego un manejo para la tardanza de AWS en activar las cuentas creadas por Sleakops.Links de addons en build: Se agrega los links para poder ver logs y metricas en los builds.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.4​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-174","content":" 🗓️ 05/12/2024  🚀 New Features:  Accesibilidad a addons: Se agregaron enlaces en SleakOps para acceder fácilmente a ver logs, APM o métricas de recursos específicos.OpenTelemetry (beta): Se introdujo un add-on para mejorar la observabilidad en las aplicaciones desplegadas con SleakOps. Con OpenTelemetry, puedes tener tu propio APM para monitorear métricas como tasa de solicitudes, latencia y tasa de errores de tu aplicación.Addons, Configuraciones de disponibilidad: Se agregaron diversas configuraciones de disponibilidad para cada add-on.Documentacion: Se actualizó la documentación de los add-ons y se puso a disposición en español.  🐞 Correcciones:  Revision Kubecost: Se revisó la integración entre Prometheus y Kubecost. Ahora Kubecost asigna correctamente los nombres de los recursos desplegados a sus costos, mejorando significativamente la precisión de sus estimaciones. Es posible habilitar en Kubecost el análisis aproximado de costos de tráfico de red dentro del clúster (Beta).  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.3​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-173","content":" 🗓️ 14/11/2024  🚀 New Features:  Oracle (beta): Ahora podes gestionar Oracle RDS como dependency en Sleakops .Aurora postgres serverless (beta): Se agrega soporte para crear y gestionar aurora postgres serverless.  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.2​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-172","content":" 🗓️ 05/11/2024  🚀 New Features:  Eliminacion de bucket s3: Eliminacion de bucket s3 con muchos archivos.VPN: actualizacion del modulo de Pritunl  🐞 Correcciones:  Varias correcciones de errores menores  ","version":"Next","tagName":"h2"},{"title":"Version 1.7.1​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#version-171","content":" 🗓️ 30/10/2024  🚀 Nuevas Funciones:  Creacion de entornos y dominios: Se mejora la creacion de entornos y dominios; ya no exite limitacion para usar un dominio diferente al que fue configurado a nivel globalNotificaciones: Se agrega un sistema de notificaciones para avisar al usuario de todas las acciones manules que tiene pendiente y actualizaciones de infraestructura programadas.Documentacion: Se actualiza documentacion para la gestion de dominios, proyectos, dependencias, variables de entorno.  🐞 Correcciones:  Varias correcciones de errores menores.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.7.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-170","content":" 🗓️ 14/10/2024  🚀 Nuevas Funciones:  Gestión Avanzada de Nodos: Se agregó la gestión de pools de nodos para tener un mayor control sobre los tipos de nodos donde se ejecutan las cargas de trabajo.Migración de Módulos de Clúster: Todos los módulos creados con el clúster ahora se ejecutan en instancias Graviton, mejorando el rendimiento y reduciendo costos.Complementos de Clúster: Todos los complementos ahora se ejecutan en instancias Graviton, lo que mejora el rendimiento y reduce los costos.Nodos de Construcción Aislados: Las construcciones ahora se ejecutan en nodos dedicados separados de los nodos de aplicaciones, mejorando la estabilidad de los nodos que ejecutan aplicaciones.  🐞 Correcciones  Varias correcciones menores de errores.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.6.3​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-163","content":" 🗓️ 27/09/2024  🚀 Nuevas Funciones:  Registro: Implementado un nuevo flujo de registro.  🐞 Correcciones  Varias correcciones menores de errores y mejoras.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.6.2​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-162","content":" 🗓️ 19/09/2024  🚀 Nuevas Funciones:  Actualizaciones: Actualizados Prometheus, Loki y EBS CSI Driver a las versiones más recientes de agosto de 2024.Migración del Driver EBS CSI: SleakOps ahora usa el complemento gestionado por AWS para EKS, reemplazando la versión autogestionada.Prometheus con EBS: Prometheus ahora utiliza volúmenes EBS para la persistencia de datos, evitando pérdidas en caso de fallos de pods.Loki con SimpleScalable: Adopta una estructura SimpleScalable con almacenamiento TSDB para registros, mejorando el rendimiento.Colas Muertas en SQS: Ahora es compatible con la creación de colas SQS con colas muertas asociadas para un mejor manejo de errores.  🐞 Correcciones  Varias correcciones menores de errores y mejoras en los flujos de ejecución de la plataforma.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.6.1​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-161","content":" 🗓️ 22/08/2024  🚀 Nuevas Funciones:  Actualización de Versiones de Dependencias: Se actualizaron versiones de dependencias como MQ, Elasticsearch, Memcache y Redis.Mejoras en la Autenticación: Se agregó soporte para almacenar tokens de autenticación mediante cookies en lugar de almacenamiento local.Se agregó la impresión de registros de validación ACM en la pantalla de detalles y el estado de ACM ahora está incluido en el sistema.  🐞 Correcciones  Se resolvieron problemas en el flujo de creación de proveedores.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.6.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-160","content":" 🗓️ 12/08/2024  🚀 Nuevas Funciones:  Soporte para Instancias ARM y Versiones Adicionales de RDS: Se añadieron instancias ARM y versiones extra en RDS.Actualización de EKS a la Versión 1.29: EKS ha sido actualizado a la versión 1.29. Ahora se muestran los registros de cambios de EKS.Mejoras en Creación y Edición de Proveedores: Se actualizaron las pantallas y campos de los formularios de proveedores, incluyendo cambios en estados y visualización.Búsqueda Mejorada de Repositorios: Añadido soporte para búsqueda asincrónica en el selector de repositorios y se mejoró la búsqueda en GitHub, GitLab y Bitbucket.Parametrización de Healthchecks: Ahora se pueden parametrizar propiedades de healthcheck con JSONSchema.Nuevo Tablero: Se añadió un nuevo tablero para ver el consumo por namespace.  🐞 Correcciones  Solucionado un error al regenerar certificados y problemas con construcciones que no se ejecutaban correctamente.Errores de frontend relacionados con listados y problemas de API que causaban errores en filtros fueron corregidos.  Versión 1.5.1  🗓️ 24/06/2024  🚀 Nuevas Funciones:  Configuración Avanzada de Recursos: Se implementaron opciones avanzadas para la configuración de recursos en entornos de proyectos.Optimización de Scripts de Recolección de Datos: Mejorada la eficiencia de los scripts de recolección de datos para una ejecución más rápida.  🐞 Correcciones:  Resueltos varios errores de interfaz que afectaban la usabilidad del sistema.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.5.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-150","content":" 🗓️ 23/05/2024  🚀 Nuevas Funciones:  Creación de Múltiples Entornos de Proyecto: Ahora puedes crear múltiples entornos de proyecto utilizando el mismo repositorio y rama.Validación de Dominios para Alias: Mejorada la validación de creación de dominios para alias utilizando un ACM existente y utilizable para ingress.Configuración de Recursos en Entornos de Proyecto: Se añadió la capacidad de configurar recursos de construcción y despliegue por entorno de proyecto.Configuración de Solicitudes de Despliegue y Construcción: Se agregó la opción de configurar solicitudes de despliegue y construcción en un entorno de proyecto.Tablero de Grafana: Se incorporó un tablero de Grafana para visualizar el consumo por namespace.Configuración de Loki: Ahora es posible buscar registros por namespace con la nueva configuración de Loki.Recolección de Datos: Mejorado el script de recolección de costos para que sea idempotente y ejecutable en fechas específicas.  🐞 Correcciones:  Corregido un error al crear dependencias de S3 y solucionado un problema crítico con vargroups durante actualizaciones de apagado del clúster.Corregido un error crítico al invitar colaboradores.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.4.3​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-143","content":" 🗓️ 13/05/2024  🚀 Nuevas Funciones:  Mejoras en la Gestión de Tableros: Mejorada la carga de tableros, permitiendo visualizarlos incluso si no se selecciona una cuenta.Mejoras en las Pantallas de Facturación y Proyecto: Se realizaron mejoras en la pantalla de facturación, incluyendo una nueva sección &quot;otros&quot; para considerar costos previamente no contabilizados. También se mejoró la pantalla de entornos de proyecto.Actualización de Políticas: La política de CloudFormation ha sido actualizada para mejorar la gestión y seguridad.  🐞 Correcciones:  Corregido un error crítico que impedía la creación de proveedores.Revisado y resuelto un problema relacionado con la integración de NewRelic.Solucionado un problema con el token de actualización al solicitar la URI de la VPN.Errores en la Pantalla de Validación de ACM y Logs de Construcción: Se corrigieron problemas en la tabla de validación de ACM y en la visualización de logs para construcciones en estado de creación.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.4.2​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-142","content":" 🗓️ 25/04/2024  🚀 Nuevas Funciones:  Nuevas Métricas: Se añadieron nuevas métricas para los buckets de S3 y RabbitMQ, mejorando el monitoreo de servicios. También se implementó un sistema de monitoreo para métricas de OpenSearch.Reorganización del Esquema de Monitoreo: Las estructuras del esquema de monitoreo se reorganizaron para una mejor gestión y visualización. La pantalla de monitoreo de dependencias ahora admite diferentes tipos de recursos, proporcionando una vista más detallada.  🐞 Correcciones:  Resuelto un problema crítico con vargroups, asegurando su correcto funcionamiento.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.4.1​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-141","content":" 🗓️ 11/04/2024  🚀 Nuevas Funciones:  Monitoreo de Dependencias y OpenSearch: Se creó una nueva página de monitoreo para dependencias, facilitando el seguimiento de su estado. También se incluyó OpenSearch.Política de Ciclo de Vida para ECR: Se configuró una política de ciclo de vida para ECR, mejorando la gestión de imágenes.  🐞 Correcciones:  Solucionado el problema de nombres duplicados entre clúster y nodo en Redis.Resueltos varios errores de frontend que afectaban la experiencia del usuario.Corregido el problema donde se mostraba un error al intentar publicar un vargroup sin un servicio asociado.Se solucionaron los problemas al realizar múltiples despliegues y lanzamientos consecutivos.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.4.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-140","content":" 🗓️ 06/03/2024  🚀 Nuevas Funciones:  Configuración de Grafana: Se configuró la base de datos para el addon de Grafana, junto con DataSources y Dashboards.Persistencia de Métricas de Prometheus con Thanos: Se agregó soporte para la persistencia de métricas de Prometheus usando Thanos.Nueva API de Volúmenes: Se implementó soporte para la nueva API de volúmenes, mostrando estados y aplicando configuraciones para despliegues.La opción de actualización en addons fue deshabilitada.Ahora, cuando se elimina una dependencia, se crea un despliegue con estado &quot;pendiente de aprobación&quot; en lugar de uno automático.  🐞 Correcciones:  Solucionado un problema donde se añadían pre-hooks y nuevos volúmenes durante los despliegues, impidiendo su generación.Los subdominios ahora se marcan correctamente como delegados si los dominios principales ya están delegados.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.3.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-130","content":" 🗓️ 03/01/2024  🚀 Nuevas Funciones:  Vista Detallada de Proyectos: Ahora está disponible una vista detallada de proyectos en la nueva interfaz.API de Métricas de RDS: Se agregó una nueva API para mostrar métricas de RDS, mejorando la visibilidad de los recursos.LogViewer Mejorado: La carga de LogViewer ahora es más rápida y eficiente.Mejor Onboarding: Se implementó un nuevo proceso de onboarding para una configuración más sencilla.Monitoreo de Redis: Se añadió el monitoreo de Redis, mejorando la supervisión de infraestructura.Configuración de Réplicas en RDS: Se agregó la opción de configurar réplicas en la dependencia RDS para mayor flexibilidad.Estado de Eliminación de Dominios: La eliminación de dominios ahora crea un despliegue con estado pendiente de aprobación en lugar de un despliegue automático.Mejoras en la Ejecución de Jobs: Se mejoró la ejecución de jobs, permitiendo reintentos automáticos en caso de fallas iniciales.  🐞 Correcciones:  Se resolvieron problemas de integración con Bitbucket.Corregidos problemas de valores indefinidos en Vargroups.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.2.4​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-124","content":" 🗓️ 15/02/2024  🚀 Nuevas Funciones:  Optimización del Selector de Clústeres: Se optimizó el comportamiento del selector de clústeres.Inicio de Sesión en el Flujo de Subscripción de AWS: El flujo de subscripción de AWS ahora incluye la posibilidad de iniciar sesión directamente.  🐞 Correcciones:  Resueltos problemas de callbacks para integraciones con Git y rutas de archivos Docker para GitLab.Corregidos errores menores relacionados con la pantalla de facturación.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.2.3​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-123","content":" 🗓️ 05/02/2024  🚀 Nuevas Funciones:  Desacoplamiento de Alias en Servicios Web: La creación de alias ahora está separada del formulario de servicios web.Restablecimiento de Contraseña IAM: Ahora es posible restablecer la contraseña de IAM para un usuario.  🐞 Correcciones:  Se corrigió un problema menor con las tareas de lanzamiento.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.2.2​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-122","content":" 🗓️ 25/01/2024  🚀 Nuevas Funciones:  Botón de Validación de Dominio: Se agregó un botón de &quot;verificar validación&quot; en el panel de dominio para facilitar la gestión de dominios.Tabla de Registro de Actividad: Se creó una tabla de registro de actividad.Cifrado de Claves de Acceso: Ahora las claves de acceso para proveedores de código (GIT) están cifradas.  🐞 Correcciones:  Se resolvió un problema donde la API no recreaba correctamente el módulo ACM durante la regeneración.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.2.1​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-121","content":" 🗓️ 12/01/2024  🚀 Nuevas Funciones:  Optimización de Formularios de Vargroups: Se mejoró la usabilidad de los formularios de Vargroups.Eliminación de Proveedores y Cuentas de Usuario: Eliminar un proveedor ahora también elimina las cuentas de usuario asociadas.  🐞 Correcciones:  Se corrigió un error en la regeneración de certificados ACM.Solucionado un problema en la eliminación de proveedores.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.2.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-120","content":" 🗓️ 05/01/2024  🚀 Nuevas Funciones:  Logs en Grafana: Se configuró una fuente de datos en Grafana para mostrar logs de S3.Botón de Actualización de Clúster: Se añadió un botón para permitir la actualización de clústeres desde la interfaz.Registro de Actividad de Usuario: Se creó un registro de actividad para acciones de usuarios.Despliegue para Validación de Dominios: Ahora se puede crear un despliegue que se ejecuta una vez que los dominios son validados.Autenticación de Dos Factores: Se añadió autenticación de dos factores (2FA) en el inicio de sesión para mayor seguridad.  🐞 Correcciones:  Se resolvió un problema con builds que usaban la misma rama que la predeterminada.Mejorado el procesamiento de logs para mayor velocidad.Varias optimizaciones de frontend, incluyendo estilos, búsqueda y visibilidad de recursos pendientes.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.1.1​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-111","content":" 🗓️ 05/12/2023  🚀 Nuevas Funciones:  Visor de Logs en Jobs: Se agregó un visor de logs en la lista de jobs, similar al de los despliegues.Dashboard v2: Mejoras en la segunda versión del Dashboard, con más opciones y mejor organización de la información.Certificados de Clúster: Los certificados de clúster ahora se eliminan y actualizan automáticamente para evitar problemas de expiración.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.1.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-110","content":" 🗓️ 06/11/2023  🚀 Nuevas Funciones:  Gestión de Vargroups: Se añadió la opción de mostrar vargroups en los formularios de servicios, workers, hooks y cronjobs.Kubecost: Se integró Kubecost con Prometheus-stack.  🐞 Correcciones:  Solucionado el problema con Karpenter en instancias spot.Corrección en roles de usuario y edición de usuarios.Resueltos problemas al eliminar un entorno y la eliminación incorrecta de dominios.Solucionado el error al intentar iniciar manualmente el clúster.Corregido un error en la generación de hooks.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.0.5​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-105","content":" 🗓️ 27/10/2023  🐞 Correcciones:  Solucionados problemas de despliegue y corrección de Karpenter con instancias spot.Se corrigieron problemas al eliminar entidades y validar URLs de servicios.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.0.4​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-104","content":" 🗓️ 11/10/2023  🚀 Nuevas Funciones:  Refactorización y Mejoras: Refactorización del dashboard y mejoras en la visualización de logs y gestión de eliminación de entidades.  🐞 Correcciones:  Solucionados problemas al editar usuarios.Corrección en la gestión del estado de clústeres.Resueltos problemas con dominios de entornos.Arreglado el manejo de errores en respuestas de S3 con CloudFront.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.0.3​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-103","content":" 🗓️ 25/09/2023  🚀 Nuevas Funciones:  Botones de Gestión y Mejoras en Formularios: Se añadieron botones para gestión de recursos y mejoras en los formularios de mapeo de variables.Cronjobs y Regeneración de Dominios: Ahora puedes detener o activar cronjobs y regenerar dominios.  🐞 Correcciones:  Solucionado el problema de obtención de la URI VPN en Pritunl.Corregido el problema de selección de cuenta para usuarios solo visualizadores.Mejorado el manejo de información de health checks enviada al backend.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.0.2​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-102","content":" 🗓️ 04/09/2023  🚀 Nuevas Funciones:  Optimización de Despliegues: Simplificación del proceso de despliegue y edición de entornos de proyecto (ProjectEnv), facilitando configuración y despliegue.Ajustes de Recursos y Configuración: Ahora puedes crear alias personalizados para buckets.Mejoras en Health Checks: La sonda de readiness para servicios en la cuenta de desarrollo ahora es opcional.  🐞 Correcciones:  Resueltos problemas relacionados con VPN y configuración de parámetros de seguridad.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.0.1​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-101","content":" 🗓️ 29/08/2023  🚀 Nuevas Funciones:  Gestión de Suscripciones: El inicio de sesión y las actualizaciones de tokens ahora se controlan en función del estado de la suscripción. Además, se implementó una nueva API para registrar usuarios y empresas, validando suscripciones pendientes, con un nuevo modelo que mejora la gestión de suscripciones e integra AwsClient.Onboarding desde Marketplace: Proceso simplificado para la creación de usuarios provenientes de un marketplace.  ","version":"Next","tagName":"h2"},{"title":"Versión 1.0.0​","type":1,"pageTitle":"Registro de Cambios","url":"/preview-docs/es/docs/changelog#versión-100","content":" 🗓️ 23/08/2023  🚀 Nuevas Funciones:  Configuración de Volúmenes: Ahora puedes configurar volúmenes en entornos de proyecto directamente desde el formulario.Apagado Nocturno con Zona Horaria: Se añadió soporte para seleccionar zonas horarias en el apagado nocturno.Inicio Manual de Clústeres: Nuevo botón para iniciar clústeres manualmente.Integración con CloudFront: Soporte para usar CloudFront y mejorar la entrega de contenido.Backups Automáticos: Configuración de backups automáticos para dependencias.Instancias Graviton: Soporte para usar instancias Graviton en nodos.Cifrado: Implementación de cifrado en StackSettings para mayor seguridad.  🐞 Correcciones:  Resuelto un problema en la API de facturación y estimación de costos.Corregidos errores al eliminar Proveedores y VPNs.Ahora puedes eliminar certificados ACM usados por un Load Balancer sin problemas. ","version":"Next","tagName":"h2"},{"title":"Node Pools","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/nodepools","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Node Pools","url":"/preview-docs/es/docs/cluster/nodepools#preguntas-frecuentes","content":" ¿Cuáles son los diferentes tipos de Node Pools?​ Reserved: Son instancias a las que te comprometes a usar por un período específico (1 o 3 años) a cambio de ahorros significativos en costos (hasta 75% menos que el precio On-Demand). Proporcionan el mejor precio con compromiso y son ideales para: Cargas de Trabajo Predecibles: Aplicaciones con patrones de uso estables y predecibles que pueden beneficiarse de un compromiso a largo plazo.Entornos de Producción: Aplicaciones críticas que requieren capacidad garantizada y optimización de costos.Optimización de Costos: Cargas de trabajo donde puedes comprometerte al uso por períodos extendidos para maximizar los ahorros. Spot: Son instancias que aprovechan la capacidad sobrante en los centros de datos del proveedor de la nube. Están disponibles con un descuento significativo en comparación con las instancias On-Demand, pero conllevan el riesgo de ser terminadas si el proveedor necesita la capacidad de nuevo. Son ideales para: Aplicaciones Sin Estado: Adecuadas para cargas de trabajo que pueden tolerar interrupciones, como trabajos de procesamiento por lotes, entornos de prueba y computación distribuida.Cargas de Trabajo Sensibles al Costo: Ideales para tareas donde los ahorros en costos son más importantes que la disponibilidad. On-Demand: Son instancias en un clúster de Kubernetes que operan con un modelo de precios fijo, proporcionando acceso confiable a recursos de cómputo sin riesgo de interrupciones. Se pueden usar para: Tareas Críticas: Aplicaciones que requieren tiempo de actividad constante, como bases de datos, sistemas financieros u otros servicios críticos.Tareas de Larga Duración: Tareas que no pueden interrumpirse sin consecuencias significativas. Orden de Prioridad: Cuando seleccionas múltiples tipos de nodos, el sistema los priorizará automáticamente en el siguiente orden para optimizar costos: Reserved (mejor precio con compromiso) → Spot (mejor precio sin compromiso) → On-Demand (precio más alto pero más flexible). Para obtener orientación detallada sobre cómo elegir los tipos de instancias correctos y evaluar la compatibilidad de aplicaciones, consulta Tipos de Instancias y Manejo de Nodos.  ¿Cuántos Node Pools puedo tener?​ El plan base de SleakOps te permite tener tres Node Pools adicionales, además de los Node Pools de build. Si necesitas más, contáctanos.  ¿Puedo convertir un Node Pool Spot en uno On-Demand y viceversa?​ No puedes convertir directamente un Node Pool Spot en uno On-Demand o viceversa, pero puedes lograr el resultado deseado siguiendo una serie de pasos en SleakOps. Así es como puedes hacer la transición entre tipos de Node Pools: Crea un Node Pool del nuevo tipo deseado.Actualiza tus Workloads y proyectos para que se ejecuten en el nuevo Node Pool.Elimina el Node Pool anterior si ya no es necesario.  ¿Puedo convertir un Node Pool ARM en uno X86 y viceversa?​ No puedes cambiar el tipo de arquitectura de un Node Pool, pero puedes lograr el resultado deseado siguiendo una serie de pasos en SleakOps. Así es como puedes hacer la transición entre arquitecturas de Node Pools: Crea un Node Pool de la nueva arquitectura deseada.Actualiza tus Workloads y proyectos para que se ejecuten en el nuevo Node Pool.Elimina el Node Pool anterior si ya no es necesario.  ¿Cómo creo un Node Pool?​ Sigue la guía Creando un Node Pool.  ¿Cómo gestiono un Node Pool?​ Sigue la guía Gestionando un Node Pool. ","version":"Next","tagName":"h2"},{"title":"Open Telemetry","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/addons/otel","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Open Telemetry","url":"/preview-docs/es/docs/cluster/addons/otel#faqs","content":" How it works​ In order to use OpenTelemetry, you need to have a project instrumented with OpenTelemetry. Sleakops will deploy the necessary resources to collect and store the data. Instrumentation is the process of adding code to your application to collect telemetry data. OpenTelemetry provides libraries to instrument your application in a variety of languages. Also Sleakops offers Autoinstrumentation for some languages, learn more about it in the section Autoinstrumentation.  Traces and Metrics​ Telemetry data consist of three main components: traces, metrics and logs. For logs Sleakops offers Loki. Traces are the path of a request through the system, while metrics are the values of the system at a given time. The OpenTelemetry addon collects traces from the pods running your project and sends them to the OpenTelemetry collector. The collector stores the traces throw Tempo . Traces could be visualized in Grafana. Also the collector generates metrics via the SpanMetrics Connector and stores them in Prometheus. A dashboard is available in Grafana for every project that gets instrumented.  Using the Addon​ Let's dive in with a view of the OpenTelemetry dashboard. First three metrics are Request rates, Error rates and Durations, or RED metrics. These metrics are the most important to monitor the health of your application. Then we see a table that list Top operations (endpoints) and their error rate as well. Tipically the dashboard gives a quick look to problematic endpoints, application performance bottlenecks, as well as the overall health of the application.  Autoinstrumentation​ Sleakops offers autoinstrumentation for some languages. This means that Sleakops will automatically instrument your project with OpenTelemetry. This is done by deploying an init container alongside your project. The sidecar container will collect the telemetry data and send it to the OpenTelemetry collector.  Manual instrumentation​ Manual instrumentation resolves the implementation through code of OpenTelemetry in your project. This is done by adding the OpenTelemetry libraries to your project and adding the necessary code to collect the telemetry data. Sleakops presents the endpoint where the telemetry data should be sent.  What does Sleakops install when installing OpenTelemetry​ The stack deployed when the addon is installed is the following: OpenTelemetry Operator OpenTelemetry Collector Custom resource (CRD)OpenTelemetry Instrumentation Custom resource (CRD) for every autoinstrumentated projectTempo with a frontend, and caching enabledS3 Bucket as Tempo Backend  ","version":"Next","tagName":"h2"},{"title":"Start using OpenTelemetry​","type":1,"pageTitle":"Open Telemetry","url":"/preview-docs/es/docs/cluster/addons/otel#start-using-opentelemetry","content":" To start using OpenTelemetry, you need to install the addon. Then go to the Project list page, activate the project Instrumentation using the small white icon at the left of the name of the project.    These are the options you can choose from:  Option\tDescriptionEnabled\tEnable or disable instrumentation on this proyect. Autoinstrumentation\tOpt for autoinstrumentation. Read more on Autoinstrumentation and Manual Instrumentation Language\tIf autoinstrumentation is enabled, this option marks the language of the project. Currently GO, Java, NodeJS, Python and DotNet are available. Sample Rate\tIf autoinstrumentation is enabled, this option marks the sampling rate, where 0 is none and 1 is all the traces.  Projects that are instrumented are visible in the Project list page. Marked with a green icon, as in the image:   ","version":"Next","tagName":"h2"},{"title":"Creando un Node Pool","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/nodepools/creating-nodepool","content":"","keywords":"","version":"Next"},{"title":"1. Accede a la configuración de tu clúster para acceder a la sección de Node Pools​","type":1,"pageTitle":"Creando un Node Pool","url":"/preview-docs/es/docs/cluster/nodepools/creating-nodepool#1-accede-a-la-configuración-de-tu-clúster-para-acceder-a-la-sección-de-node-pools","content":" Desde la lista de clústeres, selecciona uno y accede a la opción de Configuración. Luego, haz clic en la caja de Node Pools.    ","version":"Next","tagName":"h3"},{"title":"2. Haz clic en Crear​","type":1,"pageTitle":"Creando un Node Pool","url":"/preview-docs/es/docs/cluster/nodepools/creating-nodepool#2-haz-clic-en-crear","content":" En la sección de Node Pools, si tienes permisos, encontrarás la opción Crear en la esquina superior derecha. Haz clic en ella.  Ten en cuenta que la cantidad de Node Pools por clúster puede estar limitada según tu plan.    ","version":"Next","tagName":"h3"},{"title":"3. Configura tu Node Pool​","type":1,"pageTitle":"Creando un Node Pool","url":"/preview-docs/es/docs/cluster/nodepools/creating-nodepool#3-configura-tu-node-pool","content":" En el modal de creación de Node Pool, completa los siguientes campos:  Configuración\tDescripciónNombre\tIngresa el nombre de tu elección para tu Node Pool. No puede repetirse dentro de un clúster. Tipo de Instancia\tSelecciona uno o más tipos de instancias (ej. t3.medium, m5.large, c5.xlarge) basado en tus requisitos de cómputo. Puedes elegir múltiples tipos de instancias para proporcionar flexibilidad al autoscaler para provisionar la instancia disponible más rentable. Tipo de Nodo\tSelecciona uno o más modelos de facturación para tus instancias. Puedes elegir múltiples opciones, y el sistema las priorizará en el siguiente orden: Reserved (mejor precio con compromiso) → Spot (mejor precio sin compromiso) → On Demand (precio más alto pero más flexible). Consulta ¿Cuáles son los diferentes tipos de Node Pools?. Tipo de Arquitectura\tSelecciona el tipo de arquitectura a utilizar durante la creación de tus instancias: (64-Bit) ARM o (64-Bit) X86, según tus necesidades de rendimiento y compatibilidad. Luego podrás crear nuevas instancias usando una arquitectura diferente. Límite de Memoria\tEsto establece la memoria máxima que el clúster puede usar a medida que los servicios escalan. El autoscaler provisiona instancias basado en la demanda, pero esto no significa que el clúster siempre use la memoria máxima; simplemente define el límite superior para el autoscaler. Límite de CPU\tEsto establece la CPU máxima que el clúster puede usar a medida que los servicios escalan. El autoscaler provisiona instancias basado en la demanda, pero esto no significa que el clúster siempre use la CPU máxima; simplemente define el límite superior para el autoscaler. Almacenamiento\tConfigurado por defecto en 20GB, puedes modificarlo según tus necesidades. (Por Nodo) Memoria Mínima\tDefine la cantidad mínima de memoria que debe estar disponible en cada nodo antes de que el autoscaler considere el nodo como &quot;utilizado&quot;. Esta configuración ayuda a prevenir el sobre-aprovisionamiento asegurando que los nodos mantengan un buffer mínimo de memoria para procesos del sistema y picos inesperados de carga de trabajo. (Por Nodo) CPU Mínima\tDefine la cantidad mínima de CPU que debe estar disponible en cada nodo antes de que el autoscaler considere el nodo como &quot;utilizado&quot;. Esta configuración ayuda a prevenir el sobre-aprovisionamiento asegurando que los nodos mantengan un buffer mínimo de CPU para procesos del sistema y picos inesperados de carga de trabajo.  Una vez que hayas completado el formulario, haz clic en Crear para iniciar la creación del Node Pool en el clúster seleccionado. ","version":"Next","tagName":"h3"},{"title":"Tipos de Instancias y Manejo de Nodos","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/nodepools/instance-types","content":"","keywords":"","version":"Next"},{"title":"Tipos de Instancias Disponibles​","type":1,"pageTitle":"Tipos de Instancias y Manejo de Nodos","url":"/preview-docs/es/docs/cluster/nodepools/instance-types#tipos-de-instancias-disponibles","content":" ","version":"Next","tagName":"h2"},{"title":"1. Instancias Spot​","type":1,"pageTitle":"Tipos de Instancias y Manejo de Nodos","url":"/preview-docs/es/docs/cluster/nodepools/instance-types#1-instancias-spot","content":" Las instancias Spot aprovechan la capacidad no utilizada en los centros de datos de AWS, ofreciendo descuentos significativos (hasta 90% menos que On-Demand) pero con el riesgo de interrupción.  Características:  Costo: Hasta 90% de descuento vs On-DemandDisponibilidad: Variable, puede ser interrumpida con 2 minutos de avisoUso ideal: Aplicaciones tolerantes a fallos, procesamiento por lotes, entornos de desarrollo  ","version":"Next","tagName":"h3"},{"title":"2. Instancias On-Demand​","type":1,"pageTitle":"Tipos de Instancias y Manejo de Nodos","url":"/preview-docs/es/docs/cluster/nodepools/instance-types#2-instancias-on-demand","content":" Las instancias On-Demand proporcionan acceso inmediato y confiable a recursos de computación con precios fijos por hora o segundo.  Características:  Costo: Precio fijo, más alto que SpotDisponibilidad: Garantizada, sin riesgo de interrupciónUso ideal: Aplicaciones críticas, bases de datos, servicios de producción  ","version":"Next","tagName":"h3"},{"title":"3. Instancias Reserved​","type":1,"pageTitle":"Tipos de Instancias y Manejo de Nodos","url":"/preview-docs/es/docs/cluster/nodepools/instance-types#3-instancias-reserved","content":" Las instancias Reserved ofrecen descuentos significativos (hasta 75%) a cambio de un compromiso de uso por 1 o 3 años.  Características:  Costo: Hasta 75% de descuento con compromisoDisponibilidad: Garantizada para el período comprometidoUso ideal: Cargas de trabajo predecibles, entornos de producción estables  ","version":"Next","tagName":"h3"},{"title":"FAQs​","type":1,"pageTitle":"Tipos de Instancias y Manejo de Nodos","url":"/preview-docs/es/docs/cluster/nodepools/instance-types#faqs","content":" ¿Cómo evaluar si mi aplicación funciona en instancias Spot?​ Para determinar si tu aplicación es compatible con instancias Spot, evalúa los siguientes aspectos: ✅ Aplicaciones IDEALES para Spot: Stateless: No mantienen estado local críticoFault-tolerant: Pueden recuperarse de interrupcionesBatch processing: Tareas que se pueden reiniciarDevelopment/Testing: Entornos no críticosMicroservicios: Con circuit breakers y retry logicTested with FIS: Aplicaciones validadas con AWS Fault Injection Simulator para probar interrupciones de nodos ❌ Aplicaciones NO recomendadas para Spot: Aplicaciones de tiempo real: Que requieren latencia constanteProcesos largos: Que no pueden reiniciarse fácilmenteSistemas de pago: Que requieren alta disponibilidad  ¿Cuándo debo usar instancias On-Demand?​ Usa instancias On-Demand en los siguientes escenarios: Aplicaciones Críticas: Sistemas de pago y transacciones financierasAPIs de alta disponibilidad (99.9%+ SLA)Servicios de autenticación y autorización Cargas de Trabajo Específicas: Procesos que no pueden interrumpirseAplicaciones con requisitos de latencia estrictosSistemas legacy que no son fault-tolerantEntornos de producción sin redundancia Consideraciones de Costo: Cuando el costo de downtime supera el ahorro de SpotPara workloads con patrones de uso impredeciblesEn casos donde la capacidad garantizada es crítica ","version":"Next","tagName":"h2"},{"title":"Apagado del Cluster","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/shutdown-cluster","content":"","keywords":"","version":"Next"},{"title":"¿Cómo puedo activar esta funcionalidad?​","type":1,"pageTitle":"Apagado del Cluster","url":"/preview-docs/es/docs/cluster/shutdown-cluster#cómo-puedo-activar-esta-funcionalidad","content":" El Apagado del Cluster debe activarse manualmente en la configuración del cluster, a través de la tarjeta &quot;Apagado Programado&quot;.      Cuando configures el Apagado del Cluster, estarás creando dos cronjobs: uno para ENCENDER el cluster en el horario programado y otro para APAGARLO. Los campos de configuración son los siguientes:  Attribute\tDescriptionDays\tLos días en los que se ejecutarán los cronjobs de apagado. Auto Downtime (Local Time)\tLa hora a la que se ejecuta la acción de APAGADO. Se muestra en tu hora local. Auto Uptime (Local Time)\tLa hora a la que se ejecuta la acción de ENCENDIDO. Se muestra en tu hora local.  Debajo verás un cuadro que muestra las 'Generated Cron Expressions (UTC)', que despliega las expresiones cron de APAGADO y ENCENDIDO para estas dos acciones en horario UTC.  ","version":"Next","tagName":"h3"},{"title":"¿Cómo puedo apagar mi cluster en cualquier momento?​","type":1,"pageTitle":"Apagado del Cluster","url":"/preview-docs/es/docs/cluster/shutdown-cluster#cómo-puedo-apagar-mi-cluster-en-cualquier-momento","content":" Para apagar un cluster, simplemente haz clic en el botón Stop y confirma la acción.  Esta acción solo puede realizarse en clusters con estado Activo.  aviso El apagado requiere que no se estén actualizando Dependencies y que no haya procesos de build o ejecución activos.    ","version":"Next","tagName":"h2"},{"title":"Encender el cluster​","type":1,"pageTitle":"Apagado del Cluster","url":"/preview-docs/es/docs/cluster/shutdown-cluster#encender-el-cluster","content":" Para encender un cluster, haz clic en el botón Play y confirma la acción.  Esta acción está disponible para clusters con estado Apagado Programado o Apagado.    info Las acciones cron que encienden o apagan el cluster según el horario programado seguirán ejecutándose, incluso si lo has encendido o apagado manualmente. ","version":"Next","tagName":"h3"},{"title":"Gestionando un Node Pool","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/cluster/nodepools/managing-nodepool","content":"","keywords":"","version":"Next"},{"title":"1. Accede a la configuración de tu clúster para ingresar a la sección de Node Pools​","type":1,"pageTitle":"Gestionando un Node Pool","url":"/preview-docs/es/docs/cluster/nodepools/managing-nodepool#1-accede-a-la-configuración-de-tu-clúster-para-ingresar-a-la-sección-de-node-pools","content":" Desde la Lista de Clústeres, selecciona un Node Pool y accede a la opción de Configuración. Luego, haz clic en la caja de Node Pools.  ","version":"Next","tagName":"h3"},{"title":"2. Selecciona el Node Pool​","type":1,"pageTitle":"Gestionando un Node Pool","url":"/preview-docs/es/docs/cluster/nodepools/managing-nodepool#2-selecciona-el-node-pool","content":" Una vez que hayas seleccionado tu Node Pool, encontrarás las opciones para actualizar y eliminarlo. Cada Node Pool se muestra con barras de CPU y Memoria que indican cuánta capacidad queda disponible. La barra completa representa la capacidad total del Node Pool, mientras que la porción coloreada indica la capacidad combinada utilizada por todos los proyectos/workloads asociados.  ","version":"Next","tagName":"h3"},{"title":"Cambiar la configuración de un Node Pool​","type":1,"pageTitle":"Gestionando un Node Pool","url":"/preview-docs/es/docs/cluster/nodepools/managing-nodepool#cambiar-la-configuración-de-un-node-pool","content":" ","version":"Next","tagName":"h2"},{"title":"1. Haz clic en el botón de configuración en la parte superior derecha de la tarjeta del Node Pool​","type":1,"pageTitle":"Gestionando un Node Pool","url":"/preview-docs/es/docs/cluster/nodepools/managing-nodepool#1-haz-clic-en-el-botón-de-configuración-en-la-parte-superior-derecha-de-la-tarjeta-del-node-pool","content":" Actualiza los parámetros en el modal y haz clic en Guardar.    ","version":"Next","tagName":"h3"},{"title":"Eliminar un Node Pool​","type":1,"pageTitle":"Gestionando un Node Pool","url":"/preview-docs/es/docs/cluster/nodepools/managing-nodepool#eliminar-un-node-pool","content":" ","version":"Next","tagName":"h2"},{"title":"1. Haz clic en el botón de papelera en la parte superior derecha de la tarjeta del Node Pool​","type":1,"pageTitle":"Gestionando un Node Pool","url":"/preview-docs/es/docs/cluster/nodepools/managing-nodepool#1-haz-clic-en-el-botón-de-papelera-en-la-parte-superior-derecha-de-la-tarjeta-del-node-pool","content":" Haz clic en Eliminar para confirmar y activar la acción en SleakOps. ","version":"Next","tagName":"h3"},{"title":"Resumen","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/domain/setup","content":"","keywords":"","version":"Next"},{"title":"Configura tus dominios​","type":1,"pageTitle":"Resumen","url":"/preview-docs/es/docs/domain/setup#configura-tus-dominios","content":" ","version":"Next","tagName":"h2"},{"title":"1. Accede a la información del dominio o subdominio​","type":1,"pageTitle":"Resumen","url":"/preview-docs/es/docs/domain/setup#1-accede-a-la-información-del-dominio-o-subdominio","content":" SleakOps proporciona información detallada sobre dominios, subdominios y alias. Se ve así:    Para acceder a ella, hay diferentes maneras según lo que necesites hacer:  Si deseas delegar tu dominio principal​  a. Accede al Dashboard y busca el widget del dominio. b. Haz clic en el dominio deseado para mostrar el detalle.    Para delegar el subdominio de un Environment​  a. Accede a la lista de Environments y selecciona un Environment. b. Haz clic en el ícono de la nube para mostrar el detalle del dominio.  Crear un Alias para la ejecución de un servicio web y delegarlo​  a. Accede a la lista de Workloads y luego a la sección Web Services. b. Selecciona una ejecución y haz clic en el botón de tres puntos. c. Elige la opción Detalle. d. Crea el Alias si no existe haciendo clic en Asociar Nuevo Dominio y completa el formulario. e. Haz clic en el dominio del Alias para mostrar el detalle.      ","version":"Next","tagName":"h3"},{"title":"2. Actualiza los Name Servers con el registrador del dominio​","type":1,"pageTitle":"Resumen","url":"/preview-docs/es/docs/domain/setup#2-actualiza-los-name-servers-con-el-registrador-del-dominio","content":" Inicia sesión en la cuenta donde está registrado tu dominio (por ejemplo, GoDaddy, Namecheap, etc.).Localiza las configuraciones DNS de tu dominio.Reemplaza los registros existentes con los proporcionados.  ","version":"Next","tagName":"h3"},{"title":"3. Verifica la delegación​","type":1,"pageTitle":"Resumen","url":"/preview-docs/es/docs/domain/setup#3-verifica-la-delegación","content":" Los cambios de DNS pueden tardar algún tiempo en propagarse globalmente (usualmente dentro de unas horas).SleakOps verifica periódicamente, pero si deseas hacerlo manualmente, puedes hacer clic en el botón amarillo Check Delegation para activar el proceso.   ","version":"Next","tagName":"h3"},{"title":"Conectar tu Cuenta Git","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/connect_to_git","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Conectar tu Cuenta Git","url":"/preview-docs/es/docs/connect_to_git#preguntas-frecuentes","content":" ¿Puedo conectar más de una Cuenta Git?**​ Aún no está permitido.  ¿Cómo conecto mi cuenta?​ Accede a la sección Configuración &gt;&gt; Autorizaciones en SleakOps. Selecciona tu proveedor y concede acceso a SleakOps. Consulta los pasos a continuación.  ¿Puedo cambiar mi Cuenta Git?​ Sí, puedes hacerlo eliminando la existente y conectando la nueva. Asegúrate de que la nueva cuenta tenga acceso a los proyectos que usas en SleakOps.  ¿Cómo desconecto una cuenta?​ Haciendo clic en el botón X junto al proveedor Git. Ten en cuenta que los proyectos actuales continuarán funcionando, pero no podrán recibir actualizaciones una vez que se elimine esta integración. Si estás usando GitHub, también necesitarás eliminar la aplicación Sleakops de tu cuenta de GitHub para completar el proceso de eliminación.  ","version":"Next","tagName":"h2"},{"title":"Integraciones​","type":1,"pageTitle":"Conectar tu Cuenta Git","url":"/preview-docs/es/docs/connect_to_git#integraciones","content":" Github​  Gitlab​  Bitbucket​  GitLab Autohospedado​ Conectar una instancia de GitLab autohospedada requiere crear una aplicación OAuth en tu instalación de GitLab, ya que cada instancia autohospedada tiene una URL y sistema de autenticación únicos. Requisitos Previos​ Acceso de administrador a tu instancia de GitLab autohospedadaTu instancia de GitLab debe ser accesible desde internet (SleakOps necesita comunicarse con ella)Se recomienda encarecidamente usar HTTPS por seguridad Paso 1: Crear una Aplicación OAuth en Tu Instancia de GitLab​ Acceder a la página de Aplicaciones Navega a tu instancia de GitLab: https://tugitlab.com/-/profile/applicationsO ve a: Configuración de Usuario → Aplicaciones Crear una nueva aplicación Haz clic en &quot;Agregar nueva aplicación&quot; o &quot;Nueva aplicación&quot;Completa la siguiente información: Campo\tValorNombre\tSleakOps (o cualquier nombre descriptivo) URI de Redirección\thttps://api.sleakops.com/api/integrations/self-gitlab/callback/ Ámbitos\tSelecciona api y offline_access (requeridos para acceso persistente y renovación automática de tokens) aviso La URI de Redirección debe ser exactamente como se muestra a continuación (incluyendo la barra final): https://api.sleakops.com/api/integrations/self-gitlab/callback/ No modifiques esta URL. Guardar la aplicación Haz clic en &quot;Guardar aplicación&quot; o &quot;Enviar&quot;Se te mostrarán dos valores importantes: ID de Aplicación (Client ID)Secreto (Client Secret) precaución Copia inmediatamente el ID de Aplicación y el Secreto. El Secreto solo se mostrará una vez y no podrá recuperarse después. tip Guarda estas credenciales de forma segura. Si pierdes el Secreto, necesitarás regenerar la aplicación OAuth. Paso 2: Conectar Tu GitLab Autohospedado a SleakOps​ Navegar a Autorizaciones de SleakOps Inicia sesión en tu cuenta de SleakOpsVe a Configuración → Autorizaciones Seleccionar GitLab Autohospedado Haz clic en la opción de integración &quot;GitLab Autohospedado&quot; Ingresar los detalles de tu aplicación OAuth URL de Instancia GitLab: Ingresa la URL de tu instancia de GitLab (ej., https://gitlab.tuempresa.com) No incluyas una barra finalDebe comenzar con http:// o https:// ID de Aplicación: Pega el ID de Aplicación del Paso 1Secreto de Aplicación: Pega el Secreto del Paso 1 Autorizar SleakOps Haz clic en &quot;Conectar&quot; o &quot;Autorizar&quot;Serás redirigido a tu instancia de GitLabRevisa los permisos y haz clic en &quot;Autorizar&quot;Serás redirigido de vuelta a SleakOps Verificar la conexión Una vez redirigido, deberías ver tu cuenta de GitLab autohospedada listada como conectadaAhora puedes seleccionar repositorios de tu instancia de GitLab autohospedada al crear proyectos ¿Qué permisos necesita SleakOps?​ SleakOps requiere dos ámbitos: Ámbito api otorga los siguientes permisos: Leer información del repositorio y contenido de archivosCrear y administrar ramasCrear y actualizar archivos (para despliegues automatizados)Crear merge requestsAcceder a información de commits Ámbito offline_access permite a SleakOps: Obtener un refresh token para acceso a largo plazoRenovar automáticamente tokens de acceso expiradosMantener conexión persistente sin requerir re-autorización aviso Sin offline_access, el token de acceso expirará después de ~2 horas y la integración se romperá hasta ser re-autorizada manualmente. Estos permisos son necesarios para que SleakOps pueda clonar tus repositorios, construir imágenes de contenedores, desplegar aplicaciones y administrar infraestructura como código. Solución de Problemas​ La conexión falla con error &quot;URL Inválida&quot;​ Asegúrate de que la URL de tu instancia de GitLab no termine con una barra finalVerifica que la URL comience con http:// o https://Ejemplo: ✅ https://gitlab.empresa.com ❌ https://gitlab.empresa.com/ La autorización redirige pero la conexión falla​ Verifica que la URI de Redirección en tu aplicación OAuth de GitLab coincida exactamente: https://api.sleakops.com/api/integrations/self-gitlab/callback/Verifica que el ID de Aplicación y el Secreto sean correctosAsegúrate de que ambos ámbitos api y offline_access fueron seleccionados al crear la aplicación OAuth Problemas de Red/Firewall​ Asegúrate de que tu instancia de GitLab autohospedada sea accesible desde los servidores de SleakOpsSi tu GitLab está detrás de un firewall, podrías necesitar agregar las direcciones IP de SleakOps a la lista blancaContacta al soporte de SleakOps para información sobre las IP de la lista blanca Errores de SSL/Certificado​ Los certificados autofirmados pueden causar problemas de conexiónUsa un certificado SSL válido de una autoridad certificadora confiableAsegúrate de que tu instancia de GitLab tenga una configuración HTTPS adecuada  ","version":"Next","tagName":"h2"},{"title":"Configurar tu Cuenta Git​","type":1,"pageTitle":"Conectar tu Cuenta Git","url":"/preview-docs/es/docs/connect_to_git#configurar-tu-cuenta-git","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navega a la sección de autorización de Git​","type":1,"pageTitle":"Conectar tu Cuenta Git","url":"/preview-docs/es/docs/connect_to_git#1-navega-a-la-sección-de-autorización-de-git","content":" En el Panel Izquierdo, accede a la opción Configuración y luego haz clic en Autorizaciones.    ","version":"Next","tagName":"h3"},{"title":"2. Selecciona tu Proveedor Git y concede acceso a SleakOps​","type":1,"pageTitle":"Conectar tu Cuenta Git","url":"/preview-docs/es/docs/connect_to_git#2-selecciona-tu-proveedor-git-y-concede-acceso-a-sleakops","content":" Haz clic en tu proveedor y sigue los pasos requeridos para cada uno para conceder acceso.   ","version":"Next","tagName":"h3"},{"title":"Niveles de Dominio y Estrategias","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/domain","content":"","keywords":"","version":"Next"},{"title":"Descripción General​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#descripción-general","content":"     ","version":"Next","tagName":"h2"},{"title":"1. Dominio del Proveedor (Nivel Raíz)​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#1-dominio-del-proveedor-nivel-raíz","content":" Qué es: El dominio raíz de tu organización.  Ejemplo: sleakops.com  Lo que Sleakops crea:  ✅ Zona Alojada de AWS✅ Certificado SSL  Caso de uso:Establece la infraestructura principal de tu dominio. Todos los entornos y servicios se organizarán bajo este dominio.  Cuándo usarlo:  Configurando Sleakops por primera vezGestionando el dominio principal de tu organización    ","version":"Next","tagName":"h2"},{"title":"2. Dominio del Entorno (Nivel de Subdominio)​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#2-dominio-del-entorno-nivel-de-subdominio","content":" Qué es: Subdominios que representan diferentes entornos.  Ejemplos:  qa.sleakops.comstaging.sleakops.comprod.sleakops.com  Lo que Sleakops crea:  ✅ Zona Alojada de AWS✅ Certificado SSL  Caso de uso:Aislar y organizar tus entornos de despliegue. Cada entorno obtiene su propio subdominio con gestión DNS independiente.  Cuándo usarlo:  Crear entornos separados (desarrollo, staging, producción)Aislar equipos o proyectosGestionar múltiples etapas de despliegue    ","version":"Next","tagName":"h2"},{"title":"3. Dominio del Webservice (Auto-generado)​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#3-dominio-del-webservice-auto-generado","content":" Qué es: Asignación automática de dominio para cada webservice.  Patrón: [nombre-webservice].[dominio-entorno]  Ejemplo:  Nombre del webservice: apiEntorno: qa.sleakops.comResultado: api.qa.sleakops.com  Lo que Sleakops crea:  ✅ Registro CNAME (agregado automáticamente a la zona alojada del entorno)✅ Apunta al Application Load Balancer (ALB)  Caso de uso:Configuración de dominio sin configuración. Cada servicio obtiene automáticamente un dominio jerárquico y predecible.  Cuándo usarlo:  Escenario predeterminado para todos los webservicesCuando quieres URLs consistentes y predeciblesDespliegues rápidos sin configuración de dominio personalizada    ","version":"Next","tagName":"h2"},{"title":"4. Dominios Alias (Nivel Personalizado)​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#4-dominios-alias-nivel-personalizado","content":" Qué es: Dominios personalizados fuera de tu jerarquía estándar.  Ejemplos:  api.dominio-externo.comwww.miempresa.iocualquiera.com  Lo que hace Sleakops:  ","version":"Next","tagName":"h2"},{"title":"Escenario A: El dominio coincide con una zona alojada existente​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#escenario-a-el-dominio-coincide-con-una-zona-alojada-existente","content":" Si dominio-externo.com ya es un Proveedor o Entorno en Sleakops:  ✅ Proporciona registros DNS para validación de certificado SSL✅ Proporciona nombre ALB para configuración DNS⚠️ Tú configuras los registros DNS por tu cuenta  ","version":"Next","tagName":"h3"},{"title":"Escenario B: El dominio no coincide con ninguna zona alojada​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#escenario-b-el-dominio-no-coincide-con-ninguna-zona-alojada","content":" Si cualquiera.com es completamente externo:  ✅ Crea certificado SSL✅ Proporciona registros de validación para el certificado✅ Proporciona nombre ALB para configuración DNS⚠️ Tú gestionas el DNS en tu proveedor de dominios  Caso de uso:  Dominios de marca personalizadosDominios externos apuntando a tus serviciosURLs de marketing o vanidadServicios multi-dominio  Cuándo usarlo:  El dominio predeterminado del webservice no se ajusta a tus necesidadesNecesitas múltiples dominios para el mismo servicioConectar dominios externos a tus servicios de Sleakops    ","version":"Next","tagName":"h3"},{"title":"Estrategias de Delegación​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#estrategias-de-delegación","content":" Sleakops ofrece tres enfoques de delegación, dándote flexibilidad basada en tus necesidades de infraestructura y políticas organizacionales.  ","version":"Next","tagName":"h2"},{"title":"Estrategia A: Delegación Completa (Recomendada)​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#estrategia-a-delegación-completa-recomendada","content":" Delegar el Proveedor (dominio raíz) y dejar que Sleakops gestione todo    Lo que delegas:​  Servidores de nombres del dominio del Proveedor a AWS Route 53  Lo que Sleakops gestiona automáticamente:  ✅ Todos los dominios del entorno (zonas alojadas + certificados SSL)✅ Todos los dominios de webservice (registros CNAME + enrutamiento)✅ Propagación DNS y validación✅ Ciclo de vida completo del certificado SSL  Beneficios:  🚀 Configuración DNS cero después de la delegación inicial🔒 Gestión automatizada de certificados SSL🎯 Infraestructura completamente gestionada⚡ Experiencia de despliegue más rápida  Mejor para:  Nuevos proyectos empezando desde ceroEquipos que quieren mínima sobrecarga DNSOrganizaciones que adoptan soluciones completamente gestionadasStartups y equipos que se mueven rápido  Configuración:  Delegar tu dominio raíz (ej., sleakops.com) a Sleakops Todo lo demás es automático    ","version":"Next","tagName":"h3"},{"title":"Estrategia B: Delegación Por Entorno​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#estrategia-b-delegación-por-entorno","content":" Delegar dominios de entorno individuales mientras mantienes el control del dominio raíz    Lo que delegas:​  Servidores de nombres de dominios de entorno individuales (ej., qa.sleakops.com, prod.sleakops.com)  Lo que Sleakops gestiona automáticamente:  ✅ Todos los dominios de webservice dentro de entornos delegados✅ Certificados SSL para entornos delegados✅ Registros DNS dentro de zonas delegadas  Lo que tú gestionas:  ⚙️ DNS del dominio raíz⚙️ Registros NS apuntando a cada entorno  Beneficios:  🎛️ Control del dominio raíz para otros propósitos (email, sitios de marketing, etc.)🔒 Gestión aislada de entornos✅ DNS automático de webservice dentro de cada entorno🏢 Cumplimiento con políticas DNS organizacionales  Mejor para:  Organizaciones con infraestructura de dominio raíz existenteEquipos que necesitan dominio raíz para servicios no-SleakopsMigración gradual a SleakopsOrganizaciones multi-equipo con aislamiento a nivel de entorno  Configuración:  Mantener tu dominio raíz (ej., sleakops.com) gestionado externamente Delegar cada entorno (ej., qa.sleakops.com) a Sleakops Agregar registros NS en tu DNS de dominio raíz para cada entorno    ","version":"Next","tagName":"h3"},{"title":"Estrategia C: Control Completo (Gestión Manual)​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#estrategia-c-control-completo-gestión-manual","content":" Retener control DNS completo y configurar manualmente todos los registros    Lo que delegas:​  Nada - tú gestionas todo el DNS  Lo que Sleakops proporciona:  📋 Registros DNS para validación de certificado SSL📋 Endpoints ALB para enrutamiento de tráfico  Lo que tú gestionas:  ⚙️ Todas las zonas DNS y registros⚙️ Registros de validación de certificados⚙️ Registros CNAME apuntando al ALB⚙️ Todas las actualizaciones y cambios DNS  Beneficios:  🎛️ Control completo de infraestructura DNS🔐 Mantener DNS dentro de límites de seguridad existentes📊 Integración con monitoreo DNS existente🏢 Cumplir requisitos estrictos de cumplimiento  Mejor para:  Organizaciones con gobernanza DNS estrictaInfraestructura DNS compleja existentePolíticas de seguridad que requieren aislamiento DNSEmpresas con equipos DNS dedicados  Configuración:  Crear dominios en Sleakops (sin delegación) Sleakops proporciona registros de validación y endpoints ALB Agregar manualmente todos los registros DNS requeridos en tu proveedor DNS    ","version":"Next","tagName":"h3"},{"title":"Comparación de Estrategias de Delegación​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#comparación-de-estrategias-de-delegación","content":" Aspecto\tDelegación Completa\tPor Entorno\tControl CompletoComplejidad de Configuración\t⭐ Más Fácil\t⭐⭐ Moderada\t⭐⭐⭐ Compleja Mantenimiento Continuo\t⭐ Ninguno\t⭐⭐ Mínimo\t⭐⭐⭐ Alto Flexibilidad\t⭐⭐ Limitada\t⭐⭐⭐ Equilibrada\t⭐⭐⭐⭐ Máxima Tiempo de Despliegue\t⚡ Instantáneo\t⚡⚡ Minutos\t⚡⚡⚡ Manual Control DNS\tSleakops\tCompartido\tTú Mejor para Equipos\tPequeño-Mediano\tMediano-Grande\tEmpresarial    ","version":"Next","tagName":"h3"},{"title":"Patrones de Organización de Dominios​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#patrones-de-organización-de-dominios","content":" ","version":"Next","tagName":"h2"},{"title":"Patrón 1: Jerarquía Estándar (Funciona con cualquier estrategia de delegación)​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#patrón-1-jerarquía-estándar-funciona-con-cualquier-estrategia-de-delegación","content":"   Beneficios:  Separación clara de entornosFácil de entender y gestionarSSL y DNS automáticos    ","version":"Next","tagName":"h3"},{"title":"Patrón 2: Jerarquía Mixta con Dominios Personalizados​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#patrón-2-jerarquía-mixta-con-dominios-personalizados","content":"   Beneficios:  Dominios profesionales cara al clienteMantiene estructura internaFlexibilidad para etiquetado blancoRequiere DNS manual para alias (todas las estrategias)    ","version":"Next","tagName":"h3"},{"title":"Patrón 3: Entorno por Equipo/Proyecto​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#patrón-3-entorno-por-equipoproyecto","content":"   Beneficios:  Propiedad clara del equipoGestión DNS independiente por equipoEscalable para organizaciones grandes    ","version":"Next","tagName":"h3"},{"title":"Guía de Decisión Rápida​","type":1,"pageTitle":"Niveles de Dominio y Estrategias","url":"/preview-docs/es/docs/domain#guía-de-decisión-rápida","content":" Necesidad\tEstrategia RecomendadaConfiguración más rápida\tDelegación Completa Mantener raíz para email/otros servicios\tDelegación Por Entorno Máximo control DNS\tControl Completo Migración gradual\tDelegación Por Entorno Cumplimiento estricto\tControl Completo Proyecto nuevo\tDelegación Completa Empresa con equipo DNS\tControl Completo o Por Entorno  Tarea\tHerramientaConfiguración inicial\tDominio del Proveedor Crear nuevo entorno\tDominio del Entorno Desplegar un servicio\tWebservice (automático) URL de marca personalizada\tDominio Alias Integración de dominio externo\tDominio Alias Solución de etiqueta blanca\tDominio Alias ","version":"Next","tagName":"h2"},{"title":"Entorno","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/environment","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Entorno","url":"/preview-docs/es/docs/environment#preguntas-frecuentes","content":" ¿Cómo puedo diseñar mis Entornos?​ Los Entornos pueden adaptarse en función del ciclo de vida de una aplicación o las necesidades de diferentes equipos. Por ejemplo, crear Environments para desarrollo (dev), aseguramiento de calidad (QA), pruebas (stg) y producción (prod) permite que cada uno tenga configuraciones personalizadas adecuadas a sus roles específicos. Antes de crear un Entorno, lee Diseñando tu Infraestructura: Esquema Simple vs. Esquema Múltiple.  ¿Puedo editar un Entorno?​ No. Debes eliminarlo y crear uno nuevo.  ¿Cómo elimino un Entorno?​ Accede a la Lista de Entornos, en la columna de Acciones, haz clic en el ícono de papelera. Luego confirma la acción.  ¿Cómo puedo delegar un dominio?​ Sigue: Delegar Dominios.  Configuración DNS Requerida Antes de continuar, debes delegar manualmente tu servicio DNS al Route53 Principal de SleakOps. Sin este paso, ¡tu Environment no funcionará correctamente! Sigue la guía oficial de AWS Verifica la delegación antes de crear tu Environment  ","version":"Next","tagName":"h2"},{"title":"Configura tu Entorno​","type":1,"pageTitle":"Entorno","url":"/preview-docs/es/docs/environment#configura-tu-entorno","content":" 1. Navega a la sección de Entornos​  En el Panel Izquierdo, accede a la opción Entornos y luego, en la esquina superior derecha, haz clic en el botón Crear.    2. Configura tu Entorno​  Con tu Account seleccionada, accederás al siguiente formulario:    Configuración\tDescripciónNombre\tDefine un nombre para tu Entorno utilizando letras en minúscula y guiones medios. Cluster\tSelecciona uno de los clústeres disponibles para alojar el nuevo Entorno. Dominio\tEspecifica el dominio para tu Entorno.  Una vez que hayas completado el formulario, haz clic en Crear para iniciar la creación del Entorno en el clúster seleccionado. ","version":"Next","tagName":"h2"},{"title":"Guía de Delegación de Dominios","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/domain/delegation","content":"","keywords":"","version":"Next"},{"title":"Descripción General​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#descripción-general","content":" Cuando Sleakops crea una zona alojada, necesitas delegar el dominio actualizando los registros DNS en tu proveedor de dominios (registrador). Esta guía explica el proceso para cada nivel de dominio.    ","version":"Next","tagName":"h2"},{"title":"Delegación de Dominio del Proveedor​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#delegación-de-dominio-del-proveedor","content":" ","version":"Next","tagName":"h2"},{"title":"Qué estás delegando​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#qué-estás-delegando","content":" Tu dominio raíz (por ejemplo, sleakops.com) a AWS Route 53 a través de Sleakops.    ","version":"Next","tagName":"h3"},{"title":"Pasos​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#pasos","content":" Crear el dominio del Proveedor en Sleakops Sleakops crea una zona alojada en AWS Route 53Verás una tabla con 4 registros de servidor de nombres (NS) Localizar los servidores de nombres  ns-123.awsdns-12.com ns-456.awsdns-45.net ns-789.awsdns-78.org ns-012.awsdns-01.co.uk   Actualizar tu registrador de dominio Inicia sesión en tu registrador de dominio (GoDaddy, Namecheap, Google Domains, etc.)Busca la configuración DNS o de Servidores de nombresReemplaza los servidores de nombres existentes con los 4 servidores de nombres de AWS de SleakopsGuardar cambios Verificar delegación Hacer clic en el botón &quot;Verificar Delegación&quot; en SleakopsEsperar la propagación DNS (puede tomar hasta 48 horas, usualmente más rápido)La marca verde indica delegación exitosa  ","version":"Next","tagName":"h3"},{"title":"Registradores Comunes​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#registradores-comunes","content":" GoDaddy Ve a Administrador de DominiosHaz clic en tu dominioDesplázate hasta &quot;Servidores de nombres&quot; → Haz clic en &quot;Cambiar&quot;Selecciona &quot;Ingresar mis propios servidores de nombres (avanzado)&quot;Agrega los 4 servidores de nombres de AWSGuardar  Namecheap Ve a Lista de DominiosHaz clic en &quot;Administrar&quot; junto a tu dominioSelecciona &quot;DNS Personalizado&quot; bajo Servidores de nombresAgrega los 4 servidores de nombres de AWSHaz clic en la marca verde  Cloudflare Nota: Si usas Cloudflare, debes deshabilitar el proxy de Cloudflare para una delegación adecuada. Remover el dominio de Cloudflare, OActualizar servidores de nombres a AWS (elimina la gestión DNS de Cloudflare)    ","version":"Next","tagName":"h3"},{"title":"Delegación de Dominio del Entorno​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#delegación-de-dominio-del-entorno","content":" ","version":"Next","tagName":"h2"},{"title":"Qué estás delegando​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#qué-estás-delegando-1","content":" Un subdominio (por ejemplo, qa.sleakops.com) a su propia zona alojada.    ","version":"Next","tagName":"h3"},{"title":"Dos Escenarios​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#dos-escenarios","content":" Escenario A: El dominio padre ES administrado por Sleakops​    ¡Buenas noticias! Sleakops crea automáticamente los registros NS en la zona alojada padre.  ✅ No se requiere acción - la delegación es automática    Escenario B: El dominio padre NO es administrado por Sleakops​    Si sleakops.com se administra fuera de Sleakops, pero quieres qa.sleakops.com en Sleakops:  Crear el dominio del Entorno en Sleakops Sleakops crea una zona alojadaVerás 4 registros de servidor de nombres Agregar registros NS al dominio padre Ve a donde se administra el DNS de sleakops.com (registrador, Cloudflare, etc.)Crear 4 registros NS para el subdominio:  Tipo de Registro: NS Nombre: qa Valor: ns-123.awsdns-12.com Tipo de Registro: NS Nombre: qa Valor: ns-456.awsdns-45.net (repetir para los 4 servidores de nombres)   Verificar delegación Hacer clic en &quot;Verificar Delegación&quot; en SleakopsEsperar la propagación DNS (usualmente 5-30 minutos)    ","version":"Next","tagName":"h3"},{"title":"Configuración de Dominio del Webservice​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#configuración-de-dominio-del-webservice","content":" ","version":"Next","tagName":"h2"},{"title":"Qué sucede​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#qué-sucede","content":" Los dominios de webservice (por ejemplo, api.qa.sleakops.com) se configuran automáticamente.    ✅ No se necesita delegación - Sleakops automáticamente:  Crea registro CNAME en la zona alojada del entornoApunta al Application Load Balancer (ALB)Configura certificado SSL  ¡No necesitas hacer nada!    ","version":"Next","tagName":"h3"},{"title":"Configuración de Dominio Alias​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#configuración-de-dominio-alias","content":" Los dominios alias requieren configuración DNS manual en tu proveedor de dominio.  ","version":"Next","tagName":"h2"},{"title":"Escenario A: El alias coincide con una zona alojada existente​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#escenario-a-el-alias-coincide-con-una-zona-alojada-existente","content":" Ejemplo: Tu alias es api.external.com y ya tienes external.com como Proveedor o Entorno en Sleakops.    Para Validación de Certificado SSL​  Sleakops proporciona registros de validación Verás registros CNAME para validación de certificadoEjemplo:  _acme-challenge.api.external.com → _validation123.acme.aws.com   Agregar registros de validación a tu DNS Ve a la zona alojada de external.com (en Sleakops o donde sea que se administre)Agrega los registros CNAME exactamente como se muestraEsperar validación del certificado (usualmente 5-15 minutos)  Para Enrutamiento de Tráfico​  Sleakops proporciona endpoint ALB Verás el nombre DNS del ALB:  ALB: my-alb-123456.us-east-1.elb.amazonaws.com   Crear registro CNAME Ve a tu administración DNS para external.comCrear un registro CNAME:  Tipo de Registro: CNAME Nombre: api Valor: my-alb-123456.us-east-1.elb.amazonaws.com TTL: 300   Verificar Probar el dominio: curl https://api.external.comDebería devolver la respuesta de tu servicio    ","version":"Next","tagName":"h3"},{"title":"Escenario B: El alias no coincide con ninguna zona alojada​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#escenario-b-el-alias-no-coincide-con-ninguna-zona-alojada","content":" Ejemplo: Tu alias es anything.com y este dominio no se administra en Sleakops.    Para Certificado SSL​  Sleakops crea certificado SSL Se proporcionan registros de validación de certificadoEjemplo:  _acme-challenge.anything.com → _validation456.acme.aws.com   Agregar registros de validación Inicia sesión en tu proveedor de dominio para anything.comAgregar los registros CNAME para validación de certificadoEsperar validación (5-15 minutos)  Para Enrutamiento de Tráfico​  Sleakops proporciona endpoint ALB  ALB: my-alb-789012.us-east-1.elb.amazonaws.com   Configurar DNS en tu proveedor Opción 1: CNAME (para subdominios)  Tipo de Registro: CNAME Nombre: www (o subdominio) Valor: my-alb-789012.us-east-1.elb.amazonaws.com   Opción 2: Registro A con ALIAS (para dominio raíz)  Algunos proveedores soportan registros ALIAS (Route 53, Cloudflare)  Tipo de Registro: A (ALIAS) Nombre: @ (raíz) Valor: my-alb-789012.us-east-1.elb.amazonaws.com   Opción 3: Registro A con IP (no recomendado)  Buscar IPs del ALB y crear registros A⚠️ Las IPs pueden cambiar - usa CNAME cuando sea posible  Verificar Probar: curl https://anything.comAsegurar que el certificado SSL sea válido    ","version":"Next","tagName":"h3"},{"title":"Lista de Verificación​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#lista-de-verificación","content":" ","version":"Next","tagName":"h2"},{"title":"Dominio Proveedor/Entorno​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#dominio-proveedorentorno","content":"  Servidores de nombres actualizados en el registrador &quot;Verificar Delegación&quot; botón muestra éxito La búsqueda DNS devuelve servidores de nombres correctos: dig NS tudominio.com  ","version":"Next","tagName":"h3"},{"title":"Dominio Webservice​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#dominio-webservice","content":"  Webservice desplegado y funcionando Dominio resuelve: curl https://api.qa.sleakops.com Certificado SSL válido (sin advertencias del navegador) La búsqueda DNS devuelve CNAME correcto: dig CNAME api.qa.sleakops.com  ","version":"Next","tagName":"h3"},{"title":"Dominio Alias​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#dominio-alias","content":"  Registros de validación de certificado agregados Certificado muestra como validado en Sleakops Registro CNAME/A apunta al ALB Dominio resuelve: curl https://tu-alias.com La búsqueda DNS devuelve CNAME correcto: dig CNAME tu-alias.com Certificado SSL válido    ","version":"Next","tagName":"h3"},{"title":"Resolución de Problemas​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#resolución-de-problemas","content":" ","version":"Next","tagName":"h2"},{"title":"\"Verificar Delegación\" falla​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#verificar-delegación-falla","content":"   Problema: Servidores de nombres no delegados correctamente  Soluciones:  Verificar que agregaste TODOS los 4 servidores de nombresRevisar errores tipográficos en los valores de los servidores de nombresEsperar más tiempo (la propagación DNS puede tomar hasta 48 horas)Limpiar caché DNS: dig @8.8.8.8 tudominio.comVerificar en el registrador que los cambios fueron guardados    ","version":"Next","tagName":"h3"},{"title":"Validación de certificado atascada​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#validación-de-certificado-atascada","content":" Problema: Certificado SSL no se valida  Soluciones:  Verificar que los registros CNAME se agregaron correctamente (sin puntos extra, valores correctos)Revisar que el TTL no haya expiradoRemover cualquier registro DNS en conflictoEsperar 15-30 minutos para propagación DNSRevisar DNS: dig _acme-challenge.tudominio.com    ","version":"Next","tagName":"h3"},{"title":"Dominio no resuelve​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#dominio-no-resuelve","content":" Problema: El dominio no carga tu servicio  Soluciones:  Verificar que el registro CNAME/A apunte al endpoint ALB correctoRevisar que el ALB esté saludable y recibiendo tráficoVerificar que el webservice esté desplegado y funcionandoProbar con curl -v https://tudominio.com para errores detalladosRevisar que los grupos de seguridad permitan tráfico en el puerto 443    ","version":"Next","tagName":"h3"},{"title":"Errores de certificado SSL en el navegador​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#errores-de-certificado-ssl-en-el-navegador","content":" Problema: El navegador muestra &quot;No Seguro&quot; o advertencias de certificado  Soluciones:  Verificar que el certificado esté validado en SleakopsRevisar que el certificado incluya tu nombre de dominioLimpiar caché del navegadorVerificar que el certificado correcto esté adjunto al listener del ALBRevisar que el certificado no haya expirado    ","version":"Next","tagName":"h3"},{"title":"Tiempo de Propagación DNS​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#tiempo-de-propagación-dns","content":" Tipo de Cambio\tTiempo Típico\tTiempo MáximoActualización de servidor de nombres\t15-30 minutos\t48 horas Registro CNAME\t5-15 minutos\t24 horas Registro A\t5-15 minutos\t24 horas Validación de certificado\t5-15 minutos\t30 minutos  💡 Consejo: Usa https://dnschecker.org para verificar la propagación DNS globalmente    ","version":"Next","tagName":"h2"},{"title":"¿Necesitas Ayuda?​","type":1,"pageTitle":"Guía de Delegación de Dominios","url":"/preview-docs/es/docs/domain/delegation#necesitas-ayuda","content":" Revisa Niveles de Dominio y EstrategiasContacta al soporte de Sleakops con los detalles de configuración de tu dominio ","version":"Next","tagName":"h2"},{"title":"Empezando","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/gettingstarted","content":"","keywords":"","version":"Next"},{"title":"Inicia sesión con tu correo electrónico​","type":1,"pageTitle":"Empezando","url":"/preview-docs/es/docs/gettingstarted#inicia-sesión-con-tu-correo-electrónico","content":" Inicia sesión en nuestra aplicación web.    info En caso de que no tengas una cuenta con nosotros, necesitas suscribirte a través de AWS. Sigue la guía en Cómo suscribirse a SleakOps usando AWS .  ","version":"Next","tagName":"h2"},{"title":"Requisitos para Unirse​","type":1,"pageTitle":"Empezando","url":"/preview-docs/es/docs/gettingstarted#requisitos-para-unirse","content":" Necesitas tener un usuario root en AWS. Este es el usuario inicial creado con permisos completos para gestionar todos los recursos y servicios, y sirve como cuenta principal para AWS Organizations. Ir a AWS Organizations .Necesitas acceso a tus repositorios de código (GitLab, Bitbucket o GitHub).Necesitas tener tus servicios en archivos Docker.Necesitas poder gestionar tus dominios. ","version":"Next","tagName":"h3"},{"title":"Networking y Recursos de Red","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/network","content":"","keywords":"","version":"Next"},{"title":"1. Descripción general de la arquitectura​","type":1,"pageTitle":"Networking y Recursos de Red","url":"/preview-docs/es/docs/network#1-descripción-general-de-la-arquitectura","content":" La infraestructura de red en SleakOps se basa en los siguientes componentes principales:  VPC (Virtual Private Cloud): Segmenta la red por entorno (Management, Production, Development).Subredes: Públicas: expuestas a Internet.Privadas: acceso restringido, acceden a Internet a través de un NAT Gateway.Persistencia: bases de datos, almacenamiento. Internet Gateway: Permite la comunicación entre la VPC y el exterior (Internet).Route Tables: Definen las rutas de tráfico entre subredes y hacia/desde Internet.Security Groups: Firewalls virtuales que controlan el tráfico de entrada y salida de los recursos.DNS Interno: Permite que los recursos se comuniquen usando nombres en vez de IPs.External-DNS: Servicio que corre dentro de cada clúster Kubernetes (EKS), encargado de gestionar automáticamente los registros DNS públicos en Route53 para los servicios expuestos desde el clúster.  ","version":"Next","tagName":"h2"},{"title":"2. Flujo típico de comunicación​","type":1,"pageTitle":"Networking y Recursos de Red","url":"/preview-docs/es/docs/network#2-flujo-típico-de-comunicación","content":" El siguiente es un ejemplo de cómo viaja el tráfico en la red de SleakOps:  Acceso desde Internet: Un usuario accede a un servicio expuesto (por ejemplo, una API). El tráfico llega al Internet Gateway y es dirigido a la subred pública. Control de acceso: El Security Group asociado al recurso valida si la conexión está permitida. Comunicación interna: Los servicios internos (en subredes privadas o de persistencia) pueden comunicarse entre sí usando el DNS interno, siempre bajo las reglas de los Security Groups. Exposición de servicios: Si un servicio dentro del clúster Kubernetes debe ser accesible desde Internet (por ejemplo, una API), se expone a través de un Application Load Balancer y External-DNS se encarga de registrar automáticamente el nombre en Route53.  Esta segmentación y control aseguran que solo los servicios necesarios sean expuestos y que los datos sensibles permanezcan protegidos.    ","version":"Next","tagName":"h2"},{"title":"3. External-DNS y Route53​","type":1,"pageTitle":"Networking y Recursos de Red","url":"/preview-docs/es/docs/network#3-external-dns-y-route53","content":" Se utiliza una solución automatizada para gestionar los registros DNS públicos de los servicios desplegados, integrando la infraestructura con servicios de DNS externos como Route53.  External-DNS no expone servicios directamente, sino que automatiza la gestión de registros DNS públicos para recursos ya expuestos (por ejemplo, mediante un Application Load Balancer).Esto permite que los servicios sean accesibles de forma segura y sencilla desde Internet.  ","version":"Next","tagName":"h2"},{"title":"4. Conectividad entre entornos mediante VPC Peering​","type":1,"pageTitle":"Networking y Recursos de Red","url":"/preview-docs/es/docs/network#4-conectividad-entre-entornos-mediante-vpc-peering","content":" Para permitir la comunicación controlada entre entornos (por ejemplo, entre Management y Production), SleakOps configura conexiones VPC Peering de manera explícita entre las VPCs de los distintos entornos.  Un VPC Peering permite que dos VPCs puedan intercambiar tráfico interno como si estuvieran en la misma red.No requiere pasar por Internet, NAT Gateway ni VPN.Es una conexión directa entre dos redes.  💡 Además del acceso mediante Internet Gateway, SleakOps contempla otros mecanismos de conectividad como Pritunl VPN, NAT Gateway y Transit Gateway, dependiendo del caso de uso y el nivel de aislamiento requerido. ","version":"Next","tagName":"h2"},{"title":"Projecto","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Projecto","url":"/preview-docs/es/docs/project#preguntas-frecuentes","content":" ¿Qué es un ProjectEnv o Namespace?​ Un ProjectEnv es la combinación de un projecto y un Entorno. Actúa como un Namespace de Kubernetes en el clúster y contiene todos los servicios y recursos relacionados con el projecto dentro de ese Entorno.  ¿Cómo creo un ProjectEnv en SleakOps?​ El projecto y el ProjectEnv se crean al mismo tiempo. Debes conectar tu cuenta Git (por ejemplo, GitHub, GitLab o Bitbucket) a SleakOps, seleccionar un repositorio, elegir una rama y especificar la ubicación del Dockerfile. Una vez completados estos pasos, se crea un ProjectEnv y se dispara la primera construcción de imagen. Sigue los pasos a continuación.  ¿Qué sucede cuando creo un ProjectEnv?​ Cuando se crea un ProjectEnv, se configuran los siguientes recursos: AWS Elastic Container Registry (ECR) para almacenar imágenes de contenedores y Helm charts.Un Namespace de Kubernetes para gestionar servicios de forma aislada.Una Service Account para manejar permisos y conexiones seguras con recursos de AWS.Un análisis del Dockerfile para verificar su corrección y construir una imagen de contenedor usando Kaniko.  ¿Cómo agrego Dockerfile Args?​ Si se requieren Docker Args (argumentos) durante el tiempo de construcción, SleakOps te pedirá ingresarlos antes de ejecutar la construcción inicial. Estos argumentos pueden modificarse para construcciones futuras.  ¿Cuál es el propósito del Dockerfile en mi projecto?​ El Dockerfile define cómo tu aplicación se construye en una imagen de contenedor. Durante la creación del ProjectEnv, SleakOps analiza el Dockerfile para garantizar que esté correctamente configurado y luego construye la imagen usando Kaniko.  ¿Dónde se almacenan las imágenes Docker?​ Las imágenes Docker se almacenan en el AWS ECR (Elastic Container Registry) asociado a tu projecto. Las imágenes se nombran según el ProjectEnv, que combina el nombre del Entorno y el nombre del projecto.  ¿Cuál es el rol de la Service Account?​ La Service Account maneja los permisos para recursos dentro del clúster de Kubernetes. Permite que los servicios desplegados en el ProjectEnv interactúen de forma segura con recursos de AWS como S3, RDS o cualquier otro servicio que pueda requerir tu aplicación.  ¿Puedo actualizar el repositorio, la rama o la ruta del Dockerfile después de crear un projecto?​ Solo se pueden actualizar la Rama y la Ruta del Dockerfile. Si necesitas trabajar con un Entorno, Repositorio o Nombre diferentes, deberás crear un nuevo registro.  ¿Cómo maneja SleakOps la construcción inicial de la imagen?​ SleakOps automatiza la construcción inicial de la imagen como parte del proceso de creación del ProjectEnv. Esta construcción inicial asegura una implementación más rápida al utilizar la infraestructura existente. Posteriormente, las futuras construcciones de imágenes se activan cuando se publican servicios en despliegues o manualmente mediante el Formulario de Construcción.  ¿Cómo controlo los gastos del projecto?​ SleakOps te permite ver todos los gastos de tu projecto en un solo lugar, clasificados por cuenta, recursos y fechas. Accede a Projects, selecciona uno y haz clic en el botón:  ¿Cómo monitoreo mi projecto?​ Puedes monitorear tu projecto accediendo a Projects, seleccionando uno y haciendo clic en el botón:   ¿Cómo creo un Kubernetes Volume?​ Al editar un project, puedes habilitar y definir Kubernetes Volumes especificando la ruta de montaje y la capacidad de almacenamiento. SleakOps utiliza el AWS EFS CSI Driver para gestionar estos volúmenes como sistemas de archivos EFS en el clúster EKS.  🚩 ¿Cómo gestiono futuras construcciones y despliegues?​ Las futuras construcciones y despliegues se pueden gestionar manualmente a través de la interfaz de SleakOps o automatizar utilizando el SleakOps CLI.  ","version":"Next","tagName":"h2"},{"title":"Creemos tu primer Projecto en SleakOps​","type":1,"pageTitle":"Projecto","url":"/preview-docs/es/docs/project#creemos-tu-primer-projecto-en-sleakops","content":" aviso Debes tener tu cuenta de Git Repository conectada. Consulta Conecta tu cuenta Git  ","version":"Next","tagName":"h2"},{"title":"1. Navega a la sección Crear Projecto​","type":1,"pageTitle":"Projecto","url":"/preview-docs/es/docs/project#1-navega-a-la-sección-crear-projecto","content":" En el Panel Izquierdo, accede a la opción Projects y luego, en la esquina superior derecha, haz clic en el botón Crear.    ","version":"Next","tagName":"h3"},{"title":"2. Configura tu Projecto​","type":1,"pageTitle":"Projecto","url":"/preview-docs/es/docs/project#2-configura-tu-projecto","content":" Accederás al siguiente formulario:    Aquí están los parámetros que SleakOps te permite personalizar durante la creación:  Configuración\tDescripciónNombre\tIdentifica tu Project. Environment\tEl Entorno representa una etapa o configuración específica dentro de tu infraestructura donde se desplegará tu projecto (por ejemplo, Development, Staging, Production). Estás asociando el código de tu project con un Entorno particular en tu clúster de Kubernetes. Repositorio\tEl repositorio es el repositorio Git que contiene el código base de tu projecto. SleakOps accederá a este repositorio para gestionar actualizaciones de código, construcciones y despliegues. Asegúrate de haber conectado tu proveedor de Git (por ejemplo, GitHub, GitLab, Bitbucket) y que el repositorio seleccionado contenga todos los archivos necesarios para tu project. Nodepool\tEs el recurso encargado de aprovisionar el servidor donde se ejecutarán tus servicios. Más información aquí. Rama\tLa rama representa una versión específica o línea de desarrollo dentro del repositorio. Esto te permite desplegar una versión particular de tu código (por ejemplo, main, develop o una rama específica de características). La rama que selecciones determinará el código que se construirá y desplegará en el Entorno asociado. Ruta del Dockerfile\tEl Dockerfile es un componente crítico utilizado para construir tu projecto en un contenedor. El campo de Ruta del Dockerfile requiere la ruta relativa al Dockerfile dentro del repositorio (por ejemplo, /Dockerfile, /src/Dockerfile o /app/Dockerfile). Este archivo contiene las instrucciones necesarias para crear la imagen del contenedor, que SleakOps construirá y utilizará posteriormente para los despliegues.  Una vez que hayas completado el formulario, haz clic en Enviar para iniciar la validación del Dockerfile y luego la construcción.  ","version":"Next","tagName":"h3"},{"title":"ProjectAccess​","type":1,"pageTitle":"Projecto","url":"/preview-docs/es/docs/project#projectaccess","content":" ProjectAccess te permite configurar políticas y roles IAM personalizados para tu proyecto, proporcionando control granular sobre los permisos de recursos de AWS. Esta característica te permite definir patrones de acceso específicos que se alinean con tus requisitos de seguridad y necesidades operativas.  ","version":"Next","tagName":"h2"},{"title":"Políticas Personalizadas​","type":1,"pageTitle":"Projecto","url":"/preview-docs/es/docs/project#políticas-personalizadas","content":" Las políticas personalizadas te permiten crear políticas IAM adaptadas que otorgan permisos específicos a las cargas de trabajo de tu proyecto. Estas políticas deben crearse en la misma cuenta de AWS donde se despliega tu proyecto.  Crear Políticas Personalizadas​  Navega a la Consola IAM de AWS en la cuenta de AWS de tu proyectoCrea una nueva política con los permisos específicos que requiere tu aplicaciónReferencia la política en SleakOps usando el ARN de la política  Mejores Prácticas de Políticas Sigue el principio de menor privilegio - otorga solo los permisos mínimos necesariosUsa ARNs específicos de recursos cuando sea posible para limitar el alcance del accesoRevisa y audita regularmente los permisos de las políticas  Referenciar Políticas Personalizadas en SleakOps​  Al configurar ProjectAccess, puedes referenciar tus políticas personalizadas proporcionando el ARN de la política:  arn:aws:iam::ACCOUNT_ID:policy/YourCustomPolicyName   ","version":"Next","tagName":"h3"},{"title":"Políticas Gestionadas por AWS​","type":1,"pageTitle":"Projecto","url":"/preview-docs/es/docs/project#políticas-gestionadas-por-aws","content":" SleakOps también admite políticas gestionadas por AWS, que son políticas preconfiguradas mantenidas por AWS. Estas políticas proporcionan conjuntos de permisos comunes para varios servicios de AWS.  Políticas Gestionadas por AWS Comunes​  AmazonS3ReadOnlyAccess: Acceso de solo lectura a buckets de S3AmazonRDSReadOnlyAccess: Acceso de solo lectura a instancias de RDSCloudWatchReadOnlyAccess: Acceso de solo lectura a métricas y logs de CloudWatchAmazonEC2ReadOnlyAccess: Acceso de solo lectura a recursos de EC2  Asociación de Políticas Al asociar roles o políticas con tu proyecto, se recomienda usar el número mínimo de políticas necesario. Este enfoque: Reduce la complejidad en la gestión de permisosMejora la seguridad limitando los vectores de ataque potencialesFacilita la resolución de problemas cuando surgen problemas de permisos  ","version":"Next","tagName":"h3"},{"title":"Mejores Prácticas para la Gestión de Políticas​","type":1,"pageTitle":"Projecto","url":"/preview-docs/es/docs/project#mejores-prácticas-para-la-gestión-de-políticas","content":" Minimizar el Número de Políticas: Asocia el menor número de políticas posible mientras cumples tus requisitosAuditorías Regulares: Revisa y audita periódicamente las políticas asociadas con tus proyectosPolíticas Específicas del Entorno: Considera usar diferentes políticas para diferentes entornos (dev, staging, prod)Documentación: Mantén documentación clara de por qué se requieren políticas específicas para cada proyecto ","version":"Next","tagName":"h3"},{"title":"Configuración de Acceso","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/access_config","content":"","keywords":"","version":"Next"},{"title":"Pasos de Configuración​","type":1,"pageTitle":"Configuración de Acceso","url":"/preview-docs/es/docs/project/access_config#pasos-de-configuración","content":" Navega a Proyecto → ConfiguraciónSelecciona Configuración de Acceso del menú de configuraciónConfigura las dependencias externas y políticas adicionales según sea necesarioHaz clic en Aplicar cambios para guardar tu configuración    ","version":"Next","tagName":"h2"},{"title":"Dependencias Externas​","type":1,"pageTitle":"Configuración de Acceso","url":"/preview-docs/es/docs/project/access_config#dependencias-externas","content":" ","version":"Next","tagName":"h2"},{"title":"Dependencias Ya Asignadas​","type":1,"pageTitle":"Configuración de Acceso","url":"/preview-docs/es/docs/project/access_config#dependencias-ya-asignadas","content":" Esta sección muestra las dependencias que ya han sido vinculadas a tu proyecto actual. Estas dependencias están disponibles para que las usen tus cargas de trabajo y están marcadas con una casilla azul para indicar que están activas.  Características:  Ver todas las dependencias externas asignadas actualmenteVer información del tipo de dependencia y del proyectoLas dependencias se configuran automáticamente con los permisos apropiados  ","version":"Next","tagName":"h3"},{"title":"Dependencias Externas Disponibles​","type":1,"pageTitle":"Configuración de Acceso","url":"/preview-docs/es/docs/project/access_config#dependencias-externas-disponibles","content":" Esta sección muestra las dependencias de otros proyectos a las que puedes otorgar acceso a tu proyecto actual. Esto permite el intercambio de recursos entre proyectos y la colaboración.  Cómo funciona:  Selecciona dependencias de otros proyectos a las que deseas otorgar acceso a este proyectoSolo se mostrarán las dependencias de proyectos a los que tienes accesoUna vez seleccionada, la dependencia estará disponible en la sección &quot;Dependencias Ya Asignadas&quot;  ","version":"Next","tagName":"h3"},{"title":"Políticas Adicionales​","type":1,"pageTitle":"Configuración de Acceso","url":"/preview-docs/es/docs/project/access_config#políticas-adicionales","content":" La sección de Políticas Adicionales te permite adjuntar políticas IAM adicionales a tu proyecto, proporcionando permisos mejorados más allá del acceso predeterminado del proyecto.  ","version":"Next","tagName":"h2"},{"title":"Agregar Políticas Adicionales​","type":1,"pageTitle":"Configuración de Acceso","url":"/preview-docs/es/docs/project/access_config#agregar-políticas-adicionales","content":" Haz clic en el botón &quot;Adjuntar más políticas&quot;Selecciona de las políticas IAM disponibles en tu cuenta de AWSRevisa los permisos de la política antes de adjuntarlaLas políticas se aplicarán para otorgar permisos adicionales al proyecto  ","version":"Next","tagName":"h3"},{"title":"Gestión de Políticas​","type":1,"pageTitle":"Configuración de Acceso","url":"/preview-docs/es/docs/project/access_config#gestión-de-políticas","content":" Políticas Personalizadas: Adjunta políticas que has creado en tu consola IAM de AWSPolíticas Gestionadas por AWS: Usa políticas preconfiguradas de AWS para casos de uso comunesRevisión de Políticas: Todas las políticas adjuntas se listan y pueden ser revisadasEliminación: Las políticas pueden ser desvinculadas si ya no son necesarias  Acceso Entre Proyectos Las dependencias externas permiten a los equipos compartir recursos entre diferentes proyectos, mejorando la colaboración y la utilización de recursos.  Consideraciones de Seguridad Revisa todas las políticas adjuntas para asegurar que sigan el principio de menor privilegioAudita regularmente las dependencias externas para asegurar que aún sean necesariasMonitorea los patrones de acceso para identificar cualquier actividad inusual ","version":"Next","tagName":"h3"},{"title":"Build","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/build","content":"","keywords":"","version":"Next"},{"title":"Build creation​","type":1,"pageTitle":"Build","url":"/preview-docs/es/docs/project/build#build-creation","content":" To create a Build you only need four parameters, only the Project field is required as the other three are, if not set, wait until this access is automatically enabled are chosen by default:  Project: Refers to what we call ProjectEnv, here you choose which ProjectEnv you want to build.Branch: Lets you choose any branch of the repository that you've chosen as Project. Defaults to Environment name.Commit hash: You can also choose the commit has to build a specific commit and not the last one as we do by default. Defaults to last commit.Tag: Just a tag to differentiate builds. Defaults to 'latest'.  ","version":"Next","tagName":"h3"},{"title":"Why do we need to Build a Docker image?​","type":1,"pageTitle":"Build","url":"/preview-docs/es/docs/project/build#why-do-we-need-to-build-a-docker-image","content":" As we use Helm charts we need the image because is what they use to deploy a Kubernetes Release.  info Remember that you need a Build to update the code that the Deployment runs inside the Kubernetes Cluster.  CI/CD integration with SleakOps SleakOps has its own CLI Tool that you can use to automate Builds and Deployments in your CI/CD. More info here. ","version":"Next","tagName":"h2"},{"title":"Recursos de Deploy Build","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/build_resources","content":"","keywords":"","version":"Next"},{"title":"Configuración de Recursos​","type":1,"pageTitle":"Recursos de Deploy Build","url":"/preview-docs/es/docs/project/build_resources#configuración-de-recursos","content":"   Accede a la configuración de Recursos de Deploy Build:  Navega a Proyecto → ConfiguraciónSelecciona Deploy Build Resources del menú de configuraciónConfigura los valores de recursos según los requisitos de tu proyectoHaz clic en Save para aplicar los cambios  ","version":"Next","tagName":"h2"},{"title":"Recursos de Solicitud de Build​","type":1,"pageTitle":"Recursos de Deploy Build","url":"/preview-docs/es/docs/project/build_resources#recursos-de-solicitud-de-build","content":" Configura los recursos asignados durante el proceso de construcción:  Build Request CPU: Especifica la asignación de CPU para procesos de construcción (medido en millicores)Build Request Memory: Especifica la asignación de memoria para procesos de construcción (medido en GiB)  ","version":"Next","tagName":"h3"},{"title":"Recursos de Solicitud de Deploy​","type":1,"pageTitle":"Recursos de Deploy Build","url":"/preview-docs/es/docs/project/build_resources#recursos-de-solicitud-de-deploy","content":" Configura los recursos asignados durante el proceso de despliegue:  Deploy Request CPU: Especifica la asignación de CPU para procesos de despliegue (medido en millicores)Deploy Request Memory: Especifica la asignación de memoria para procesos de despliegue (medido en GiB)  Optimización de Recursos Comienza con valores por defecto y ajusta basándote en el rendimiento del buildMonitorea los tiempos de build y uso de recursos para optimizar las asignacionesAsignaciones de recursos más altas pueden reducir los tiempos de build pero aumentar los costos  Límites de Recursos Asegúrate de que tu clúster tenga recursos suficientes para acomodar las asignaciones solicitadas ","version":"Next","tagName":"h3"},{"title":"Dependencias de Chart","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/chart/chart_dependencies","content":"","keywords":"","version":"Next"},{"title":"Repositorios de Chart Soportados​","type":1,"pageTitle":"Dependencias de Chart","url":"/preview-docs/es/docs/project/chart/chart_dependencies#repositorios-de-chart-soportados","content":" Actualmente, SleakOps soporta Charts de Bitnami exclusivamente. Puedes explorar los charts disponibles en ArtifactHub para encontrar dependencias adecuadas para tu proyecto.  ","version":"Next","tagName":"h2"},{"title":"Agregando Dependencias de Chart​","type":1,"pageTitle":"Dependencias de Chart","url":"/preview-docs/es/docs/project/chart/chart_dependencies#agregando-dependencias-de-chart","content":" Para agregar una nueva Dependencia de Chart, haz clic en el botón Crear en la sección de Configuración de Chart:    ","version":"Next","tagName":"h2"},{"title":"Pasos de Configuración​","type":1,"pageTitle":"Dependencias de Chart","url":"/preview-docs/es/docs/project/chart/chart_dependencies#pasos-de-configuración","content":" Buscar y Seleccionar: Usa los primeros dos campos para buscar el nombre del chart y seleccionar la versión deseadaConfigurar Valores: Modifica la sección de valores abajo para personalizar el despliegueEstablecer Tolerations: Crítico - Actualiza todos los campos tolerations en los valores del chart para apuntar a tu NodePool    Importante Asegúrate de que cada campo tolerations en los valores del chart esté configurado correctamente para usar un NodePool. Sin esta configuración, Kubernetes no puede determinar dónde programar los pods, lo que lleva a fallas en el despliegue.  ","version":"Next","tagName":"h3"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Dependencias de Chart","url":"/preview-docs/es/docs/project/chart/chart_dependencies#preguntas-frecuentes","content":" Mi despliegue fue exitoso pero los pods no funcionan. ¿Qué está mal?​ La causa más común es una configuración incorrecta de NodePool. Verifica que: Todos los campos tolerations estén configurados correctamente para apuntar a NodePools existentesEl NodePool tenga recursos suficientesEl NodePool esté en un estado saludable  No puedo encontrar el chart que necesito. ¿Cuáles son mis opciones?​ Actualmente, solo se soportan charts del repositorio de Bitnami. Si necesitas un chart que no esté disponible en el repositorio de Bitnami, por favor contacta a nuestro equipo de soporte para discutir alternativas o solicitar soporte adicional de repositorios.  ¿Cómo soluciono problemas de despliegue de dependencias?​ Pasos comunes de solución de problemas: Verifica que las tolerations de NodePool estén configuradas correctamenteComprueba que la versión del chart sea compatibleAsegúrate de que los valores requeridos estén configurados correctamenteRevisa los logs de pods para mensajes de error específicos  Mis recursos no montan los volúmenes EBS correctamente. ¿Qué debería verificar?​ Asegúrate de que el EBS CSI Driver esté instalado y funcionando en tu clúster. Puedes consultar la documentación de Addon para obtener orientación sobre cómo configurar EBS.Asegúrate de haber completado los valores con el storageClass apropiado que se crea con el addon de EBS. Por ejemplo, un valor de persistencia para un chart podría verse así: persistence: enabled: true storageClass: &quot;ebs-csi-default-sc&quot; accessModes: - ReadWriteOnce size: 5Gi En caso de que necesites otro storageClass, puedes definirlo como un extra template y usarlo. Recuerda configurar el provisioner como ebs.csi.aws.com.En caso de que los pods no estén iniciando, revisa los logs del EBS CSI Controller para verificar errores  Mis recursos no montan los volúmenes EFS correctamente. ¿Qué debería verificar?​ Asegúrate de que el EFS CSI Driver esté instalado y funcionando en tu clúster. Sleakops instala este addon cuando creas un volumen para un proyecto. Puedes crear y luego eliminar un volumen para completar la instalación.Asegúrate de haber completado los valores con el storageClass apropiado que prefieras para estos datos. Sleakops crea dos StorageClasses al instalar el addon de EFS: efs-sc-retain y efs-sc-delete. Por ejemplo, un valor de persistencia para un chart podría verse así: persistence: enabled: true storageClass: &quot;efs-sc-retain&quot; accessModes: - ReadWriteMany size: 5Gi En caso de que necesites otro storageClass, puedes definirlo como un extra template y usarlo. Recuerda configurar el provisioner como efs.csi.aws.com.En caso de que los pods no estén iniciando, revisa los logs del EFS CSI Controller para verificar errores  Los Pods no inician debido a errores de image pull. ¿Qué debería verificar?​ Verifica que el nombre de la imagen y el tag especificados en los valores del chart sean correctos.Verifica que el repositorio sea bitnamilegacy en lugar de bitnami.Verifica si existe un valor allowInsecureImages: false y cámbialo a allowInsecureImages: true. ","version":"Next","tagName":"h2"},{"title":"Extra Templates","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/chart/extra_templates","content":"","keywords":"","version":"Next"},{"title":"Casos de Uso​","type":1,"pageTitle":"Extra Templates","url":"/preview-docs/es/docs/project/chart/extra_templates#casos-de-uso","content":" Configuraciones de Ingress personalizadas para enrutamiento especializadoPods de prueba para depuración y desarrolloConfigMaps o Secrets adicionalesPolíticas de red personalizadasComponentes especializados de monitoreo o logging  Configuración de NodePool Requerida Dado que SleakOps utiliza NodePools para la ubicación de recursos, todos los recursos personalizados deben incluir la configuración adecuada de tolerations apuntando a un NodePool existente.  ","version":"Next","tagName":"h2"},{"title":"Desplegando un Ingress Personalizado​","type":1,"pageTitle":"Extra Templates","url":"/preview-docs/es/docs/project/chart/extra_templates#desplegando-un-ingress-personalizado","content":" Para desplegar un Ingress personalizado, agrega tu configuración YAML de Kubernetes en la sección Templates. Aquí tienes un ejemplo completo que puedes usar como punto de partida:  apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: coreexampledjangocelerysleakopscom namespace: example-django-celery-myenv labels: app.kubernetes.io/name: example-django-celery annotations: alb.ingress.kubernetes.io/certificate-arn: &gt;- arn:aws:acm:REGION:ACCOUNT_ID:certificate/XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX alb.ingress.kubernetes.io/group.name: example-django-celery-public alb.ingress.kubernetes.io/healthcheck-path: /health alb.ingress.kubernetes.io/healthcheck-port: '8000' alb.ingress.kubernetes.io/listen-ports: '[{&quot;HTTP&quot;: 80}, {&quot;HTTPS&quot;:443}]' alb.ingress.kubernetes.io/ssl-redirect: '443' alb.ingress.kubernetes.io/success-codes: '200' alb.ingress.kubernetes.io/target-type: ip meta.helm.sh/release-name: example-django-celery-myenv meta.helm.sh/release-namespace: example-django-celery-myenv spec: ingressClassName: alb-ingressclass-public tls: - hosts: - core.example-django-celery.sleakops.com rules: - host: core.example-django-celery.sleakops.com http: paths: - path: /api/public/ pathType: Prefix backend: service: name: example-django-celery-myenv-api-public-svc port: number: 8000   Una vez que hayas definido tu plantilla de Ingress, puedes desplegarla usando la interfaz:    ","version":"Next","tagName":"h2"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Extra Templates","url":"/preview-docs/es/docs/project/chart/extra_templates#preguntas-frecuentes","content":" ¿Cómo uso valores personalizados en mis plantillas?​ Puedes definir valores personalizados en la sección Values en el lado derecho de la interfaz. Estos valores pueden ser referenciados en tus plantillas usando la sintaxis de plantillas de Helm. El ejemplo anterior muestra cómo crear una plantilla de Pod que usa valores personalizados y cómo referenciarlos en tu configuración YAML.  ¿Qué tipos de recursos de Kubernetes puedo desplegar?​ SleakOps soporta solo recursos con alcance de namespace debido a requisitos de seguridad y aislamiento. Cada proyecto opera dentro de su propio namespace con permisos con alcance de namespace. Recursos soportados incluyen: Pods, Deployments, ServicesIngresses, NetworkPoliciesConfigMaps, SecretsPersistentVolumeClaimsJobs, CronJobs No soportados: ClusterRoles, ClusterRoleBindingsCustomResourceDefinitionsPersistentVolumesCualquier recurso con alcance de cluster  ¿Cómo soluciono problemas de despliegue de plantillas?​ Pasos comunes de solución de problemas: Validar sintaxis YAML - Asegúrate de que tu plantilla sea YAML válido de KubernetesVerificar tolerations de NodePool - Verifica que las tolerations apunten a NodePools existentesRevisar cuotas de recursos - Asegúrate de que haya recursos suficientes disponiblesValidar referencias - Verifica que los servicios, secrets o configmaps referenciados existanRevisar logs - Revisa los logs de despliegue para mensajes de error específicos ","version":"Next","tagName":"h2"},{"title":"Configura tu Dockerfile","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/configure_your_dockerfile","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Configura tu Dockerfile","url":"/preview-docs/es/docs/project/configure_your_dockerfile#preguntas-frecuentes","content":" ¿Qué debo especificar al configurar el Dockerfile en SleakOps?​ Al configurar tu Dockerfile en SleakOps, necesitas: Establecer la Ruta del Dockerfile: Proporciona la ruta relativa del Dockerfile dentro de tu repositorio.Proporcionar Argumentos del Dockerfile: Si tu Dockerfile requiere argumentos específicos para la construcción (por ejemplo, variables de entorno, configuraciones), debes proporcionar estos valores durante el proceso de construcción de la imagen Docker.  ¿Cómo agrego los argumentos del Dockerfile?​ Una vez que especifiques la ruta del Dockerfile, SleakOps lo analizará para identificar cualquier argumento de construcción necesario. Si es necesario, SleakOps te pedirá que proporciones los valores para estos argumentos. Puedes actualizar estos argumentos en cualquier momento a través de la interfaz de SleakOps. DockerArgs desde CLI También puedes definir DockerArgs cuando uses la CLI de SleakOps para builds. Usa el parámetro --docker-args para pasar argumentos de construcción directamente desde la línea de comandos: sleakops build -p myproject -b main --docker-args &quot;ARG1=value1,ARG2=value2&quot; Esto es particularmente útil para pipelines de CI/CD donde quieres pasar diferentes argumentos basados en el entorno o contexto de construcción.  ¿Qué son los argumentos de construcción Docker?​ Los argumentos de construcción Docker son variables que se pasan durante el proceso de construcción del Docker para personalizar la construcción según diferentes entornos o configuraciones. Se definen en el Dockerfile utilizando la palabra clave ARG. SleakOps identificará estos argumentos y te pedirá que proporciones los valores necesarios. También puedes actualizar estos argumentos más adelante si es necesario.  ¿Cómo actualizo la ruta del Dockerfile y los argumentos?​ Puedes añadirlos siguiendo los pasos descritos a continuación.  ","version":"Next","tagName":"h2"},{"title":"Configura tu Dockerfile​","type":1,"pageTitle":"Configura tu Dockerfile","url":"/preview-docs/es/docs/project/configure_your_dockerfile#configura-tu-dockerfile-1","content":" ","version":"Next","tagName":"h2"},{"title":"1. Accede a la configuración de tu project​","type":1,"pageTitle":"Configura tu Dockerfile","url":"/preview-docs/es/docs/project/configure_your_dockerfile#1-accede-a-la-configuración-de-tu-project","content":" Completa la Ruta del Dockerfile: Para habilitar que SleakOps busque los argumentos necesarios, especifica la Ruta del Dockerfile y guarda los cambios. SleakOps analizará tu Dockerfile y mostrará los argumentos de construcción requeridos para que los proporciones.  Ruta del Dockerfile\tEl Dockerfile es un componente crítico utilizado para construir tu project en un contenedor. El campo de Ruta del Dockerfile requiere la ruta relativa al Dockerfile dentro del repositorio (por ejemplo, /Dockerfile, /src/Dockerfile o /app/Dockerfile). Este archivo contiene las instrucciones necesarias para crear la imagen del contenedor, que SleakOps construirá y usará posteriormente para los despliegues.  Agrega Argumentos Antes de Guardar: Si ya conoces los argumentos requeridos, puedes ingresarlos antes de guardar. Esto te permite proporcionar los valores necesarios desde el principio en lugar de esperar a que SleakOps analice el Dockerfile.  tip Si eliges agregar los argumentos utilizando la opción de texto: Cada argumento debe añadirse en una nueva línea, separado por un signo igual (=), sin espacios adicionales. ARGUMENT_NAME = VALUE ARGUMENT_TWO = VALUE ARGUMENT_ONE = VALUE ","version":"Next","tagName":"h3"},{"title":"Chart","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/chart","content":"","keywords":"","version":"Next"},{"title":"Accediendo a la Configuración del Chart​","type":1,"pageTitle":"Chart","url":"/preview-docs/es/docs/project/chart#accediendo-a-la-configuración-del-chart","content":" Puedes encontrar la sección de Chart navegando a Proyecto → Configuración:    Requisitos de NodePool SleakOps utiliza NodePools para determinar dónde se despliegan los recursos. Debes configurar el parámetro tolerations para apuntar a un NodePool existente para todos los recursos desplegados.    ","version":"Next","tagName":"h2"},{"title":"Valores por Defecto​","type":1,"pageTitle":"Chart","url":"/preview-docs/es/docs/project/chart#valores-por-defecto","content":" SleakOps aplica automáticamente valores por defecto a sus Charts. Puedes ver estos valores haciendo clic en el área designada:    Esto abre un panel lateral en el lado derecho que muestra los valores por defecto para todas las cargas de trabajo del Proyecto.  ","version":"Next","tagName":"h2"},{"title":"Valores Específicos de Carga de Trabajo​","type":1,"pageTitle":"Chart","url":"/preview-docs/es/docs/project/chart#valores-específicos-de-carga-de-trabajo","content":" Por ejemplo, aquí están los valores por defecto para un WebService 'api':    ","version":"Next","tagName":"h3"},{"title":"Valores Globales​","type":1,"pageTitle":"Chart","url":"/preview-docs/es/docs/project/chart#valores-globales","content":" Valores que se aplican a todo el Proyecto:    ","version":"Next","tagName":"h3"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Chart","url":"/preview-docs/es/docs/project/chart#preguntas-frecuentes","content":" ¿Dónde puedo encontrar el Chart de mi Proyecto?​ Actualmente, los Charts no son visibles directamente en la plataforma. Sin embargo, puedes descargar el Chart desde el repositorio ECR creado para tu Proyecto en la Cuenta AWS correspondiente.  ¿Puedo modificar el Chart desplegado por un Proyecto?​ Sí, con algunas limitaciones. Puedes: Agregar plantillas personalizadas usando Extra TemplatesAgregar dependencias de chart usando Chart Dependencies, similar a Helm Chart Dependencies   ¿Puedo agregar un Ingress personalizado a mi Proyecto?​ Sí, este es uno de los casos de uso principales de la funcionalidad Extra Templates. Consulta la documentación de Extra Templates para instrucciones detalladas.  ¿Puedo modificar las plantillas existentes de Kubernetes Service?​ No, la modificación de plantillas integradas de SleakOps no está soportada actualmente. Estamos trabajando en habilitar modificaciones a las plantillas integradas en futuras versiones. ","version":"Next","tagName":"h2"},{"title":"Dependencias: Integración de Bases de Datos, Caché y Servicios de Mensajería","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Dependencias: Integración de Bases de Datos, Caché y Servicios de Mensajería","url":"/preview-docs/es/docs/project/dependency#preguntas-frecuentes","content":" ¿Qué tipos de dependencias están incluidas en SleakOps?​ Aquí está la lista actualizada de dependencias incluidas en SleakOps: Bases de Datos Amazon RDS: Bases de datos relacionales gestionadas como MySQL, PostgreSQL, y otras. Servicios de Caché Amazon ElastiCache para Redis: Almacén de datos en memoria para cachear datos frecuentemente accedidos.Amazon ElastiCache para Memcached: Servicio de caché en memoria para mejorar el rendimiento y reducir la carga de la base de datos. Almacenamiento de Objetos Amazon S3: Almacenamiento de objetos escalable y seguro para almacenar y recuperar cualquier cantidad de datos. Búsqueda y Análisis Amazon OpenSearch: Un potente motor de búsqueda y análisis para explorar y visualizar datos, permitiendo insights y decisiones en tiempo real. Colas de Mensajes Amazon SQS: Servicio de colas de mensajes completamente gestionado que permite desacoplar componentes y mejorar la escalabilidad y confiabilidad de las aplicaciones.RabbitMQ: Un broker de mensajes de código abierto ampliamente utilizado que facilita la mensajería confiable y la integración entre componentes de aplicaciones. Estas dependencias se integran perfectamente con SleakOps, proporcionando un conjunto completo de servicios de AWS y de código abierto para mejorar la funcionalidad, el rendimiento y la escalabilidad de tu aplicación.  ¿Puedo modificar la configuración de una dependencia después de la configuración inicial?​ Sí, puedes actualizar la configuración de las dependencias en cualquier momento. Asegúrate de guardar los cambios en la interfaz de SleakOps para aplicarlos.  ¿Puede utilizarse la misma dependencia en varios proyectos?​ Por el momento, esto no es posible; necesitas una dependencia para cada proyecto.  ¿Cómo elimino una dependencia?​ Accede a la sección Dependency Listing y haz clic en la opción de eliminar.  ¿Qué sucede cuando elimino una dependencia?​ Al eliminar una dependencia, SleakOps eliminará toda la información relacionada con ella, y todo lo que dependa de esta dejará de funcionar. Para resolver esto, SleakOps crea un Deployment con el estado PENDING_APPROVAL, que debe ejecutarse manualmente lo antes posible para evitar tiempos de inactividad. En caso de eliminar una base de datos, SleakOps generará una instantánea final antes de su eliminación.  ","version":"Next","tagName":"h2"},{"title":"Agregar una dependencia a tu proyecto​","type":1,"pageTitle":"Dependencias: Integración de Bases de Datos, Caché y Servicios de Mensajería","url":"/preview-docs/es/docs/project/dependency#agregar-una-dependencia-a-tu-proyecto","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navega a la sección Crear Dependencia​","type":1,"pageTitle":"Dependencias: Integración de Bases de Datos, Caché y Servicios de Mensajería","url":"/preview-docs/es/docs/project/dependency#1-navega-a-la-sección-crear-dependencia","content":" En el Panel Izquierdo, accede a la opción Dependencies y luego, en la esquina superior derecha, haz clic en el botón Crear.    ","version":"Next","tagName":"h3"},{"title":"2. Selecciona el tipo de dependencia que deseas crear​","type":1,"pageTitle":"Dependencias: Integración de Bases de Datos, Caché y Servicios de Mensajería","url":"/preview-docs/es/docs/project/dependency#2-selecciona-el-tipo-de-dependencia-que-deseas-crear","content":"   ","version":"Next","tagName":"h3"},{"title":"3. Completa los atributos iniciales​","type":1,"pageTitle":"Dependencias: Integración de Bases de Datos, Caché y Servicios de Mensajería","url":"/preview-docs/es/docs/project/dependency#3-completa-los-atributos-iniciales","content":" En SleakOps, todas las dependencias comienzan con los mismos pasos. Completa los siguientes atributos y haz clic en Next para continuar.  Configuración\tDescripciónNombre\tIdentifica tu proyecto. Proyecto\tSelecciona entre los proyectos existentes.    ","version":"Next","tagName":"h3"},{"title":"4. Sigue las guías específicas de cada dependencia​","type":1,"pageTitle":"Dependencias: Integración de Bases de Datos, Caché y Servicios de Mensajería","url":"/preview-docs/es/docs/project/dependency#4-sigue-las-guías-específicas-de-cada-dependencia","content":" Para continuar, elige entre las siguientes guías:  S3 Bucket. MySQL. PostgreSQL. Redis. Memcached. OpenSearch. SQS.  ","version":"Next","tagName":"h3"},{"title":"Acceso a Dependencias​","type":1,"pageTitle":"Dependencias: Integración de Bases de Datos, Caché y Servicios de Mensajería","url":"/preview-docs/es/docs/project/dependency#acceso-a-dependencias","content":" El acceso a dependencias se refiere a los mecanismos de seguridad y conectividad que permiten que las cargas de trabajo de tu aplicación interactúen de forma segura con dependencias externas. SleakOps gestiona automáticamente estos patrones de acceso para asegurar una comunicación segura entre tus servicios y sus dependencias.  ","version":"Next","tagName":"h2"},{"title":"Gestión de Acceso​","type":1,"pageTitle":"Dependencias: Integración de Bases de Datos, Caché y Servicios de Mensajería","url":"/preview-docs/es/docs/project/dependency#gestión-de-acceso","content":" Configuración Automática de Service Account​  Cuando creas una dependencia, SleakOps automáticamente:  Crea roles IAM con permisos apropiados para el tipo específico de dependenciaConfigura service accounts en tu namespace de KubernetesEstablece conexiones seguras entre tus cargas de trabajo y la dependenciaGestiona credenciales a través de secrets de Kubernetes y roles IAM  Seguridad de Red​  Integración VPC: Las dependencias se crean dentro de la VPC de tu proyecto para acceso seguro de redSecurity Groups: Configurados automáticamente para permitir el tráfico necesario entre serviciosEndpoints Privados: Las dependencias usan endpoints privados cuando están disponibles para minimizar la exposición  ","version":"Next","tagName":"h3"},{"title":"Patrones de Acceso​","type":1,"pageTitle":"Dependencias: Integración de Bases de Datos, Caché y Servicios de Mensajería","url":"/preview-docs/es/docs/project/dependency#patrones-de-acceso","content":" Acceso a Base de Datos​  Para dependencias de base de datos (MySQL, PostgreSQL, etc.):  Cadenas de Conexión: Generadas automáticamente y almacenadas como secrets de KubernetesAutenticación: Gestionada a través de roles IAM y credenciales específicas de la base de datosSSL/TLS: Las conexiones encriptadas se configuran por defectoConnection Pooling: Gestión optimizada de conexiones para mejor rendimiento  Acceso a Cache​  Para servicios de caché (Redis, Memcached):  Configuración de Endpoint: Configurada automáticamente en el entorno de tu aplicaciónAutenticación: Acceso seguro a través de roles IAM y credenciales específicas del servicioPolíticas de Red: Acceso restringido solo a cargas de trabajo autorizadas  Acceso a Almacenamiento​  Para servicios de almacenamiento (S3, etc.):  Políticas de Bucket: Configuradas automáticamente con acceso de menor privilegioPermisos IAM: Las service accounts reciben solo los permisos necesariosAccess Keys: Gestionadas a través de roles IAM de AWS para mayor seguridad  ","version":"Next","tagName":"h3"},{"title":"Mejores Prácticas de Seguridad​","type":1,"pageTitle":"Dependencias: Integración de Bases de Datos, Caché y Servicios de Mensajería","url":"/preview-docs/es/docs/project/dependency#mejores-prácticas-de-seguridad","content":" Principio de Menor Privilegio​  Permisos Mínimos: Las dependencias reciben solo los permisos mínimos requeridosAcceso Específico de Recursos: El acceso se limita a recursos específicos cuando es posibleAuditorías Regulares: SleakOps proporciona herramientas para revisar y auditar el acceso a dependencias  Gestión de Credenciales​  Rotación Automática: Las credenciales se rotan automáticamente cuando es posibleAlmacenamiento Seguro: Todas las credenciales se almacenan como secrets de KubernetesSin Secrets Hardcodeados: Las aplicaciones acceden a dependencias a través de variables de entorno  Monitoreo de Acceso SleakOps proporciona capacidades de monitoreo y logging para rastrear patrones de acceso a dependencias, ayudándote a identificar posibles problemas de seguridad y optimizar el rendimiento.  Resolución de Problemas de Acceso Si encuentras problemas de acceso con dependencias: Verifica el estado de la dependencia en la consola de SleakOpsConfirma que tu carga de trabajo tiene la service account correctaRevisa los permisos del rol IAM para la dependenciaVerifica la conectividad de red y configuraciones de security groups ","version":"Next","tagName":"h3"},{"title":"AWS Aurora MySQL","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/aurora-mysql-aws","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"AWS Aurora MySQL","url":"/preview-docs/es/docs/project/dependency/aurora-mysql-aws#preguntas-frecuentes","content":" ¿Cómo gestiona SleakOps las credenciales de Aurora MySQL?​ Cuando creas una dependencia Aurora MySQL en SleakOps, se genera automáticamente un Vargroup para tu clúster de base de datos. Este Grupo de Variables almacena de forma segura las credenciales de Aurora MySQL y otros detalles importantes de configuración, como el endpoint del clúster y la información de acceso del usuario. Podrás gestionarlos desde la sección de Vargroups.  ¿Puedo cambiar la versión de Aurora MySQL después de desplegar el clúster?​ Sí, Aurora MySQL soporta actualizaciones de versión del motor. Sin embargo, el proceso de actualización requiere planificación cuidadosa y puede involucrar tiempo de inactividad. Se recomienda probar el proceso de actualización en un entorno no productivo primero.  ¿Qué pasa si necesito más almacenamiento para mi clúster Aurora MySQL?​ Aurora MySQL escala automáticamente el almacenamiento de 10 GB hasta 128 TB sin requerir que provisiones almacenamiento por adelantado. El almacenamiento se escala automáticamente a medida que tus datos crecen, y solo pagas por el almacenamiento que uses.  ¿Cómo creo un dump de mi base de datos Aurora MySQL?​ Para crear un dump de tu base de datos Aurora MySQL: Ejecuta el comando mysqldump: mysqldump -h AURORA_MYSQL_ADDRESS -u AURORA_MYSQL_USERNAME -p --all-databases &gt; dump.sql Reemplaza AURORA_MYSQL_ADDRESS, AURORA_MYSQL_USERNAME, y dump.sql con los valores apropiados. Consulta la Documentación: Para más información sobre cómo crear un dump, consulta la documentación oficial de MySQL .  ¿Cómo importo un dump existente usando docker?​ Para importar un dump de base de datos a tu clúster Aurora MySQL: Conecta a la VPN: Asegúrate de estar conectado a la VPN de la cuenta AWS donde se encuentra el clúster Aurora.Prepara el archivo dump: Coloca tu archivo dump de base de datos (ej., dump.sql) en el directorio ./initial_data/ en tu máquina local.Ejecuta Contenedor Docker (Recomendado): Instala Docker en tu máquina local si no está instalado.Dejar tu dump en una carpeta &quot;initial_data&quot;.Ejecuta un contenedor MySQL Docker con el siguiente comando: docker run -it --name aurora-mysql-container -v ./initial_data/:/tmp/data/ -e MYSQL_ROOT_PASSWORD=AURORA_MYSQL_PASSWORD -d mysql bash Conecta a la terminal del contenedor: docker exec -t -i aurora-mysql-container bash Importa el archivo dump: mysql -h AURORA_MYSQL_ADDRESS -u AURORA_MYSQL_USERNAME -p &lt; /tmp/data/dump.sql Reemplaza AURORA_MYSQL_ADDRESS, AURORA_MYSQL_USERNAME, y dump.sql con tus detalles específicos.  ¿Cómo importo un dump existente a mi máquina local?​ Alternativamente, puedes usar un cliente MySQL instalado en tu máquina local para importar el dump: mysql -h AURORA_MYSQL_ADDRESS -u AURORA_MYSQL_USERNAME -p &lt; dump.sql   ¿Qué debo hacer si encuentro problemas de conexión con mi clúster Aurora MySQL?​ Verifica lo siguiente: Asegúrate de que el endpoint del clúster, nombre de usuario y contraseña sean correctos.Verifica que tus grupos de seguridad y reglas de firewall permitan el acceso.Asegúrate de que el clúster esté ejecutándose y tenga suficientes recursos (CPU, memoria).Verifica si el clúster está en estado disponible. De lo contrario, contáctanos.  ¿Cuáles son los beneficios de Aurora MySQL sobre MySQL estándar en RDS?​ Aurora MySQL ofrece varias ventajas: Rendimiento: Hasta 5x más rápido que MySQL estándar en RDSEscalabilidad: Escalado automático de almacenamiento hasta 128 TBDisponibilidad: Respaldo continuo a S3 con recuperación punto en el tiempoDurabilidad: Replicación de 6 vías a través de 3 Zonas de DisponibilidadCompatibilidad: Compatible con MySQL con cambios mínimos de códigoRentable: Paga solo por el almacenamiento que uses  info Documentación de AWS: Documentación de Amazon Aurora MySQL  ","version":"Next","tagName":"h2"},{"title":"Configura tu Aurora MySQL​","type":1,"pageTitle":"AWS Aurora MySQL","url":"/preview-docs/es/docs/project/dependency/aurora-mysql-aws#configura-tu-aurora-mysql","content":" ","version":"Next","tagName":"h2"},{"title":"1. Agrega Aurora MySQL como Dependencia​","type":1,"pageTitle":"AWS Aurora MySQL","url":"/preview-docs/es/docs/project/dependency/aurora-mysql-aws#1-agrega-aurora-mysql-como-dependencia","content":" Para integrar Aurora MySQL con SleakOps:  En la consola de SleakOps, ve a la sección &quot;Dependencies&quot;Elige &quot;Aurora MySQL&quot; de la lista de tipos de dependencias disponibles. Para más detalles, consulta Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Configura tu Aurora MySQL.​","type":1,"pageTitle":"AWS Aurora MySQL","url":"/preview-docs/es/docs/project/dependency/aurora-mysql-aws#2-configura-tu-aurora-mysql","content":" Accederás al siguiente formulario:    Aquí están los parámetros que SleakOps te permite personalizar durante la creación:  Atributo\tDescripciónNombre de la Base de Datos\tNombre para la base de datos Aurora MySQL. Debe seguir el patrón: letras minúsculas y números, no puede ser &quot;db&quot; o &quot;database&quot;. Versión del Motor de la Base de Datos\tSelecciona la versión específica del motor de la base de datos Aurora MySQL. La versión 3 es compatible con MySQL 8, la versión 2 con MySQL 5. Modo del Motor de la Base de Datos\tElige entre Serverless (auto-escalado, pago por uso para cargas de trabajo impredecibles) o Provisioned (capacidad fija, mejor para cargas de trabajo consistentes). Nombre de Usuario Maestro de la Base de Datos\tNombre de usuario maestro para el clúster Aurora MySQL. No puede ser &quot;admin&quot;, &quot;user&quot;, &quot;database&quot;, o &quot;name&quot;. Auto-generar Contraseña\tSi está habilitado, el backend generará una contraseña segura automáticamente. Contraseña Maestra de la Base de Datos\tContraseña para el usuario maestro. Requerida si auto-generar está deshabilitado. No puede contener caracteres @, ', &quot;, o /. Clase de Instancia de la Base de Datos\tModo Serverless: Fijo a db.serverless Modo Provisioned: Elige entre db.t3.medium, db.t4g.medium, db.t3.large, db.t4g.large, db.r8g.large, db.r8g.xlarge, db.r7i.large, db.r7i.xlarge.t3.medium. Capacidad Mínima de Aurora\t(Solo Serverless) Unidades de Capacidad Mínima de Aurora (0.5-256). Cada unidad ≈ 2GB RAM. Capacidad Máxima de Aurora\t(Solo Serverless) Unidades de Capacidad Máxima de Aurora (1-256). Cada unidad ≈ 2GB RAM. Crear un RDS desde un snapshot\tMarca esto si restauras desde un snapshot de base de datos. Identificador del Snapshot\t(Requerido si restauras desde snapshot) Identificador del snapshot RDS desde el cual restaurar. Período de Retención de Respaldo\tNúmero de días (1-35) para los cuales se mantienen los respaldos automáticos. Ventana de Respaldo\tPeríodo para respaldos automatizados en formato HH:MM-HH:MM (UTC). Réplicas de Lectura\tConfiguración para réplicas de lectura de la base de datos. Cada réplica requiere un nombre y configuración de acceso público.  ","version":"Next","tagName":"h3"},{"title":"3. Personaliza el nombre de tus variables para tu clúster Aurora MySQL.​","type":1,"pageTitle":"AWS Aurora MySQL","url":"/preview-docs/es/docs/project/dependency/aurora-mysql-aws#3-personaliza-el-nombre-de-tus-variables-para-tu-clúster-aurora-mysql","content":" Como se explicó, cuando se crea una dependencia, SleakOps genera un vargroup para contener todos los atributos necesarios. En este paso puedes cambiar el nombre de los atributos en caso de que sea necesario. SleakOps completa los valores automáticamente. Después de este paso, tu dependencia es creada.   ","version":"Next","tagName":"h3"},{"title":"AWS Aurora PostgreSQL","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/aurora-postgresql-aws","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"AWS Aurora PostgreSQL","url":"/preview-docs/es/docs/project/dependency/aurora-postgresql-aws#preguntas-frecuentes","content":" ¿Cómo gestiona SleakOps las credenciales de Aurora PostgreSQL?​ Cuando creas una dependencia Aurora PostgreSQL en SleakOps, se genera automáticamente un Vargroup para tu clúster de base de datos. Este Grupo de Variables almacena de forma segura las credenciales de Aurora PostgreSQL y otros detalles importantes de configuración, como el endpoint del clúster y la información de acceso del usuario. Podrás gestionarlos desde la sección de Vargroups.  ¿Puedo cambiar la versión de Aurora PostgreSQL después de desplegar el clúster?​ Sí, Aurora PostgreSQL soporta actualizaciones de versión del motor. Sin embargo, el proceso de actualización requiere planificación cuidadosa y puede involucrar tiempo de inactividad. Se recomienda probar el proceso de actualización en un entorno no productivo primero.  ¿Qué pasa si necesito más almacenamiento para mi clúster Aurora PostgreSQL?​ Aurora PostgreSQL escala automáticamente el almacenamiento de 10 GB hasta 128 TB sin requerir que provisiones almacenamiento por adelantado. El almacenamiento se escala automáticamente a medida que tus datos crecen, y solo pagas por el almacenamiento que uses.  ¿Cómo creo un dump de mi base de datos Aurora PostgreSQL?​ Para crear un dump de tu base de datos Aurora PostgreSQL: Ejecuta el comando pg_dump: pg_dump -h AURORA_POSTGRESQL_ADDRESS -U AURORA_POSTGRESQL_USERNAME -W &gt; dump.sql Reemplaza AURORA_POSTGRESQL_ADDRESS, AURORA_POSTGRESQL_USERNAME, y dump.sql con los valores apropiados. Consulta la Documentación: Para más información sobre cómo crear un dump, consulta la documentación oficial de PostgreSQL .  ¿Cómo importo un dump existente usando docker?​ Para importar un dump de base de datos a tu clúster Aurora PostgreSQL: Conecta a la VPN: Asegúrate de estar conectado a la VPN de la cuenta AWS donde se encuentra el clúster Aurora.Ejecuta Contenedor Docker (Recomendado): Instala Docker en tu máquina local si no está instalado.Ejecuta un contenedor PostgreSQL Docker con el siguiente comando: docker run -it --name aurora-postgresql-container -v ./initial_data/:/tmp/data/ -e POSTGRESQL_ROOT_PASSWORD=AURORA_POSTGRESQL_PASSWORD -d postgres bash Conecta a la terminal del contenedor: docker exec -t -i aurora-postgresql-container bash Importa el archivo dump: psql -h AURORA_POSTGRESQL_ADDRESS -U AURORA_POSTGRESQL_USERNAME -W -f /tmp/data/dump.sql Reemplaza AURORA_POSTGRESQL_ADDRESS, AURORA_POSTGRESQL_USERNAME, y dump.sql con tus detalles específicos.  ¿Cómo importo un dump existente a mi máquina local?​ Alternativamente, puedes usar un cliente PostgreSQL instalado en tu máquina local para importar el dump: psql -h AURORA_POSTGRESQL_ADDRESS -U AURORA_POSTGRESQL_USERNAME -W -f /tmp/data/dump.sql   ¿Qué debo hacer si encuentro problemas de conexión con mi clúster Aurora PostgreSQL?​ Verifica lo siguiente: Asegúrate de que el endpoint del clúster, nombre de usuario y contraseña sean correctos.Verifica que tus grupos de seguridad y reglas de firewall permitan el acceso.Asegúrate de que el clúster esté ejecutándose y tenga suficientes recursos (CPU, memoria).Verifica si el clúster está en estado disponible. De lo contrario, contáctanos.  ¿Cuáles son los beneficios de Aurora PostgreSQL sobre PostgreSQL estándar en RDS?​ Aurora PostgreSQL ofrece varias ventajas: Rendimiento: Hasta 3x más rápido que PostgreSQL estándar en RDSEscalabilidad: Escalado automático de almacenamiento hasta 128 TBDisponibilidad: Respaldo continuo a S3 con recuperación punto en el tiempoDurabilidad: Replicación de 6 vías a través de 3 Zonas de DisponibilidadCompatibilidad: Compatible con PostgreSQL con cambios mínimos de código  info Documentación de AWS: Documentación de Amazon Aurora PostgreSQL  ","version":"Next","tagName":"h2"},{"title":"Configura tu Aurora PostgreSQL​","type":1,"pageTitle":"AWS Aurora PostgreSQL","url":"/preview-docs/es/docs/project/dependency/aurora-postgresql-aws#configura-tu-aurora-postgresql","content":" ","version":"Next","tagName":"h2"},{"title":"1. Agrega Aurora PostgreSQL como Dependencia​","type":1,"pageTitle":"AWS Aurora PostgreSQL","url":"/preview-docs/es/docs/project/dependency/aurora-postgresql-aws#1-agrega-aurora-postgresql-como-dependencia","content":" Para integrar Aurora PostgreSQL con SleakOps:  En la consola de SleakOps, ve a la sección &quot;Dependencies&quot;Elige &quot;Aurora PostgreSQL&quot; de la lista de tipos de dependencias disponibles. Para más detalles, consulta Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Configura tu Aurora PostgreSQL.​","type":1,"pageTitle":"AWS Aurora PostgreSQL","url":"/preview-docs/es/docs/project/dependency/aurora-postgresql-aws#2-configura-tu-aurora-postgresql","content":" Accederás al siguiente formulario:    Aquí están los parámetros que SleakOps te permite personalizar durante la creación:  Atributo\tDescripciónNombre de la Base de Datos\tNombre para la base de datos Aurora PostgreSQL. Debe seguir el patrón: letras minúsculas y números, no puede ser &quot;db&quot; o &quot;database&quot;. Versión del Motor de la Base de Datos\tSelecciona la versión específica del motor de la base de datos Aurora PostgreSQL. Elige entre las versiones soportadas. Cada versión incluye características específicas de PostgreSQL y actualizaciones de seguridad. Modo del Motor de la Base de Datos\tAurora PostgreSQL está disponible solo en modo Serverless, que proporciona escalado automático basado en las necesidades de tu aplicación. Este modo escala la capacidad de cómputo hacia arriba y hacia abajo automáticamente, haciéndolo rentable para cargas de trabajo variables. Nombre de Usuario Maestro de la Base de Datos\tNombre de usuario maestro para el clúster Aurora PostgreSQL. Este es el usuario principal con privilegios administrativos. No puede ser &quot;admin&quot;, &quot;user&quot;, &quot;database&quot;, o &quot;name&quot;. Debe comenzar con una letra y contener solo caracteres alfanuméricos. Auto-generar Contraseña\tSi está habilitado, el backend generará una contraseña segura automáticamente para mayor seguridad. Esto se recomienda para entornos de producción. Contraseña Maestra de la Base de Datos\tContraseña para el usuario maestro. Requerida si auto-generar está deshabilitado. Debe tener al menos 8 caracteres y no puede contener caracteres @, ', &quot;, o /. Capacidad Mínima de Aurora\tUnidades de Capacidad Mínima de Aurora (0.5-256) para el clúster serverless. Cada unidad es aproximadamente igual a 2GB de RAM. Esto establece el nivel de rendimiento base y asegura que los recursos mínimos estén siempre disponibles. Capacidad Máxima de Aurora\tUnidades de Capacidad Máxima de Aurora (1-256) para el clúster serverless. Cada unidad es aproximadamente igual a 2GB de RAM. Esto previene que el clúster escale más allá de los límites de tu presupuesto mientras permite la optimización del rendimiento. Período de Retención de Respaldo\tNúmero de días (1-35) para los cuales se mantienen los respaldos automáticos. Aurora PostgreSQL respalda automáticamente tu base de datos y almacena los respaldos en Amazon S3. Períodos de retención más largos proporcionan más opciones de recuperación pero aumentan los costos de almacenamiento. Ventana de Respaldo\tPeríodo de tiempo para respaldos automatizados en formato HH:MM-HH:MM (UTC). Elige un momento cuando la actividad de tu base de datos típicamente sea baja para minimizar el impacto en el rendimiento. Aurora realiza respaldos durante esta ventana sin afectar tu aplicación. Réplicas de Lectura\tConfiguración para réplicas de lectura de la base de datos para mejorar el rendimiento de lectura y proporcionar disponibilidad adicional. Cada réplica requiere un nombre único y puede configurarse como públicamente accesible o privada. Las réplicas de lectura ayudan a distribuir el tráfico de lectura y proporcionan capacidades de conmutación por error.  ","version":"Next","tagName":"h3"},{"title":"3. Personaliza el nombre de tus variables para tu clúster Aurora PostgreSQL.​","type":1,"pageTitle":"AWS Aurora PostgreSQL","url":"/preview-docs/es/docs/project/dependency/aurora-postgresql-aws#3-personaliza-el-nombre-de-tus-variables-para-tu-clúster-aurora-postgresql","content":" Como se explicó, cuando se crea una dependencia, SleakOps genera un vargroup para contener todos los atributos necesarios. En este paso puedes cambiar el nombre de los atributos en caso de que sea necesario. SleakOps completa los valores automáticamente. Después de este paso, tu dependencia es creada.   ","version":"Next","tagName":"h3"},{"title":"AWS MariaDB","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/mariadb-aws","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"AWS MariaDB","url":"/preview-docs/es/docs/project/dependency/mariadb-aws#preguntas-frecuentes","content":" ¿Cómo gestiona SleakOps las credenciales de MariaDB?​ Cuando creas una dependencia MariaDB en SleakOps, se genera automáticamente un Vargroup para tu base de datos. Este Grupo de Variables almacena de forma segura las credenciales de MariaDB y otros detalles importantes de configuración, como el endpoint de la base de datos y la información de acceso del usuario. Podrás gestionarlos desde la sección de Vargroups.  ¿Qué es el despliegue Multi-AZ y debería habilitarlo?​ El despliegue Multi-AZ (Zona de Disponibilidad) garantiza alta disponibilidad y soporte para conmutación por error al replicar tu base de datos en otra zona de disponibilidad. Se recomienda para entornos de producción para evitar tiempos de inactividad. Ten en cuenta que aumenta los costos.  ¿Puedo cambiar la versión de MariaDB después de desplegar la base de datos?​ Sí, MariaDB soporta actualizaciones de versión del motor. Sin embargo, el proceso de actualización requiere planificación cuidadosa y puede involucrar tiempo de inactividad. Se recomienda probar el proceso de actualización en un entorno no productivo primero.  ¿Qué pasa si necesito más almacenamiento para mi base de datos MariaDB?​ Puedes ajustar el tamaño de almacenamiento al configurar tu base de datos. Si necesitas más almacenamiento después del despliegue, SleakOps te permite escalar el tamaño de almacenamiento sin tiempo de inactividad.  ¿Cómo creo un dump de mi base de datos MariaDB?​ Para crear un dump de tu base de datos MariaDB: Ejecuta el comando mysqldump: mysqldump -h MARIADB_ADDRESS -u MARIADB_USERNAME -p --all-databases &gt; dump.sql Reemplaza MARIADB_ADDRESS, MARIADB_USERNAME, y dump.sql con los valores apropiados. Consulta la Documentación: Para más información sobre cómo crear un dump, consulta la documentación oficial de MariaDB .  ¿Cómo importo un dump existente usando docker?​ Para importar un dump de base de datos a tu instancia MariaDB RDS: Conecta a la VPN: Asegúrate de estar conectado a la VPN de la cuenta AWS donde se encuentra la instancia RDS.Ejecuta Contenedor Docker (Recomendado): Instala Docker en tu máquina local si no está instalado.Ejecuta un contenedor MariaDB Docker con el siguiente comando: docker run -it --name mariadb-container -v ./initial_data/:/tmp/data/ -e MARIADB_ROOT_PASSWORD=MARIADB_PASSWORD -d mariadb bash Conecta a la terminal del contenedor: docker exec -t -i mariadb-container bash Importa el archivo dump: mysql -h MARIADB_ADDRESS -u MARIADB_USERNAME -p &lt; /tmp/data/dump.sql Reemplaza MARIADB_ADDRESS, MARIADB_USERNAME, y dump.sql con tus detalles específicos.  ¿Cómo importo un dump existente a mi máquina local?​ Alternativamente, puedes usar un cliente MariaDB instalado en tu máquina local para importar el dump: mysql -h MARIADB_ADDRESS -u MARIADB_USERNAME -p &lt; dump.sql   ¿Qué debo hacer si encuentro problemas de conexión con mi base de datos MariaDB?​ Verifica lo siguiente: Asegúrate de que el endpoint de la base de datos, nombre de usuario y contraseña sean correctos.Verifica que tus grupos de seguridad y reglas de firewall permitan el acceso.Asegúrate de que la base de datos esté ejecutándose y tenga suficientes recursos (CPU, memoria). De lo contrario, contáctanos.  info Documentación de AWS: Documentación de Amazon RDS MariaDB  ","version":"Next","tagName":"h2"},{"title":"Configura tu MariaDB​","type":1,"pageTitle":"AWS MariaDB","url":"/preview-docs/es/docs/project/dependency/mariadb-aws#configura-tu-mariadb","content":" ","version":"Next","tagName":"h2"},{"title":"1. Agrega MariaDB como Dependencia​","type":1,"pageTitle":"AWS MariaDB","url":"/preview-docs/es/docs/project/dependency/mariadb-aws#1-agrega-mariadb-como-dependencia","content":" Para integrar MariaDB con SleakOps:  En la consola de SleakOps, ve a la sección &quot;Dependencies&quot;Elige &quot;MariaDB&quot; de la lista de tipos de dependencias disponibles. Para más detalles, consulta Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Configura tu MariaDB.​","type":1,"pageTitle":"AWS MariaDB","url":"/preview-docs/es/docs/project/dependency/mariadb-aws#2-configura-tu-mariadb","content":" Accederás al siguiente formulario:    Aquí están los parámetros que SleakOps te permite personalizar durante la creación:  Atributo\tDescripciónNombre de la Base de Datos\tNombre para la base de datos MariaDB. Debe seguir el patrón: letras minúsculas y números, no puede ser &quot;db&quot; o &quot;database&quot;. Esto identifica tu base de datos específica dentro de la instancia MariaDB. Versión del Motor de la Base de Datos\tSelecciona la versión específica del motor de la base de datos MariaDB. Elige entre las versiones soportadas. Cada versión incluye características específicas de MariaDB, mejoras de rendimiento y actualizaciones de seguridad. Nombre de Usuario Maestro de la Base de Datos\tNombre de usuario maestro para la instancia de base de datos MariaDB. Este es el usuario principal con privilegios administrativos. No puede ser &quot;admin&quot;, &quot;user&quot;, &quot;database&quot;, o &quot;name&quot;. Debe comenzar con una letra y contener solo caracteres alfanuméricos. Auto-generar Contraseña\tSi está habilitado, el backend generará una contraseña segura automáticamente para mayor seguridad. Esto se recomienda para entornos de producción para asegurar la complejidad de la contraseña. Contraseña Maestra de la Base de Datos\tContraseña para el usuario maestro. Requerida si auto-generar está deshabilitado. Debe tener al menos 8 caracteres y no puede contener caracteres @, ', &quot;, o /. Crear un RDS desde un snapshot\tMarca esto si restauras desde un snapshot de base de datos. Cuando está habilitado, necesitarás proporcionar el identificador del snapshot y algunos campos se vuelven de solo lectura. Identificador del Snapshot\t(Requerido si restauras desde snapshot) Identificador del snapshot RDS desde el cual restaurar. Esto te permite restaurar tu base de datos desde un punto de respaldo anterior. Clase de Instancia de la Base de Datos\tDefine la clase de instancia que especifica la configuración de hardware para tu base de datos MariaDB. Elige entre tipos de instancia t4g/t3 (rendimiento burstable) o m7i/m8g (optimizado para memoria). Esto controla el rendimiento de CPU, memoria y red. Almacenamiento de la Base de Datos\tEspecifica la cantidad de almacenamiento asignado para la base de datos en GiB (20-6144 GB). MariaDB usa almacenamiento SSD de propósito general por defecto. Esta es la asignación de almacenamiento inicial para tu base de datos. Auto-escalado de Almacenamiento Habilitado\tHabilita el escalado automático de almacenamiento para la instancia RDS. Cuando está habilitado, AWS aumentará automáticamente el almacenamiento cuando sea necesario, hasta el límite máximo de almacenamiento asignado. Almacenamiento Máximo Asignado\t(Requerido si el auto-escalado de almacenamiento está habilitado) Tamaño máximo de almacenamiento en GiB (20-65536 GB) cuando el auto-escalado de almacenamiento está habilitado. Esto previene costos inesperados estableciendo un límite superior para el escalado automático. Multi-AZ de la Base de Datos\tHabilita el despliegue Multi-Zona de Disponibilidad para alta disponibilidad. Esto crea una réplica en espera en una AZ diferente y proporciona capacidad de conmutación por error automática. Recomendado para entornos de producción. Respaldo Automatizado\tHabilita respaldos automáticos para la instancia RDS. Cuando está habilitado, MariaDB realizará snapshots diarios y respaldos de logs de transacciones, proporcionando capacidades de recuperación punto en el tiempo. Período de Retención de Respaldo\t(Requerido si el respaldo automatizado está habilitado) Número de días (1-35) para los cuales se mantienen los respaldos automáticos. Períodos de retención más largos proporcionan más opciones de recuperación pero aumentan los costos de almacenamiento. Ventana de Respaldo\t(Requerido si el respaldo automatizado está habilitado) Período de tiempo para respaldos automatizados en formato HH:MM-HH:MM (UTC). Elige un momento cuando la actividad de tu base de datos típicamente sea baja para minimizar el impacto en el rendimiento. Réplicas de Lectura\t(Requerido si el respaldo automatizado está habilitado) Configuración para réplicas de lectura de la base de datos para mejorar el rendimiento de lectura y proporcionar disponibilidad adicional. Cada réplica requiere un nombre, clase de instancia y configuración de acceso público.  ","version":"Next","tagName":"h3"},{"title":"3. Personaliza el nombre de tus variables para tu base de datos MariaDB.​","type":1,"pageTitle":"AWS MariaDB","url":"/preview-docs/es/docs/project/dependency/mariadb-aws#3-personaliza-el-nombre-de-tus-variables-para-tu-base-de-datos-mariadb","content":" Como se explicó, cuando se crea una dependencia, SleakOps genera un vargroup para contener todos los atributos necesarios. En este paso puedes cambiar el nombre de los atributos en caso de que sea necesario. SleakOps completa los valores automáticamente. Después de este paso, tu dependencia es creada.   ","version":"Next","tagName":"h3"},{"title":"AWS Memcached","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/memcached-aws","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"AWS Memcached","url":"/preview-docs/es/docs/project/dependency/memcached-aws#preguntas-frecuentes","content":" ¿Cuáles son los casos de uso clave para Memcached?​ Memcached es ideal para cachear consultas de bases de datos frecuentemente accedidas, almacenar datos temporales de sesiones de usuario y cachear respuestas de API para reducir la carga en la base de datos.  ¿Cuándo debería usar Memcached?​ Memcached es ideal para: Necesidades de caché simples: Si necesitas un caché básico y de alta velocidad para datos frecuentemente accedidos.Datos no persistentes: Cuando no necesitas que los datos sean persistentes y puedes tolerar la pérdida de datos en caso de fallo o reinicio del nodo.Escalabilidad horizontal: Para aplicaciones que se beneficien de agregar múltiples nodos de caché para distribuir la carga de manera eficiente.Aplicaciones sensibles al costo: Memcached es más rentable que Redis porque carece de funciones avanzadas como persistencia y replicación.  ¿Por qué debería elegir Memcached sobre Redis?​ Memcached es una solución de caché más simple y rentable si no necesitas persistencia de datos, replicación o tipos de datos avanzados. Es adecuado para aplicaciones que priorizan el caché distribuido rápido.  ¿Cómo escala Memcached en SleakOps?​ Memcached escala horizontalmente agregando más nodos a tu cluster, lo que permite distribuir la carga de caché entre múltiples nodos.  ¿Memcached ofrece persistencia de datos?​ No, Memcached no soporta persistencia de datos. Todos los datos cacheados se almacenan en memoria y se perderán si el nodo se reinicia o falla.  ¿Qué sucede con los datos cacheados si un nodo falla?​ Los datos cacheados en Memcached son volátiles, lo que significa que se perderán si un nodo falla o se reinicia. Para aplicaciones críticas, Redis (que soporta persistencia de datos) podría ser una mejor opción.  ","version":"Next","tagName":"h2"},{"title":"Configura tu AWS Memcached​","type":1,"pageTitle":"AWS Memcached","url":"/preview-docs/es/docs/project/dependency/memcached-aws#configura-tu-aws-memcached","content":" ","version":"Next","tagName":"h2"},{"title":"1. Agrega AWS Memcached como una dependencia​","type":1,"pageTitle":"AWS Memcached","url":"/preview-docs/es/docs/project/dependency/memcached-aws#1-agrega-aws-memcached-como-una-dependencia","content":" Para integrar Memcached con SleakOps:  En la consola de SleakOps, ve a la sección &quot;Dependencies&quot;.Elige &quot;AWS Redis&quot; de la lista de tipos de dependencias disponibles. Para más detalles, consulta Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Configura tu base de datos Memcached​","type":1,"pageTitle":"AWS Memcached","url":"/preview-docs/es/docs/project/dependency/memcached-aws#2-configura-tu-base-de-datos-memcached","content":" Al agregar Memcached como una dependencia en SleakOps, necesitas configurar varios atributos clave:    Atributo\tDescripciónNode Type\tClase de instancia que determina el rendimiento y la capacidad de memoria de la instancia de Redis. Ejemplos: cache.t3.micro, cache.m5.large, cache.r6g.large. Nodes Quantity\tDefine la cantidad de nodos Memcached para la escalabilidad horizontal. Agregar más nodos aumenta la escalabilidad. Ejemplo: 1 o más. Port\tEl puerto de comunicación utilizado por Redis para interactuar con tu aplicación. Predeterminado: 11121 (puede personalizarse).  ","version":"Next","tagName":"h3"},{"title":"3. Personaliza los nombres de tus variables para Memcached​","type":1,"pageTitle":"AWS Memcached","url":"/preview-docs/es/docs/project/dependency/memcached-aws#3-personaliza-los-nombres-de-tus-variables-para-memcached","content":" Como se explicó, cuando se crea una dependencia, SleakOps genera un vargroup para contener todos los atributos necesarios. En este paso, puedes cambiar el nombre de los atributos si es necesario. SleakOps completa los valores automáticamente. Después de este paso, tu dependencia estará creada.   ","version":"Next","tagName":"h3"},{"title":"AWS MSK (Managed Streaming for Apache Kafka)","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/msk-aws","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"AWS MSK (Managed Streaming for Apache Kafka)","url":"/preview-docs/es/docs/project/dependency/msk-aws#preguntas-frecuentes","content":" ¿Cómo gestiona SleakOps las credenciales de MSK?​ Cuando creas una dependencia MSK en SleakOps, se genera automáticamente un Vargroup para tu clúster Kafka. Este Grupo de Variables almacena de forma segura las credenciales de MSK y otros detalles importantes de configuración, como los endpoints del clúster y la información de autenticación. Podrás gestionarlos desde la sección de Vargroups.  ¿Puedo cambiar la versión de Kafka después de desplegar el clúster?​ Sí, Amazon MSK soporta actualizaciones de versión de Kafka. Puedes actualizar entre las versiones soportadas. Sin embargo, el proceso de actualización requiere planificación cuidadosa y puede involucrar tiempo de inactividad. Se recomienda probar el proceso de actualización en un entorno no productivo primero.  ¿Qué pasa si necesito más almacenamiento para mi clúster MSK?​ Para modo Provisioned: Configuras el tamaño de almacenamiento por nodo broker (1-16384 GB) durante la creación del clúster. Este almacenamiento se provisiona y gestiona automáticamente por AWS. Si necesitas más almacenamiento, tendrás que modificar la configuración del clúster, lo que puede requerir tiempo de inactividad. Para modo Serverless: El almacenamiento se gestiona y escala automáticamente por AWS basado en tus patrones de uso. No necesitas configurar el tamaño de almacenamiento ya que se escala automáticamente.  ¿Cómo me conecto a mi clúster MSK?​ Para conectarte a tu clúster MSK: Obtén los Bootstrap Servers: Usa los endpoints de bootstrap server proporcionados por SleakOps en el vargroup.Configura la Autenticación: MSK soporta varios métodos de autenticación incluyendo SASL/SCRAM, IAM, y TLS.Usa Clientes Kafka: Conéctate usando clientes y librerías estándar de Kafka.Conexión VPN: Asegúrate de estar conectado a la VPN de la cuenta AWS donde se encuentra el clúster MSK. Nota: Tanto el modo Provisioned como Serverless usan los mismos métodos de conexión, pero el modo Serverless puede tener diferentes características de rendimiento y comportamiento de escalado.  ¿Cómo creo topics en mi clúster MSK?​ Para crear topics en tu clúster MSK: Usando Herramientas Kafka: kafka-topics.sh --create --topic my-topic --bootstrap-server MSK_BOOTSTRAP_SERVERS --partitions 3 --replication-factor 3 Usando Kafka Admin Client: Usa el Kafka Admin Client en el código de tu aplicación.Reemplaza Variables: Reemplaza MSK_BOOTSTRAP_SERVERS con los endpoints reales de bootstrap server de tu vargroup. Nota: Para modo Provisioned, establece el factor de replicación para que coincida con tu número de nodos broker (mínimo 3 para producción). Para modo Serverless, AWS gestiona la replicación automáticamente.  ¿Cómo produzco y consumo mensajes?​ Para producir y consumir mensajes: Ejemplo de Productor: kafka-console-producer.sh --topic my-topic --bootstrap-server MSK_BOOTSTRAP_SERVERS Ejemplo de Consumidor: kafka-console-consumer.sh --topic my-topic --bootstrap-server MSK_BOOTSTRAP_SERVERS --from-beginning Integración de Aplicación: Usa clientes Kafka en el código de tu aplicación para uso en producción.  ¿Qué debo hacer si encuentro problemas de conexión con mi clúster MSK?​ Verifica lo siguiente: Asegúrate de que los endpoints de bootstrap server, nombre de usuario y contraseña sean correctos.Verifica que tus grupos de seguridad y reglas de firewall permitan el acceso.Asegúrate de que el clúster esté ejecutándose y tenga suficientes recursos.Verifica si el clúster está en estado disponible.Verifica tu configuración de autenticación (SASL/SCRAM, IAM, o TLS). De lo contrario, contáctanos.  ¿Cuáles son los beneficios de Amazon MSK sobre Kafka auto-gestionado?​ Amazon MSK ofrece varias ventajas: Operaciones Administradas: No necesitas gestionar la infraestructura de KafkaAlta Disponibilidad: Capacidades de replicación y conmutación por error integradasSeguridad: Integrado con servicios de seguridad de AWSMonitoreo: Integración con CloudWatch para monitoreo y alertasEscalabilidad: Escalado fácil de instancias broker y almacenamientoCompatibilidad: Completamente compatible con Apache Kafka  info Documentación de AWS: Documentación de Amazon MSK  ","version":"Next","tagName":"h2"},{"title":"Configura tu MSK​","type":1,"pageTitle":"AWS MSK (Managed Streaming for Apache Kafka)","url":"/preview-docs/es/docs/project/dependency/msk-aws#configura-tu-msk","content":" ","version":"Next","tagName":"h2"},{"title":"1. Agrega MSK como Dependencia​","type":1,"pageTitle":"AWS MSK (Managed Streaming for Apache Kafka)","url":"/preview-docs/es/docs/project/dependency/msk-aws#1-agrega-msk-como-dependencia","content":" Para integrar MSK con SleakOps:  En la consola de SleakOps, ve a la sección &quot;Dependencies&quot;Elige &quot;MSK&quot; de la lista de tipos de dependencias disponibles. Para más detalles, consulta Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Configura tu MSK.​","type":1,"pageTitle":"AWS MSK (Managed Streaming for Apache Kafka)","url":"/preview-docs/es/docs/project/dependency/msk-aws#2-configura-tu-msk","content":" Accederás al siguiente formulario:    Aquí están los parámetros que SleakOps te permite personalizar durante la creación:  Atributo\tDescripciónModo de Despliegue\tElige entre Provisioned (capacidad fija, control completo sobre la configuración) o Serverless (auto-escalado, pago por uso para cargas de trabajo variables). El modo Provisioned es ideal para cargas de trabajo consistentes con requisitos de rendimiento específicos, mientras que Serverless es perfecto para desarrollo y patrones de tráfico variables. Versión de Kafka\t(Requerido para modo Provisioned) Selecciona la versión específica de Apache Kafka para tu clúster MSK. Elige entre las versiones 2.8.1, 3.2.0, 3.3.2, 3.4.0, o 3.5.1. Cada versión incluye características específicas de Kafka, mejoras de rendimiento y actualizaciones de seguridad. Tipo de Instancia\t(Requerido para modo Provisioned) Define el tipo de instancia que especifica la configuración de hardware para tus brokers Kafka. Elige entre tipos de instancia t3 (rendimiento burstable) o m5 (propósito general). Esto controla el rendimiento de CPU, memoria y red para tus cargas de trabajo de streaming. Nodos Broker\t(Requerido para modo Provisioned) Número de nodos broker en tu clúster MSK (2-15 nodos). Usa 2 nodos para entornos de desarrollo. Para producción, usa 3 o más nodos (debe ser múltiplo de 3) para asegurar alta disponibilidad y tolerancia a fallos. Más nodos proporcionan mejor rendimiento y disponibilidad. Tamaño de Almacenamiento (GB)\t(Requerido para modo Provisioned) Tamaño de almacenamiento en GB por nodo broker (1-16384 GB). Esto determina cuántos datos puede almacenar localmente cada broker. Considera tus requisitos de retención de datos y necesidades de throughput al establecer este valor.  ","version":"Next","tagName":"h3"},{"title":"3. Personaliza el nombre de tus variables para tu clúster MSK.​","type":1,"pageTitle":"AWS MSK (Managed Streaming for Apache Kafka)","url":"/preview-docs/es/docs/project/dependency/msk-aws#3-personaliza-el-nombre-de-tus-variables-para-tu-clúster-msk","content":" Como se explicó, cuando se crea una dependencia, SleakOps genera un vargroup para contener todos los atributos necesarios. En este paso puedes cambiar el nombre de los atributos en caso de que sea necesario. SleakOps completa los valores automáticamente. Después de este paso, tu dependencia es creada.   ","version":"Next","tagName":"h3"},{"title":"MySQL en AWS","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/mysql-aws","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"MySQL en AWS","url":"/preview-docs/es/docs/project/dependency/mysql-aws#preguntas-frecuentes","content":" ¿Cómo gestiona SleakOps las credenciales de MySQL?​ Cuando creas una dependencia MySQL en SleakOps, se genera automáticamente un Vargroup para tu base de datos. Este Grupo de Variables almacena de forma segura las credenciales de MySQL y otros detalles importantes de configuración, como el endpoint de la base de datos y la información de acceso del usuario. Podrás gestionarlos desde la sección de Vargroups.  ¿Qué es el despliegue Multi-AZ y debería habilitarlo?​ El despliegue Multi-AZ (Zona de Disponibilidad) garantiza alta disponibilidad y soporte para conmutación por error al replicar tu base de datos en otra zona de disponibilidad. Se recomienda para entornos de producción para evitar tiempos de inactividad. Ten en cuenta que aumenta los costos.  ¿Puedo cambiar la versión de MySQL después de desplegar la base de datos?​ No, la versión del motor de la base de datos no puede cambiarse después del despliegue. Necesitarías crear una nueva instancia de MySQL con la versión deseada y migrar tus datos. O cambiarlo manualmente en la Consola de AWS.  ¿Qué hago si necesito más almacenamiento para mi base de datos MySQL?​ Puedes ajustar el tamaño de almacenamiento al configurar tu base de datos. Si necesitas más almacenamiento después del despliegue, puedes escalar modificando la configuración en AWS, ya que por el momento SleakOps no lo permite.  ¿Cómo creo un dump de mi base de datos MySQL?​ Para crear un dump de tu base de datos MySQL, usa el siguiente comando: sh mysqldump -h MYSQL_ADDRESS -u MYSQL_USERNAME -p MYSQL_PASSWORD &gt; dump.sql Reemplaza MYSQL_ADDRESS, MYSQL_USERNAME y MYSQL_PASSWORD con los valores apropiados. Para información adicional sobre cómo crear un dump en MySQL, consulta la documentación oficial de MySQL. Otra opción es crearlo directamente desde la Consola de AWS y luego importarlo. Consulta Restaurar en una instancia de base de datos.  ¿Cómo importo un dump existente usando Docker? Para más detalles: Documentación de dump MySQL Para importar un dump de base de datos a tu instancia MySQL en RDS: Conéctate a la VPN: Asegúrate de estar conectado a la VPN de la cuenta AWS donde está ubicada la instancia RDS.Ejecuta un contenedor Docker (Recomendado): Instala Docker en tu máquina local si aún no lo tienes instalado.Ejecuta un contenedor MySQL con el siguiente comando: sh docker run -it --name mysql-container -v ./initial_data/:/tmp/data/ -e MYSQL_ROOT_PASSWORD=MYSQL_PASSWORD -d mysql bash Conéctate a la terminal del contenedor: sh docker exec -t -i mysql-container bash Importa el archivo dump: sh mysql -h MYSQL_ADDRESS -u MYSQL_USERNAME -p &lt; /tmp/data/dump.sql Reemplaza MYSQL_ADDRESS, MYSQL_USERNAME y MYSQL_PASSWORD con los detalles de tu instancia RDS.  Cómo importo un dump existente a mi máquina local? Alternativamente, puedes usar un cliente de MySQL instalado en tu máquina local para importar el dump. mysql -h MYSQL_ADDRESS -u MYSQL_USERNAME -p MYSQL_PASSWORD &lt; /tmp/data/dump.sql   ¿Qué debo hacer si tengo problemas de conexión con mi base de datos MySQL? Verifica que el endpoint de la base de datos, el nombre de usuario y la contraseña sean correctos.Asegúrate de que los grupos de seguridad y las reglas del firewall permitan el acceso.Verifica que la base de datos esté en funcionamiento y tenga suficientes recursos (CPU, memoria). Si el problema persiste, contáctanos.  ¿Qué es una réplica de lectura en RDS? Una réplica de lectura de RDS es una copia de solo lectura de tu instancia de base de datos principal en Amazon RDS. Ayuda a distribuir cargas pesadas de lectura y mejora el rendimiento y la escalabilidad de tu base de datos al descargar las operaciones de lectura desde la base de datos principal. Las réplicas de lectura de RDS son ideales cuando necesitas: Descargar operaciones intensivas de lectura de tu instancia principal.Escalar tus operaciones de lectura a medida que tu aplicación crece.Distribuir las lecturas de la base de datos entre múltiples ubicaciones geográficas.Tener una solución de respaldo que pueda promoverse rápidamente como instancia principal en caso de falla. info Ten en cuenta que las réplicas de lectura tienen un retraso al realizar actualizaciones.  ¿Cómo configuro una réplica de lectura en SleakOps? En SleakOps, al crear una réplica de lectura para tu base de datos RDS, necesitas proporcionar la siguiente información: Nombre de la réplicaClase de instancia de la réplica, que determina el tipo de instancia para la réplica.Accesibilidad pública de la réplica, para decidir si la réplica debe tener una IP pública o ser accesible solo dentro de tu red privada.  ¿Puedo eliminar una réplica? Actualmente, la única forma de hacerlo es eliminando la dependencia.  info Documentación de AWS: Documentación de Amazon RDS MySql  ","version":"Next","tagName":"h2"},{"title":"Configura tu MySQL​","type":1,"pageTitle":"MySQL en AWS","url":"/preview-docs/es/docs/project/dependency/mysql-aws#configura-tu-mysql","content":" ","version":"Next","tagName":"h2"},{"title":"1. Agregar MySQL como una Dependencia​","type":1,"pageTitle":"MySQL en AWS","url":"/preview-docs/es/docs/project/dependency/mysql-aws#1-agregar-mysql-como-una-dependencia","content":" Para integrar MySQL con SleakOps:  En la consola de SleakOps, ve a la sección &quot;Dependencias&quot;.Elige &quot;MySQL&quot; de la lista de tipos de dependencias disponibles. Para más detalles, consulta Dependencias: Integrando Bases de Datos, Caché y Servicios de Mensajería.  ","version":"Next","tagName":"h3"},{"title":"2. Configura tu MySQL.​","type":1,"pageTitle":"MySQL en AWS","url":"/preview-docs/es/docs/project/dependency/mysql-aws#2-configura-tu-mysql","content":" Accederás al siguiente formulario:    Aquí están los parámetros que SleakOps te permite personalizar durante la creación:  Atributo\tDescripciónVersión del Motor de Base de Datos\tSelecciona la versión específica del motor de base de datos MySQL que deseas usar. Esto asegura compatibilidad con los requerimientos de tu aplicación. Ejemplo: MySQL 8.0.2, MySQL 5.7.1. Clase de Instancia de Base de Datos\tDefine la clase de instancia que especifica la configuración de hardware para tu base de datos MySQL. Esto controla el rendimiento de CPU, memoria y red. Ejemplo: db.m6g.large, db.t3.medium. Consulta más detalles en AWS. Almacenamiento de Base de Datos\tEspecifica la cantidad de almacenamiento asignado para la base de datos. Ejemplo: 100 GB, 500 GB. Nombre de Usuario\tProporciona el nombre de usuario maestro para la base de datos MySQL. Este es el usuario principal con privilegios administrativos. Ejemplo: admin, root. Contraseña\tContraseña para que el usuario maestro acceda a la base de datos. Zona de Disponibilidad Múltiple\tActiva o desactiva la implementación Multi-AZ. Esto asegura alta disponibilidad y soporte de conmutación por error replicando la base de datos en múltiples zonas de disponibilidad. Recomendado para entornos de producción. Copia de Seguridad Automática\tConfigura copias de seguridad automáticas para la base de datos MySQL. Esto asegura la protección de los datos activando instantáneas diarias y copias de seguridad del registro de transacciones. Configura el Periodo de Retención de Copias de Seguridad y la Ventana de Copias de Seguridad. Recomendado para entornos de producción. Periodo de Retención de Copias de Seguridad\tDefine el número de días para retener copias de seguridad automáticas. Ventana de Copias de Seguridad\tPeriodo de tiempo en el que se realizarán las copias de seguridad.  aviso SleakOps solo permite la creación de réplicas durante la creación de la dependencia.  Después de ingresar los datos básicos, necesitas decidir si se creará una réplica. Para hacerlo:  En el formulario, busca la sección Definición de Réplicas de Lectura RDS y haz clic en + Añadir Elemento.Completa los siguientes datos:  Configuración\tDescripciónNombre\tUn nombre para la réplica. Clase de Instancia de Réplica\tDefine la clase de instancia que especifica la configuración de hardware para tu base de datos MySQL. Esto controla el rendimiento de CPU, memoria y red. Ejemplo: db.m6g.large, db.t3.medium. Réplica Accesible Públicamente\tDecide si la réplica debería tener una IP pública o ser accesible solo dentro de tu red privada.  ","version":"Next","tagName":"h3"},{"title":"3. Personaliza el nombre de las variables para tu base de datos MySQL.​","type":1,"pageTitle":"MySQL en AWS","url":"/preview-docs/es/docs/project/dependency/mysql-aws#3-personaliza-el-nombre-de-las-variables-para-tu-base-de-datos-mysql","content":" Como se explicó, cuando se crea una dependencia, SleakOps genera un grupo de variables (vargroup) para contener todos los atributos necesarios. En este paso, puedes cambiar el nombre de los atributos si es necesario. SleakOps completa automáticamente los valores. Después de este paso, tu dependencia está creada.   ","version":"Next","tagName":"h3"},{"title":"AWS OpenSearch","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/opensearch-aws","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"AWS OpenSearch","url":"/preview-docs/es/docs/project/dependency/opensearch-aws#preguntas-frecuentes","content":" ¿Cuáles son los casos de uso de OpenSearch?​ OpenSearch se utiliza comúnmente para búsquedas de texto completo, análisis en tiempo real, monitoreo y observabilidad, y análisis de registros. También es ideal para potenciar funcionalidades de búsqueda en sitios web y aplicaciones.  ¿Qué significa &quot;Dedicated Master Enabled&quot;?​ Cuando está habilitado, SleakOps configura nodos maestros dedicados que ayudan a gestionar el dominio de OpenSearch. Proporcionan mayor estabilidad al separar las tareas de gestión de los nodos de datos. Esto es altamente recomendado para cargas de trabajo en producción.  ¿Cuál es la configuración recomendada para nodos maestros en producción?​ Para entornos de producción, SleakOps recomienda usar 3 nodos maestros dedicados para mejorar la estabilidad y el rendimiento de tu clúster de OpenSearch.  ","version":"Next","tagName":"h2"},{"title":"Configura tu OpenSearch​","type":1,"pageTitle":"AWS OpenSearch","url":"/preview-docs/es/docs/project/dependency/opensearch-aws#configura-tu-opensearch","content":" ","version":"Next","tagName":"h2"},{"title":"1. Agrega AWS OpenSearch como una Dependencia​","type":1,"pageTitle":"AWS OpenSearch","url":"/preview-docs/es/docs/project/dependency/opensearch-aws#1-agrega-aws-opensearch-como-una-dependencia","content":" Para integrar OpenSearch con SleakOps:  En la consola de SleakOps, ve a la sección &quot;Dependencias&quot;.Elige &quot;SQS&quot; de la lista de tipos de dependencias disponibles. Para más detalles, consulta Dependencias: Integrando Bases de Datos, Caché y Servicios de Mensajería.  ","version":"Next","tagName":"h3"},{"title":"2. Configura tu OpenSearch.​","type":1,"pageTitle":"AWS OpenSearch","url":"/preview-docs/es/docs/project/dependency/opensearch-aws#2-configura-tu-opensearch","content":" Al agregar OpenSearch como una dependencia en SleakOps, necesitas configurar varios atributos clave:    Atributo\tDescripciónCola FIFO\tEspecifica el tipo de cola SQS: Standard Queue (para la mayoría de los casos) o FIFO Queue (si se requiere orden de mensajes). Desduplicación FIFO\tSolo para Colas FIFO, para evitar duplicados. Periodo de Retención de Mensajes\tEspecifica la cantidad de tiempo que un mensaje será retenido en la cola si no ha sido consumido. Tamaño Máximo de Mensaje\tEl tamaño máximo de un mensaje que puede ser enviado a la cola SQS. Retraso en la Entrega en Segundos\tEl retraso entre el envío de un mensaje a SQS y su visibilidad en la cola. Sin retraso por defecto. Tiempo de Espera para Recibir Mensajes\tDetermina cuánto tiempo esperará una llamada ReceiveMessage si no hay mensajes disponibles en la cola. Timeout de Visibilidad\tLa duración durante la cual un mensaje permanece invisible después de que un componente lo lea desde la cola. Cola de Mensajes Fallidos (DLQ)\tAgrega una cola donde los mensajes que fallan en ser procesados múltiples veces son enviados para análisis adicional.  ","version":"Next","tagName":"h3"},{"title":"3. Personaliza los nombres de tus variables para tu SQS.​","type":1,"pageTitle":"AWS OpenSearch","url":"/preview-docs/es/docs/project/dependency/opensearch-aws#3-personaliza-los-nombres-de-tus-variables-para-tu-sqs","content":" Como se explicó, cuando se crea una dependencia, SleakOps genera un grupo de variables (vargroup) para contener todos los atributos necesarios. En este paso, puedes cambiar el nombre de los atributos si es necesario. SleakOps completa automáticamente los valores. Después de este paso, tu dependencia está creada.   ","version":"Next","tagName":"h3"},{"title":"AWS Oracle","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/oracle-aws","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"AWS Oracle","url":"/preview-docs/es/docs/project/dependency/oracle-aws#faqs","content":" License​ When creating an Oracle DB using Sleakops License Included (LI). Currently Bring Your Own License (BYOL) is not supported, however, contact support for more information.  How does SleakOps manage Oracle credentials?​ When you create an Oracle dependency in SleakOps, it automatically generates a Vargroup for your database. This Variable Group securely stores the Oracle credentials and other important configuration details, such as the database endpoint and user access information. You'll be able of manage them from Vargroups section.  What is Multi-AZ deployment and should I enable it?​ Multi-AZ (Availability Zone) deployment ensures high availability and failover support by replicating your database in another availability zone. It's recommended for production environments to prevent downtime. Keep in mind that it increases costs.  Can I change the Oracle version after the database is deployed?​ No, the database engine version cannot be changed after deployment. You would need to create a new Oracle instance with the desired version and migrate your data. Or change it manually into the AWS Console.  What happens if I need more storage for my Oracle database?​ You can adjust the storage size when configuring your database. If you need more storage after deployment, you can scale modifying the settings in AWS as at the moment SleakOps does not support it.  How do I create a Oracle database dump?​ aviso The client is only available for x86-64 Linux distributions. tip Follow this link to install the client To create a dump of your Oracle database, use the following command: exp ${ORACLE_USERNAME}/${ORACLE_PASSWORD}@${ORACLE_ENDPOINT}/${ORACLE_NAME} FILE=exp_file.dmp LOG=exp_file.log Replace ORACLE_USERNAME, ORACLE_ENDPOINT, ORACLE_NAME and ORACLE_PASSWORD with the appropriate values. For additional information on creating an Oracle dump, refer to the official Oracle documentation . Another option is creating it directly from the AWS Console and then import it. See Restoring to a DB instance.  How do I import an existent dump ?​ aviso The client is only available for x86-64 Linux distributions. tip Follow this link to install the client You can use a Oracle client installed on your local machine to import the dump. imp ${ORACLE_USERNAME}/${ORACLE_PASSWORD}@${ORACLE_ENDPOINT}/${ORACLE_NAME} FROMUSER=cust_schema TOUSER=cust_schema FILE=exp_file.dmp LOG=imp_file.log Replace ORACLE_USERNAME, ORACLE_ENDPOINT, ORACLE_NAME and ORACLE_PASSWORD with the appropriate values. For additional information on importing an Oracle dump, refer to the official Oracle documentation . Another option is creating it directly from the AWS Console and then import it. See Restoring to a DB instance.  What should I do if I encounter connection issues with my Oracle database?​ Ensure the database endpoint, username, and password are correct.Verify that your security groups and firewall rules allow access.Ensure the database is running and has enough resources (CPU, memory). Otherwise, contact us.  info AWS documentation: Amazon RDS Oracle Documentation  ","version":"Next","tagName":"h2"},{"title":"Set up your Oracle​","type":1,"pageTitle":"AWS Oracle","url":"/preview-docs/es/docs/project/dependency/oracle-aws#set-up-your-oracle","content":" ","version":"Next","tagName":"h2"},{"title":"1. Add Oracle as a Dependency​","type":1,"pageTitle":"AWS Oracle","url":"/preview-docs/es/docs/project/dependency/oracle-aws#1-add-oracle-as-a-dependency","content":" To integrate Oracle with SleakOps:  In the SleakOps console, go to the &quot;Dependencies&quot; sectionChoose &quot;Oracle&quot; from the list of available dependency types. For more detail see Dependencies: Integrating Databases, Caching, and Messaging Services.  ","version":"Next","tagName":"h3"},{"title":"2. Set up your Oracle.​","type":1,"pageTitle":"AWS Oracle","url":"/preview-docs/es/docs/project/dependency/oracle-aws#2-set-up-your-oracle","content":" You will access the following form:    Here the parameters that SleakOps allows you to customize during the creation:  Attribute\tDescriptionDatabase Engine Version\tSelect the specific version of the Oracle database engine you wish to use. This ensures compatibility with your application requirements. Example: 19.0.0.0.ru-2024-01.rur-2024-01.r1 Database Instance Class\tDefine the instance class that specifies the hardware configuration for your Oracle database. This controls CPU, memory, and network performance. Example: db.m6g.large, db.t3.medium. See AWS detail. Database Storage\tSpecify the amount of storage allocated for the database. Example: 100 GB, 500 GB. Username\tProvide the master username for the Oracle database. This is the main user with administrative privileges. Example: admin, root. Password\tPassword for the master user to access the database. Multi-Availability Zone\tEnable or disable Multi-AZ deployment. This ensures high availability and failover support by replicating the database across multiple availability zones. Recommended for production environments. Automated Backup\tConfigure automated backups for the Oracle database. This ensures data protection by enabling daily snapshots and transaction log backups. Set up the Backup Retention Period and the Backup Window. Recommended for production environments. Backup Retention Period\tSet the number of days to retain automated backups. Backup Window\tPeriod of time while the backup will be done.  ","version":"Next","tagName":"h3"},{"title":"3. Customize your variable's name for your Oracle data base.​","type":1,"pageTitle":"AWS Oracle","url":"/preview-docs/es/docs/project/dependency/oracle-aws#3-customize-your-variables-name-for-your-oracle-data-base","content":" As explained, when a dependency is created, SleakOps generates a vargroup to hold all the needed attributes. In this step you can change the name of the attributes in case it is needed. SleakOps completes the values automatically. After this step, your dependency is created.   ","version":"Next","tagName":"h3"},{"title":"AWS PosgreSQL","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/postgresql-aws","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"AWS PosgreSQL","url":"/preview-docs/es/docs/project/dependency/postgresql-aws#preguntas-frecuentes","content":" ¿Cómo gestiona SleakOps las credenciales de PostgreSQL?​ Cuando creas una dependencia de PostgreSQL en SleakOps, este genera automáticamente un Vargroup para tu base de datos. Este Grupo de Variables almacena de forma segura las credenciales de MySQL y otros detalles importantes de configuración, como el endpoint de la base de datos y la información de acceso de usuarios. Podrás gestionarlos desde la sección Vargroups.  ¿Qué es una implementación Multi-AZ y debería habilitarla?​ La implementación Multi-AZ (Zona de Disponibilidad) garantiza alta disponibilidad y soporte de conmutación por error al replicar tu base de datos en otra zona de disponibilidad. Se recomienda para entornos de producción para evitar tiempos de inactividad. Ten en cuenta que incrementa los costos.  ¿Puedo cambiar la versión de PostgreSQL después de que la base de datos esté implementada?​ No, la versión del motor de base de datos no puede cambiarse después de la implementación. Necesitarías crear una nueva instancia de PostgreSQL con la versión deseada y migrar tus datos. O bien cambiarla manualmente en la consola de AWS.  ¿Qué sucede si necesito más almacenamiento para mi base de datos PostgreSQL?​ Puedes ajustar el tamaño de almacenamiento al configurar tu base de datos. Si necesitas más almacenamiento después de la implementación, SleakOps te permite escalar el tamaño de almacenamiento sin tiempos de inactividad.  ¿Cómo puedo crear un backup (dump) de mi base de datos PostgreSQL?​ Para crear un backup de tu base de datos PostgreSQL: Ejecuta el comando pg_dump: sh pg_dump -h POSTGRESQL_ADDRESS -U POSTGRESQL_USERNAME -W &gt; dump.sql Reemplaza POSTGRESQL_ADDRESS, POSTGRESQL_USERNAME y dump.sql con los valores correspondientes. 2. Consulta la documentación: Para más información, consulta la documentación oficial de PostgreSQL.  ¿Cómo importo un backup existente usando Docker?​ Para importar un dump de base de datos en tu instancia de PostgreSQL RDS: Conéctate a la VPN: Asegúrate de estar conectado a la VPN de la cuenta AWS donde está ubicada la instancia RDS.Ejecuta un contenedor Docker (Recomendado): Instala Docker en tu máquina local si aún no lo tienes.Ejecuta un contenedor Docker de PostgreSQL con el siguiente comando: sh docker run -it --name postgresql-container -v ./initial_data/:/tmp/data/ -e POSTGRESQL_ROOT_PASSWORD=POSTGRESQL_PASSWORD -d postgres bash Conéctate al terminal del contenedor: sh docker exec -t -i postgresql-container bash Importa el archivo de backup: pg_dump -h POSTGRESQL_ADDRESS -U POSTGRESQL_USERNAME -W &lt; /tmp/data/dump.sql Reemplaza POSTGRESQL_ADDRESS, POSTGRESQL_USERNAME y dump.sql con tus detalles específicos.  ¿Cómo importo un dump existente a mi máquina local?​ Alternativamente, puedes usar un cliente de PostgreSQL instalado en tu máquina local para importar el dump. sh psql -h POSTGRESQL_ADDRESS -U POSTGRESQL_USERNAME -W -f /tmp/data/dump.sql   ¿Qué debo hacer si encuentro problemas de conexión con mi base de datos PostgreSQL?​ Verifica lo siguiente: Asegúrate de que el endpoint de la base de datos, el nombre de usuario y la contraseña sean correctos.Verifica que las reglas de tu firewall permitan el acceso.Asegúrate de que la base de datos esté funcionando y tenga suficientes recursos (CPU, memoria). De lo contrario, contáctanos.  ¿Qué es una réplica de lectura de RDS?​ Una réplica de lectura de RDS es una copia de solo lectura de tu instancia principal de base de datos en Amazon RDS. Ayuda a distribuir las cargas de trabajo de lectura intensivas y mejora el rendimiento y la escalabilidad de tu base de datos al descargar las operaciones de lectura de la base de datos principal. Las réplicas de lectura de RDS son ideales cuando necesitas: Descargar operaciones de lectura intensivas de tu instancia principal.Escalar las operaciones de lectura a medida que tu aplicación crece.Distribuir las lecturas de la base de datos en múltiples ubicaciones geográficas.Tener una solución de respaldo que pueda ser promovida rápidamente a una instancia principal en caso de falla. info Ten en cuenta que las réplicas de lectura tienen un retraso al realizar actualizaciones.  ¿Cómo configuro una réplica de lectura en SleakOps?​ En SleakOps, cuando creas una réplica de lectura para tu base de datos RDS, necesitarás proporcionar la siguiente información: Nombre de la réplicaClase de Instancia de la réplica, que determina el tipo de instancia para la réplica.Accesibilidad Pública de la réplica, para decidir si la réplica debe tener una IP pública o ser accesible solo dentro de tu red privada.  ¿Puedo eliminar una réplica?​ Por el momento, la única forma es eliminar la dependencia.  info Documentación de AWS: Documentación de Amazon RDS PostgreSQL  ","version":"Next","tagName":"h2"},{"title":"Configura tu PostgreSQL​","type":1,"pageTitle":"AWS PosgreSQL","url":"/preview-docs/es/docs/project/dependency/postgresql-aws#configura-tu-postgresql","content":" ","version":"Next","tagName":"h2"},{"title":"1. Agregar PostgreSQL como una dependencia​","type":1,"pageTitle":"AWS PosgreSQL","url":"/preview-docs/es/docs/project/dependency/postgresql-aws#1-agregar-postgresql-como-una-dependencia","content":" Para integrar PostgreSQL con SleakOps:  En la consola de SleakOps, ve a la sección &quot;Dependencies&quot;.Elige &quot;PostgreSQL&quot; de la lista de tipos de dependencia disponibles. Para más detalles, consulta Dependencies: Integración de Bases de Datos, Caching y Servicios de Mensajería.  ","version":"Next","tagName":"h3"},{"title":"2. Configura tu base de datos PostgreSQL.​","type":1,"pageTitle":"AWS PosgreSQL","url":"/preview-docs/es/docs/project/dependency/postgresql-aws#2-configura-tu-base-de-datos-postgresql","content":" Accederás al siguiente formulario:    Estos son los parámetros que SleakOps te permite personalizar durante la creación:  Atributo\tDescripciónVersión del Motor de Base de Datos\tSelecciona la versión específica del motor de base de datos PostgreSQL que deseas usar. Esto asegura la compatibilidad con los requisitos de tu aplicación. Ejemplo: PostgreSQL 14.9, PostgreSQL 16.5. Clase de Instancia de Base de Datos\tDefine la clase de instancia que especifica la configuración de hardware para tu base de datos PostgreSQL. Esto controla el rendimiento de CPU, memoria y red. Ejemplo: db.m6g.large, db.t3.medium. Consulta detalles de AWS. Almacenamiento de Base de Datos\tEspecifica la cantidad de almacenamiento asignado para la base de datos. Ejemplo: 100 GB, 500 GB. Nombre de Usuario\tProporciona el nombre de usuario principal para la base de datos PostgreSQL. Este es el usuario principal con privilegios administrativos. Ejemplo: admin, root. Contraseña\tContraseña para el usuario principal para acceder a la base de datos. Zona de Disponibilidad Múltiple (Multi-AZ)\tHabilita o deshabilita la implementación Multi-AZ. Esto asegura alta disponibilidad y soporte de conmutación por error al replicar la base de datos en múltiples zonas de disponibilidad. Se recomienda para entornos de producción. Respaldo Automático\tConfigura respaldos automáticos para la base de datos PostgreSQL. Esto asegura la protección de datos al habilitar instantáneas diarias y respaldos de registros de transacciones. Configura el Periodo de Retención de Respaldo y la Ventana de Respaldo. Se recomienda para entornos de producción. Periodo de Retención de Respaldo\tEstablece el número de días para retener los respaldos automáticos. Ventana de Respaldo\tPeríodo de tiempo durante el cual se realizarán los respaldos.  aviso SleakOps permite la creación de réplicas solo durante la creación de la dependencia.  Después de estos datos básicos, necesitarás decidir si se creará una réplica. Para hacerlo:  En el formulario, busca la sección Definición de Réplicas de Lectura de RDS y haz clic en + Añadir Elemento.Completa los siguientes datos:  Configuración\tDescripciónNombre\tUn nombre para la réplica Clase de Instancia de la réplica\tDefine la clase de instancia que especifica la configuración de hardware para la réplica. Esto controla el rendimiento de CPU, memoria y red. Ejemplo: db.m6g.large, db.t3.medium. Accesibilidad Pública de la réplica\tDecide si la réplica debe tener una IP pública o ser accesible solo dentro de tu red privada.  ","version":"Next","tagName":"h3"},{"title":"3. Personaliza el nombre de tus variables para tu base de datos PostgreSQL.​","type":1,"pageTitle":"AWS PosgreSQL","url":"/preview-docs/es/docs/project/dependency/postgresql-aws#3-personaliza-el-nombre-de-tus-variables-para-tu-base-de-datos-postgresql","content":" Como se explicó, cuando se crea una dependencia, SleakOps genera un vargroup para almacenar todos los atributos necesarios. En este paso, puedes cambiar el nombre de los atributos si es necesario. SleakOps completa los valores automáticamente. Después de este paso, tu dependencia se crea.   ","version":"Next","tagName":"h3"},{"title":"AWS Redis","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/redis-aws","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"AWS Redis","url":"/preview-docs/es/docs/project/dependency/redis-aws#preguntas-frecuentes","content":" ¿Qué características hacen de Redis una buena opción para mi aplicación?​ Redis ofrece varias características avanzadas que lo hacen adecuado para una amplia gama de aplicaciones: Persistencia de Datos: Redis puede guardar los datos en disco, asegurando que la información no se pierda en caso de un reinicio.Estructuras de Datos Avanzadas: Redis soporta estructuras de datos más complejas que los almacenes clave-valor simples, como listas, conjuntos, hashes, conjuntos ordenados y más.Alta Disponibilidad: A través de replicación y conmutación por error automática, Redis asegura que tu aplicación siga funcionando incluso si un nodo falla.Escalabilidad: Redis se puede escalar tanto verticalmente (con instancias más grandes) como horizontalmente (mediante particionamiento y clústeres).Mensajería Pub/Sub: Redis ofrece soporte nativo para patrones de mensajería de publicación/suscripción, útiles para construir aplicaciones en tiempo real.  ¿Cuáles son los casos de uso comunes de Redis?​ Redis es versátil y puede utilizarse en una variedad de escenarios, incluidos: Gestión de Sesiones: Redis se usa comúnmente para almacenar datos de sesiones de usuario debido a su acceso a datos de baja latencia y características de persistencia.Caché: Redis es ideal para almacenar en caché los datos a los que se accede con frecuencia, reduciendo la carga sobre las bases de datos principales y mejorando los tiempos de respuesta.Análisis en Tiempo Real: Las capacidades de procesamiento rápido en memoria de Redis lo hacen perfecto para análisis en tiempo real, clasificaciones y contadores.Colas de Mensajes: Con la funcionalidad pub/sub de Redis, puedes utilizarlo para sistemas de mensajería y transmisión de eventos.Colas de Trabajo: Redis se usa para gestionar colas de trabajo en segundo plano en aplicaciones a gran escala.  ¿Cómo se diferencia Redis de Memcached?​ Redis es más completo que Memcached. Redis soporta una variedad de estructuras de datos como listas, conjuntos y hashes, mientras que Memcached se limita a pares clave-valor simples. Redis también soporta persistencia de datos y replicación, lo que lo hace adecuado para aplicaciones donde la durabilidad y la alta disponibilidad son críticas. Sin embargo, Memcached es típicamente más ligero y rápido para escenarios básicos de almacenamiento en caché.  ","version":"Next","tagName":"h2"},{"title":"Configura tu Redis en AWS​","type":1,"pageTitle":"AWS Redis","url":"/preview-docs/es/docs/project/dependency/redis-aws#configura-tu-redis-en-aws","content":" ","version":"Next","tagName":"h2"},{"title":"1. Agregar AWS Redis como Dependencia​","type":1,"pageTitle":"AWS Redis","url":"/preview-docs/es/docs/project/dependency/redis-aws#1-agregar-aws-redis-como-dependencia","content":" Para integrar Redis con SleakOps:  En la consola de SleakOps, ve a la sección &quot;Dependencias&quot;.Elige &quot;AWS Redis&quot; de la lista de tipos de dependencias disponibles. Para más detalles, consulta Dependencias: Integración de Bases de Datos, Caching y Servicios de Mensajería.  ","version":"Next","tagName":"h3"},{"title":"2. Configura tu base de datos Redis.​","type":1,"pageTitle":"AWS Redis","url":"/preview-docs/es/docs/project/dependency/redis-aws#2-configura-tu-base-de-datos-redis","content":" Accederás al siguiente formulario:    Aquí están los parámetros que SleakOps te permite personalizar durante la creación:  Atributo\tDescripciónTipo de Nodo\tClase de instancia que determina el rendimiento y la capacidad de memoria de la instancia Redis. Ejemplos: cache.t3.micro, cache.m5.large, cache.r6g.large Puerto\tEl puerto de comunicación utilizado por Redis para interactuar con tu aplicación. Por defecto: 6379 (puede ser personalizado)  ","version":"Next","tagName":"h3"},{"title":"3. Personaliza los nombres de tus variables para Redis.​","type":1,"pageTitle":"AWS Redis","url":"/preview-docs/es/docs/project/dependency/redis-aws#3-personaliza-los-nombres-de-tus-variables-para-redis","content":" Como se explicó, cuando se crea una dependencia, SleakOps genera un vargroup para contener todos los atributos necesarios. En este paso, puedes cambiar el nombre de los atributos si es necesario. SleakOps completará los valores automáticamente. Después de este paso, tu dependencia estará creada.   ","version":"Next","tagName":"h3"},{"title":"AWS SQS","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/sqs-aws","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"AWS SQS","url":"/preview-docs/es/docs/project/dependency/sqs-aws#preguntas-frecuentes","content":" ¿Cuál es la diferencia entre una Cola Estándar y una Cola FIFO?​ Una Cola Estándar soporta un alto rendimiento con entrega de mensajes al menos una vez. El orden de los mensajes no está garantizado, pero es ideal para escenarios en los que el orden de los mensajes no es crítico.Una Cola FIFO asegura el orden de los mensajes y entrega exacta una vez. Es adecuada para aplicaciones donde el orden de los mensajes es crucial.  ¿Qué es la implementación Multi-AZ y debo habilitarla?​ La implementación Multi-AZ (Zona de Disponibilidad) asegura alta disponibilidad y soporte de conmutación por error replicando tu base de datos en otra zona de disponibilidad. Se recomienda para entornos de producción para evitar el tiempo de inactividad. Ten en cuenta que aumenta los costos.  ¿Qué es una Cola de Muertos (DLQ) y cuándo debo usarla?​ Una DLQ es una cola secundaria donde los mensajes que no se pueden procesar exitosamente después de varios intentos se envían. Debes configurar una DLQ para ayudar con el manejo de errores y prevenir la pérdida de mensajes. Consulta AWS SQS DLQ .  ¿Qué es la Deduplificación en una Cola FIFO?​ En una Cola FIFO de SQS, la deduplificación asegura que los mensajes duplicados se eliminen automáticamente, manteniendo el estricto orden de los mensajes.  ","version":"Next","tagName":"h2"},{"title":"Configura tu SQS​","type":1,"pageTitle":"AWS SQS","url":"/preview-docs/es/docs/project/dependency/sqs-aws#configura-tu-sqs","content":" ","version":"Next","tagName":"h2"},{"title":"1. Agregar SQS como Dependencia​","type":1,"pageTitle":"AWS SQS","url":"/preview-docs/es/docs/project/dependency/sqs-aws#1-agregar-sqs-como-dependencia","content":" Para integrar SQS con SleakOps:  En la consola de SleakOps, ve a la sección &quot;Dependencias&quot;.Elige &quot;SQS&quot; de la lista de tipos de dependencias disponibles. Para más detalles consulta Dependencias: Integrando Bases de Datos, Caching y Servicios de Mensajería.  ","version":"Next","tagName":"h3"},{"title":"2. Configura tu base de datos SQS.​","type":1,"pageTitle":"AWS SQS","url":"/preview-docs/es/docs/project/dependency/sqs-aws#2-configura-tu-base-de-datos-sqs","content":" Accederás al siguiente formulario:    Aquí están los parámetros que SleakOps te permite personalizar durante la creación:  Atributo\tDescripciónFifo Queue\tSelecciona si la cola es estándar o FIFO. Lee más en las preguntas frecuentes. Fifo Deduplication\tSelecciona si la deduplicación está activada. Lee más en las preguntas frecuentes. Message Delay Seconds\tSegundos de retraso en la entrega de mensajes en la cola. Message Max Size\tLímite máximo de bytes por mensaje. Message Retention Seconds\tSegundos que un mensaje es retenido por SQS. Receive WaitTime Seconds\tEl tiempo que una llamada a ReceiveMessage esperará a que llegue un mensaje (long polling) antes de regresar. Visibility Timeout Seconds\tSegundos que un mensaje es retenido por SQS. Dead Letter Queue\tSelecciona si la cola de mensajes muertos está habilitada. Lee más en las preguntas frecuentes.  Al activar la opción Master Dedicado Habilitado, también debes completar lo siguiente:  Atributo\tDescripciónTipo de Master Dedicado\tEspecifica el tipo de instancia para los nodos maestros, usados para gestionar el clúster. Ejemplo: r6g.large.search Cantidad de Masters Dedicados\tNúmero de nodos maestros dedicados. Se recomienda tener 3 para producción.  ","version":"Next","tagName":"h3"},{"title":"3. Personaliza los nombres de tus variables para SQS.​","type":1,"pageTitle":"AWS SQS","url":"/preview-docs/es/docs/project/dependency/sqs-aws#3-personaliza-los-nombres-de-tus-variables-para-sqs","content":" Como se explicó, cuando se crea una dependencia, SleakOps genera un grupo de variables para almacenar todos los atributos necesarios. En este paso, puedes cambiar el nombre de los atributos si es necesario. SleakOps completa los valores automáticamente. Después de este paso, tu dependencia estará creada.   ","version":"Next","tagName":"h3"},{"title":"AWS S3 Bucket","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dependency/s3bucket-aws","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"AWS S3 Bucket","url":"/preview-docs/es/docs/project/dependency/s3bucket-aws#preguntas-frecuentes","content":" ¿Cuándo debería usar Amazon S3?​ Deberías usar Amazon S3 cuando necesites: Almacenamiento escalable para archivos, medios, copias de seguridad o activos estáticos.Almacenamiento altamente duradero y disponible para datos críticos.Soluciones de archivo de datos o recuperación ante desastres.Una solución rentable para almacenar grandes cantidades de datos no estructurados.  ¿Cómo creo un backup de S3?​ Para crear una copia de seguridad de los datos de tu cubo S3, sigue estos pasos: Asegúrate de tener acceso de administrador: Verifica que tienes acceso de administrador a la cuenta de AWS donde se encuentra el cubo S3.Instala AWS CLI: Asegúrate de que AWS CLI esté instalado en tu máquina local. Para instrucciones de instalación, consulta la documentación oficial de AWS CLI .Configura AWS CLI: Asegúrate de que tus claves de acceso y secretas estén configuradas en el perfil predeterminado. Si están bajo un perfil diferente, utiliza la opción --profile PROFILE_NAME con los comandos.Ejecuta los comandos de copia de seguridad: sh aws sts assume-role --role-arn arn:aws:iam::ACCOUNT_ID:role/SleakopsAdminRole aws s3 sync s3://BUCKET_NAME /path/to/local/directorySustituye ACCOUNT_ID, BUCKET_NAME y /path/to/local/directory con tus detalles específicos.  ¿SleakOps crea Grupos de Variables para las dependencias de S3?​ Sí, cuando configuras un cubo S3 en SleakOps, automáticamente creará un Grupo de Variables. Esto almacena de forma segura las claves de acceso y otra información sensible necesaria para gestionar e interactuar con tu cubo S3.  ¿Qué es una Lista de Control de Acceso (ACL) de S3?​ Una Lista de Control de Acceso (ACL) de S3 define los permisos sobre quién puede acceder a tu cubo S3 y su contenido. Controla el nivel de acceso que se concede a usuarios, grupos o entidades de AWS predefinidas. Puedes elegir un ACL que defina quién puede acceder al cubo y qué nivel de permiso tienen. Las opciones disponibles son: private: Solo el propietario del cubo tiene acceso completo. (Por defecto)public-read: Cualquier persona puede leer los objetos en el cubo.public-read-write: Cualquier persona puede leer y escribir en el cubo.aws-exec-read: Otorga acceso de lectura a los servicios de AWS como CloudFront.authenticated-read: Otorga acceso de lectura a usuarios autenticados de AWS.log-delivery-write: Otorga acceso de escritura al cubo para fines de registro. Para más detalles, consulta la documentación de S3 ACL de AWS .  ¿Qué es Amazon CloudFront?​ Amazon CloudFront es una Red de Distribución de Contenido (CDN) que acelera la entrega de tu contenido estático y dinámico (como HTML, CSS, imágenes y videos) al almacenarlo en ubicaciones cercanas a tus usuarios alrededor del mundo.  ¿Puedo usar un dominio personalizado con CloudFront?​ Sí, SleakOps te permite establecer un alias personalizado (subdominio) para tu distribución de CloudFront. Por ejemplo, podrías usar cdn.mydomain.com como la URL de tu distribución de CloudFront en lugar de la URL predeterminada de CloudFront.  ¿Qué es un encabezado personalizado en CloudFront?​ Los Encabezados Personalizados te permiten incluir información adicional en cada solicitud que CloudFront realiza a tu cubo S3. Esta característica te brinda un mayor control sobre cómo se accede y entrega tu contenido de S3 al adjuntar metadatos específicos a las solicitudes. SleakOps te permite definir encabezados personalizados para CloudFront, que serán incluidos en todas las solicitudes enviadas a tu cubo S3. Esto es útil para agregar medidas de seguridad, gestionar permisos o realizar un seguimiento de las solicitudes. custom_headers: - key: &quot;X-Custom-Header&quot; value: &quot;MyCustomValue&quot;   ","version":"Next","tagName":"h2"},{"title":"Configura tu cubo S3​","type":1,"pageTitle":"AWS S3 Bucket","url":"/preview-docs/es/docs/project/dependency/s3bucket-aws#configura-tu-cubo-s3","content":" ","version":"Next","tagName":"h2"},{"title":"1. Agregar S3 Bucket como Dependencia​","type":1,"pageTitle":"AWS S3 Bucket","url":"/preview-docs/es/docs/project/dependency/s3bucket-aws#1-agregar-s3-bucket-como-dependencia","content":" Para integrar S3 Bucket con SleakOps:  En la consola de SleakOps, ve a la sección &quot;Dependencias&quot;Elige &quot;S3 Bucket&quot; de la lista de tipos de dependencias disponibles. Para más detalles, consulta Dependencias: Integración de Bases de Datos, Caching y Servicios de Mensajería.  ","version":"Next","tagName":"h3"},{"title":"2. Configura tu cubo S3.​","type":1,"pageTitle":"AWS S3 Bucket","url":"/preview-docs/es/docs/project/dependency/s3bucket-aws#2-configura-tu-cubo-s3","content":" Al agregar un cubo S3 como dependencia en SleakOps, deberás configurar los siguientes atributos:  Atributo\tDescripciónLista de Control de Acceso (ACL) de S3\tEspecifica el nivel de acceso para el cubo S3 y su contenido. Opciones: private, public-read, public-read-write, aws-exec-read, authenticated-read, log-delivery-write Habilitar CloudFront\tPermite habilitar Amazon CloudFront, una CDN para entregar el contenido del cubo S3 a nivel global. Alias\tEl alias para el cubo S3 o la distribución de CloudFront (por ejemplo, cdn.mydomain.com). Clase de Precio\tDefine el conjunto de ubicaciones de borde globales de CloudFront utilizadas para servir contenido. Opciones: Usar todas las ubicaciones de borde (mejor rendimiento), Usar solo América del Norte, Europa, Asia, Medio Oriente y África, Usar solo América del Norte y Europa. Revisa Clase de Precios de AWS . Encabezados Personalizados\tEncabezados personalizados que CloudFront incluirá en todas las solicitudes enviadas al cubo S3. - Clave: La clave del encabezado, como X-Custom-Header. - Valor: El valor que deseas asignar al encabezado, como MyCustomValue. Sobrescribir\tEspecifica si CloudFront debe sobrescribir los encabezados existentes en las solicitudes del origen.    Después de esos datos básicos, si activaste CloudFront, podrás personalizar sus encabezados. Para hacerlo:  En el formulario, busca el campo Encabezados personalizados de CloudFront y haz clic en + Agregar ítem.Completa Clave y Valor. Puedes agregar tantos como necesites.    ","version":"Next","tagName":"h3"},{"title":"3. Personaliza los nombres de tus variables para tu S3.​","type":1,"pageTitle":"AWS S3 Bucket","url":"/preview-docs/es/docs/project/dependency/s3bucket-aws#3-personaliza-los-nombres-de-tus-variables-para-tu-s3","content":" Como se explicó, cuando se crea una dependencia, SleakOps genera un vargroup para contener todos los atributos necesarios.    En este paso, puedes cambiar el nombre de los atributos si es necesario, pero SleakOps completará los valores automáticamente. Después de este paso, tu dependencia estará creada. ","version":"Next","tagName":"h3"},{"title":"Deployment","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/deployment","content":"","keywords":"","version":"Next"},{"title":"Desplegando tu ProjectEnv​","type":1,"pageTitle":"Deployment","url":"/preview-docs/es/docs/project/deployment#desplegando-tu-projectenv","content":" Al crear un Deployment, obtenemos la imagen correspondiente al Build que se va a desplegar. Antes de esto, ejecutamos el Helm Release en el namespace del clúster adecuado. Este release de Helm incluye los servicios de Kubernetes necesarios, ingresses, workers y otros servicios.  Existen varios métodos para generar un Deployment. Estos se describen a continuación. Ten en cuenta que forzamos ciertos Deployments. Para más detalles, consulta Más sobre Deployment.  Workloads: Proporciona un conmutador que te permite decidir si ejecutar un nuevo Deployment.VariableGroup: Funciona de manera similar a las Cargas de Trabajo, pero no crea un nuevo Release. En su lugar, solo actualiza los valores del Deployment.Dependency: Desencadena un Deployment automáticamente. Profundiza más sobre esto en Más sobre Deployment.    ","version":"Next","tagName":"h2"},{"title":"Deployment Manual​","type":1,"pageTitle":"Deployment","url":"/preview-docs/es/docs/project/deployment#deployment-manual","content":" Si no realizas el deployment de tus cambios inmediatamente, o si tu modificación no fuerza un deployment, tienes tres métodos para ejecutar un Deployment:  Build section: Usando el botón Deploy, puedes determinar qué Build desplegar.    Unpublished banner​    Unpublished Changes Banner: Este banner se muestra cuando hay contenido pendiente que aún no se ha desplegado en el clúster. A través de este banner, puedes elegir desplegar solo los VariableGroups o si deseas desplegar todo, incluidos los Workloads en estado 'borrador'.    A través del CLI . ","version":"Next","tagName":"h3"},{"title":"Un poco mas sobre los Deployments:","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/deployment/more_on_deployment","content":"","keywords":"","version":"Next"},{"title":"Cómo maneja SleakOps los Deployments​","type":1,"pageTitle":"Un poco mas sobre los Deployments:","url":"/preview-docs/es/docs/project/deployment/more_on_deployment#cómo-maneja-sleakops-los-deployments","content":" Para ejecutar un deployment, SleakOps utiliza las imágenes de Build almacenadas en el repositorio de imágenes de tu proyecto (AWS ECR), las cuales se crean ya sea con la entidad ProjectEnv durante la Build Inicial o con la creación de una entidad Build que se sube a ECR. Cada vez que se inicia un Deployment, obtenemos la imagen correspondiente al Build designado.  La siguiente fase implica construir y desplegar el Helm chart. Esto se logra usando plantillas diseñadas generalmente para ese propósito. Una vez construido, subimos el Helm chart al mismo ECR utilizado para las imágenes Build y procedemos a desplegar un Helm Release en el clúster de Kubernetes, específicamente dentro del namespace de ProjectEnv.  info Todos estos recursos residen en tus propias cuentas de AWS. SleakOps no almacena datos de manera exclusiva.  ","version":"Next","tagName":"h2"},{"title":"Forced Deployments​","type":1,"pageTitle":"Un poco mas sobre los Deployments:","url":"/preview-docs/es/docs/project/deployment/more_on_deployment#forced-deployments","content":" Forced Deployment Ten en cuenta que bajo ciertas circunstancias, SleakOps obliga un Deploy.  Si bien se destacaron múltiples métodos para generar un Deployment en la documentación principal de Deployment, es crucial entender que SleakOps a veces impone Deployments. La razón detrás de esto es optimizar el tiempo de actividad, salvaguardar el estado actual de la infraestructura desplegada y mitigar posibles tiempos de inactividad del servicio en el Cluster. Este imperativo surge porque las plantillas de Helm siempre deben sincronizarse con los Kubernetes Secrets presentes en el namespace para evitar fallos en el deployment.  Como ya sabes, si no es un deployment 'forzado', se te presentará una opción (conmutador) para decidir si deseas desplegar tus modificaciones. Los Deployments se fuerzan en los siguientes escenarios:  Cambios en la configuración del Workload Alias: Un Deployment es forzado si se realizan modificaciones en la configuración del 'alias'.Dependency: Siempre fuerza un Deployment para sincronizar el estado de su VariableGroup asociado con las plantillas del Helm Chart, asegurando que el funcionamiento de los Workloads no se vea afectado.Eliminación de VariableGroup: Igual que la eliminación de Dependency. ","version":"Next","tagName":"h3"},{"title":"Release","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/deployment/release","content":"","keywords":"","version":"Next"},{"title":"¿Qué es un Release?​","type":1,"pageTitle":"Release","url":"/preview-docs/es/docs/project/deployment/release#qué-es-un-release","content":" En Sleakops, un release representa un estado desplegable de todos los servicios (servicios web, workers, cron jobs y jobs) de un proyecto en un entorno.  ","version":"Next","tagName":"h2"},{"title":"Creación de Releases​","type":1,"pageTitle":"Release","url":"/preview-docs/es/docs/project/deployment/release#creación-de-releases","content":" Sleakops administra los releases por ti. Cada vez que modificas, eliminas o agregas un servicio, worker, hook o cron job, Sleakops te da la opción de publicar los cambios. Cada vez que publicas esos cambios, Sleakops crea un nuevo release con versiones auto-incrementadas.  ","version":"Next","tagName":"h2"},{"title":"Recursos del Helm Chart​","type":1,"pageTitle":"Release","url":"/preview-docs/es/docs/project/deployment/release#recursos-del-helm-chart","content":" Web Service:​  Un deployment de KubernetesUn servicio de KubernetesUn HPA de Kubernetes (Horizontal Pod Autoscaler)Un ingress de Kubernetes  El ingress genera sus hosts usando &lt;service_name&gt;.&lt;environment_name&gt;.&lt;organization_name&gt;.&lt;yourdomain.com&gt;  Worker:​  Un deployment de KubernetesUn HPA de Kubernetes  Hook:​  Un job de Kubernetes  Este job usa hooks de Kubernetes para iniciarse.  Cron Job:​  Un cron job de Kubernetes ","version":"Next","tagName":"h3"},{"title":"VariableGroups","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/vargroup","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"VariableGroups","url":"/preview-docs/es/docs/project/vargroup#preguntas-frecuentes","content":" ¿Puedo editar un VariableGroup creado por SleakOps?​ Sí, puedes acceder y gestionar el VariableGroup para tu instancia MySQL desde la consola de SleakOps. Puedes modificar valores como nombres de usuario, contraseñas u otras credenciales específicas del entorno.  ¿Cómo usan mis aplicaciones los Vargroups?​ Los Vargroups se inyectan de forma segura en el entorno de tu aplicación cuando se despliega. Tus aplicaciones pueden acceder a estas credenciales y otras variables sin exponer información sensible en el código.  ¿Cómo asegura SleakOps la seguridad de los Vargroups?​ SleakOps almacena de forma segura los Vargroups como secretos de Kubernetes dentro de tu clúster EKS. El acceso se controla a través de Service Accounts de Kubernetes, asegurando que solo los componentes autorizados puedan acceder a la información sensible.  ¿Puedo eliminar un Variable Group?​ Sí, los Vargroups se pueden eliminar o actualizar según sea necesario. Sin embargo, ten cuidado al eliminarlos, ya que puede interrumpir tu aplicación.  ¿Cuál es la diferencia entre un Vargroup Global y uno con Ámbito de Servicio?​ Global: Disponible para todos los servicios dentro del namespace. Se crea sin seleccionar un servicio específico. Para crearlos selecciona &quot;global&quot;.Variable Group con Ámbito de Servicio: Solo aplica al servicio seleccionado dentro del proyecto y el entorno. Sobrescribe los valores del Vargroup global si tienen la misma clave.  ¿Qué ocurre si hay claves duplicadas en diferentes Vargroups?​ Si existen claves duplicadas en diferentes Vargroups: Si la clave existe tanto en un Vargroup global como en uno con Ámbito de Servicio, el valor del Vargroup con Ámbito de Servicio tiene prioridad.Si dos Vargroups globales tienen la misma clave, se usará el más recientemente creado.  ","version":"Next","tagName":"h2"},{"title":"Crea un grupo de variables​","type":1,"pageTitle":"VariableGroups","url":"/preview-docs/es/docs/project/vargroup#crea-un-grupo-de-variables","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navega a la sección para crear un Vargroup​","type":1,"pageTitle":"VariableGroups","url":"/preview-docs/es/docs/project/vargroup#1-navega-a-la-sección-para-crear-un-vargroup","content":" En el Panel izquierdo, accede a la opción Vargroups bajo Proyectos y luego, en la esquina superior derecha, haz clic en el botón Crear.    ","version":"Next","tagName":"h3"},{"title":"2. Selecciona un Proyecto y completa los atributos necesarios​","type":1,"pageTitle":"VariableGroups","url":"/preview-docs/es/docs/project/vargroup#2-selecciona-un-proyecto-y-completa-los-atributos-necesarios","content":" Completa los siguientes atributos para crear un nuevo Vargroup:  Atributo\tDescripciónProyecto\tLa aplicación o carga de trabajo específica dentro de SleakOps. Determina el alcance del grupo de variables. Servicio\tUn microservicio o componente dentro del proyecto. Si se selecciona, el Vargroup está limitado a él; si no, al seleccionar global estará accesible dentro del namespace. Nombre\tUn identificador único para el Vargroup, utilizado para diferenciarlo dentro del proyecto. Debe ser descriptivo del propósito del grupo. Desplegar\tHabilita esta opción si deseas que SleakOps publique y despliegue automáticamente tu servicio en el proyecto.  info Si eliges agregar el argumento usando la opción de texto: Cada argumento debe agregarse en una nueva línea, separada por un signo de igual (=), sin espacios adicionales. NOMBRE_ARGUMENTO=VALOR ARGUMENTO_DOS=VALOR ARGUMENTO_UNO=VALOR    Envía para crear y desplegar tu Vargroup. ","version":"Next","tagName":"h3"},{"title":"Dockertron - Generación de Dockerfiles y Docker Compose","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/dockertron","content":"","keywords":"","version":"Next"},{"title":"Resumen​","type":1,"pageTitle":"Dockertron - Generación de Dockerfiles y Docker Compose","url":"/preview-docs/es/docs/project/dockertron#resumen","content":" Dockertron es un sistema automatizado de dockerización que analiza su código fuente y genera automáticamente la infraestructura necesaria para ejecutar su aplicación en contenedores Docker. El sistema utiliza inteligencia artificial para comprender la estructura de su proyecto y crear los archivos de configuración apropiados.  Podes encontrarlo en Sleakops en la sección de Proyectos&gt;Configuración&gt;Docketron.      ## ¿Qué hace Dockertron?  Dockertron automatiza el proceso de containerización de su aplicación siguiendo estos pasos:  Análisis del Repositorio: Examina la estructura de su código fuenteIdentificación de Servicios: Detecta qué componentes de su aplicación necesitan ejecutarseGeneración de Dockerfiles: Crea archivos Dockerfile optimizados para cada servicioCreación de Docker Compose: Genera un archivo docker-compose.yml que orquesta todos los serviciosConfiguración de Infraestructura: Prepara la configuración para despliegue en SleakOps    ","version":"Next","tagName":"h2"},{"title":"Flujo del Proceso de Dockerización​","type":1,"pageTitle":"Dockertron - Generación de Dockerfiles y Docker Compose","url":"/preview-docs/es/docs/project/dockertron#flujo-del-proceso-de-dockerización","content":" 1. Enviar el Proyecto​ Para iniciar el proceso de dockerización, debe completar el formulario de Dockertron en tres pasos: Paso 1: Información del Lenguaje​ Especifique el lenguaje de programación principal de su proyecto: Language Name: Nombre del lenguaje (ej: Python, Node.js, Java, Go)Language Version: Versión específica del lenguaje (ej: 3.12, 18.0, 11) Paso 2: Frameworks de la Aplicación​ Configure los frameworks que utiliza su aplicación. Puede agregar múltiples frameworks: Framework Name: Nombre del framework (ej: Django, Express, Spring Boot)Command: Comando para ejecutar el framework (ej: python manage.py runserver 0.0.0.0)Framework Version: Versión del framework (ej: 5.2, 4.18.2) Puede agregar más frameworks haciendo clic en &quot;+ Add Item&quot;.  2. Análisis Inteligente​ El sistema realiza un análisis profundo de su proyecto: Fase 1: Auditoría del Repositorio​ Confirma el lenguaje de programación principalConfirma frameworks y librerías utilizadasAnaliza la estructura de carpetasIdentifica archivos de configuración (package.json, requirements.txt, etc.) Fase 2: Identificación de Servicios​ El sistema detecta automáticamente: Aplicaciones web (frontend, backend)APIs y microserviciosWorkers y procesos en segundo planoBases de datos necesariasServicios de caché (Redis, Memcached)Colas de mensajes (RabbitMQ, SQS)  3. Generación de Archivos​ Dockerfiles​ Para cada servicio que requiere construcción, se genera un Dockerfile que incluye: Imagen base apropiadaInstalación de dependenciasConfiguración del entornoComandos de inicioHealthchecksOptimizaciones de rendimiento Docker Compose​ Se genera un archivo docker-compose.yml que: Define todos los serviciosConfigura redes entre serviciosEstablece volúmenes para persistencia de datosDefine variables de entornoConfigura puertos y exposición de serviciosEstablece dependencias entre servicios README​ Se genera documentación con: Instrucciones para ejecutar el proyectoComandos necesariosConfiguraciones requeridasTroubleshooting básico  4. Preparación para SleakOps​ El sistema genera la configuración de infraestructura para SleakOps, identificando: Workloads (Cargas de Trabajo)Dependencies (Dependencias)Environment Variables (Variables de Entorno)  5. Generación de Pull Request​ Una vez completado el análisis y la generación de archivos, Dockertron crea automáticamente una Pull Request en su repositorio con todos los archivos de configuración generados: Dockerfilesdocker-compose.ymlREADME.md con instruccionesArchivos de configuración adicionales Esto le permite: Revisar todos los cambios propuestos antes de integrarlosComentar y solicitar ajustes si es necesarioAprobar y fusionar cuando esté satisfecho con la configuraciónMantener un historial claro de los cambios en su repositorio  Integración con su Repositorio​ Al finalizar el proceso, Dockertron: Genera una Pull Request en su repositorio con todos los archivos de configuración DockerEnvía la información a SleakOps para que pueda desplegar fácilmente desde la consola con las configuraciones recomendadas por el agente de IA De esta manera, usted mantiene el control total sobre los cambios en su código mientras aprovecha la automatización de SleakOps.  Ejemplo Completo​ Proyecto de Entrada​ mi-app/ ├── backend/ ├── package.json ├── server.js └── ... Salida Generada​ Servicios Detectados: Backend (Node.js API)Frontend (React App)Worker (Python) Dependencias Identificadas: PostgreSQL (para el backend)Redis (para cache y colas) Archivos Generados: backend/Dockerfiledocker-compose.ymlREADME.md    ","version":"Next","tagName":"h2"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Dockertron - Generación de Dockerfiles y Docker Compose","url":"/preview-docs/es/docs/project/dockertron#preguntas-frecuentes","content":" ¿Cuánto tiempo toma el proceso?​ Típicamente entre 5-30 minutos, dependiendo del tamaño y complejidad del proyecto.  ¿Qué pasa si mi proyecto tiene configuraciones especiales?​ Puede proporcionar contexto adicional en el campo contexts al enviar la solicitud, indicando frameworks específicos, versiones, o configuraciones especiales.  ¿Puedo revisar los archivos antes del despliegue?​ Sí, todos los archivos generados se envían de vuelta y pueden ser revisados antes de proceder con el despliegue.  ¿Qué pasa si el proceso falla?​ El sistema envía un mensaje de error detallado indicando qué salió mal, permitiendo ajustes, reintentos y modificaciones en la informacion enviada para que el agente de IA pueda generar la configuracion correcta.  ¿Se pueden modificar los archivos generados?​ Sí, los archivos generados son completamente editables y pueden ser ajustados según sus necesidades específicas.  Versión del documento: 1.0Última actualización: Noviembre 2025 ","version":"Next","tagName":"h2"},{"title":"Workloads","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/workload","content":"","keywords":"","version":"Next"},{"title":"Cual workload deberia crear para mi aplicacion?​","type":1,"pageTitle":"Workloads","url":"/preview-docs/es/docs/project/workload#cual-workload-deberia-crear-para-mi-aplicacion","content":"   Web Service: Elige esta opción si necesitas que tu aplicación o servicio esté disponible 24/7 para responder solicitudes HTTP.Worker: Úsalo para tareas de procesamiento en segundo plano, como colas de mensajes o procesos de datos, sin interacción HTTP directa.CronJob: Ideal para tareas de mantenimiento o generación de reportes que deban ejecutarse periódicamente en momentos específicos.Job: Adecuado para tareas puntuales o ejecutadas bajo demanda (por ejemplo, migraciones manuales de base de datos).Hook: Perfecto si quieres automatizar ciertas acciones (como migraciones de base de datos o análisis) en cada despliegue. ","version":"Next","tagName":"h2"},{"title":"Volumes","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/volumes","content":"","keywords":"","version":"Next"},{"title":"Crear Volúmenes​","type":1,"pageTitle":"Volumes","url":"/preview-docs/es/docs/project/volumes#crear-volúmenes","content":"   Para crear un nuevo volumen para tu proyecto:  Haz clic en &quot;Create Volumes&quot; en la configuración del ProyectoAgrega la ruta de montaje - Especifica la ruta del directorio donde se montará el volumen en tus contenedoresEstablece la capacidad de almacenamiento - Define la cantidad de espacio de almacenamiento asignado al volumenElige la política de retención - Selecciona entre: Delete: El volumen será eliminado cuando se elimine de SleakOpsRetain: El volumen persistirá en AWS incluso si se elimina de SleakOps  Configuración de Volúmenes Las rutas de montaje deben ser rutas absolutas (ej., /app/data, /var/logs)La capacidad de almacenamiento se especifica en GBLa política de retención determina la persistencia de datos cuando se eliminan volúmenes  ","version":"Next","tagName":"h2"},{"title":"Eliminar Volúmenes​","type":1,"pageTitle":"Volumes","url":"/preview-docs/es/docs/project/volumes#eliminar-volúmenes","content":"   Para eliminar un volumen de tu proyecto:  Haz clic en el botón &quot;X&quot; junto al volumen que quieres eliminarConfirma la eliminación cuando se te solicite  Advertencia de Pérdida de Datos Eliminar un volumen eliminará permanentemente todos los datos almacenados en él. Asegúrate de hacer una copia de seguridad de cualquier dato importante antes de la eliminación.  Comportamiento de la Política de Retención Política Delete: El volumen y todos los datos se eliminan permanentemente de AWSPolítica Retain: El volumen permanece en AWS pero se desvincula del proyecto, preservando tus datos ","version":"Next","tagName":"h2"},{"title":"Cronjobs","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/workload/cronjob","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/es/docs/project/workload/cronjob#faqs","content":" ¿Cómo puedo configurar la memoria y los ajustes de CPU para mi Cronjob?​ Puedes configurar los valores CPU Request y CPU Limit para establecer los recursos mínimos y máximos de CPU que cada instancia en tu clúster puede usar. De manera similar, puedes establecer Memory Request y Memory Limit para la asignación de memoria por instancia.  ","version":"Next","tagName":"h2"},{"title":"Añadir un Cronjob para tu Proyecto​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/es/docs/project/workload/cronjob#añadir-un-cronjob-para-tu-proyecto","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navegar a la sección de crear un Cronjob​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/es/docs/project/workload/cronjob#1-navegar-a-la-sección-de-crear-un-cronjob","content":" En el Panel izquierdo, accede a Workloads. Luego selecciona la pestaña Cronjob y, en la esquina superior derecha, haz clic en el botón Crear.    ","version":"Next","tagName":"h3"},{"title":"2. Selecciona un Proyecto y un Nombre para el Cronjob​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/es/docs/project/workload/cronjob#2-selecciona-un-proyecto-y-un-nombre-para-el-cronjob","content":" Comienza con la información básica, completa estos atributos y haz clic en Siguiente para continuar.  Atributo\tDescripciónNombre\tIdentifica tu Cronjob. Proyecto\tSelecciona entre los proyectos existentes. Comando\tEl comando que ejecuta el servicio.  Una vez completados estos atributos, haz clic en el botón Siguiente para continuar.    ","version":"Next","tagName":"h3"},{"title":"3. Define la periodicidad​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/es/docs/project/workload/cronjob#3-define-la-periodicidad","content":" Select the schedule and click Next.  Atributo\tDescripciónCrontab\tExpresión cron para determinar el horario de ejecución del cronjob    ","version":"Next","tagName":"h3"},{"title":"5. Finalizar la configuración​","type":1,"pageTitle":"Cronjobs","url":"/preview-docs/es/docs/project/workload/cronjob#5-finalizar-la-configuración","content":" Este paso describe los atributos clave para configurar los recursos de un Cronjob en SleakOps, permitiendo una gestión flexible de CPU, memoria y comportamientos de escalado.  Atributo\tDescripciónCPU Request\tLa cantidad mínima de recursos de CPU asignados para cada instancia en el clúster. Esto garantiza que cada instancia siempre tenga esta cantidad de CPU disponible. CPU Limit\tLa cantidad máxima de recursos de CPU que cada instancia en el clúster puede utilizar. Este límite ayuda a prevenir que una instancia consuma demasiada CPU. Memory Request\tLa cantidad mínima de memoria asignada para cada instancia en el clúster. Esto garantiza que la instancia tenga suficiente memoria para operar eficientemente. Memory Limit\tLa cantidad máxima de memoria que cada instancia en el clúster puede utilizar. Limita el uso de memoria para evitar que una sola instancia consuma recursos en exceso.    Submit to create and Deploy your cronjob. ","version":"Next","tagName":"h3"},{"title":"Hooks","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/workload/hook","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Hooks","url":"/preview-docs/es/docs/project/workload/hook#faqs","content":" ¿Cómo puedo configurar la memoria y los ajustes de CPU para mi Hook?​ Puedes configurar los valores CPU Request y CPU Limit para establecer los recursos mínimos y máximos de CPU que cada instancia en tu clúster puede usar. De manera similar, puedes establecer Memory Request y Memory Limit para la asignación de memoria por instancia.  ","version":"Next","tagName":"h2"},{"title":"Añadir un Hook para tu Proyecto​","type":1,"pageTitle":"Hooks","url":"/preview-docs/es/docs/project/workload/hook#añadir-un-hook-para-tu-proyecto","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navegar a la sección de crear un Hook​","type":1,"pageTitle":"Hooks","url":"/preview-docs/es/docs/project/workload/hook#1-navegar-a-la-sección-de-crear-un-hook","content":" En el Panel izquierdo, accede a Workloads. Luego selecciona la pestaña Hook y, en la esquina superior derecha, haz clic en el botón Crear.    ","version":"Next","tagName":"h3"},{"title":"2. Selecciona un Proyecto y un Nombre para el Hook​","type":1,"pageTitle":"Hooks","url":"/preview-docs/es/docs/project/workload/hook#2-selecciona-un-proyecto-y-un-nombre-para-el-hook","content":" Comienza con la información básica, completa estos atributos y haz clic en Siguiente para continuar.  Atributo\tDescripciónNombre\tIdentifica tu Hook. Proyecto\tSelecciona entre los proyectos existentes. Comando\tEl comando que ejecuta el servicio.  Una vez completados estos atributos, haz clic en el botón Siguiente para continuar.    ","version":"Next","tagName":"h3"},{"title":"3. Define el evento de despliegue​","type":1,"pageTitle":"Hooks","url":"/preview-docs/es/docs/project/workload/hook#3-define-el-evento-de-despliegue","content":" Selecciona cuándo se ejecutará tu hook y haz clic en Siguiente.  Atributo\tDescripciónEvent\tDefine cuándo ejecutar el hook. Ver eventos disponibles    ","version":"Next","tagName":"h3"},{"title":"5. Finalizar la configuración​","type":1,"pageTitle":"Hooks","url":"/preview-docs/es/docs/project/workload/hook#5-finalizar-la-configuración","content":" Este paso describe los atributos clave para configurar los recursos de un Hook en SleakOps, permitiendo una gestión flexible de CPU, memoria y comportamientos de escalado.  Atributo\tDescripciónCPU Request\tLa cantidad mínima de recursos de CPU asignados para cada instancia en el clúster. Esto garantiza que cada instancia siempre tenga esta cantidad de CPU disponible. CPU Limit\tLa cantidad máxima de recursos de CPU que cada instancia en el clúster puede utilizar. Este límite ayuda a prevenir que una instancia consuma demasiada CPU. Memory Request\tLa cantidad mínima de memoria asignada para cada instancia en el clúster. Esto garantiza que la instancia tenga suficiente memoria para operar eficientemente. Memory Limit\tLa cantidad máxima de memoria que cada instancia en el clúster puede utilizar. Limita el uso de memoria para evitar que una sola instancia consuma recursos en exceso.    Submit to create and Deploy your hook. ","version":"Next","tagName":"h3"},{"title":"Job","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/workload/job","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Job","url":"/preview-docs/es/docs/project/workload/job#faqs","content":" ¿Cómo puedo configurar la memoria y los ajustes de CPU para mi Job?​ Puedes configurar los valores CPU Request y CPU Limit para establecer los recursos mínimos y máximos de CPU que cada instancia en tu clúster puede usar. De manera similar, puedes establecer Memory Request y Memory Limit para la asignación de memoria por instancia.  ","version":"Next","tagName":"h2"},{"title":"Añadir un Job para tu Proyecto​","type":1,"pageTitle":"Job","url":"/preview-docs/es/docs/project/workload/job#añadir-un-job-para-tu-proyecto","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navegar a la sección de crear un Job​","type":1,"pageTitle":"Job","url":"/preview-docs/es/docs/project/workload/job#1-navegar-a-la-sección-de-crear-un-job","content":" En el Panel izquierdo, accede a Workloads. Luego selecciona la pestaña Job y, en la esquina superior derecha, haz clic en el botón Crear.    ","version":"Next","tagName":"h3"},{"title":"2. Selecciona un Proyecto y un Nombre para el Job​","type":1,"pageTitle":"Job","url":"/preview-docs/es/docs/project/workload/job#2-selecciona-un-proyecto-y-un-nombre-para-el-job","content":" Comienza con la información básica, completa estos atributos y haz clic en Siguiente para continuar.  Atributo\tDescripciónNombre\tIdentifica tu Job. Proyecto\tSelecciona entre los proyectos existentes. Comando\tEl comando que ejecuta el servicio. Image\tPor defecto el job utiliza la imagen de tu proyecto, pero puedes reemplazarla por otra Image tag\tPuedes especificar la etiqueta de la imagen.  Una vez completados estos atributos, haz clic en el botón Siguiente para continuar.    ","version":"Next","tagName":"h3"},{"title":"3. Finalizar la configuración​","type":1,"pageTitle":"Job","url":"/preview-docs/es/docs/project/workload/job#3-finalizar-la-configuración","content":" Este paso describe los atributos clave para configurar los recursos de un Job en SleakOps, permitiendo una gestión flexible de CPU, memoria y comportamientos de escalado.  Atributo\tDescripciónCPU Request\tLa cantidad mínima de recursos de CPU asignados para cada instancia en el clúster. Esto garantiza que cada instancia siempre tenga esta cantidad de CPU disponible. CPU Limit\tLa cantidad máxima de recursos de CPU que cada instancia en el clúster puede utilizar. Este límite ayuda a prevenir que una instancia consuma demasiada CPU. Memory Request\tLa cantidad mínima de memoria asignada para cada instancia en el clúster. Esto garantiza que la instancia tenga suficiente memoria para operar eficientemente. Memory Limit\tLa cantidad máxima de memoria que cada instancia en el clúster puede utilizar. Limita el uso de memoria para evitar que una sola instancia consuma recursos en exceso.    Submit to create and Deploy your job. ","version":"Next","tagName":"h3"},{"title":"Worker","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/workload/worker","content":"","keywords":"","version":"Next"},{"title":"FAQs​","type":1,"pageTitle":"Worker","url":"/preview-docs/es/docs/project/workload/worker#faqs","content":" ¿Cómo configuro el auto-escalado para mi Worker?​ Para habilitar el auto-escalado, puedes activar la opción Autoscaling y definir el Memory Target y el CPU Target. Estos objetivos determinan los umbrales de uso de recursos que desencadenan el auto-escalado. También debes especificar el número mínimo y máximo de réplicas que se deben mantener cuando el auto-escalado está habilitado.  ¿Cómo puedo configurar la memoria y los ajustes de CPU para mi Worker?​ Puedes configurar los valores CPU Request y CPU Limit para establecer los recursos mínimos y máximos de CPU que cada instancia en tu clúster puede usar. De manera similar, puedes establecer Memory Request y Memory Limit para la asignación de memoria por instancia.  ","version":"Next","tagName":"h2"},{"title":"Añadir un Worker para tu Proyecto​","type":1,"pageTitle":"Worker","url":"/preview-docs/es/docs/project/workload/worker#añadir-un-worker-para-tu-proyecto","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navegar a la sección de crear un Worker​","type":1,"pageTitle":"Worker","url":"/preview-docs/es/docs/project/workload/worker#1-navegar-a-la-sección-de-crear-un-worker","content":" En el Panel izquierdo, accede a Workloads. Luego selecciona la pestaña Worker y, en la esquina superior derecha, haz clic en el botón Crear.    ","version":"Next","tagName":"h3"},{"title":"2. Selecciona un Proyecto y un Nombre para el Worker​","type":1,"pageTitle":"Worker","url":"/preview-docs/es/docs/project/workload/worker#2-selecciona-un-proyecto-y-un-nombre-para-el-worker","content":" Comienza con la información básica, completa estos atributos y haz clic en Siguiente para continuar.  Atributo\tDescripciónNombre\tIdentifica tu Worker. Proyecto\tSelecciona entre los proyectos existentes. Comando\tEl comando que ejecuta el servicio.  Una vez completados estos atributos, haz clic en el botón Siguiente para continuar.    ","version":"Next","tagName":"h3"},{"title":"3. Finalizar la configuración​","type":1,"pageTitle":"Worker","url":"/preview-docs/es/docs/project/workload/worker#3-finalizar-la-configuración","content":" Este paso describe los atributos clave para configurar los recursos de un Worker en SleakOps, permitiendo una gestión flexible de CPU, memoria y comportamientos de escalado.  Atributo\tDescripciónCPU Request\tLa cantidad mínima de recursos de CPU asignados para cada instancia en el clúster. Esto garantiza que cada instancia siempre tenga esta cantidad de CPU disponible. CPU Limit\tLa cantidad máxima de recursos de CPU que cada instancia en el clúster puede utilizar. Este límite ayuda a prevenir que una instancia consuma demasiada CPU. Memory Request\tLa cantidad mínima de memoria asignada para cada instancia en el clúster. Esto garantiza que la instancia tenga suficiente memoria para operar eficientemente. Memory Limit\tLa cantidad máxima de memoria que cada instancia en el clúster puede utilizar. Limita el uso de memoria para evitar que una sola instancia consuma recursos en exceso. Autoscaling\tActivar o desactivar el auto-escalado. Cuando está habilitado, permite que el servicio ajuste el número de réplicas según la demanda y el uso de recursos. CPU Target\tEl porcentaje de uso de CPU que desencadena el auto-escalado. Si el uso supera este objetivo, se pueden desplegar réplicas adicionales para equilibrar la carga. Memory Target\tEl porcentaje de uso de memoria que activa el ajuste de auto-escalado. Cuando las instancias superan este objetivo, el sistema escala hacia arriba para acomodar la demanda. Replicas Min\tEl número mínimo de réplicas que deben mantenerse cuando el auto-escalado está activo. Un mínimo de 2 réplicas garantiza alta disponibilidad y previene tiempos de inactividad. Replicas Max\tEl número máximo de réplicas que se pueden desplegar cuando el auto-escalado está habilitado. Establece un límite superior en el número de instancias para evitar la sobreasignación de recursos.    Submit to create and Deploy your worker. ","version":"Next","tagName":"h3"},{"title":"Cuentas","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/provider/accounts","content":"","keywords":"","version":"Next"},{"title":"Cuentas del Provider​","type":1,"pageTitle":"Cuentas","url":"/preview-docs/es/docs/provider/accounts#cuentas-del-provider","content":" SleakOps implementa una infraestructura bien estructurada, diseñada para optimizar la excelencia operativa y garantizar un entorno seguro y escalable para los usuarios. Esta infraestructura se compone de cuatro cuentas, cada una con propósitos específicos y aisladas entre sí.  Cada cuenta tiene una instancia de VPN generada al crear el primer clúster.  Una vez que las Cuentas están activas, asignamos a cada una lo que llamamos Módulo de Red, que contiene una variedad de servicios de AWS utilizados para realizar conexiones de red dentro de las cuentas.    ","version":"Next","tagName":"h2"},{"title":"Cuenta de Seguridad​","type":1,"pageTitle":"Cuentas","url":"/preview-docs/es/docs/provider/accounts#cuenta-de-seguridad","content":" La Cuenta de Seguridad centraliza la administración de usuarios de IAM y sus permisos de acceso al sistema. Aprende cómo cambiar entre cuentas en Autenticación de Consola de AWS.  ","version":"Next","tagName":"h3"},{"title":"Cuenta de Management​","type":1,"pageTitle":"Cuentas","url":"/preview-docs/es/docs/provider/accounts#cuenta-de-management","content":" Diseñada para mantener servicios internos utilizados para el mantenimiento de aplicaciones, independientemente de si se comparten entre cuentas. Ejemplo: Sentry.  Contiene un clúster de EKS con CI/CD integrado (GitHub y HashiCorp Vault).Vault gestiona credenciales para CloudWatch, mejorando las capacidades de monitoreo.VPC Peering permite conexiones privadas a otras cuentas.  ","version":"Next","tagName":"h3"},{"title":"Cuenta de Desarrollo​","type":1,"pageTitle":"Cuentas","url":"/preview-docs/es/docs/provider/accounts#cuenta-de-desarrollo","content":" Para las diferentes etapas de tu aplicación antes de que pase a producción.  Contiene tres entornos: dev, QA y Staging.Réplicas del entorno de producción para escribir código, realizar pruebas y pre-lanzamientos.Asegura pruebas aisladas para evitar problemas a los usuarios externos.Arquitectura similar a prod pero sin RDS Slave para reducir los requisitos de alta disponibilidad.  ","version":"Next","tagName":"h3"},{"title":"Cuenta de Producción​","type":1,"pageTitle":"Cuentas","url":"/preview-docs/es/docs/provider/accounts#cuenta-de-producción","content":" Esta cuenta está destinada a que tu aplicación se instale en un entorno productivo, aislado del resto de las etapas de tu aplicación.  Soporta usuarios externos y requiere una base de datos completamente funcional (RDS Master).Utiliza Subnet de BD Privada para RDS Master, RDS Slave y ElastiCache, cada uno en diferentes Zonas de Disponibilidad (AZs) para alta disponibilidad.Despliegue de Backend con réplicas distribuidas en diferentes AZs.Despliegue de Frontend con LoadBalancer para una distribución uniforme de la carga de red.Route53 actúa como DNS y realiza comprobaciones de salud para la aplicación.AWS CloudFront sirve contenido frontend estático desde un bucket de S3.RDS Slave actúa como réplica de RDS Master para escenarios de conmutación por error, maximizando el tiempo de actividad.  ","version":"Next","tagName":"h3"},{"title":"Selección de una Cuenta en SleakOps​","type":1,"pageTitle":"Cuentas","url":"/preview-docs/es/docs/provider/accounts#selección-de-una-cuenta-en-sleakops","content":" Para seleccionar una cuenta y poder trabajar en ella, selecciónala desde el panel izquierdo. El icono de la izquierda se refiere al Provider que agrupa las cuentas. ","version":"Next","tagName":"h3"},{"title":"Providers","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/provider","content":"","keywords":"","version":"Next"},{"title":"Vamos a crear tu provider en SleakOps​","type":1,"pageTitle":"Providers","url":"/preview-docs/es/docs/provider#vamos-a-crear-tu-provider-en-sleakops","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navega a la sección de providers​","type":1,"pageTitle":"Providers","url":"/preview-docs/es/docs/provider#1-navega-a-la-sección-de-providers","content":" En el Panel Izquierdo, accede a la opción Configuración y luego Providers. En la esquina superior derecha, haz clic en el botón Crear.    ","version":"Next","tagName":"h3"},{"title":"2. Configura la Información Básica​","type":1,"pageTitle":"Providers","url":"/preview-docs/es/docs/provider#2-configura-la-información-básica","content":"   Estos son los ajustes que debes definir:  Configuración\tDescripciónNombre\tSelecciona un nombre para la Unidad Organizativa en AWS bajo la cual se crearán las cuentas necesarias. Región\tRegión de AWS a utilizar. Si deseas saber más sobre ellas, puedes visitar esta documentación aquí . Dominio\tAquí debes proporcionar el dominio que posees en el cual se desplegarán los diferentes entornos. Debe delegarse manualmente al Route53 principal de SleakOps. Sigue los pasos descritos en esta guía . Email\tPor defecto, SleakOps usa el correo electrónico de la cuenta root proporcionada. Si deseas utilizar otro correo para registrar tus cuentas de SleakOps en AWS, completa este campo.  Una vez completado el formulario, haz clic en Siguiente para continuar.  ","version":"Next","tagName":"h3"},{"title":"3. Conéctate a tu Cuenta Root de AWS​","type":1,"pageTitle":"Providers","url":"/preview-docs/es/docs/provider#3-conéctate-a-tu-cuenta-root-de-aws","content":" aviso Debes estar conectado a tu Cuenta Root de AWS.  Para comenzar la instalación de tu aplicación, necesitamos conectarnos a tu Cuenta Root de AWS. Así es como hacerlo:  Al hacer clic en el botón Siguiente, serás redirigido a AWS para crear un rol de IAM en tu cuenta principal llamado &quot;SleakopsIntegrationRole&quot;.  Este rol nos permite acceder a los recursos necesarios, haciendo que la instalación sea rápida y fluida.Después de la instalación, eliminaremos este rol para mantener la seguridad de tu cuenta.    ","version":"Next","tagName":"h3"},{"title":"4. Proceso de creación de la Unidad Organizativa en curso​","type":1,"pageTitle":"Providers","url":"/preview-docs/es/docs/provider#4-proceso-de-creación-de-la-unidad-organizativa-en-curso","content":" nota Crear una Unidad Organizativa no genera ningún costo en tu cuenta de AWS 😃  Una vez establecida la conexión y creado el rol, SleakOps iniciará automáticamente la creación de la Unidad Organizativa.  Este proceso tomará unos minutos.    ","version":"Next","tagName":"h3"},{"title":"5. Conoce la arquitectura de infraestructura creada por SleakOps para ti.​","type":1,"pageTitle":"Providers","url":"/preview-docs/es/docs/provider#5-conoce-la-arquitectura-de-infraestructura-creada-por-sleakops-para-ti","content":" Para entender lo que se creó en tu cuenta de AWS, consulta Cuentas. ","version":"Next","tagName":"h3"},{"title":"Eliminar un Provider","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/provider/deleting-a-provider","content":"","keywords":"","version":"Next"},{"title":"Cómo eliminar un Provider​","type":1,"pageTitle":"Eliminar un Provider","url":"/preview-docs/es/docs/provider/deleting-a-provider#cómo-eliminar-un-provider","content":" ","version":"Next","tagName":"h2"},{"title":"1. Selecciona el Provider a eliminar​","type":1,"pageTitle":"Eliminar un Provider","url":"/preview-docs/es/docs/provider/deleting-a-provider#1-selecciona-el-provider-a-eliminar","content":" Una vez que estés en la sección Providers, selecciona un Provider y haz clic en el botón de Tres Puntos **para mostrar la opción Eliminar. Haz clic en ella.    ","version":"Next","tagName":"h3"},{"title":"2. Confirma el procedimiento​","type":1,"pageTitle":"Eliminar un Provider","url":"/preview-docs/es/docs/provider/deleting-a-provider#2-confirma-el-procedimiento","content":" Verás un modal para confirmar la acción. Recuerda que esta acción eliminará toda la infraestructura creada en AWS bajo este Provider.    ","version":"Next","tagName":"h3"},{"title":"3. Elimina manualmente la Organización y sus Cuentas​","type":1,"pageTitle":"Eliminar un Provider","url":"/preview-docs/es/docs/provider/deleting-a-provider#3-elimina-manualmente-la-organización-y-sus-cuentas","content":" Como se mencionó anteriormente, la Organización creada y sus cuentas (gestión, desarrollo, producción y seguridad) no se eliminarán automáticamente.  Accede a tu Cuenta Root de AWS para eliminarlas manualmente ingresando a AWS Organizations.   ","version":"Next","tagName":"h3"},{"title":"Errores comunes en Providers","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/provider/common-errors","content":"","keywords":"","version":"Next"},{"title":"1. El ID de la cuenta configurada no tiene acceso Root​","type":1,"pageTitle":"Errores comunes en Providers","url":"/preview-docs/es/docs/provider/common-errors#1-el-id-de-la-cuenta-configurada-no-tiene-acceso-root","content":" En este caso, al hacer clic en el botón Fix, serás redirigido nuevamente a AWS.  Asegúrate de haber iniciado sesión como usuario Root.    ","version":"Next","tagName":"h3"},{"title":"2. Se alcanzó el número máximo de cuentas de AWS​","type":1,"pageTitle":"Errores comunes en Providers","url":"/preview-docs/es/docs/provider/common-errors#2-se-alcanzó-el-número-máximo-de-cuentas-de-aws","content":" AWS tiene un límite de cuentas que puede impedir la creación de nuevas.  Antes de volver a intentar el proceso, aumenta ese límite. De lo contrario, el proceso fallará nuevamente.    ","version":"Next","tagName":"h3"},{"title":"3. Otros errores​","type":1,"pageTitle":"Errores comunes en Providers","url":"/preview-docs/es/docs/provider/common-errors#3-otros-errores","content":" Pueden surgir otros problemas que generalmente se resuelven ejecutando nuevamente la conexión con AWS.  Si el error persiste después de intentar eliminar el Provider y crear uno nuevo, no dudes en reportarnos el problema.   ","version":"Next","tagName":"h3"},{"title":"Web Service","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/project/workload/webservice","content":"","keywords":"","version":"Next"},{"title":"Preguntas Frecuentes​","type":1,"pageTitle":"Web Service","url":"/preview-docs/es/docs/project/workload/webservice#preguntas-frecuentes","content":" ¿Cuál es la diferencia entre los esquemas de servicio Público, Privado e Interno?​ Público: Accesible a través de Internet y abierto a cualquier persona.Privado: Acceso restringido, disponible solo cuando se está conectado a la VPN.Interno: Solo accesible dentro del mismo clúster de Kubernetes y se utiliza para la comunicación interna entre servicios.  ¿Cómo configuro el auto-escalado para mi Web Service?​ Para habilitar el auto-escalado, puedes activar la opción Autoscaling y definir el Memory Target y el CPU Target. Estos objetivos determinan los umbrales de uso de recursos que desencadenan el auto-escalado. También debes especificar el número mínimo y máximo de réplicas que se deben mantener cuando el auto-escalado está habilitado.  ¿Cuáles son los códigos de éxito predeterminados para un Web Service y puedo cambiarlos?​ El código de éxito predeterminado es el 200, que indica que el servicio está sano. Puedes cambiar este código según los requisitos de tu aplicación, ya que algunos servicios pueden devolver diferentes códigos de éxito dependiendo de las acciones específicas.  ¿Qué pasa si mi verificación de salud falla repetidamente?​ Si la verificación de salud falla de manera consecutiva y alcanza el umbral de fallos (el valor predeterminado es 60), el servicio se marcará como no saludable, y Kubernetes podría reiniciar o terminar la instancia del servicio para intentar una recuperación.  ¿Cómo puedo configurar la memoria y los ajustes de CPU para mi Web Service?​ Puedes configurar los valores CPU Request y CPU Limit para establecer los recursos mínimos y máximos de CPU que cada instancia en tu clúster puede usar. De manera similar, puedes establecer Memory Request y Memory Limit para la asignación de memoria por instancia.  ¿Cuáles son algunas buenas prácticas al configurar un Web Service en SleakOps?​ Siempre establece un mínimo de 2 réplicas para evitar el tiempo de inactividad.Asegúrate de que las rutas de verificación de salud y los códigos de éxito estén configurados correctamente para reflejar la verdadera salud de tu servicio.Usa auto-escalado siempre que sea posible para optimizar los recursos dinámicamente según la demanda.Revisa y ajusta adecuadamente los objetivos de memoria y uso de CPU para evitar sobrecargar tu infraestructura.  ¿Qué debo hacer si mi servicio muestra tiempos de respuesta superiores a los 10 segundos?​ Los tiempos de respuesta largos pueden indicar problemas como limitaciones de recursos, ineficiencias en la aplicación o problemas de red. Deberías revisar los registros de tu servicio, asegurarte de que los recursos (CPU, memoria) estén asignados adecuadamente y revisar el código de la aplicación para posibles optimizaciones.  Como puedo desplegar mi sitio web estatico?​ Por el momento, Sleakops no ofrece soporte nativo para sitios estáticos. Sin embargo, puedes desplegarlos utilizando el mismo flujo que para otros sitios, contenedorizándolos con un servidor web como Nginx. A continuación, se muestra un ejemplo sencillo de un Dockerfile y su correspondiente nginx.conf para servir tu contenido estático. FROM node:20.11.0-alpine AS base WORKDIR /app FROM base AS build ARG BACKEND_URL WORKDIR /app COPY package.json package-lock.json ./ RUN npm install COPY . ./ RUN npm run build FROM nginx:1.25.3-alpine AS production COPY --from=build /app/config/nginx.conf /etc/nginx/conf.d/default.conf COPY --from=build /app/dist /usr/share/nginx/html EXPOSE 80 CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] Un ejemplo de config/nginx.conf: server { listen 80; location = /health { access_log off; add_header 'Content-Type' 'application/json'; return 200 '{&quot;status&quot;:&quot;OK&quot;}'; } location / { root /usr/share/nginx/html; index index.html index.htm; try_files $uri $uri/ /index.html =404; add_header Last-Modified $date_gmt; add_header Cache-Control 'no-store, no-cache'; if_modified_since off; expires off; etag off; } } Utilizando este enfoque basado en Docker, puedes servir tu sitio estático con Nginx, todo dentro de un contenedor.  ","version":"Next","tagName":"h2"},{"title":"Añadir un Web Service para tu Proyecto​","type":1,"pageTitle":"Web Service","url":"/preview-docs/es/docs/project/workload/webservice#añadir-un-web-service-para-tu-proyecto","content":" ","version":"Next","tagName":"h2"},{"title":"1. Navegar a la sección de crear un Web Service​","type":1,"pageTitle":"Web Service","url":"/preview-docs/es/docs/project/workload/webservice#1-navegar-a-la-sección-de-crear-un-web-service","content":" En el Panel izquierdo, accede a Workloads. Luego selecciona la pestaña Servicios Web y, en la esquina superior derecha, haz clic en el botón Crear.    ","version":"Next","tagName":"h3"},{"title":"2. Selecciona un Proyecto y un Nombre para el Web Service​","type":1,"pageTitle":"Web Service","url":"/preview-docs/es/docs/project/workload/webservice#2-selecciona-un-proyecto-y-un-nombre-para-el-web-service","content":" Comienza con la información básica, completa estos atributos y haz clic en Siguiente para continuar.  Atributo\tDescripciónNombre\tIdentifica tu Web Service. Proyecto\tSelecciona entre los proyectos existentes. Comando\tEl comando que ejecuta el servicio. Puerto\tEl número de puerto donde se ejecuta el servicio. Predeterminado: 8000  Una vez completados estos atributos, haz clic en el botón Siguiente para continuar.    ","version":"Next","tagName":"h3"},{"title":"3. Define la conexión​","type":1,"pageTitle":"Web Service","url":"/preview-docs/es/docs/project/workload/webservice#3-define-la-conexión","content":" Selecciona cómo será tu conexión y haz clic en Siguiente.  Atributo\tDescripciónEsquema de Servicio\tDefine la accesibilidad del servicio: público, privado o interno. URL\tLa URL asignada al servicio según el entorno y la configuración del proyecto. Formato: name.myenv.sleakops.com.    ","version":"Next","tagName":"h3"},{"title":"4. Especifica los ajustes de tu servicio​","type":1,"pageTitle":"Web Service","url":"/preview-docs/es/docs/project/workload/webservice#4-especifica-los-ajustes-de-tu-servicio","content":" Verás los siguientes atributos para especificar las condiciones.    Atributo\tDescripciónRuta\tLa ruta donde Kubernetes verifica si el Web Service está operativo. Predeterminado: / Código de Éxito\tEl código HTTP de éxito que indica la salud del servicio. Predeterminado: 200. Retraso Inicial en Segundos\tNúmero de segundos después del inicio antes de que comiencen las verificaciones de salud. Predeterminado: 10. Segundos de Tiempo de Espera\tNúmero de segundos después del inicio antes de que comiencen las verificaciones de salud. Predeterminado: 1. Segundos entre cada Verificación\tIntervalo (en segundos) entre cada prueba de verificación de salud. Predeterminado: 5. Umbral de Éxitos\tNúmero mínimo de éxitos consecutivos requeridos para que la prueba se considere exitosa después de fallar. Predeterminado: 1. Umbral de Fallos\tNúmero de fallos consecutivos antes de que la prueba se considere fallida. Predeterminado: 60.  Una vez completados estos atributos, haz clic en el botón Siguiente para continuar con el siguiente paso.  ","version":"Next","tagName":"h3"},{"title":"5. Finalizar la configuración​","type":1,"pageTitle":"Web Service","url":"/preview-docs/es/docs/project/workload/webservice#5-finalizar-la-configuración","content":" Este paso describe los atributos clave para configurar los recursos de un Servicio Web en SleakOps, permitiendo una gestión flexible de CPU, memoria y comportamientos de escalado.  Atributo\tDescripciónCPU Request\tLa cantidad mínima de recursos de CPU asignados para cada instancia en el clúster. Esto garantiza que cada instancia siempre tenga esta cantidad de CPU disponible. CPU Limit\tLa cantidad máxima de recursos de CPU que cada instancia en el clúster puede utilizar. Este límite ayuda a prevenir que una instancia consuma demasiada CPU. Memory Request\tLa cantidad mínima de memoria asignada para cada instancia en el clúster. Esto garantiza que la instancia tenga suficiente memoria para operar eficientemente. Memory Limit\tLa cantidad máxima de memoria que cada instancia en el clúster puede utilizar. Limita el uso de memoria para evitar que una sola instancia consuma recursos en exceso. Autoscaling\tActivar o desactivar el auto-escalado. Cuando está habilitado, permite que el servicio ajuste el número de réplicas según la demanda y el uso de recursos. CPU Target\tEl porcentaje de uso de CPU que desencadena el auto-escalado. Si el uso supera este objetivo, se pueden desplegar réplicas adicionales para equilibrar la carga. Memory Target\tEl porcentaje de uso de memoria que activa el ajuste de auto-escalado. Cuando las instancias superan este objetivo, el sistema escala hacia arriba para acomodar la demanda. Replicas Min\tEl número mínimo de réplicas que deben mantenerse cuando el auto-escalado está activo. Un mínimo de 2 réplicas garantiza alta disponibilidad y previene tiempos de inactividad. Replicas Max\tEl número máximo de réplicas que se pueden desplegar cuando el auto-escalado está habilitado. Establece un límite superior en el número de instancias para evitar la sobreasignación de recursos.    Envía para crear y desplegar tu web service. ","version":"Next","tagName":"h3"},{"title":"Diseñando tu Infraestructura","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/provider/schemas","content":"","keywords":"","version":"Next"},{"title":"Esquema Simple vs. Esquema Múltiple​","type":1,"pageTitle":"Diseñando tu Infraestructura","url":"/preview-docs/es/docs/provider/schemas#esquema-simple-vs-esquema-múltiple","content":" SleakOps ofrece la flexibilidad y el control necesarios para construir una infraestructura adaptada a tus requisitos específicos.  Si bien recomendamos adoptar una configuración de Esquema Múltiple para alinearte con las mejores prácticas, entendemos que diferentes etapas de tu proyecto pueden requerir configuraciones alternativas de esquemas.    Aquí tienes una comparativa entre las dos opciones:  \tEsquema Múltiple ⭐️\tEsquema ÚnicoDescripción\tAlineado con las mejores prácticas. Configurarás primero la cuenta de Desarrollo.\tCentraliza tus entornos dentro de un solo clúster. Cuenta a utilizar\tUtiliza todas las cuentas como se describe aquí.\tSolo la cuenta de Producción. Ventajas\tIncrementa la seguridad al otorgar acceso por cuenta. La cuenta de Producción permanece aislada.\tReduce costos, ya que solo utiliza un clúster. Desventajas\tEs más costoso, ya que cada entorno tendrá su propio clúster y VPN.\tMenos seguro, ya que todos los entornos comparten la misma cuenta.  Estas son solo dos opciones; tienes la libertad de crear el esquema que mejor se adapte a tus necesidades.  ","version":"Next","tagName":"h2"},{"title":"Ejemplo Multi-Schema​","type":1,"pageTitle":"Diseñando tu Infraestructura","url":"/preview-docs/es/docs/provider/schemas#ejemplo-multi-schema","content":"   ","version":"Next","tagName":"h2"},{"title":"Ejemplo Single-Schema​","type":1,"pageTitle":"Diseñando tu Infraestructura","url":"/preview-docs/es/docs/provider/schemas#ejemplo-single-schema","content":"  ","version":"Next","tagName":"h2"},{"title":"Modelo de Responsabilidad Compartida","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/responsability-model","content":"Modelo de Responsabilidad Compartida Utilizamos de manera transparente todos los servicios de AWS, lo que implica que la responsabilidad se extiende a las pautas establecidas por AWS. Para proteger tus datos y asegurarte de que no se pierdan debido a posibles interrupciones en los servicios, es recomendable contar con políticas de respaldo. Actualmente, no ofrecemos soporte para respaldos de nuestras dependencias (RDS, S3, RabbitMQ, etc.). Para configurarlos, puedes acceder a través de tu cliente de AWS y definir tus políticas de respaldo. [Obtén más información sobre el Modelo de Responsabilidad Compartida de AWS] (https://aws.amazon.com/compliance/shared-responsibility-model/)","keywords":"","version":"Next"},{"title":"Django + Celery","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/quickstart/django_celery","content":"","keywords":"","version":"Next"},{"title":"Prerrequisitos​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#prerrequisitos","content":" Cuenta en SleakopsUn Clúster en esta cuenta. Si no lo tienes, aquí está la documentación sobre cómo hacerlo.Un Ambiente configurado. Si no lo tienes, aquí está la documentación sobre cómo hacerloProyecto Django configurado con celery (Este proyecto necesita tener docker).  ","version":"Next","tagName":"h2"},{"title":"Empecemos​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#empecemos","content":" Para este ejemplo, vamos a usar este proyecto . Es un proyecto Django con Celery que ya tiene Docker configurado para funcionar. También vamos a configurar una base de datos Postgresql, bucket S3 y Rabbitmq necesarios para este proyecto.  ","version":"Next","tagName":"h2"},{"title":"Crear un proyecto​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#crear-un-proyecto","content":" Para empezar, vamos a crear un nuevo proyecto. Para hacer esto, hacemos clic en el botón &quot;Projects&quot; en el panel izquierdo:    Dentro del panel de Proyectos podrás ver todos los proyectos que tienes y gestionarlos desde aquí. Queremos crear uno nuevo así que hagamos clic en el botón &quot;create&quot; en la parte superior derecha:    En la pantalla de creación de proyecto tenemos los siguientes campos:  Configuración\tDescripciónEnvironment\tTenemos que seleccionar el ambiente creado previamente. Nodepool\tDejaremos el predeterminado. Repositories\tSeleccionaremos nuestro repositorio que queremos desplegar. En nuestro caso example-django-celery. Project Name\tPodemos definir un nombre de proyecto. Para el ejemplo dejaremos el predeterminado. Branch\tTiene que coincidir con el que tenemos en nuestro proyecto. En nuestro caso es &quot;Main&quot;. Dockerfile path\tEs la ruta relativa al dockerfile en tu proyecto.  Una vez configurado todo eso, creamos el proyecto con el botón &quot;Submit&quot; en la parte inferior derecha:    Con eso, el proyecto comienza a crearse. Mientras tanto vamos a las cargas de trabajo con el botón &quot;Workloads&quot; en el panel izquierdo:    ","version":"Next","tagName":"h3"},{"title":"Crear un Servicio Web​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#crear-un-servicio-web","content":" Aquí lo que vamos a hacer es crear un servicio web, así que vamos a la sección de servicio web y creamos uno:    En esta página vamos a completar el primer formulario con los siguientes campos:  Configuración\tDescripciónProject\tSeleccionamos el proyecto que creamos previamente, en nuestro caso &quot;example-django-celery&quot;. Name\tDefinimos un nombre para el servicio web. Command\tPor defecto esto tomará el valor que está en el dockerfile, en nuestro caso esto está bien. Port\tLo mismo que el command.  Luego continuamos haciendo clic en el botón &quot;Next&quot; hasta el paso 3:    En el paso 3 tenemos que editar el campo path y poner el endpoint de healthcheck que en nuestro caso es &quot;/healthcheck/&quot;. Luego hacemos clic en el botón &quot;Next&quot; hasta que se cree el servicio web:    ","version":"Next","tagName":"h3"},{"title":"Desplegar celery worker​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#desplegar-celery-worker","content":" Bueno, con esto podemos ver nuestro servicio web desplegándose. Ahora vamos a desplegar el celery. Para esto tenemos que ir a la sección workers dentro de la misma pantalla de workloads:    Y hacemos clic en el botón &quot;Create&quot; para crear uno nuevo:    En la pantalla de creación de workers tendremos que completar los siguientes campos:  Configuración\tDescripciónProject\tSeleccionar el proyecto creado previamente. En nuestro caso &quot;example-django-celery&quot;. Name\tDefinimos el nombre que le vamos a dar al worker. En nuestro caso &quot;celery&quot;. Command\tAquí establecemos el comando para ejecutar celery, en nuestro caso es: bash celery -A core.celery_app worker -l INFO --concurrency 1 --max-tasks-per-child 1 --prefetch-multiplier 1 -n celery@%h --queues default,build,deployment,cluster,canvas,billing  Con estos campos completados haremos clic en el botón &quot;Next&quot; en la parte inferior derecha y luego &quot;Submit&quot; ya que no necesitamos editar nada más:    Con esto veremos nuestro celery publicado. Ahora tenemos que configurar los hooks. Para esto vamos a la sección hooks:    ","version":"Next","tagName":"h3"},{"title":"Crear un hook de migración​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#crear-un-hook-de-migración","content":" En la pantalla de creación de hook tendremos los siguientes campos:  Configuración\tDescripciónProject\tSeleccionar el proyecto creado previamente. En nuestro caso &quot;example-django-celery&quot;. Name\tDefinimos el nombre que le vamos a dar al worker. En nuestro caso &quot;migrations&quot;. Command\tAquí establecemos el comando para ejecutar celery, en nuestro caso es: bash python manage.py migrate --no-input   Con estos campos completados haremos clic en el botón &quot;Next&quot; en la parte inferior derecha y luego &quot;Submit&quot; ya que no necesitamos editar nada más:    ","version":"Next","tagName":"h3"},{"title":"Crear un hook de collect static​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#crear-un-hook-de-collect-static","content":" Ahora procedemos a crear otro hook que necesitamos para los estáticos:    En este formulario vamos a hacer lo mismo que el anterior pero modificando el comando. Hacemos clic en next hasta crear el hook (sin modificar nada más):    El comando que usamos es el siguiente:  python manage.py collectstatic --no-input   ","version":"Next","tagName":"h3"},{"title":"Crear una Base de Datos Postgresql​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#crear-una-base-de-datos-postgresql","content":" Una vez que hemos creado los hooks tenemos que ir a crear nuestra base de datos. Para hacer esto vamos a la sección &quot;Dependencies&quot;:    Dentro de esta sección hacemos clic en el botón &quot;Create&quot; en la parte superior derecha y luego seleccionamos &quot;Postgresql&quot;:      En el 1er formulario de creación de postgresql tendremos que seleccionar nuestro proyecto creado previamente y definir un nombre para él, luego hacemos clic en el botón &quot;Next&quot; en la parte inferior derecha:    En el 2do formulario vamos a tener muchos campos, los únicos que nos importan son los siguientes:  Configuración\tDescripciónDatabase Master Username\tAquí asignamos un nombre de usuario root a nuestra base de datos. Database Master Password\tUna contraseña para este usuario root.  Una vez rellenados estos campos, estamos listos para continuar. Haga clic en el botón «Siguiente» situado en la parte inferior derecha para pasar al tercer formulario:    En este último formulario, vamos a ajustar las variables de entorno que tenemos en nuestro proyecto con respecto a la base de datos. Para ello, debemos cambiar las siguientes variables por las nuestras propias:  Antes\tDespues*_POSTGRESQL_NAME\tDB_NAME *_POSTGRESQL_USERNAME\tDB_USER *_POSTGRESQL_PASSWORD\tDB_PASSWORD *_POSTGRESQL_ADDRESS\tDB_HOST *_POSTGRESQL_PORT\tDB_PORT  Debería verse similar a la imagen de abajo. A continuación, haga clic en el botón «Enviar» y se creará su base de datos:    ","version":"Next","tagName":"h3"},{"title":"Crear Bucket S3​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#crear-bucket-s3","content":" En la misma página de dependencias tenemos que crear nuestro bucket s3, para ello vamos a ir al botón &quot;Create&quot; nuevamente:    Y seleccionamos S3 Bucket:    En el primer formulario tenemos que seleccionar nuestro proyecto creado previamente y definir un nombre para el bucket, tenemos que tomar en cuenta que el nombre del bucket es global así que tiene que ser único. Ahora hacemos clic en el botón &quot;Next&quot; y vamos al paso 3:    Aquí vamos a ver algunas variables de entorno definidas para el bucket. Vamos a editar la que dice COLLECTSTATICEXAMPLEDJANGOCELERY_BUCKET_NAME y la vamos a llamar DJANGO_AWS_STORAGE_BUCKET_NAME. Con este simple cambio hacemos clic en el botón &quot;Submit&quot; en la parte inferior derecha para terminar de crear el bucket:    ","version":"Next","tagName":"h3"},{"title":"Crear Rabbitmq​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#crear-rabbitmq","content":" Ahora necesitamos una dependencia más. Nuestro Rabbitmq para encolar las tareas de celery, así que vamos a ello:    Y seleccionamos Rabbitmq:    En el primer formulario tendremos que seleccionar nuestro proyecto y definir un nombre para él. Luego hacemos clic en el botón &quot;Next&quot; en la parte inferior derecha:    En el siguiente formulario tenemos varios campos pero los únicos que nos importan para este ejemplo son el username y password, podemos definir lo que queramos. Para este ejemplo elegí admin como username y para la contraseña la generé aleatoriamente con el botón de dado. Luego hacemos clic en el botón &quot;Next&quot; para ir al siguiente formulario:    En este último formulario tenemos que cambiar el nombre de la variable que termina en *_BROKER_AUTH_URL a CELERY_BROKER_URL (como se muestra en la imagen). Luego hacemos clic en el botón &quot;Submit&quot; en la parte inferior derecha para terminar de crear rabbitmq:    ","version":"Next","tagName":"h3"},{"title":"Crear tus variables de entorno​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#crear-tus-variables-de-entorno","content":" Una vez que las dependencias están desplegadas tenemos que configurar nuestras variables de entorno. Vamos a ir a la sección Vargroups:    Aquí verás todas tus variables de entorno que creaste agrupadas en grupos, por ejemplo deberías haber creado una con los datos para la base de datos (que es la que ves en la imagen). Ahora vamos a crear otra para nuestras variables de entorno de django, para esto hacemos clic en el botón &quot;Create&quot; en la parte superior derecha:    En este formulario tenemos los siguientes campos:  Project: seleccionamos el proyecto que creamos previamente.Workload: Seleccionamos &quot;global&quot; que hace referencia a ser usado por todos nuestros workloads.Name: Definimos un nombre para este grupo de variables.Type: Si queremos cargarlo por archivo o por variable.Vars: Aquí habilitamos el textmode y copiamos las siguientes variables de entorno:  CELERY_RESULT_BACKEND=django-db DJANGO_ADMIN_URL=admin/ DJANGO_DEBUG=False DJANGO_SECRET_KEY=secret_key DJANGO_SETTINGS_MODULE=core.settings.production DJANGO_STATIC_STORAGE=storages.backends.s3boto3.S3StaticStorage DB_ENGINE=django.db.backends.postgresql_psycopg2 ENVIRONMENT=production LOGS_LEVEL=INFO PYTHONPATH=.   Estas variables de entorno son requeridas para nuestro proyecto de ejemplo. Finalmente hacemos clic en el botón &quot;Submit&quot; en la parte inferior derecha para crear el grupo de variables.    ","version":"Next","tagName":"h3"},{"title":"Despliegues​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#despliegues","content":" Como último paso vamos a ver nuestro proyecto desplegado, para esto vamos a la sección &quot;Deployments&quot; del panel izquierdo:    Aquí vamos a ver todos los despliegues que hacemos. En nuestro caso es el primero y podemos ver que se ha creado correctamente, en caso de que veas algún error si haces clic en &quot;error&quot; puedes ver una descripción del mismo. Si no vemos ningún error entonces significa que el proyecto ya está desplegado, podríamos comenzar a usarlo desde la url que nos proporcionó el servicio web.    Esto concluye nuestro proceso de despliegue de proyecto. Te dejamos un paso opcional que es configurar el ci con github.  ","version":"Next","tagName":"h3"},{"title":"Opcional​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#opcional","content":" ","version":"Next","tagName":"h2"},{"title":"CI con Github​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/docs/quickstart/django_celery#ci-con-github","content":" Cada vez que hagas un cambio en tu código y quieras desplegarlo tendrás que hacer un build y un deploy, esto eventualmente se vuelve tedioso. Por eso para evitar esto tenemos que implementar ci en github.  Para esto vamos a ir a &quot;Projects&quot; en el panel izquierdo:    Ubiquemos nuestro proyecto y hagamos clic en el engranaje para acceder a la configuración del proyecto:    En la configuración del proyecto ubicamos el que dice &quot;Git pipelines&quot; y hacemos clic en él:    Aquí vamos a encontrar lo que necesitamos para hacer esto. Básicamente necesitamos configurar un archivo en la raíz de nuestro proyecto .github/workflows/ llamado ci_sleakops_demo.yml y en ese archivo vamos a pegar el contenido que aparece en esta página.    Esto necesita tener una variable de entorno SLEAKOPS_KEY, si no la tienes tienes que ir al enlace que aparece ahí Settings -&gt; CLI, obtenerla y guardarla como una variable de entorno.  Con esto configurado y desplegado cada vez que hagas un push a tu rama &quot;main&quot; se lanzará automáticamente una nueva versión de tu aplicación. ","version":"Next","tagName":"h3"},{"title":"Autenticación de la Consola de AWS","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/user/aws_console_authentication","content":"Autenticación de la Consola de AWS [VIDEO] Cómo acceder a cualquiera de tus Cuentas. As described in the Architecture Overview. You'll have to enter the 'security' account, then, assume the role on the account you want. The easiest way to do this is by using the Sleakops Dashboard: First, use the AWS Login button: This will open the AWS login form. The Account ID field should be automatically filled with the 'security' account ID. If this doesn't happen, it might be because another service is attempting to fill the fields. Once logged into the 'security' account, it will appear as shown in the following image: Now, in the AWS console, you need to return to the SleakOps dashboard, select 'Get Access' and use the drawer, on it, select the account you want to log in to. This will prompt a new AWS tab to switch the role from your 'security' Account into the account you've selected, you'll leave the 'security account' and enter the selected one. info If you're in 'security' or another account you can directly use the account switchers, AWS understands that you are already inside the 'security' account. For more information about this process, you can read its AWS documentation .","keywords":"","version":"Next"},{"title":"Usuarios","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/user","content":"","keywords":"","version":"Next"},{"title":"Creación de usuarios​","type":1,"pageTitle":"Usuarios","url":"/preview-docs/es/docs/user#creación-de-usuarios","content":" Sleakops tiene tres campos fundamentales de permisos de usuario:  Viewer (Solo Lectura)​  Objetivo: Proporcionar acceso de solo lectura para monitorear y revisar la infraestructura sin realizar cambiosAlcance: Ver todos los proyectos, clusters y recursosAcceder a dashboards de monitoreo y logsRevisar historial de despliegues y configuracionesNo puede crear, modificar o eliminar recursos Política AWS IAM: ReadOnlyAccess Ejemplos: Ingenieros DevOps que necesitan monitorear entornos de producciónAuditores de seguridad revisando el cumplimiento de infraestructuraLíderes de equipo que necesitan visibilidad del estado de los proyectos  Editor (Usuario Avanzado)​  Objetivo: Habilitar capacidades de gestión de infraestructura y despliegue manteniendo límites de seguridadAlcance: Crear y gestionar proyectos, clusters y cargas de trabajoDesplegar aplicaciones y gestionar recursos de infraestructuraConfigurar entornos, dependencias y redesNo puede gestionar otros usuarios ni acceder a todas las cuentas por defecto Política AWS IAM: PowerUserAccess Ejemplos: Desarrolladores senior desplegando aplicacionesIngenieros DevOps gestionando infraestructuraMiembros del equipo responsables de despliegues de proyectos específicos  Admin (Administrador)​  Objetivo: Proporcionar control completo de la plataforma incluyendo gestión de usuarios y acceso entre cuentasAlcance: Todas las capacidades de Editor más gestión de usuariosCrear, modificar y eliminar cuentas de usuarioAsignar roles y permisos a otros usuariosAcceso a todas las cuentas AWS sin restriccionesGestión de configuración y configuraciones de la plataforma Política AWS IAM: AdministratorAccess Ejemplos: Administradores de plataformaLíderes de equipo gestionando múltiples proyectosGerentes DevOps con responsabilidades entre equipos  ","version":"Next","tagName":"h2"},{"title":"Configuración de Acceso​","type":1,"pageTitle":"Usuarios","url":"/preview-docs/es/docs/user#configuración-de-acceso","content":" AWS Account Access: Este campo muestra todas las cuentas, aquí seleccionas a qué cuentas el usuario (Editor o Read-only) tendrá acceso.  VPN Account Access: Es similar al campo de accesos a cuentas de AWS, pero aquí defines si el usuario también será creado en el servidor VPN de la cuenta que le otorgues. Más información se puede consultar en la documentación de VPN.    Para el acceso a las cuentas de AWS, SleakOps inicialmente establece una contraseña aleatoria y la envía al correo electrónico del usuario creado. El usuario puede iniciar sesión con esa contraseña, pero se le obligará a cambiarla en su primer inicio de sesión. Para el acceso a la plataforma SleakOps, utilizamos la contraseña configurada en el formulario de usuario.  Después de la creación de este usuario, se creará un Usuario de AWS en la cuenta 'security', que es donde controlamos los accesos a todas las cuentas de AWS de SleakOps. También crearemos, dependiendo de la configuración, usuarios en los servidores VPN; consulta cómo usarlos en la correspondiente documentación y en la sección de usuarios de SleakOps.  ","version":"Next","tagName":"h3"},{"title":"Usuarios Sin Acceso a SleakOps​","type":1,"pageTitle":"Usuarios","url":"/preview-docs/es/docs/user#usuarios-sin-acceso-a-sleakops","content":" Algunos usuarios en tu organización pueden no tener acceso directo a la plataforma SleakOps pero aún interactúan con la infraestructura:  ","version":"Next","tagName":"h2"},{"title":"Colaboradores Externos​","type":1,"pageTitle":"Usuarios","url":"/preview-docs/es/docs/user#colaboradores-externos","content":" Escenario: Contratistas o consultores externos que necesitan acceso temporal a recursos específicos de AWSMétodo de Acceso: Acceso directo a la consola de AWS con permisos IAM limitadosGestión: Manejado a través de AWS IAM directamente, no a través de la gestión de usuarios de SleakOps  ","version":"Next","tagName":"h3"},{"title":"Observadores de Solo Lectura​","type":1,"pageTitle":"Usuarios","url":"/preview-docs/es/docs/user#observadores-de-solo-lectura","content":" Escenario: Stakeholders que necesitan visibilidad de costos y uso de infraestructura sin acceso operacionalMétodo de Acceso: AWS Cost Explorer, dashboards de CloudWatch o herramientas de reportes personalizadasGestión: Solo permisos de facturación y monitoreo de AWS  ","version":"Next","tagName":"h3"},{"title":"Consumidores solo de VPN​","type":1,"pageTitle":"Usuarios","url":"/preview-docs/es/docs/user#consumidores-solo-de-vpn","content":" Escenario: Usuarios que necesitan consumir cargas de trabajo y aplicaciones dentro de la VPN, pero no requieren capacidades de administración ni monitorización de la infraestructura.Método de acceso: Solo acceso a la VPN, con permisos limitados para acceder a aplicaciones y servicios específicos.Gestión: Cuentas de usuario de VPN con acceso restringido a cargas de trabajo y entornos designados. ","version":"Next","tagName":"h3"},{"title":"Conexión a la VPN","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/user/vpn","content":"Conexión a la VPN Para manejar las conexiones VPN utilizamos Pritunl. Puedes descargar el cliente aquí. Una vez que hayas creado un Proveedor, ve al Panel de SleakOps y selecciona la cuenta para la cual quieres obtener acceso VPN. Recuerda que para hacer esto, necesitas tener acceso a la VPN de esa cuenta, pero la VPN también debe estar creada. Creamos la VPN de una cuenta específica cuando se crea el primer clúster de esa cuenta. Esto te mostrará lo que se denomina perfil URI. Tiene un período de validación de 24 horas, y debes cargarlo en el cliente Pritunl. Cópialo e impórtalo en el cliente Pritunl, y podrás conectarte:","keywords":"","version":"Next"},{"title":"n8n + Modo Worker","type":0,"sectionRef":"#","url":"/preview-docs/es/docs/quickstart/n8n","content":"","keywords":"","version":"Next"},{"title":"¿Por qué Auto-hospedar n8n?​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#por-qué-auto-hospedar-n8n","content":" Auto-hospedar n8n proporciona numerosas ventajas sobre las soluciones hospedadas en la nube:  ","version":"Next","tagName":"h2"},{"title":"🔒 Seguridad y Privacidad​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#-seguridad-y-privacidad","content":" Control completo de datos: Tus flujos de trabajo, credenciales y datos sensibles nunca abandonan tu infraestructuraPolíticas de seguridad personalizadas: Implementa los requisitos de seguridad específicos de tu organizaciónAislamiento de red: Mantén n8n dentro de tu red privada, reduciendo vectores de ataque externosCumplimiento: Cumple con requisitos regulatorios estrictos (GDPR, HIPAA, SOC2) con despliegue local  ","version":"Next","tagName":"h3"},{"title":"💰 Optimización de Costos​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#-optimización-de-costos","content":" Sin límites por ejecución: Ejecuta flujos de trabajo ilimitados sin precios basados en usoCostos predecibles: Costos de infraestructura fijos independientemente del volumen de usoEficiencia de recursos: Escala recursos basándote en necesidades reales, no en niveles de precios de proveedoresAhorros a largo plazo: Reducción significativa de costos para escenarios de automatización de alto volumen  ","version":"Next","tagName":"h3"},{"title":"⚡ Rendimiento y Escalabilidad​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#-rendimiento-y-escalabilidad","content":" Asignación de recursos personalizada: Asigna CPU y memoria basándote en los requisitos específicos de tu carga de trabajoBaja latencia: Acceso directo a sistemas internos sin roundtrips de internetAlta disponibilidad: Diseña sistemas redundantes con múltiples réplicas y mecanismos de failoverIntegraciones personalizadas: Conéctate a APIs internas y sistemas no accesibles desde proveedores de nube  ","version":"Next","tagName":"h3"},{"title":"🎛️ Control Total y Personalización​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#️-control-total-y-personalización","content":" Control de versiones: Elige cuándo actualizar y prueba nuevas versiones en tu entornoNodos personalizados: Instala y desarrolla nodos propietarios para tus casos de uso específicosVariables de entorno: Acceso completo a configuraciones a nivel de sistema y gestión de secretosEstrategias de respaldo: Implementa tus propios procedimientos de respaldo y recuperación ante desastres  ","version":"Next","tagName":"h3"},{"title":"Beneficios de Escalado en Kubernetes​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#beneficios-de-escalado-en-kubernetes","content":" Desplegar n8n en un clúster de Kubernetes con Sleakops proporciona escalabilidad de nivel empresarial:  ","version":"Next","tagName":"h2"},{"title":"🚀 Escalado Horizontal​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#-escalado-horizontal","content":" Pods de worker: Escala automáticamente instancias de worker basándote en la profundidad de cola y uso de CPUDistribución de carga: Distribuye la ejecución de flujos de trabajo a través de múltiples nodos workerAuto-escalado: Kubernetes HPA (Horizontal Pod Autoscaler) ajusta automáticamente el conteo de workersOptimización de recursos: Escala diferentes componentes independientemente (UI web vs workers)  ","version":"Next","tagName":"h3"},{"title":"🏗️ Resistencia de Infraestructura​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#️-resistencia-de-infraestructura","content":" Alta disponibilidad: Múltiples réplicas aseguran cero tiempo de inactividad durante fallas de nodosActualizaciones continuas: Despliega nuevas versiones sin interrupción del servicioVerificaciones de salud: Kubernetes reinicia automáticamente pods fallidos y enruta tráfico a instancias saludablesDespliegue multi-zona: Distribuye carga de trabajo a través de zonas de disponibilidad para recuperación ante desastres  ","version":"Next","tagName":"h3"},{"title":"📊 Monitoreo y Observabilidad​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#-monitoreo-y-observabilidad","content":" Métricas en tiempo real: Monitorea ejecución de flujos de trabajo, profundidad de cola y uso de recursosRegistro centralizado: Agrega logs de todos los componentes n8n en un solo lugarInsights de rendimiento: Rastrea tiempos de ejecución, tasas de error y throughputAlertas: Notificaciones proactivas para problemas del sistema y cuellos de botella de rendimiento  ","version":"Next","tagName":"h3"},{"title":"🔧 Integración DevOps​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#-integración-devops","content":" Flujos de trabajo GitOps: Control de versiones de tu infraestructura n8n como códigoPipelines CI/CD: Pruebas automatizadas y despliegue de configuraciones n8nGestión de secretos: Integra con secretos de Kubernetes y gestores de secretos externosPolíticas de red: Controles de seguridad de red de grano fino  ","version":"Next","tagName":"h3"},{"title":"Prerrequisitos​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#prerrequisitos","content":" Cuenta en SleakopsUn Clúster en esta cuenta. Si no lo tienes, aquí está la documentación sobre cómo hacerlo.Un Entorno configurado. Si no lo tienes, aquí está la documentación sobre cómo hacerloProyecto n8n configurado con Docker. Sino lo tienes puedes hacer un fork o copia a n8n-code. Este proyecto incluye un docker-compose para que puedas desplegarlo en local tambien asi puedes tener entornos distribuidos como quieras.  Comencemos  Para este ejemplo, vamos a desplegar un proyecto n8n en modo distribuido con workers. Esta configuración incluye el servicio principal n8n (interfaz web) y procesos worker para ejecutar flujos de trabajo. También vamos a configurar una base de datos PostgreSQL y Redis para gestión de colas necesarias para este proyecto.  ","version":"Next","tagName":"h2"},{"title":"Crear Proyecto​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#crear-proyecto","content":" Los proyectos son nuestros repositorios de codigo. Lo unico que necesita Sleakops para poder ejecutar comandos es un Dockerfile. Para mas informacion puedes ver nuestra documentación de proyectos  Para empezar, crearemos un nuevo proyecto:  Haz clic en el botón &quot;Projects&quot; en el panel izquierdoLuego haz clic en &quot;Create&quot; en la esquina superior derecha    Dentro del panel Projects podrás ver todos los proyectos que tienes y gestionarlos desde aquí. Queremos crear uno nuevo así que hagamos clic en el botón &quot;create&quot; en la parte superior derecha:  En la pantalla de creación del proyecto tenemos los siguientes campos:  Configuración\tDescripciónEnvironment\tTenemos que seleccionar el entorno creado previamente. Nodepool\tDejaremos el predeterminado. Repositories\tSeleccionaremos nuestro repositorio que contiene el proyecto n8n. Project Name\tPodemos definir un nombre de proyecto. Por ejemplo &quot;n8n-server&quot;. Branch\tTiene que coincidir con el que tenemos en nuestro proyecto. En nuestro caso es &quot;main&quot;. Dockerfile path\tEs la ruta relativa al dockerfile en tu proyecto.  Una vez configurado todo eso creamos el proyecto con el botón &quot;Submit&quot; en la parte inferior derecha:    Con eso, el proyecto comienza a crearse. Mientras tanto vamos a las cargas de trabajo con el botón &quot;Workloads&quot; en el panel izquierdo:    ","version":"Next","tagName":"h2"},{"title":"Crear Workloads​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#crear-workloads","content":" Los workloads son los procesos que corre tu proyecto. Para el caso de n8n que vamos a correrlo en modo queue vamos a crear un webservice para la interfaz web y un worker Para mas informacion puedes ver nuestra documentación de workloads  ","version":"Next","tagName":"h2"},{"title":"Crear el Servicio Web​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#crear-el-servicio-web","content":" Aquí vamos a crear el servicio web principal n8n que manejará la interfaz de usuario y API:  En esta página vamos a completar el primer formulario con los siguientes campos:  Configuración\tDescripciónProject\tSeleccionamos el proyecto que creamos previamente, en nuestro caso &quot;n8n-server&quot;. Name\tDefinimos un nombre para el servicio web, por ejemplo &quot;n8n-main&quot;. Command\tComando predeterminado del Dockerfile (usualmente n8n start). Port\tPuerto 5678 (puerto predeterminado de n8n).    En el segundo paso, configuraremos el webservice como privado:  ¿Qué significa esto?  El servicio de n8n estará dentro de la VPCSolo será accesible desde servicios en la misma redRequiere VPN para acceso externo  Alternativa para webhooks públicos:Si necesitas conectar webhooks públicos (Jira, Slack, Google Drive, etc.), puedes:  Dejar este servicio como público, OCrear un webservice adicional público con el comando webhook    Sigue hasta el paso 3 &quot;Service settings&quot; y configura el healthcheck  Para esto solo necesitamos definir bien el path del healthcheck que trae n8n /healthz , y le damos siguiente hasta finalizar el flujo y crear el web services.    Este healthcheck es importante para que kubernetes sepa cuando esta listo el servicio para empezar a entregarle trafico http. Esto es util para no tener downtime entre cada deploy o rotacion de nodos.  El ultimo paso del formulario, donde definimos la memoria, cpu y condiciones de escalado por el momento no vamos a modificarlo, lo dejamos como te lo ofrece la plataforma.  ","version":"Next","tagName":"h3"},{"title":"Crear el Worker n8n​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#crear-el-worker-n8n","content":" Bien, con esto podemos ver nuestro servicio web desplegándose. Ahora vamos a desplegar el worker n8n para ejecución distribuida. Para esto tenemos que ir a la sección workers dentro de la misma pantalla de workloads y hacer clic en el botón &quot;Create&quot;.    En la pantalla de creación de workers tendremos que completar los siguientes campos:  Configuración\tDescripciónProject\tSeleccionar el proyecto creado previamente. En nuestro caso &quot;n8n-server&quot;. Name\tDefinimos el nombre que le vamos a dar al worker. En nuestro caso &quot;n8n-worker&quot;. Command\tAquí establecemos el comando para ejecutar el worker n8n: worker  Con estos campos completados haremos clic en el botón &quot;Next&quot; en la parte inferior derecha y luego &quot;Submit&quot; ya que no necesitamos editar nada más:    Con esto veremos nuestro worker n8n desplegado.  ","version":"Next","tagName":"h3"},{"title":"Crear dependencias (redis y postgresql)​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#crear-dependencias-redis-y-postgresql","content":" Las dependencias son recursos necesarios para que tu aplicacion funcione, en el caso de n8n en modo queue, necesita una base de datos y un redis. Sleakops se nutre de los servicios que ofrece AWS para ofrecerte alternativas. Puedes ver mas informacion en documentación de dependencias  Vamos a la sección de dependencias:    ","version":"Next","tagName":"h2"},{"title":"Crear Dependencia Redis​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#crear-dependencia-redis","content":" Primero, necesitamos crear Redis para la cola de tareas. En la pantalla de creación de dependencias, seleccionamos Redis y tendremos los siguientes campos:  Configuración\tDescripciónDependency Type\tSeleccionar &quot;Redis&quot; de las opciones disponibles. Project\tSeleccionar el proyecto creado previamente. En nuestro caso &quot;n8n-server&quot;. Name\tDefinimos el nombre para Redis. En nuestro caso &quot;n8n-redis&quot;.    Con estos campos completados haremos clic en el botón &quot;Next&quot; en la parte inferior derecha y en el ultimo paso, antes de hacer &quot;Submit&quot;, vamos a cambiar los nombres de variables de entorno a como los espera n8n  Necesitamos configurar las variables de conexión Redis para que coincidan con lo que n8n espera:  Variable\tValorQUEUE_BULL_REDIS_HOST\t(Host de Redis de la dependencia) QUEUE_BULL_REDIS_PORT\t6379    Con esto le decimos a Sleakops con que nombre queremos que publique las variables generadas por la dependencia &quot;Redis&quot;  Asegúrate de que los nombres de las variables coincidan con lo que espera tu configuración n8n.  ","version":"Next","tagName":"h3"},{"title":"Crear Base de Datos PostgreSQL​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#crear-base-de-datos-postgresql","content":" Ahora procedemos a crear la base de datos PostgreSQL para almacenamiento de datos n8n:    Puedes variar entre &quot;produccion&quot; y &quot;no produccion&quot; esto te da valores de configuracion por defecto en el siguiente paso para cada entorno. Por ejemplo: para el entorno de produccion te deja activo el multi A-Z, backups automaticos etc. A modo de ejemplo en esta guia vamos a dejarlo en &quot;no produccion&quot;  Lo mismo que para redis,necesitamos configurar los nombres de las variables de entorno como lo espera n8n. Vamos hasta el ultimo paso y antes de apretar submit, cambiamos los nombres por los siguientes:  Antes\tDespués*_POSTGRESQL_NAME\tDB_POSTGRESDB_DATABASE *_POSTGRESQL_USERNAME\tDB_POSTGRESDB_USER *_POSTGRESQL_PASSWORD\tDB_POSTGRESDB_PASSWORD *_POSTGRESQL_ADDRESS\tDB_POSTGRESDB_HOST *_POSTGRESQL_PORT\tDB_POSTGRESDB_PORT  Debería verse algo como la imagen a continuación. Luego haz clic en el botón &quot;Submit&quot; y tu base de datos debería crearse:    ","version":"Next","tagName":"h3"},{"title":"Configurar Variables de Entorno n8n​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#configurar-variables-de-entorno-n8n","content":" Ahora necesitamos crear las variables de entorno que quedaron pendientes, podemos ver en el repositorio de codigo las variables que tenemos en .env.example. Hay variables que ya fuimos configurando en cada dependencia, pero otras quedan por definir. Para esto vamos a la seccion de &quot;Variablegroups&quot;    Vamos a crear un nuevo grupo de variables, ponemos en modo texto para copiar del .env.example las variables que faltan y ajustamos los valores acordes a nuestro caso.  En este formulario tenemos los siguientes campos:  Project: seleccionamos el proyecto que creamos previamente.Workload: Seleccionamos &quot;global&quot; que hace referencia a ser usado por todas nuestras cargas de trabajo.Name: Definimos un nombre para este grupo de variables.Type: Si queremos cargarlo por archivo o por variable.Vars: Aquí habilitamos el modo texto y copiamos las siguientes variables de entorno:  Variable\tDescripciónDB_TYPE\tEstablecer a &quot;postgresdb&quot; EXECUTIONS_MODE\tEstablecer a &quot;queue&quot; para modo worker N8N_ENCRYPTION_KEY\tGenerar una clave de encriptación segura OFFLOAD_MANUAL_EXECUTIONS_TO_WORKERS\tEstablecer a &quot;true&quot; N8N_HOST\tdefine el host que configuraste en tu webservice, para este ejemplo seria n8n.demo.sleakops.com N8N_WEBHOOK_URL\tEsta variable no es estrictamente necesaria para definirla, en caso de agregar una instancia de webservice aparte para atender los webhooks con otra url hay que especificar cual es la url que atienda los webooks.https://n8n.demo.sleakops.com/ N8N_EDITOR_BASE_URL\thttps://n8n.demo.sleakops.com  Si quieres ver todas las variables de entorno disponibles para configurar n8n puedes entrear a la siguiente pagina de documentación n8n    ","version":"Next","tagName":"h2"},{"title":"Despliegues​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#despliegues","content":" Como último paso vamos a ver nuestro proyecto desplegado, para esto vamos a la sección &quot;Deployments&quot; del panel izquierdo:    Aquí vamos a ver todos los despliegues que hacemos. En nuestro caso es el primero y podemos ver que se ha creado correctamente, en caso de que veas algún error si haces clic en &quot;error&quot; puedes ver una descripción del mismo. Si no vemos ningún error entonces significa que el proyecto ya está desplegado, podríamos comenzar a usarlo desde la url que nos proporcionó el servicio web.  Esto concluye nuestro proceso de despliegue del proyecto. Te dejamos un paso opcional que es configurar el ci con github.  ","version":"Next","tagName":"h2"},{"title":"Configuración de CI/CD (Opcional pero Recomendado)​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#configuración-de-cicd-opcional-pero-recomendado","content":" ","version":"Next","tagName":"h2"},{"title":"¿Por qué configurar CI/CD?​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#por-qué-configurar-cicd","content":" Sin CI/CD, cada cambio en tu código requiere:  Build manual desde SleakOpsDeploy manualVerificación manual  Con CI/CD configurado:  ✅ Push a main → Deploy automático✅ Rollback automático en caso de error✅ Notificaciones de estado de deploy  ","version":"Next","tagName":"h3"},{"title":"Pasos para configurar:​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#pasos-para-configurar","content":" Ve a tu proyecto en SleakOpsHaz clic en el ⚙️ (configuración)Selecciona &quot;Git pipelines&quot;Copia el YAML proporcionadoAñade SLEAKOPS_KEY a los secrets de GitHub      Esto necesita tener una variable de entorno SLEAKOPS_KEY, si no la tienes tienes que ir al enlace que aparece ahí Settings -&gt; CLI, obtenerla y guardarla como una variable de entorno.  Con esto configurado y desplegado cada vez que hagas un push a tu rama &quot;main&quot; se lanzará automáticamente una nueva versión de tu aplicación.  ","version":"Next","tagName":"h3"},{"title":"🎯 Próximos pasos​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#-próximos-pasos","content":" Una vez completada la instalación:  ","version":"Next","tagName":"h2"},{"title":"Configuración inicial de n8n​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#configuración-inicial-de-n8n","content":" Primer acceso: Usa la URL de tu webserviceCrear usuario administrador: n8n te pedirá crear el primer usuarioConfigurar webhooks: Si los necesitas, configura las URLs públicas  ","version":"Next","tagName":"h3"},{"title":"Monitoreo y optimización​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#monitoreo-y-optimización","content":" Revisar métricas: Usa el dashboard de Grafana integradoAjustar recursos: Modifica CPU/memoria según uso realConfigurar alertas: Define umbrales de rendimiento  ","version":"Next","tagName":"h3"},{"title":"Backup y seguridad​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#backup-y-seguridad","content":" Backups automáticos: Configura respaldos de PostgreSQLSecrets management: Revisa el manejo de credencialesActualizaciones: Planifica actualizaciones regulares  ","version":"Next","tagName":"h3"},{"title":"Actualizar y extender n8n​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#actualizar-y-extender-n8n","content":" Ya tenemos nuestro propio n8n instalado y corriendo en el cluster. Tenemos la definicion de nuestro n8n en un Dockerfile.  Para actualizar la version​  Este proceso es muy simple, vamos a modificar el Dockerfile y cambiamos el tag de la imagen . Podemos ver las imagenes disponibles en el repositorio oficial de n8n en dockerhub  Para tener en cuenta, leer el changelog por si hay algun breakingchanges o algo que rompa entre versiones. Hacer backups de la base de datos previamente por las dudas  Para agregar nuevas dependencias dentro de tus nodos​  Como hicimos para actualizar la version en este caso vamos a aprovecharnos de la facilidad de tener nuestro Dockerfile y podemos instalar lo que querramos aca adentro, esto quedara disponible para usarlo en nuestros nodos de n8n  Puedes ver ejemplos de esto en el README del repositorio.  ","version":"Next","tagName":"h2"},{"title":"Mejores Prácticas de Escalado (Bonus)​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#mejores-prácticas-de-escalado-bonus","content":" Una vez que tu despliegue n8n esté funcionando, considera estas estrategias de escalado:  ","version":"Next","tagName":"h2"},{"title":"🎯 Optimización de Workers​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#-optimización-de-workers","content":" Monitoreo de colas: Monitorea la profundidad de cola de Redis para determinar cuándo escalar workersAsignación de recursos: Asigna suficiente CPU y memoria basándote en la complejidad del flujo de trabajoAjuste de concurrencia: Ajusta la concurrencia del worker basándote en tipos de flujo de trabajo (intensivos en CPU vs I/O)Workers dedicados: Crea pools de workers especializados para diferentes categorías de flujos de trabajo  ","version":"Next","tagName":"h3"},{"title":"📈 Monitoreo de Rendimiento​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#-monitoreo-de-rendimiento","content":" Ajusta la memoria y cpu de tus workloads a lo que realmennte necesitan tus procesos. Esto es util para no tener infraestructura sobredimencionada y ademas para tomar decisiones a la hora de escalar horizontalmente en base a memoria o cpu  ¿Como lo hacemos desde Sleakops?​  Simple, vamos al detalle de tu worker o webservices que creamos anteriormente y tocamos en el icono de &quot;grafana&quot; . Esto nos abrira un dashboard dentro de grafana con el consumo historico de tu proceso, asegurate de mirar un rango largo de tiempo para cubrir todos tus casos    ","version":"Next","tagName":"h3"},{"title":"🔧 Optimización de Base de Datos​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#-optimización-de-base-de-datos","content":" Pooling de conexiones: Configura pools de conexión PostgreSQL para alta concurrencia.Réplicas de lectura: Usa réplicas de lectura para consultas de reportes y análisis. (Esto podes hacerlo desde sleakops desde la configuracion de Postgres)Indexación: Optimiza índices de base de datos para consultas de ejecución de flujos de trabajoEstrategias de respaldo: Implementa respaldos automatizados con recuperación point-in-time. (Esto podes hacerlo desde sleakops desde la configuracion de Postgres)  ","version":"Next","tagName":"h3"},{"title":"🚀 Configuraciones Avanzadas​","type":1,"pageTitle":"n8n + Modo Worker","url":"/preview-docs/es/docs/quickstart/n8n#-configuraciones-avanzadas","content":" Afinidad de nodos: Programa workers en tipos de nodos apropiados (CPU vs optimizados para memoria). (Esto podes hacerlo desde sleakops usando Nodepools)Presupuestos de disrupción de pods: Asegura disponibilidad mínima durante mantenimiento del clúster. (Esto ya lo cubre sleakops)Cuotas de recursos: Establece límites apropiados para prevenir agotamiento de recursos. (Esto podes hacerlo desde sleakops definiendo limites en tus Workloads y en tus Nodepools)Políticas de red: Asegura comunicación inter-pod. (Esto ya lo hace sleakops) ","version":"Next","tagName":"h3"},{"title":"El nuevo tuto Title","type":0,"sectionRef":"#","url":"/preview-docs/es/tutorial/el-nuevo-tuto-title","content":"El nuevo tuto Title El nuevo Body","keywords":"","version":"Next"},{"title":"Loki's Dashboard is not responding","type":0,"sectionRef":"#","url":"/preview-docs/es/tutorial/dashboard-loki-not-responding","content":"Loki's Dashboard is not responding QUICK SOLUTION Remove the 'loki-read' pod. After 60 seconds, it will start working again, along with the Loki DataSource and its related dashboards. info This error is more common in clusters with low availability because they generate more node and pod turnover. You can reduce the frequency of this error by increasing the number of loki-read pods in the Loki add-on settings. Loki may be running, as in the following image: If, due to some Kubernetes rotation, the loki-backend pod is reset WITHOUT the loki-read pod being reset, it starts to fail, such as when I force it by restarting the loki-backend StatefulSet, which leads to the following situation: It can be seen that the 'Age' of loki-backend is less than the 'Age' of loki-read. In these cases, this error occurs, causing the Loki DataSource to malfunction and, consequently, the dashboards that use it to stop working. The error arises because the 'loki-read' pods do not attempt to reconnect to 'loki-backend' and remain in this state where they do not respond to requests from 'loki-backend'. It can be seen that the error was successfully forced, and now the dashboard is unresponsive: The way to fix it is by restarting the 'loki-read' Deployment or by removing the running Pod. Once that is done, we return to the desired situation, which is as follows: As you can see, the Age of loki-read is now less than the Age of loki-backend, which confirms that loki-read is connected and the Dashboard is working correctly again, as shown in the following image: The frequency of this error can be reduced by increasing the number of active 'loki-read' pods. This can be done in the Loki Addon settings.","keywords":"","version":"Next"},{"title":"Configure AWS WAF","type":0,"sectionRef":"#","url":"/preview-docs/es/tutorial/config-aws-waf","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/es/tutorial/config-aws-waf#prerequisites","content":" An AWS account with access to WAF and Application Load BalancerAn Application Load Balancer already configured in your AWS accountBasic understanding of AWS console navigation  ","version":"Next","tagName":"h2"},{"title":"Estimated Cost​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/es/tutorial/config-aws-waf#estimated-cost","content":" The cost of AWS WAF depends on:  The number of active rulesThe number of requests processed by WAF  ","version":"Next","tagName":"h2"},{"title":"Cost Breakdown:​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/es/tutorial/config-aws-waf#cost-breakdown","content":" Component\tCostCost per rule\t$1 USD/month per rule Cost per WebACL\t$5 USD/month per WebACL Cost per request\t$0.60 USD per million requests  ","version":"Next","tagName":"h3"},{"title":"Example Cost Calculation:​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/es/tutorial/config-aws-waf#example-cost-calculation","content":" If you have 5 active rules and process 10 million requests per month, the cost would be:  WebACL: $5 USDRules: $5 USD (5 rules × $1 USD)Requests: $6 USD (10 million × $0.60 USD)  Approximate total cost: $16 USD/month    ","version":"Next","tagName":"h3"},{"title":"Step 1: Create a Web ACL​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/es/tutorial/config-aws-waf#step-1-create-a-web-acl","content":" Go to the AWS console and search for WAFClick on Create web ACLEnter the name of your Web ACL (for example, waf-alb-prod)Choose the region where your ALB is locatedSelect Regional if your ALB is in a specific region (usually the case), or CloudFront if you're using a CloudFront distributionIn the Associated AWS resources (optional) section, select your Application Load Balancer so all traffic passes through WAFClick Next  ","version":"Next","tagName":"h2"},{"title":"Step 2: Configure Basic Rules​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/es/tutorial/config-aws-waf#step-2-configure-basic-rules","content":" Click Add rules and rule groupsSelect AWS Managed Rules and choose some of the following rules as examples:  Rule\tDescriptionAWSManagedRulesCommonRuleSet\tFor basic protection against common web vulnerabilities AWSManagedRulesBotControl\tTo block known bots and automated traffic AWSManagedRulesAnonymousIPList\tTo block IP addresses associated with services that hide user identity (VPN, proxies, Tor) AWSManagedRulesAmazonIpReputationList\tTo block traffic from IPs known for malicious behavior AWSManagedRulesSQLiRuleSet\tTo protect against SQL injection attacks  These are just examples, as there are many other options depending on the nature of your application and the threats you want to mitigate. We recommend exploring all available options and selecting the rules that best fit your needs.    ","version":"Next","tagName":"h2"},{"title":"Verification​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/es/tutorial/config-aws-waf#verification","content":" Go back to the WAF service and select your Web ACLReview the metrics and statistics to verify that the rules are blocking unwanted trafficYou can create custom rules if you notice suspicious traffic    ","version":"Next","tagName":"h2"},{"title":"Updating Rules​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/es/tutorial/config-aws-waf#updating-rules","content":" If you need to add or modify rules:  Go to the AWS WAF consoleSelect your Web ACLClick Rules and Add rule or Edit ruleSave the changes and verify the traffic again    ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Configure AWS WAF","url":"/preview-docs/es/tutorial/config-aws-waf#conclusion","content":" AWS WAF is a powerful tool to protect your application against malicious or unwanted traffic. With this basic configuration, you can block common bots and ensure that only legitimate traffic reaches your ALB.  If you have more questions or need additional support, don't hesitate to ask for help! ","version":"Next","tagName":"h2"},{"title":"Django + Celery","type":0,"sectionRef":"#","url":"/preview-docs/es/tutorial/django-celery","content":"","keywords":"","version":"Next"},{"title":"Prerequisites​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#prerequisites","content":" Account in SleakopsA Cluster in this account. If you don't have it, here is the documentation on how to do it.An Environment configured. If you don't have it, here is the documentation on how to do itDjango project configured with celery (This project needs to have docker).  ","version":"Next","tagName":"h2"},{"title":"Let's Start​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#lets-start","content":" For this example, we are going to use this project . It is a Django project with Celery that already has Docker configured to run. We are also going to configure a Postgresql database, S3 bucket and Rabbitmq needed for this project.  ","version":"Next","tagName":"h2"},{"title":"Create a project​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#create-a-project","content":" To start, we are going to create a new project. To do this, click the &quot;Projects&quot; button in the left panel:    Inside the Projects panel you will be able to see all the projects you have and manage them from here. We want to create a new one so let's click on the “create” button at the top right:    In the project creation screen we have the following fields:  Setting\tDescriptionEnvironment\tWe have to select the previously created environment. Nodepool\tWe will leave the default one. Repositories\tWe will select our repository that we want to deploy. In our case example-django-celery. Project Name\tWe can define a project name. For the example we will leave the default. Branch\tIt has to coincide with the one we have in our project. In our case it is “Main”. Dockerfile path\tIt is the relative path to the dockerfile in your project.  Once configured all that we create the project with the “Submit” button at the bottom right:    With that, the project begins to be created. In the meantime we go to the workloads with the “Workloads” button in the left panel:    ","version":"Next","tagName":"h3"},{"title":"Create a Web Service​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#create-a-web-service","content":" Here what we are going to do is to create a web service so we go to the web service section and create one:    In this page we are going to complete the first form with the following fields:  Setting\tDescriptionProject\tWe select the project we created previously, in our case “example-django-celery”. Name\tWe define a name for the web service. Command\tBy default this will take the value that is in the dockerfile, in our case this is fine. Port\tThe same as the command.  Then we continue by clicking on the “Next” button up to step 3:    In step 3 we have to edit the path field and put the endpoint of healthcheck which in our case is “/healthcheck/”. Then click on the “Next” button until the web service is created:    ","version":"Next","tagName":"h3"},{"title":"Deploy celery worker​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#deploy-celery-worker","content":" Well, with this we can see our web service deploying. Now we are going to deploy the celery. For this we have to go to the workers section inside the same workloads screen:    And click on the “Create” button to create a new one:    In the workers creation screen we will have to complete the following fields:  Setting\tDescriptionProject\tSelect the previously created project. In our case “example-django-celery”. Name\tWe define the name that we are going to give to the worker. In our case “celery”. Command\tHere we set the command to run celery, in our case it is: bash celery -A core.celery_app worker -l INFO --concurrency 1 --max-tasks-per-child 1 --prefetch-multiplier 1 -n celery@%h --queues default,build,deployment,cluster,canvas,billing  With these fields filled in we will click on the “Next” button at the bottom right and then “Submit” as we do not need to edit anything else:    With this we will see our celery published. Now we have to configure the hooks. For this we go to the hooks section:    ","version":"Next","tagName":"h3"},{"title":"Create a migration hook​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#create-a-migration-hook","content":" In the hook creation screen we will have the following fields:  Setting\tDescriptionProject\tSelect the previously created project. In our case “example-django-celery”. Name\tWe define the name that we are going to give to the worker. In our case “migrations”. Command\tHere we set the command to run celery, in our case it is: bash python manage.py migrate --no-input   With these fields filled in we will click on the “Next” button at the bottom right and then “Submit” as we do not need to edit anything else:    ","version":"Next","tagName":"h3"},{"title":"Create a collect static hook​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#create-a-collect-static-hook","content":" Now we proceed to create another hook that we need for the statics:        In this form we are going to do the same as the previous one but modifying the command. We click next until we create the hook (without modifying anything else):    The command we use is as follows:  bash python manage.py collectstatic --no-input   ","version":"Next","tagName":"h3"},{"title":"Create a Postgresql Database​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#create-a-postgresql-database","content":" Once we have created the hooks we have to go to create our database. To do this we go to the “Dependencies” section:    Inside this section we click on the “Create” button at the top right and then select “Postgresql”:      In the 1st postgresql creation form we will have to select our previously created project and define a name for it, then click on the “Next” button at the bottom right:    In the 2nd form we are going to have a lot of fields, the only ones that matter to us are the following:  Setting\tDescriptionDatabase Master Username\tHere we assign a root user name to our database. Database Master Password\tA password for this root user.  With these fields filled in, we are ready to move on. Click on the “Next” button at the bottom right to proceed to the third form:    In this last form, we are going to adjust the environment variables we have in our project with respect to the database. To do this, we need to change the following variables to our own:  Before\tAfter*_POSTGRESQL_NAME\tDB_NAME *_POSTGRESQL_USERNAME\tDB_USER *_POSTGRESQL_PASSWORD\tDB_PASSWORD *_POSTGRESQL_ADDRESS\tDB_HOST *_POSTGRESQL_PORT\tDB_PORT  It should look something like the image below. Then click on the “Submit” button and your database should be created:    ","version":"Next","tagName":"h3"},{"title":"Create S3 Bucket​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#create-s3-bucket","content":" In the same page of dependencies we have to create our s3 bucket, for it we are going to go to the “Create” button again:    And select S3 Bucket:    In the first form we have to select our previously created project and define a name for the bucket, we have to take into account that the name of the bucket is global so it has to be unique. Now click on the “Next” button and go to step 3:    Here we are going to see some environment variables defined for the bucket. We are going to edit the one that says COLLECTSTATICEXAMPLEDJANGOCELERY_BUCKET_NAME and we are going to call it DJANGO_AWS_STORAGE_BUCKET_NAME. With this simple change we click on the “Submit” button at the bottom right to finish creating the bucket:    ","version":"Next","tagName":"h3"},{"title":"Create Rabbitmq​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#create-rabbitmq","content":" Now we need one more dependency. Our Rabbitmq to queue celery tasks, so let's get to it:    And select Rabbitmq:    In the first form we will have to select our project and define a name for it. Then click on the “Next” button at the bottom right:    In the following form we have several fields but the only ones that matter to us for this example are the username and password, we can define whatever we want. For this example I chose admin as username and for the password I generated it randomly with the dice button. Then we click on the “Next” button to go to the next form:    In this last form we have to change the name of the variable that ends in *_BROKER_AUTH_URL to CELERY_BROKER_URL (as shown in the image). Then we click on the “Submit” button at the bottom right to finish creating rabbitmq:    ","version":"Next","tagName":"h3"},{"title":"Create your environment variables​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#create-your-environment-variables","content":" Once the dependencies are deployed we have to configure our environment variables. We are going to go to the Vargroups section:    Here you will see all your environment variables that you created grouped in groups, for example you should have created one with the data for the database (which is the one you see in the image). Now we are going to create another one for our django environment variables, for this we click on the “Create” button at the top right:    In this form we have the following fields:  Project: we select the project we created previously.Workload: We select “global” that makes reference to be used by all our workloads.Name: We define a name for this group of variables.Type: If we want to load it by file or by variable.Vars: Here we enable the textmode and copy the following environment variables:  CELERY_RESULT_BACKEND=django-db DJANGO_ADMIN_URL=admin/ DJANGO_DEBUG=False DJANGO_SECRET_KEY=secret_key DJANGO_SETTINGS_MODULE=core.settings.production DJANGO_STATIC_STORAGE=storages.backends.s3boto3.S3StaticStorage DB_ENGINE=django.db.backends.postgresql_psycopg2 ENVIRONMENT=production LOGS_LEVEL=INFO PYTHONPATH=.   These environment variables are required for our example project. Finally click on the “Submit” button at the bottom right to create the variable group.    ","version":"Next","tagName":"h3"},{"title":"Deployments​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#deployments","content":" As last step we are going to see our project deployed, for this we go to the “Deployments” section of the left panel:    Here we are going to see all the deploys that we do. In our case it is the first one and we can see that it has been created correctly, in case you see any error if you click on “error” you can see a description of it. If we do not see any error then it means that the project is already deployed, we could begin to use it from the url that the web service provided us.    This concludes our project deployment process. We leave you an optional step which is to configure the ci with github.  ","version":"Next","tagName":"h3"},{"title":"Optional​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#optional","content":" ","version":"Next","tagName":"h2"},{"title":"CI with Github​","type":1,"pageTitle":"Django + Celery","url":"/preview-docs/es/tutorial/django-celery#ci-with-github","content":" Every time you make a change in your code and want to deploy it you will have to do a build and a deploy, this eventually becomes tedious. That's why to avoid this we have to implement ci on github.  For this we are going to go to “Projects” in the left panel:    Let's locate our project and click on the gear to access the project configuration:    In the project configuration we locate the one that says “Git pipelines” and click on it:    Here we are going to find what we need to do this. Basically we need to set up a file in the root of our project .github/workflows/ called ci_sleakops_demo.yml and in that file we are going to paste the content that appears in this page.    This needs to have an environment variable SLEAKOPS_KEY, if you don't have it you have to go to the link that appears there Settings -&gt; CLI, get it and save it as an environment variable.  With this configured and deployed every time you do a push to your “main” branch a new version of your application will be launched automatically. ","version":"Next","tagName":"h3"},{"title":"Getting Started","type":0,"sectionRef":"#","url":"/preview-docs/es/tutorial/getting-started","content":"","keywords":"","version":"Next"},{"title":"Sign in with your email​","type":1,"pageTitle":"Getting Started","url":"/preview-docs/es/tutorial/getting-started#sign-in-with-your-email","content":" Sign in to our web app.    info In case you do not have an account with us, you need to subscribe using AWS. Follow How to subscribe to SleakOps using AWS.  ","version":"Next","tagName":"h2"},{"title":"Requirements to Join​","type":1,"pageTitle":"Getting Started","url":"/preview-docs/es/tutorial/getting-started#requirements-to-join","content":" You need to have a root user on AWS. It is the initial account created with full permissions to manage all resources and services, serving as the primary account for AWS Organizations. Go to AWS Organizations.You need access to your code repositories (GitLab, Bitbucket or GitHub).You need your services in Docker files.You need to be able to manage your domains. ","version":"Next","tagName":"h3"},{"title":"Install KEDA","type":0,"sectionRef":"#","url":"/preview-docs/es/tutorial/install-keda","content":"","keywords":"","version":"Next"},{"title":"Installation Methods​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/es/tutorial/install-keda#installation-methods","content":" ","version":"Next","tagName":"h2"},{"title":"Using Lens Interface (option 1)​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/es/tutorial/install-keda#using-lens-interface-option-1","content":" In the Lens menu or the Kubernetes IDE you use, go to Helm &gt; Charts.In the search box, type keda. The official Bitnami chart should appear: bitnami/keda Select the version you want (for example, the most recent available).Click on Install and in the next window review the values (YAML) for installation if you want to customize something (by default, it is usually sufficient).Confirm the installation by pressing Install again.  ","version":"Next","tagName":"h3"},{"title":"Using Helm via Terminal (option 2)​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/es/tutorial/install-keda#using-helm-via-terminal-option-2","content":" If you prefer the command line or do not have the Helm section in Lens, you can install it like this:  helm repo add bitnami https://charts.bitnami.com/bitnami helm repo update # Create a namespace (optional) kubectl create namespace keda # Install KEDA helm install keda bitnami/keda --namespace keda   ","version":"Next","tagName":"h3"},{"title":"Installation Verification​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/es/tutorial/install-keda#installation-verification","content":" After installation, you should see that the KEDA resources have been created:  ","version":"Next","tagName":"h2"},{"title":"In Lens​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/es/tutorial/install-keda#in-lens","content":" Select the namespace where you installed KEDA (by default, keda if you created it manually).You will see a Deployment called keda-operator, one or more Pods, and other CRD (Custom Resource Definitions) type resources such as ScaledObjects and TriggerAuthentications.  ","version":"Next","tagName":"h3"},{"title":"Via Terminal (optional)​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/es/tutorial/install-keda#via-terminal-optional","content":" kubectl get all -n keda   You should see the operator running, for example:  NAME READY STATUS RESTARTS AGE pod/keda-operator-xxxxx-xxxxx 1/1 Running 0 1m   If everything is in order, you can now use KEDA for your first autoscaling based on events or custom metrics.  ","version":"Next","tagName":"h3"},{"title":"Define ScaledObject in KEDA​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/es/tutorial/install-keda#define-scaledobject-in-keda","content":" Now we will create a ScaledObject. This resource is what tells KEDA how and when to scale the deployment. In this example, we will use a CPU trigger, although KEDA handles it internally via HorizontalPodAutoscaler (HPA), but the logic integrates with the KEDA CRD.  You can review all possible triggers that KEDA offers in the official documentation here.  ","version":"Next","tagName":"h2"},{"title":"Creating the ScaledObject​","type":1,"pageTitle":"Install KEDA","url":"/preview-docs/es/tutorial/install-keda#creating-the-scaledobject","content":" To create this object we will use the extend-charts function in Sleakops. To get there from the project list in Sleakops, go to Settings &gt; Chart Configuration.      Once you are on the Chart Configuration screen, you can add your ScaledObjects.  To complete the ScaledObject values, you will need some values such as the namespace and the deployment object name (generated by Sleakops) in the cluster.  For the namespace, you could use the following annotation, as in the following example: {{ .Values.global.namespace }} to extract it from the values that Sleakops already generatesFor the deployment name, we do not currently provide it. To get it, you can enter Lens or your Kubernetes IDE and go to the Workloads &gt; Deployments section  apiVersion: keda.sh/v1alpha1 kind: ScaledObject metadata: name: http-echo-scaledobject namespace: { { .Values.global.namespace } } spec: scaleTargetRef: # Must match the Deployment name name: http-echo-deployment # minReplicaCount and maxReplicaCount determine scaling limits minReplicaCount: 1 maxReplicaCount: 5 # Trigger that defines the scaling condition (in this case CPU) triggers: - type: cpu metadata: type: Utilization # or AverageValue value: &quot;50&quot; # scales above 50% CPU  ","version":"Next","tagName":"h3"},{"title":"Make RDS Database Public","type":0,"sectionRef":"#","url":"/preview-docs/es/tutorial/make-rds-public","content":"","keywords":"","version":"Next"},{"title":"Introduction and Current Case​","type":1,"pageTitle":"Make RDS Database Public","url":"/preview-docs/es/tutorial/make-rds-public#introduction-and-current-case","content":" Currently, all databases deployed with SleakOps have the same access configuration:  Publicly Accessible ❌Allocated in a SubnetGroup composed of &quot;Persistence&quot; subnets created in the SleakOps VPC.  Under this configuration, there is no direct way to make the database publicly accessible, so a small workaround must be performed.  Why can't a database be made public directly?  A SubnetGroup of RDS cannot be edited.AWS does not allow editing the SubnetGroup associated with an RDS without a VPC change. Therefore, it forces us to do it using an external VPC.    ","version":"Next","tagName":"h2"},{"title":"Solution with Workaround​","type":1,"pageTitle":"Make RDS Database Public","url":"/preview-docs/es/tutorial/make-rds-public#solution-with-workaround","content":" ","version":"Next","tagName":"h2"},{"title":"Prerequisites:​","type":1,"pageTitle":"Make RDS Database Public","url":"/preview-docs/es/tutorial/make-rds-public#prerequisites","content":" Approximately 30 minutes. Have the default VPC created with Subnets where the DB will be located. If you don't have it, you'll need to create a new one from scratch on your own, as well as subnets within it that will be used for this change. Let's call it &quot;transitory&quot;. Create the SubnetGroup that uses Subnets from the transitory VPC. It doesn't matter which subnets it uses. It is used to migrate to the other VPC. In my case, I created the following. Note that both the VPC and the Subnets are from the Default VPC. Create the SubnetGroup that uses the Public Subnets from the VPC deployed by SleakOps. This is the one the DB will use at the end of the flow. Create a SecurityGroup that allows public access, or edit the existing one. In both cases, it must belong to the VPC where the Database is located. In my case, I created the following.  ","version":"Next","tagName":"h3"},{"title":"Step by Step:​","type":1,"pageTitle":"Make RDS Database Public","url":"/preview-docs/es/tutorial/make-rds-public#step-by-step","content":" With the prerequisites completed, only perform the modifications to the configurations.  Change the SubnetGroup to the one corresponding to the Transitory VPC and remove the current SG. Click next and review the changes. Make sure to select 'Apply Immediately'. Once this is done, you must wait for the change to be applied before continuing with the following steps where we return to the initial VPC, which is the one created by SleakOps. After the VPC change is completed. Change the SubnetGroup to the public one that was created, which is composed of the Public Subnets from the SleakOps VPC. Again, remove the default SG that is automatically linked. Make the DB Publicly Accessible. Review the changes. They should be as follows. Click next and Apply Immediately. Wait again for the change to complete for the last step: Add the SecurityGroup created in the prerequisites. Review the change. Click next and Apply Immediately again.    ","version":"Next","tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Make RDS Database Public","url":"/preview-docs/es/tutorial/make-rds-public#conclusion","content":" With this, our DB is completely public for all requests on the port used by the DB. For PostgreSQL, this is port 5432. ","version":"Next","tagName":"h2"},{"title":"S3 Batch","type":0,"sectionRef":"#","url":"/preview-docs/es/tutorial/s3-batch","content":"","keywords":"","version":"Next"},{"title":"1. Enable and configure an inventory or manifest (list of objects)​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#1-enable-and-configure-an-inventory-or-manifest-list-of-objects","content":" ","version":"Next","tagName":"h2"},{"title":"Create an S3 Inventory (optional, but recommended)​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#create-an-s3-inventory-optional-but-recommended","content":" In the Amazon S3 console, select the source bucket.In the &quot;Management&quot; (or &quot;Administration&quot;) section, create an S3 Inventory that generates a periodic report (CSV or Parquet) of all objects.Verify that the inventory includes &quot;Object version&quot; information (if applicable) and &quot;ETag&quot;.  ","version":"Next","tagName":"h3"},{"title":"Or use a custom manifest (custom CSV)​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#or-use-a-custom-manifest-custom-csv","content":" Alternatively, you can create your own CSV file with the following structure on each line:  s3://SOURCE_BUCKET_NAME/object1.txt s3://SOURCE_BUCKET_NAME/object2.txt ...   Upload this CSV file (manifest) to an S3 bucket that you have access to.  Note This inventory or CSV is the &quot;manifest&quot; that S3 Batch will use to know which objects to copy.  ","version":"Next","tagName":"h3"},{"title":"2. Configure permissions and roles in source and destination accounts​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#2-configure-permissions-and-roles-in-source-and-destination-accounts","content":" ","version":"Next","tagName":"h2"},{"title":"S3 Batch Execution Role​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#s3-batch-execution-role","content":" In the source account, create an IAM Role that allows S3 Batch Operations (service batchoperations.s3.amazonaws.com) to read the source bucket and write to the destination bucket at the same time.Make sure the policy includes the s3:GetObject action for the source bucket and s3:PutObject for the destination bucket.  ","version":"Next","tagName":"h3"},{"title":"Policy on the destination bucket (cross-account)​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#policy-on-the-destination-bucket-cross-account","content":" If the destination bucket is in another account, add a bucket policy that allows the s3:PutObject action for the ARN of the IAM role from the previous step.  ","version":"Next","tagName":"h3"},{"title":"3. Create the S3 Batch Operations Job​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#3-create-the-s3-batch-operations-job","content":" ","version":"Next","tagName":"h2"},{"title":"Basic Job Configuration​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#basic-job-configuration","content":" Enter the S3 console and select Batch Operations in the side menu.Create a new Job with the following basic configuration: Manifest: Indicate where the inventory or CSV (manifest) containing the list of objects is located.Operation: Select Copy.Destination Bucket: Choose the destination bucket (in the other account).IAM Role: Select the role created for this purpose (step 2.1).  ","version":"Next","tagName":"h3"},{"title":"Additional options (optional)​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#additional-options-optional","content":" Storage Class: Select the storage class you want for the destination bucket (Standard, IA, etc.).Object Tags: If you want to replicate or modify tags in the process.Retention/Legal Hold: If compliance applies.  ","version":"Next","tagName":"h3"},{"title":"Review and create Job​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#review-and-create-job","content":" Verify that the settings are correct and launch the Job.  ","version":"Next","tagName":"h3"},{"title":"4. Monitor the process​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#4-monitor-the-process","content":" In the S3 Batch Operations console, locate your Job and review the status.Depending on the volume of objects, copying can take from minutes to several hours/days (for millions of files).Review progress reports and possible errors (for example, objects with access denied).  ","version":"Next","tagName":"h2"},{"title":"5. Validate the transfer​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#5-validate-the-transfer","content":" Object count: Verify that the total number of files in the destination bucket matches what is expected.Error logs: Check error output or review CloudTrail/S3 Logs for objects that were not copied correctly.Re-run for failed objects: You can generate a new manifest with only the failed objects and launch another Job.  ","version":"Next","tagName":"h2"},{"title":"Summary of key points​","type":1,"pageTitle":"S3 Batch","url":"/preview-docs/es/tutorial/s3-batch#summary-of-key-points","content":" Manifest: Properly prepare the inventory or list of objects.Permissions: Ensure you have an IAM role with policies that allow GetObject in source and PutObject in destination (cross-account).Batch Job: Configure the &quot;Copy&quot; operation with the correct role.Monitoring: Review S3 Batch logs and reports, and retry failed objects if necessary. ","version":"Next","tagName":"h2"},{"title":"n8n + Worker Mode","type":0,"sectionRef":"#","url":"/preview-docs/es/tutorial/n8n-worker","content":"","keywords":"","version":"Next"},{"title":"Why Self-Hosted n8n?​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#why-self-hosted-n8n","content":" Self-hosting n8n provides numerous advantages over cloud-hosted solutions:  ","version":"Next","tagName":"h2"},{"title":"🔒 Security and Privacy​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#-security-and-privacy","content":" Complete Data Control: Your workflows, credentials, and sensitive data never leave your infrastructure.Customized Security Policies: Implement your organization's specific security requirements.Network Isolation: Keep n8n within your private network, reducing external attack vectors.Compliance: Meet strict regulatory requirements (GDPR, HIPAA, SOC2) with on-premises deployment.  ","version":"Next","tagName":"h3"},{"title":"💰 Cost Optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#-cost-optimization","content":" No limits per run: Run unlimited workflows without usage-based pricingPredictable costs: Fixed infrastructure costs regardless of usage volumeResource efficiency: Scale resources based on actual needs, not vendor pricing tiersLong-term savings: Significant cost reductions for high-volume automation scenarios  ","version":"Next","tagName":"h3"},{"title":"⚡ Performance and Scalability​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#-performance-and-scalability","content":" Custom Resource Allocation: Allocate CPU and memory based on your specific workload requirementsLow Latency: Direct access to internal systems without internet roundtripsHigh Availability: Design redundant systems with multiple replicas and failover mechanismsCustom Integrations: Connect to internal APIs and systems not accessible from cloud providers  ","version":"Next","tagName":"h3"},{"title":"🎛️ Total Control and Customization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#️-total-control-and-customization","content":" Version Control: Choose when to update and test new versions in your environmentCustom Nodes: Install and develop proprietary nodes for your specific use casesEnvironment Variables: Full access to system-level configurations and secret managementBackup Strategies: Implement your own backup and disaster recovery procedures  ","version":"Next","tagName":"h3"},{"title":"Benefits of Scaling in Kubernetes​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#benefits-of-scaling-in-kubernetes","content":" Deploying n8n on a Kubernetes cluster with Sleakops provides enterprise-level scalability:  ","version":"Next","tagName":"h2"},{"title":"🚀 Horizontal Scaling​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#-horizontal-scaling","content":" Worker Pods: Automatically scale worker instances based on queue depth and CPU usageLoad Distribution: Distribute workflow execution across multiple worker nodesAuto-Scaling: Kubernetes HPA (Horizontal Pod Autoscaler) automatically adjusts worker countResource Optimization: Scale different components independently (web UI vs. workers)  ","version":"Next","tagName":"h3"},{"title":"🏗️ Infrastructure Resilience​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#️-infrastructure-resilience","content":" High Availability: Multiple replicas ensure zero downtime during node failuresContinuous Upgrades: Deploy new versions without service interruptionHealth Checks: Kubernetes automatically restarts failed pods and routes traffic to healthy instancesMulti-Zone Deployment: Distribute workload across availability zones for disaster recovery  ","version":"Next","tagName":"h3"},{"title":"📊 Monitoring and Observability​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#-monitoring-and-observability","content":" Real-time metrics: Monitor workflow execution, queue depth, and resource usageCentralized logging: Aggregate logs from all n8n components in one placePerformance insights: Track execution times, error rates, and throughputAlerts: Proactive notifications for system issues and performance bottlenecks  ","version":"Next","tagName":"h3"},{"title":"🔧 DevOps Integration​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#-devops-integration","content":" GitOps Workflows: Version control of your n8n infrastructure as codeCI/CD Pipelines: Automated testing and deployment of n8n configurationsSecret Management: Integrates with Kubernetes secrets and external secret managersNetwork Policies: Fine-grained network security controls  ","version":"Next","tagName":"h3"},{"title":"Prerequisite​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#prerequisite","content":" A Sleakops accountA cluster in this account. If you don't have one, here's the documentation on how to create one.A configured environment. If you don't have one, here's the documentation on how to create one.An n8n project configured with Docker. If you don't have it, you can fork or copy n8n-code. This project includes a Docker Compose package so you can also deploy it locally, allowing you to have distributed environments as you wish.  Let's begin  For this example, we'll deploy an n8n project in distributed mode with worker processes. This configuration includes the main n8n service (web interface) and worker processes to execute workflows. We'll also configure a PostgreSQL database and Redis for queue management, which are necessary for this project.  ","version":"Next","tagName":"h2"},{"title":"Create Project​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#create-project","content":" Projects are our code repositories. All Sleakops needs to run commands is a Dockerfile.  For more information, see our project documentation.  To begin, we will create a new project:  Click the &quot;Projects&quot; button in the left panel.Then click &quot;Create&quot; in the upper right corner.    Within the Projects panel, you can see all your projects and manage them from here. We want to create a new one, so let's click the &quot;create&quot; button in the upper right corner.  On the project creation screen, we have the following fields:  Configuration\tDescriptionEnvironment\tWe need to select the previously created environment. Nodepool\tWe'll leave the default. Repositories\tWe'll select our repository that contains the n8n project. Project Name\tWe can define a project name. For example, &quot;n8n-server&quot;. Branch\tIt must match the branch in our project. In our case, it's &quot;main&quot;. Dockerfile path\tThis is the relative path to the Dockerfile in your project.  Once all that is configured, we create the project using the &quot;Submit&quot; button in the bottom right corner:    With that, the project begins to be created. In the meantime, let's go to the workloads using the &quot;Workloads&quot; button in the left panel:    ","version":"Next","tagName":"h2"},{"title":"Create Workloads​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#create-workloads","content":" Workloads are the processes that your project runs. In the case of n8n, which we'll run in queue mode, we'll create a web service for the web interface and a worker. For more information, see our workloads documentation  ","version":"Next","tagName":"h2"},{"title":"Create the Web Service​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#create-the-web-service","content":" Here we will create the main n8n web service that will handle the user interface and API:  On this page, we will complete the first form with the following fields:  Configuration\tDescriptionProject\tSelect the project we created previously, in our case &quot;n8n-server&quot;. Name\tDefine a name for the web service, for example &quot;n8n-main&quot;. Command\tDefault command from the Dockerfile (usually n8n start). Port\tPort 5678 (n8n's default port).    In the second step, we'll configure the web service as private:  What does this mean?  The n8n service will be inside the VPCIt will only be accessible from services on the same networkIt requires a VPN for external access  Alternative for public webhooks:If you need to connect to public webhooks (Jira, Slack, Google Drive, etc.), you can:  Leave this service as public, ORCreate an additional public web service using the webhook command    Continue to step 3, &quot;Service settings,&quot; and configure the health check.  To do this, simply define the path for the health check, which comes with n8n /healthz, and click &quot;Next&quot; until the flow is complete and the web service is created.    This health check is important so Kubernetes knows when the service is ready to start delivering HTTP traffic. This is useful for avoiding downtime between deployments or node rotations.  We won't modify the last step of the form, where we define memory, CPU, and scaling conditions, for now; we'll leave it as the platform provides.  ","version":"Next","tagName":"h3"},{"title":"Creating the n8n Worker​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#creating-the-n8n-worker","content":" Great, with this we can see our web service being deployed. Now let's deploy the n8n worker for distributed execution. To do this, we need to go to the Workers section within the same Workloads screen and click the &quot;Create&quot; button.    On the worker creation screen, we will need to complete the following fields:  Configuration\tDescriptionProject\tSelect the previously created project. In our case, &quot;n8n-server&quot;. Name\tDefine the name we will give to the worker. In our case, &quot;n8n-worker&quot;. Command\tHere we set the command to run the n8n worker: worker  With these fields completed, we will click the &quot;Next&quot; button in the lower right corner and then &quot;Submit,&quot; as we do not need to edit anything else.    This will show our n8n worker deployed.  ","version":"Next","tagName":"h3"},{"title":"Create dependencies (Redis and PostgreSQL)​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#create-dependencies-redis-and-postgresql","content":" Dependencies are resources necessary for your application to function. In the case of n8n in queue mode, it needs a database and Redis. Sleakops leverages AWS services to provide you with alternatives. You can find more information in the dependencies documentation (/project/dependency).  Let's go to the dependencies section:    ","version":"Next","tagName":"h2"},{"title":"Creating a Redis Dependency​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#creating-a-redis-dependency","content":" First, we need to create a Redis dependency for the task queue. On the dependency creation screen, select Redis, and you will see the following fields:  Configuration\tDescriptionDependency Type\tSelect &quot;Redis&quot; from the available options. Project\tSelect the previously created project. In our case, &quot;n8n-server&quot;. Name\tDefine the name for Redis. In our case, &quot;n8n-redis&quot;.    With these fields completed, we'll click the &quot;Next&quot; button in the bottom right corner. In the last step, before clicking &quot;Submit,&quot; we'll change the environment variable names to match what n8n expects.  We need to configure the Redis connection variables to match what n8n expects:  Variable\tValueQUEUE_BULL_REDIS_HOST\t(Redis Host of the dependency) QUEUE_BULL_REDIS_PORT\t6379    This tells Sleakops what name we want it to use to publish the variables generated by the &quot;Redis&quot; dependency.  Make sure the variable names match what your n8n configuration expects.  ","version":"Next","tagName":"h3"},{"title":"Create PostgreSQL Database​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#create-postgresql-database","content":" Now we proceed to create the PostgreSQL database for n8n data storage:    You can switch between &quot;production&quot; and &quot;non-production&quot; environments. This gives you default configuration values ​​in the next step for each environment. For example, in a production environment, it enables multi-A-Z, automatic backups, etc. As an example in this guide, we'll leave it as &quot;non-production.&quot;  Just like with Redis, we need to configure the environment variable names as n8n expects. Go to the last step and before clicking submit, change the names to the following:  Before\tAfter*_POSTGRESQL_NAME\tDB_POSTGRESDB_DATABASE *_POSTGRESQL_USERNAME\tDB_POSTGRESDB_USER *_POSTGRESQL_PASSWORD\tDB_POSTGRESDB_PASSWORD *_POSTGRESQL_ADDRESS\tDB_POSTGRESDB_HOST *_POSTGRESQL_PORT\tDB_POSTGRESDB_PORT  It should look something like the image below. Then click the &quot;Submit&quot; button and your database should be created:    ","version":"Next","tagName":"h3"},{"title":"Configuring Environment Variables​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#configuring-environment-variables","content":" Now we need to create the remaining environment variables. We can see the variables we have in .env.example in the code repository. Some variables have already been configured in each dependency, but others still need to be defined. To do this, we go to the &quot;Variablegroups&quot; section.    We're going to create a new variable group. We'll switch to text mode to copy the missing variables from the .env.example file and adjust the values ​​accordingly.  This form has the following fields:  Project: Select the project we created earlier. Workload: Select &quot;global,&quot; which means it will be used by all our workloads. Name: Define a name for this variable group. Type: Choose whether to load it by file or by variable. Vars: Here, enable text mode and copy the following environment variables:  Variable\tDescriptionDB_TYPE\tSet to &quot;postgresdb&quot; EXECUTIONS_MODE\tSet to &quot;queue&quot; for worker mode N8N_ENCRYPTION_KEY\tGenerate a secure encryption key OFFLOAD_MANUAL_EXECUTIONS_TO_WORKERS\tSet to &quot;true&quot; N8N_HOST\tDefine the host you configured in your web service; for this example, it would be n8n.demo.sleakops.com N8N_WEBHOOK_URL\tThis variable is not strictly necessary to define; if you add a separate web service instance to handle webhooks with a different URL, you must specify which URL will handle the webhooks. https://n8n.demo.sleakops.com/ N8N_EDITOR_BASE_URL\thttps://n8n.demo.sleakops.com  If you want to see all the environment variables available to configure n8n, you can go to the following page of n8n documentation    ","version":"Next","tagName":"h2"},{"title":"Deployments​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#deployments","content":" As a final step, let's view our deployed project. To do this, go to the &quot;Deployments&quot; section in the left panel:    Here we'll see all the deployments we perform. In our case, it's the first one, and we can see that it was created successfully. If you see any errors, clicking on &quot;error&quot; will show you a description.  If we don't see any errors, then the project is already deployed, and we can start using it from the URL provided by the web service.  This concludes our project deployment process. We've included an optional step: configuring CI/CD with GitHub.  ","version":"Next","tagName":"h2"},{"title":"CI/CD Configuration (Optional but Recommended)​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#cicd-configuration-optional-but-recommended","content":" ","version":"Next","tagName":"h2"},{"title":"Why Configure CI/CD?​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#why-configure-cicd","content":" Without CI/CD, every change to your code requires:  Manual build from SleakOpsManual deploymentManual verification  With CI/CD configured:  ✅ Push to main → Automatic deployment✅ Automatic rollback in case of error✅ Deployment status notifications  ","version":"Next","tagName":"h3"},{"title":"Setup steps:​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#setup-steps","content":" Go to your project in SleakOpsClick the ⚙️ (settings)Select &quot;Git pipelines&quot;Copy the provided YAML fileAdd SLEAKOPS_KEY to your GitHub secrets      This requires an environment variable called SLEAKOPS_KEY. If you don't have it, go to the link provided in Settings -&gt; CLI, retrieve it, and save it as an environment variable.  With this configured and deployed, every time you push to your &quot;main&quot; branch, a new version of your application will be automatically released.  ","version":"Next","tagName":"h3"},{"title":"🎯 Next Steps​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#-next-steps","content":" Once the installation is complete:  ","version":"Next","tagName":"h2"},{"title":"Initial n8n Configuration​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#initial-n8n-configuration","content":" First Access: Use your web service URLCreate Administrator User: n8n will prompt you to create the first userConfigure Webhooks: If needed, configure the public URLs  ","version":"Next","tagName":"h3"},{"title":"Monitoring and Optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#monitoring-and-optimization","content":" Review Metrics: Use the integrated Grafana dashboardAdjust Resources: Modify CPU/memory based on actual usageConfigure Alerts: Define performance thresholds  ","version":"Next","tagName":"h3"},{"title":"Backup and Security​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#backup-and-security","content":" Automatic Backups: Configure PostgreSQL backupsSecrets Management: Review credential managementUpdates: Schedule regular updates  ","version":"Next","tagName":"h3"},{"title":"Updating and Extending n8n​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#updating-and-extending-n8n","content":" We now have our own n8n installed and running on the cluster. We have our n8n definition in a Dockerfile.  To update the version​  This process is very simple. We'll modify the Dockerfile and change the image tag. You can see the available images in the official n8n repository on Docker Hub.  Note: Read the changelog in case there are any breaking changes or anything that might break between versions. Make backups of the database beforehand, just in case.  To add new dependencies to your nodes​  As we did to update the version, in this case we'll take advantage of having our Dockerfile and install whatever we want inside it. This will be available for use on our n8n nodes.  You can see examples of this in the repository's README.  ","version":"Next","tagName":"h2"},{"title":"Scaling Best Practices (Bonus)​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#scaling-best-practices-bonus","content":" Once your n8n deployment is up and running, consider these scaling strategies:  ","version":"Next","tagName":"h2"},{"title":"🎯 Worker Optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#-worker-optimization","content":" Queue Monitoring: Monitor the Redis queue depth to determine when to scale workers.Resource Allocation: Allocate sufficient CPU and memory based on workflow complexity.Concurrency Tuning: Tune worker concurrency based on workflow types (CPU-intensive vs. I/O-intensive).Dedicated Workers: Create pools of specialized workers for different workflow categories.  ","version":"Next","tagName":"h3"},{"title":"📈 Performance Monitoring​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#-performance-monitoring","content":" Adjust the memory and CPU of your workloads to what your processes actually need.  This is useful for avoiding oversized infrastructure and also for making decisions when scaling horizontally based on memory or CPU.  How do we do it from Sleakops?​  Simple, go to the details of your worker or web service that we created earlier and click on the &quot;Grafana&quot; icon. This will open a dashboard within Grafana showing the historical consumption of your process. Be sure to look at a long time range to cover all your scenarios.    ","version":"Next","tagName":"h3"},{"title":"🔧 Database Optimization​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#-database-optimization","content":" Connection Pooling: Configure PostgreSQL connection pools for high concurrency. Read Replicas: Use read replicas for reporting and analytics queries. (This can be done from Sleakops in the Postgres configuration.) Indexing: Optimize database indexes for workflow execution queries. Backup Strategies: Implement automated backups with point-in-time recovery. (This can be done from Sleakops in the Postgres configuration.)  ","version":"Next","tagName":"h3"},{"title":"🚀 Advanced Configurations​","type":1,"pageTitle":"n8n + Worker Mode","url":"/preview-docs/es/tutorial/n8n-worker#-advanced-configurations","content":" Node Affinity: Schedule workers on appropriate node types (CPU vs. memory-optimized). (You can do this from Sleakops using Nodepools)Pod Disruption Budgets: Ensures minimum availability during cluster maintenance. (Sleakops already handles this)Resource Quotas: Sets appropriate limits to prevent resource exhaustion. (You can do this from Sleakops by defining limits on your Workloads and Nodepools)Network Policies: Ensures inter-pod communication. (Sleakops already handles this) ","version":"Next","tagName":"h3"},{"title":"S3 Replication","type":0,"sectionRef":"#","url":"/preview-docs/es/tutorial/s3-replication","content":"","keywords":"","version":"Next"},{"title":"1. Create IAM Role in the account where the source bucket is located​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/es/tutorial/s3-replication#1-create-iam-role-in-the-account-where-the-source-bucket-is-located","content":" ","version":"Next","tagName":"h2"},{"title":"Trust Policy​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/es/tutorial/s3-replication#trust-policy","content":" You need a trust policy that allows the S3 service to assume the role:  { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: { &quot;Service&quot;: &quot;s3.amazonaws.com&quot; }, &quot;Action&quot;: &quot;sts:AssumeRole&quot; } ] }   ","version":"Next","tagName":"h3"},{"title":"Permissions Policy​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/es/tutorial/s3-replication#permissions-policy","content":" A permissions policy that allows:  Read objects and metadata from the source bucket (Account A).Put objects in the destination bucket (Account B).  { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;ReadSourceBucket&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:GetObject&quot;, &quot;s3:GetObjectAcl&quot;, &quot;s3:GetObjectVersion&quot;, &quot;s3:GetObjectVersionAcl&quot; ], &quot;Resource&quot;: &quot;arn:aws:s3:::&lt;SOURCE_BUCKET_NAME&gt;/*&quot; }, { &quot;Sid&quot;: &quot;WriteDestBucket&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;s3:PutObject&quot;, &quot;s3:PutObjectAcl&quot;, &quot;s3:ReplicateObject&quot;, &quot;s3:ReplicateDelete&quot;, &quot;s3:ReplicateTags&quot;, &quot;s3:GetObjectVersionTagging&quot;, &quot;s3:PutObjectVersionTagging&quot; ], &quot;Resource&quot;: &quot;arn:aws:s3:::&lt;DESTINATION_BUCKET_NAME&gt;/*&quot; } ] }   ","version":"Next","tagName":"h3"},{"title":"2. Add policy to the destination bucket​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/es/tutorial/s3-replication#2-add-policy-to-the-destination-bucket","content":" In the destination bucket details, go to the permissions tab and add the following policy:  { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;AllowReplicationFromAccountA&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Principal&quot;: { &quot;AWS&quot;: &quot;arn:aws:iam::&lt;ACCOUNT_A_ID&gt;:role/&lt;ROLE_NAME&gt;&quot; }, &quot;Action&quot;: [ &quot;s3:PutObject&quot;, &quot;s3:PutObjectAcl&quot;, &quot;s3:ReplicateObject&quot;, &quot;s3:ReplicateDelete&quot;, &quot;s3:ReplicateTags&quot; ], &quot;Resource&quot;: [&quot;arn:aws:s3:::&lt;DESTINATION_BUCKET_NAME&gt;/*&quot;] } ] }   ","version":"Next","tagName":"h2"},{"title":"3. Configure the replication rule in the source bucket​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/es/tutorial/s3-replication#3-configure-the-replication-rule-in-the-source-bucket","content":" In the source bucket details, go to the &quot;Management&quot; (or &quot;Properties&quot; depending on console version) tab and look for the Replication section.Create a new replication rule and define: Rule name: A descriptive name.Status: Enabled.Source bucket: The current bucket (already selected).Prefix/Filter: You can choose to replicate the entire bucket or only a specific prefix.Destination: Bucket: specify the ARN of the destination bucket in Account B. IAM role: choose the role you created in the first step, which allows replication.  ","version":"Next","tagName":"h2"},{"title":"Optional​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/es/tutorial/s3-replication#optional","content":" If the &quot;Transfer to destination bucket owner&quot; option is activated, the action must be added to both AllowReplicationFromAccountA (destination bucket policy) and WriteDestBucket (IAM role):&quot;s3:ObjectOwnerOverrideToBucketOwner&quot;  ","version":"Next","tagName":"h2"},{"title":"Ways to copy existing files​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/es/tutorial/s3-replication#ways-to-copy-existing-files","content":" There are 3 different ways to copy existing files from the bucket:  ","version":"Next","tagName":"h2"},{"title":"1. Do it along with replication​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/es/tutorial/s3-replication#1-do-it-along-with-replication","content":" When activating replication, it gives you an option to copy all existing files.  ","version":"Next","tagName":"h3"},{"title":"2. Use the S3 migration option provided by Sleakops​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/es/tutorial/s3-replication#2-use-the-s3-migration-option-provided-by-sleakops","content":" In the detail of the S3 type dependency, you can find this function that guides you step by step on what needs to be done.    ","version":"Next","tagName":"h3"},{"title":"3. Use the Batch Operation service​","type":1,"pageTitle":"S3 Replication","url":"/preview-docs/es/tutorial/s3-replication#3-use-the-batch-operation-service","content":" Once the replication rule is created, following these guides:   Batch Operations IAM role policies Replication metrics and events  Add to the S3ReplicationRolePolicy the following actions:  &quot;s3:PutObjectTagging&quot; to &quot;Sid&quot;: &quot;WriteDestBucket&quot;&quot;s3:GetObjectTagging&quot; and &quot;s3:ListBucket&quot; to &quot;Sid&quot;: &quot;ReadSourceBucket&quot;  { &quot;Sid&quot;: &quot;ReadReportBucket&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [&quot;s3:GetObject&quot;, &quot;s3:GetObjectVersion&quot;], &quot;Resource&quot;: [&quot;arn:aws:s3:::bucket-reports/*&quot;] }   And add the &quot;s3:InitiateReplication&quot; permission to both WriteDestBucket and SourceBucket. ","version":"Next","tagName":"h3"},{"title":"Third Party VPN Integration","type":0,"sectionRef":"#","url":"/preview-docs/es/tutorial/third-party-integration-vpn","content":"","keywords":"","version":"Next"},{"title":"Transit Gateway (~$197/month in the described scenario)​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/es/tutorial/third-party-integration-vpn#transit-gateway-197month-in-the-described-scenario","content":" Higher fixed cost per attachment.Excellent option for larger topologies, multiple VPCs and scalability with minimal routing complexity.  ","version":"Next","tagName":"h3"},{"title":"Site-to-Site VPN + EC2 (~$80/month estimated)​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/es/tutorial/third-party-integration-vpn#site-to-site-vpn--ec2-80month-estimated","content":" Easy configuration (native AWS solution).Suitable for a moderate number of tunnels, although less flexible than TGW for large topologies.  ","version":"Next","tagName":"h3"},{"title":"VPN on EC2 (StrongSwan + Nginx) (~$20–21/month with 1 instance, or ~$40–42/month for HA)​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/es/tutorial/third-party-integration-vpn#vpn-on-ec2-strongswan--nginx-2021month-with-1-instance-or-4042month-for-ha","content":" Significantly lower cost.Higher administration and maintenance complexity (instance management, patches, manual failover).Suitable if total traffic is low and if you have staff to operate/monitor the instance.  ","version":"Next","tagName":"h3"},{"title":"Transit Gateway​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/es/tutorial/third-party-integration-vpn#transit-gateway","content":" Acts as a centralized router that allows interconnection between multiple VPCs, on-premises networks and third-party networks.  VPN connections are established through IPsec tunnels, which can be configured to provide high availability and redundancy (two tunnels per VPN connection are generally configured to achieve automatic failover).    ","version":"Next","tagName":"h2"},{"title":"Cost Analysis​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/es/tutorial/third-party-integration-vpn#cost-analysis","content":" Hypothesis:  3 attachments in the Transit Gateway, corresponding for example to: VPC (Dev)VPN (Prod)VPN (Contingency) 730 hours of monthly usage (24/7).2 GB monthly transfer per attachment, totaling 6 GB monthly.AWS rates (in most regions): $0.09/hour/attachment.$0.002/GB of data transfer.  Costs:  Attachment costs: ~$197.10/monthData transfer cost: ~$0.01/month  Total sum: ~$197.11/month (rounded to ~$197.22/month in the original example).  ","version":"Next","tagName":"h3"},{"title":"Site-to-Site VPN​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/es/tutorial/third-party-integration-vpn#site-to-site-vpn","content":" A Site-to-Site VPN connection offers two VPN tunnels between a virtual private gateway or transit gateway on the AWS side and a customer gateway on the remote side (on-premise).  Two tunnels for automatic failover or maintenance that AWS usually does that could briefly disable one of the tunnels —&gt; Site-to-Site VPN tunnel endpoint replacement      ","version":"Next","tagName":"h2"},{"title":"Cost Analysis​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/es/tutorial/third-party-integration-vpn#cost-analysis-1","content":" Hypothesis:  3 connections (VPN) (equivalent to the 3 &quot;attachments&quot; you mentioned: Dev, Main, Contingency).Each VPN is an AWS-managed Site-to-Site tunnel.Site-to-Site VPN cost: $0.05 per hour per VPN730 hours monthly (24/7).2 GB monthly transfer per VPN.  Costs:  VPN (3 connections): ~$109.50Data transfer (6 GB total): ~$0.54Network Load Balancer: ~$20–25  Total sum: ~$130–135 monthly.  ","version":"Next","tagName":"h3"},{"title":"VPN on EC2​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/es/tutorial/third-party-integration-vpn#vpn-on-ec2","content":" In this solution, an EC2 instance is launched on which StrongSwan is installed to establish IPsec tunnels and Nginx as a proxy (normally to route traffic at the application layer towards an Application Load Balancer or other VPC resources).    ","version":"Next","tagName":"h2"},{"title":"Cost Analysis​","type":1,"pageTitle":"Third Party VPN Integration","url":"/preview-docs/es/tutorial/third-party-integration-vpn#cost-analysis-2","content":" Hypothesis:  3 tunnels (VPN) configured on the same instance (or on two instances for redundancy).EC2 instance of small size, for example, t3.small (with approx. cost $0.02–0.023/h).  Costs:  EC2 + EBS: ~$18–20/month (1 instance)Data transfer: ~$0.54/month  Total sum: ~$20–21/month (In case of 2 instances for HA =&gt; ~$40–42/month.)  Configuration of nginx and ipsec to achieve the connection setup.  nginx.conf  load_module /usr/lib/nginx/modules/ngx_stream_module.so; worker_processes 1; error_log /var/log/nginx/error.log warn; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; access_log /var/log/nginx/access.log main; sendfile on; keepalive_timeout 65; server_tokens off; } stream { server { listen 8180; proxy_pass **&lt;URL-ALB&gt;**; } }   iptables.conf  *mangle :PREROUTING ACCEPT [8165:7991805] :INPUT ACCEPT [7883:7958068] :FORWARD ACCEPT [282:33737] :OUTPUT ACCEPT [5933:572312] :POSTROUTING ACCEPT [6215:606049] COMMIT *nat :PREROUTING ACCEPT [159:9540] :INPUT ACCEPT [159:9540] :OUTPUT ACCEPT [168:10720] :POSTROUTING ACCEPT [168:10720] -A PREROUTING -i eth0 -p tcp -m tcp --dport 2222 -j DNAT --to-destination &lt;IP-BIND&gt;:22 -A PREROUTING -i eth0 -p tcp -m tcp --dport 443 -j DNAT --to-destination &lt;IP-BIND&gt;:443 -A POSTROUTING -p tcp -m tcp --dport 22 -j SNAT --to-source &lt;IP-TUNNEL-BIND&gt; -A POSTROUTING -p tcp -m tcp --dport 443 -j SNAT --to-source &lt;IP-TUNNEL-BIND&gt; COMMIT *filter :INPUT ACCEPT [6016:538920] :FORWARD ACCEPT [123:22565] :OUTPUT ACCEPT [4614:432344] -A FORWARD -d &lt;IP-BIND&gt;/32 -p tcp -m tcp --dport 443 -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT -A FORWARD -d &lt;IP-BIND&gt;/32 -p tcp -m tcp --dport 22 -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT -A FORWARD -d &lt;IP-BIND&gt;/32 -p tcp -m tcp --dport 44301 -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT -A FORWARD -d &lt;IP-BIND&gt;/32 -p tcp -m tcp --dport 22 -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT -A FORWARD -d &lt;IP-BIND&gt;/32 -p tcp -m tcp --dport 8180 -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT COMMIT  ","version":"Next","tagName":"h3"}],"options":{"languages":["en","es"],"indexBaseUrl":true,"id":"default"}}