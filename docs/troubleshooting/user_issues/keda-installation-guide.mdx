---
sidebar_position: 15
title: "Installing KEDA in SleakOps Kubernetes Clusters"
description: "Complete guide to install and configure KEDA for autoscaling workloads in SleakOps clusters"
date: "2025-02-13"
category: "cluster"
tags: ["keda", "autoscaling", "kubernetes", "workload", "scheduler"]
---

import TroubleshootingItem from "@site/src/components/HomepageFeatures/troubleshootingitem";

# Installing KEDA in SleakOps Kubernetes Clusters

**Date:** February 13, 2025  
**Category:** Cluster  
**Tags:** KEDA, Autoscaling, Kubernetes, Workload, Scheduler

## Problem Description

**Context:** Users need to implement advanced autoscaling capabilities in their SleakOps Kubernetes clusters, including the ability to scale workloads to zero and schedule workload scaling based on time or events. KEDA (Kubernetes Event-driven Autoscaling) provides these capabilities but is not natively supported in SleakOps yet.

**Observed Symptoms:**

- Need to manually start/stop workloads to save resources
- Requirement for scheduled scaling (e.g., API services that only run during business hours)
- Lack of event-driven autoscaling capabilities
- Need for cost optimization through workload scheduling

**Relevant Configuration:**

- Platform: SleakOps Kubernetes clusters
- KEDA version: Latest stable (2.11+)
- Kubernetes version: Compatible with SleakOps clusters
- Workload types: Web Services and Workers

**Error Conditions:**

- Manual resource management is time-consuming
- Resources running 24/7 when only needed during specific hours
- No native scheduling capabilities in SleakOps for workload scaling

## Detailed Solution

<TroubleshootingItem id="keda-overview" summary="What is KEDA and why use it?">

KEDA (Kubernetes Event-driven Autoscaling) is a single-purpose and lightweight component that can be added to any Kubernetes cluster. It provides:

- **Scale to Zero**: Scale deployments down to zero replicas when not needed
- **Event-driven Scaling**: Scale based on various metrics and events
- **Cron-based Scaling**: Schedule scaling operations based on time
- **Multiple Scalers**: Support for various data sources (queues, databases, HTTP, etc.)

This is particularly useful for:

- Cost optimization by stopping unused services
- Scheduled workloads (batch jobs, APIs with specific usage patterns)
- Event-driven microservices

</TroubleshootingItem>

<TroubleshootingItem id="installation-helm" summary="Installing KEDA using Helm">

The recommended way to install KEDA in your SleakOps cluster is using Helm:

```bash
# Add the KEDA Helm repository
helm repo add kedacore https://kedacore.github.io/charts
helm repo update

# Install KEDA in the keda namespace
helm install keda kedacore/keda --namespace keda --create-namespace

# Verify the installation
kubectl get pods -n keda
```

Expected output:

```
NAME                                      READY   STATUS    RESTARTS   AGE
keda-admission-webhooks-xxx               1/1     Running   0          2m
keda-operator-xxx                         1/1     Running   0          2m
keda-operator-metrics-apiserver-xxx       1/1     Running   0          2m
```

</TroubleshootingItem>

<TroubleshootingItem id="installation-kubectl" summary="Installing KEDA using kubectl (alternative method)">

Alternatively, you can install KEDA using kubectl:

```bash
# Install KEDA
kubectl apply -f https://github.com/kedacore/keda/releases/download/v2.11.2/keda-2.11.2.yaml

# Verify the installation
kubectl get pods -n keda
```

**Note**: Replace `v2.11.2` with the latest version available.

</TroubleshootingItem>

<TroubleshootingItem id="cron-scaler-example" summary="Configuring Cron-based Scaling for Scheduled Workloads">

To implement scheduled scaling (start/stop workloads at specific times), use the Cron scaler:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: api-service-scheduler
  namespace: your-namespace
spec:
  scaleTargetRef:
    name: your-api-deployment # Replace with your deployment name
  minReplicaCount: 0 # Scale to zero when not needed
  maxReplicaCount: 3 # Maximum replicas during active hours
  triggers:
    - type: cron
      metadata:
        timezone: America/Argentina/Buenos_Aires # Adjust to your timezone
        start: "0 8 * * 1-5" # Start at 8 AM, Monday to Friday
        end: "0 18 * * 1-5" # Stop at 6 PM, Monday to Friday
        desiredReplicas: "2" # Number of replicas during active hours
```

Apply the configuration:

```bash
kubectl apply -f scaled-object.yaml
```

</TroubleshootingItem>

<TroubleshootingItem id="manual-scaling" summary="Manual Start/Stop using KEDA ScaledObjects">

For manual control over workload scaling, you can pause and resume ScaledObjects:

```bash
# Pause scaling (keeps current replica count)
kubectl annotate scaledobject api-service-scheduler autoscaling.keda.sh/paused=true

# Resume scaling
kubectl annotate scaledobject api-service-scheduler autoscaling.keda.sh/paused-

# Scale to zero manually
kubectl patch scaledobject api-service-scheduler --type merge -p '{"spec":{"minReplicaCount":0}}'

# Check ScaledObject status
kubectl get scaledobject -n your-namespace
kubectl describe scaledobject api-service-scheduler
```

You can also create simple ScaledObjects that allow manual scaling to zero:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: manual-scaler
  namespace: your-namespace
spec:
  scaleTargetRef:
    name: your-deployment
  minReplicaCount: 0
  maxReplicaCount: 10
  # No triggers means manual scaling only
```

</TroubleshootingItem>

<TroubleshootingItem id="monitoring-troubleshooting" summary="Monitoring and troubleshooting KEDA">

### Monitoring KEDA Operations

```bash
# Check KEDA operator logs
kubectl logs -n keda -l app.kubernetes.io/name=keda-operator

# Check metrics server logs
kubectl logs -n keda -l app.kubernetes.io/name=keda-operator-metrics-apiserver

# View ScaledObject events
kubectl describe scaledobject <scaledobject-name> -n <namespace>

# Monitor HPA created by KEDA
kubectl get hpa -n <namespace>
```

### Common Issues and Solutions

1. **ScaledObject not creating HPA:**

   - Verify KEDA is running: `kubectl get pods -n keda`
   - Check ScaledObject syntax and indentation
   - Ensure target deployment exists

2. **Cron scaling not working:**

   - Verify timezone configuration
   - Check cron expression syntax
   - Ensure KEDA operator has correct time

3. **Scaling not happening:**
   - Check if the deployment has sufficient resources
   - Verify cluster has enough capacity
   - Review ScaledObject and HPA status

### Best Practices

1. **Resource Management:**

   - Set appropriate resource requests/limits on deployments
   - Monitor resource usage after implementing KEDA

2. **Scheduling:**

   - Use meaningful names for ScaledObjects
   - Document your scaling schedules
   - Test scaling behavior in development first

3. **Monitoring:**
   - Set up alerts for scaling events
   - Monitor application startup times
   - Track resource cost savings

</TroubleshootingItem>

<TroubleshootingItem id="advanced-examples" summary="Advanced KEDA configurations">

### HTTP-based Scaling

Scale based on HTTP traffic:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: http-scaler
spec:
  scaleTargetRef:
    name: web-service
  minReplicaCount: 0
  maxReplicaCount: 10
  triggers:
    - type: prometheus
      metadata:
        serverAddress: http://prometheus:9090
        metricName: http_requests_per_second
        threshold: "10"
        query: rate(http_requests_total[1m])
```

### Queue-based Scaling

Scale based on message queue length:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: queue-scaler
spec:
  scaleTargetRef:
    name: worker-deployment
  minReplicaCount: 0
  maxReplicaCount: 50
  triggers:
    - type: aws-sqs-queue
      metadata:
        queueURL: https://sqs.us-east-1.amazonaws.com/123456789/my-queue
        queueLength: "5"
        awsRegion: "us-east-1"
```

### Multiple Triggers

Combine multiple scaling triggers:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: multi-trigger-scaler
spec:
  scaleTargetRef:
    name: api-service
  minReplicaCount: 1
  maxReplicaCount: 20
  triggers:
    - type: cron
      metadata:
        timezone: UTC
        start: "0 8 * * *"
        end: "0 20 * * *"
        desiredReplicas: "3"
    - type: cpu
      metadata:
        type: Utilization
        value: "70"
```

</TroubleshootingItem>

---

_This FAQ was automatically generated on February 13, 2025 based on a real user query._
