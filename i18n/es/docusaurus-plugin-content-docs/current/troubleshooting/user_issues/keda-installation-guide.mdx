---
sidebar_position: 15
title: "Instalando KEDA en Clústeres de Kubernetes de SleakOps"
description: "Guía completa para instalar y configurar KEDA para el autoescalado de cargas de trabajo en clústeres SleakOps"
date: "2025-02-13"
category: "cluster"
tags: ["keda", "autoescalado", "kubernetes", "carga de trabajo", "programador"]
---

import TroubleshootingItem from "@site/src/components/HomepageFeatures/troubleshootingitem";

# Instalando KEDA en Clústeres de Kubernetes de SleakOps

**Fecha:** 13 de febrero de 2025  
**Categoría:** Clúster  
**Etiquetas:** KEDA, Autoescalado, Kubernetes, Carga de trabajo, Programador

## Descripción del Problema

**Contexto:** Los usuarios necesitan implementar capacidades avanzadas de autoescalado en sus clústeres de Kubernetes de SleakOps, incluyendo la capacidad de escalar cargas de trabajo a cero y programar el escalado de cargas según tiempo o eventos. KEDA (Kubernetes Event-driven Autoscaling) proporciona estas capacidades pero aún no está soportado nativamente en SleakOps.

**Síntomas Observados:**

- Necesidad de iniciar/detener manualmente cargas de trabajo para ahorrar recursos
- Requisito de escalado programado (por ejemplo, servicios API que solo funcionan durante horas laborales)
- Falta de capacidades de autoescalado basado en eventos
- Necesidad de optimización de costos mediante la programación de cargas de trabajo

**Configuración Relevante:**

- Plataforma: Clústeres de Kubernetes de SleakOps
- Versión de KEDA: Estable más reciente (2.11+)
- Versión de Kubernetes: Compatible con clústeres SleakOps
- Tipos de carga de trabajo: Servicios Web y Trabajadores

**Condiciones de Error:**

- La gestión manual de recursos consume mucho tiempo
- Recursos funcionando 24/7 cuando solo se necesitan en horas específicas
- No hay capacidades nativas de programación en SleakOps para el escalado de cargas de trabajo

## Solución Detallada

<TroubleshootingItem id="keda-overview" summary="¿Qué es KEDA y por qué usarlo?">

KEDA (Kubernetes Event-driven Autoscaling) es un componente ligero y de propósito único que se puede agregar a cualquier clúster de Kubernetes. Proporciona:

- **Escalado a Cero**: Escala despliegues a cero réplicas cuando no se necesitan
- **Escalado basado en Eventos**: Escala basado en diversas métricas y eventos
- **Escalado basado en Cron**: Programa operaciones de escalado basadas en tiempo
- **Múltiples Escaladores**: Soporte para varias fuentes de datos (colas, bases de datos, HTTP, etc.)

Esto es particularmente útil para:

- Optimización de costos deteniendo servicios no usados
- Cargas de trabajo programadas (trabajos por lotes, APIs con patrones específicos de uso)
- Microservicios basados en eventos

</TroubleshootingItem>

<TroubleshootingItem id="installation-helm" summary="Instalando KEDA usando Helm">

La forma recomendada para instalar KEDA en tu clúster SleakOps es usando Helm:

```bash
# Añadir el repositorio Helm de KEDA
helm repo add kedacore https://kedacore.github.io/charts
helm repo update

# Instalar KEDA en el namespace keda
helm install keda kedacore/keda --namespace keda --create-namespace

# Verificar la instalación
kubectl get pods -n keda
```

Salida esperada:

```
NAME                                      READY   STATUS    RESTARTS   AGE
keda-admission-webhooks-xxx               1/1     Running   0          2m
keda-operator-xxx                         1/1     Running   0          2m
keda-operator-metrics-apiserver-xxx       1/1     Running   0          2m
```

</TroubleshootingItem>

<TroubleshootingItem id="installation-kubectl" summary="Instalando KEDA usando kubectl (método alternativo)">

Alternativamente, puedes instalar KEDA usando kubectl:

```bash
# Instalar KEDA
kubectl apply -f https://github.com/kedacore/keda/releases/download/v2.11.2/keda-2.11.2.yaml

# Verificar la instalación
kubectl get pods -n keda
```

**Nota**: Reemplaza `v2.11.2` con la versión más reciente disponible.

</TroubleshootingItem>

<TroubleshootingItem id="cron-scaler-example" summary="Configurando escalado basado en Cron para cargas de trabajo programadas">

Para implementar escalado programado (iniciar/detener cargas en horarios específicos), usa el escalador Cron:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: api-service-scheduler
  namespace: tu-namespace
spec:
  scaleTargetRef:
    name: tu-despliegue-api # Reemplaza con el nombre de tu despliegue
  minReplicaCount: 0 # Escalar a cero cuando no se necesite
  maxReplicaCount: 3 # Réplicas máximas durante horas activas
  triggers:
    - type: cron
      metadata:
        timezone: America/Argentina/Buenos_Aires # Ajusta a tu zona horaria
        start: "0 8 * * 1-5" # Iniciar a las 8 AM, lunes a viernes
        end: "0 18 * * 1-5" # Detener a las 6 PM, lunes a viernes
        desiredReplicas: "2" # Número de réplicas durante horas activas
```

Aplica la configuración:

```bash
kubectl apply -f scaled-object.yaml
```

</TroubleshootingItem>

<TroubleshootingItem id="manual-scaling" summary="Inicio/Parada manual usando KEDA ScaledObjects">

Para control manual sobre el escalado de cargas de trabajo
