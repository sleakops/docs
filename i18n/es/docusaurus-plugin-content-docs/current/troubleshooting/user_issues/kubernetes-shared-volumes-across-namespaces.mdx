---
sidebar_position: 3
title: "Volúmenes Compartidos en Kubernetes entre Namespaces"
description: "Solución para compartir volúmenes entre pods en diferentes namespaces y enfoques alternativos"
date: "2025-01-30"
category: "cluster"
tags: ["kubernetes", "volúmenes", "namespaces", "almacenamiento", "s3"]
---

import TroubleshootingItem from "@site/src/components/HomepageFeatures/troubleshootingitem";

# Volúmenes Compartidos en Kubernetes entre Namespaces

**Fecha:** 30 de enero de 2025  
**Categoría:** Clúster  
**Etiquetas:** Kubernetes, Volúmenes, Namespaces, Almacenamiento, S3

## Descripción del Problema

**Contexto:** El usuario necesita compartir datos entre un cronjob que genera archivos y un servicio nginx que los sirve, pero están ejecutándose en diferentes namespaces dentro de un clúster de Kubernetes.

**Síntomas Observados:**

- No se puede montar el mismo volumen en diferentes namespaces
- Necesidad de compartir archivos generados entre el cronjob y el servidor web
- La configuración actual funciona en EC2 con montaje de volumen compartido
- Se busca el equivalente en Kubernetes para acceso compartido a volúmenes

**Configuración Relevante:**

- Plataforma: SleakOps en AWS EKS
- Caso de uso: Cronjob genera archivos, Nginx los sirve
- Configuración actual: EC2 con volumen compartido entre contenedores
- Objetivo: Pods de Kubernetes en diferentes namespaces

**Condiciones de Error:**

- Limitación de Kubernetes: no se puede usar el mismo volumen en diferentes namespaces
- Necesidad de solución alternativa para compartir archivos
- Requisitos de rendimiento para generación de archivos grandes (más de 5GB)

## Solución Detallada

<TroubleshootingItem id="kubernetes-volume-limitation" summary="Entendiendo las limitaciones de volúmenes en Kubernetes">

Kubernetes tiene una limitación fundamental: **el mismo PersistentVolume no puede ser montado por pods en diferentes namespaces**. Esto es por diseño para propósitos de seguridad e aislamiento.

Esto significa que el enfoque actual en EC2 de compartir un volumen entre contenedores no funcionará directamente en Kubernetes cuando los pods estén en diferentes namespaces.

</TroubleshootingItem>

<TroubleshootingItem id="s3-solution" summary="Solución recomendada: Usar S3 como almacenamiento compartido">

El enfoque recomendado es usar **Amazon S3** como almacenamiento intermedio:

### Arquitectura:

1. **Cronjob**: Genera archivos localmente → Los sube a S3
2. **Servicio Nginx**: Descarga archivos desde S3 → Los sirve

### Beneficios:

- Funciona a través de namespaces
- Escalable y confiable
- Rentable para archivos grandes
- Autenticación integrada vía cuentas de servicio de SleakOps

### Ejemplo de configuración:

```yaml
# Configuración del Cronjob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: generador-de-archivos
  namespace: jobs
spec:
  schedule: "0 2 * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: generador
              image: tu-app:latest
              env:
                - name: S3_BUCKET
                  value: "tu-nombre-de-bucket"
                - name: AWS_REGION
                  value: "us-east-1"
              volumeMounts:
                - name: almacenamiento-temporal
                  mountPath: /tmp/files
          volumes:
            - name: almacenamiento-temporal
              emptyDir:
                sizeLimit: 60Gi
```

</TroubleshootingItem>

<TroubleshootingItem id="nodepool-configuration" summary="Configurar nodepool para almacenamiento adecuado">

Para la generación de archivos grandes, configura tu nodepool con suficiente almacenamiento EBS:

### En SleakOps:

1. Ve a **Configuración de Clúster**
2. Selecciona tu **Nodepool**
3. Modifica la **Configuración del Nodo**:
   - **Tamaño del volumen EBS**: 50-60 GB
   - **Tipo de volumen**: gp3 (más rápido y económico)

### Ejemplo de configuración:

```yaml
nodepool_config:
  instance_type: "t3.medium"
  disk_size: 60 # GB
  disk_type: "gp3"
  min_nodes: 1
  max_nodes: 5
```

</TroubleshootingItem>

<TroubleshootingItem id="s3-authentication" summary="Autenticación en S3 con SleakOps">

SleakOps configura automáticamente la autenticación para S3 mediante **cuentas de servicio**. No necesitas gestionar credenciales de AWS manualmente.

### Ejemplo en Java para acceso a S3:

```java
import software.amazon.awssdk.services.s3.S3Client;
import software.amazon.awssdk.regions.Region;
import software.amazon.awssdk.services.s3.model.*;

public class S3FileUploader {
    public static void main(String[] args) {
        // SleakOps maneja la autenticación automáticamente
        S3Client s3 = S3Client.builder()
                               .region(Region.US_EAST_1)
                               .build();

        // Subir archivo a S3
        PutObjectRequest putRequest = PutObjectRequest.builder()
                .bucket("tu-nombre-de-bucket")
                .key("generated-files/data.zip")
                .build();

        s3.putObject(putRequest,
                    RequestBody.fromFile(new File("/tmp/files/data.zip")));
    }
}
```

### Ejemplo en Python:

```python
import boto3
import os

# SleakOps maneja la autenticación vía cuenta de servicio
s3_client = boto3.client('s3')
bucket_name = os.environ['S3_BUCKET']

# Subir archivo generado
s3_client.upload_file(
    '/tmp/files/generated_data.zip',
    bucket_name,
    'generated-files/generated_data.zip'
)
```

</TroubleshootingItem>

<TroubleshootingItem id="nginx-s3-integration" summary="Configurar Nginx para servir archivos desde S3">

Para servir archivos desde S3 a través de Nginx, tienes varias opciones:

### Opción 1: Nginx con proxy a S3

```nginx
server {
    listen 80;
    server_name tu-dominio.com;

    location /files/ {
        proxy_pass https://tu-bucket.s3.amazonaws.com/;
        proxy_set_header Host tu-bucket.s3.amazonaws.com;
        proxy_hide_header x-amz-id-2;
        proxy_hide_header x-amz-request-id;
    }
}
```

### Opción 2: Descargar y servir localmente

```bash
#!/bin/bash
# Script de inicio para el contenedor nginx
aws s3 sync s3://tu-bucket/generated-files/ /usr/share/nginx/html/files/
nginx -g "daemon off;"
```

### Opción 3: Usar hosting estático de sitio web en S3

Habilita el hosting estático en tu bucket S3 y apunta tu dominio directamente a S3.

</TroubleshootingItem>

<TroubleshootingItem id="alternative-solutions" summary="Soluciones alternativas dentro de Kubernetes">

Si debes mantener todo dentro de Kubernetes:

### Opción 1: Mismo namespace

Mueve tanto el cronjob como nginx al mismo namespace para compartir volúmenes.

### Opción 2: NFS o EFS

Usa Amazon EFS (Elastic File System), que puede ser montado a través de namespaces:

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: efs-pv
spec:
  capacity:
    storage: 100Gi
  accessModes:
```
