---
sidebar_position: 15
title: "Instalando KEDA en Clústeres de Kubernetes de SleakOps"
description: "Guía completa para instalar y configurar KEDA para el autoescalado de cargas de trabajo en clústeres SleakOps"
date: "2025-02-13"
category: "cluster"
tags: ["keda", "autoescalado", "kubernetes", "carga de trabajo", "programador"]
---

import TroubleshootingItem from "@site/src/components/HomepageFeatures/troubleshootingitem";

# Instalando KEDA en Clústeres de Kubernetes de SleakOps

**Fecha:** 13 de febrero de 2025  
**Categoría:** Clúster  
**Etiquetas:** KEDA, Autoescalado, Kubernetes, Carga de trabajo, Programador

## Descripción del Problema

**Contexto:** Los usuarios necesitan implementar capacidades avanzadas de autoescalado en sus clústeres de Kubernetes de SleakOps, incluyendo la capacidad de escalar cargas de trabajo a cero y programar el escalado de cargas según tiempo o eventos. KEDA (Kubernetes Event-driven Autoscaling) proporciona estas capacidades pero aún no está soportado nativamente en SleakOps.

**Síntomas Observados:**

- Necesidad de iniciar/detener manualmente cargas de trabajo para ahorrar recursos
- Requisito de escalado programado (por ejemplo, servicios API que solo funcionan durante horas laborales)
- Falta de capacidades de autoescalado basado en eventos
- Necesidad de optimización de costos mediante la programación de cargas de trabajo

**Configuración Relevante:**

- Plataforma: Clústeres de Kubernetes de SleakOps
- Versión de KEDA: Estable más reciente (2.11+)
- Versión de Kubernetes: Compatible con clústeres SleakOps
- Tipos de carga de trabajo: Servicios Web y Trabajadores

**Condiciones de Error:**

- La gestión manual de recursos consume mucho tiempo
- Recursos funcionando 24/7 cuando solo se necesitan en horas específicas
- No hay capacidades nativas de programación en SleakOps para el escalado de cargas de trabajo

## Solución Detallada

<TroubleshootingItem id="keda-overview" summary="¿Qué es KEDA y por qué usarlo?">

KEDA (Kubernetes Event-driven Autoscaling) es un componente ligero y de propósito único que se puede agregar a cualquier clúster de Kubernetes. Proporciona:

- **Escalado a Cero**: Escala despliegues a cero réplicas cuando no se necesitan
- **Escalado basado en Eventos**: Escala basado en diversas métricas y eventos
- **Escalado basado en Cron**: Programa operaciones de escalado basadas en tiempo
- **Múltiples Escaladores**: Soporte para varias fuentes de datos (colas, bases de datos, HTTP, etc.)

Esto es particularmente útil para:

- Optimización de costos deteniendo servicios no usados
- Cargas de trabajo programadas (trabajos por lotes, APIs con patrones específicos de uso)
- Microservicios basados en eventos

</TroubleshootingItem>

<TroubleshootingItem id="installation-helm" summary="Instalando KEDA usando Helm">

La forma recomendada para instalar KEDA en tu clúster SleakOps es usando Helm:

```bash
# Añadir el repositorio Helm de KEDA
helm repo add kedacore https://kedacore.github.io/charts
helm repo update

# Instalar KEDA en el namespace keda
helm install keda kedacore/keda --namespace keda --create-namespace

# Verificar la instalación
kubectl get pods -n keda
```

Salida esperada:

```
NAME                                      READY   STATUS    RESTARTS   AGE
keda-admission-webhooks-xxx               1/1     Running   0          2m
keda-operator-xxx                         1/1     Running   0          2m
keda-operator-metrics-apiserver-xxx       1/1     Running   0          2m
```

</TroubleshootingItem>

<TroubleshootingItem id="installation-kubectl" summary="Instalando KEDA usando kubectl (método alternativo)">

Alternativamente, puedes instalar KEDA usando kubectl:

```bash
# Instalar KEDA
kubectl apply -f https://github.com/kedacore/keda/releases/download/v2.11.2/keda-2.11.2.yaml

# Verificar la instalación
kubectl get pods -n keda
```

**Nota**: Reemplaza `v2.11.2` con la versión más reciente disponible.

</TroubleshootingItem>

<TroubleshootingItem id="cron-scaler-example" summary="Configurando escalado basado en Cron para cargas de trabajo programadas">

Para implementar escalado programado (iniciar/detener cargas en horarios específicos), usa el escalador Cron:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: api-service-scheduler
  namespace: tu-namespace
spec:
  scaleTargetRef:
    name: tu-despliegue-api # Reemplaza con el nombre de tu despliegue
  minReplicaCount: 0 # Escalar a cero cuando no se necesite
  maxReplicaCount: 3 # Réplicas máximas durante horas activas
  triggers:
    - type: cron
      metadata:
        timezone: America/Argentina/Buenos_Aires # Ajusta a tu zona horaria
        start: "0 8 * * 1-5" # Iniciar a las 8 AM, lunes a viernes
        end: "0 18 * * 1-5" # Detener a las 6 PM, lunes a viernes
        desiredReplicas: "2" # Número de réplicas durante horas activas
```

Aplica la configuración:

```bash
kubectl apply -f scaled-object.yaml
```

</TroubleshootingItem>

<TroubleshootingItem id="manual-scaling" summary="Inicio/Parada manual usando KEDA ScaledObjects">

Para control manual sobre el escalado de cargas de trabajo, puedes crear ScaledObjects que puedas activar/desactivar según sea necesario:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: manual-scaler
  namespace: tu-namespace
  annotations:
    autoscaling.keda.sh/paused: "true" # Pausar el escalado inicialmente
spec:
  scaleTargetRef:
    name: tu-despliegue
  minReplicaCount: 0
  maxReplicaCount: 5
  triggers:
    - type: external-push
      metadata:
        scalerAddress: localhost:9090
```

Para controlar manualmente:

```bash
# Pausar el escalado (escalar a cero)
kubectl annotate scaledobject manual-scaler autoscaling.keda.sh/paused=true

# Reanudar el escalado
kubectl annotate scaledobject manual-scaler autoscaling.keda.sh/paused-

# Verificar estado
kubectl get scaledobject manual-scaler -o yaml
```

</TroubleshootingItem>

<TroubleshootingItem id="http-scaler" summary="Escalado basado en tráfico HTTP">

Para escalar basado en el tráfico HTTP entrante, puedes usar el escalador HTTP de KEDA:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: http-scaler
  namespace: tu-namespace
spec:
  scaleTargetRef:
    name: tu-api-service
  minReplicaCount: 0
  maxReplicaCount: 10
  triggers:
    - type: prometheus
      metadata:
        serverAddress: http://prometheus:9090
        metricName: http_requests_per_second
        threshold: '10'
        query: sum(rate(http_requests_total{job="tu-servicio"}[1m]))
```

Esto escalará tu servicio basado en las solicitudes HTTP por segundo.

</TroubleshootingItem>

<TroubleshootingItem id="database-queue-scaler" summary="Escalado basado en colas de base de datos">

Para escalar basado en el tamaño de colas en tu base de datos:

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: queue-processor
  namespace: tu-namespace
spec:
  scaleTargetRef:
    name: worker-deployment
  minReplicaCount: 0
  maxReplicaCount: 20
  triggers:
    - type: postgresql
      metadata:
        connectionFromEnv: DATABASE_URL
        query: "SELECT COUNT(*) FROM job_queue WHERE status = 'pending'"
        targetQueryValue: '5'
```

Esto escalará workers basado en trabajos pendientes en tu cola de base de datos.

</TroubleshootingItem>

<TroubleshootingItem id="monitoring-keda" summary="Monitoreo y solución de problemas de KEDA">

Para monitorear el comportamiento de KEDA:

```bash
# Ver todos los ScaledObjects
kubectl get scaledobjects -A

# Ver detalles de un ScaledObject específico
kubectl describe scaledobject tu-scaler -n tu-namespace

# Ver logs del operador KEDA
kubectl logs -n keda deployment/keda-operator

# Ver métricas de KEDA
kubectl get --raw /apis/external.metrics.k8s.io/v1beta1
```

**Solución de problemas comunes:**

1. **ScaledObject no escala**: Verifica que las métricas estén disponibles
2. **Escalado lento**: Ajusta `pollingInterval` en el trigger
3. **Escalado demasiado agresivo**: Configura `cooldownPeriod`

```yaml
triggers:
  - type: cron
    metadata:
      timezone: America/Argentina/Buenos_Aires
      start: "0 8 * * 1-5"
      end: "0 18 * * 1-5"
      desiredReplicas: "2"
    # Configuraciones adicionales
    pollingInterval: 30  # Verificar cada 30 segundos
    cooldownPeriod: 300  # Esperar 5 minutos antes de escalar hacia abajo
```

</TroubleshootingItem>

<TroubleshootingItem id="cost-optimization" summary="Estrategias de optimización de costos con KEDA">

KEDA puede ayudar significativamente a reducir costos:

**1. Escalado a cero para servicios no críticos:**

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: non-critical-service
spec:
  scaleTargetRef:
    name: analytics-service
  minReplicaCount: 0  # Importante: permite escalado a cero
  maxReplicaCount: 3
  triggers:
    - type: cron
      metadata:
        timezone: America/Argentina/Buenos_Aires
        start: "0 9 * * 1-5"    # 9 AM días laborales
        end: "0 17 * * 1-5"     # 5 PM días laborales
        desiredReplicas: "1"
```

**2. Escalado basado en demanda real:**

```yaml
triggers:
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: active_users
      threshold: '1'
      query: sum(active_users{service="tu-app"})
```

**3. Escalado por lotes durante horas de menor costo:**

```yaml
triggers:
  - type: cron
    metadata:
      timezone: America/Argentina/Buenos_Aires
      start: "0 2 * * *"      # 2 AM (horas de menor costo)
      end: "0 6 * * *"        # 6 AM
      desiredReplicas: "5"    # Más réplicas para procesamiento por lotes
```

**Estimación de ahorro de costos:**

- Servicios 24/7 → Servicios programados: **60-70% de ahorro**
- Escalado manual → Escalado automático: **30-40% de ahorro**
- Escalado basado en demanda real: **40-50% de ahorro**

</TroubleshootingItem>

<TroubleshootingItem id="best-practices" summary="Mejores prácticas para KEDA en SleakOps">

**1. Configuración de recursos para KEDA:**

```yaml
# Configuración recomendada para el operador KEDA
resources:
  limits:
    cpu: 1000m
    memory: 1000Mi
  requests:
    cpu: 100m
    memory: 100Mi
```

**2. Configuración de múltiples triggers:**

```yaml
triggers:
  - type: cron
    metadata:
      timezone: America/Argentina/Buenos_Aires
      start: "0 8 * * 1-5"
      end: "0 18 * * 1-5"
      desiredReplicas: "2"
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: cpu_usage
      threshold: '70'
      query: avg(cpu_usage{service="tu-app"})
```

**3. Configuración de comportamiento de escalado:**

```yaml
behavior:
  scaleDown:
    stabilizationWindowSeconds: 300
    policies:
    - type: Percent
      value: 10
      periodSeconds: 60
  scaleUp:
    stabilizationWindowSeconds: 0
    policies:
    - type: Percent
      value: 100
      periodSeconds: 15
```

**4. Etiquetas y anotaciones recomendadas:**

```yaml
metadata:
  labels:
    app: tu-aplicacion
    environment: produccion
    managed-by: keda
  annotations:
    keda.sh/transfer-hpa-ownership: "true"
    keda.sh/paused: "false"
```

**5. Configuración de seguridad:**

```yaml
# Usar secretos para credenciales sensibles
triggers:
  - type: postgresql
    authenticationRef:
      name: postgresql-secret
    metadata:
      query: "SELECT COUNT(*) FROM jobs WHERE status = 'pending'"
      targetQueryValue: '5'
```

</TroubleshootingItem>

---

_Esta sección de preguntas frecuentes fue generada automáticamente el 13 de febrero de 2025 basada en una consulta real de usuario._
